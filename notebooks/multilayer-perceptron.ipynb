{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Understand the principles behind the creation of the multilayer perceptron\n",
    "2. Identify how the multilayer perceptron overcame many of the limitations of previous models\n",
    "3. Expand understanding of learning via gradient descent methods\n",
    "4. Develop a basic code implementation of the multilayer perceptron in Python\n",
    "5. Be aware of the main limitations of multilayer perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical and theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The origin of the backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks research came close to become an anecdote in the history of cognitive science during the '70s. The majority of researchers in cognitive science and artificial intelligence thought that neural nets were a silly idea, they could not possibly work. Minsky and Papert even provided formal proofs about it 1969. Yet, as any person that has been around science long enough knows, there are plenty of stubborn researchers that will continue paddling against the current in pursue of their own ideas. \n",
    "\n",
    "David Rumelhart first heard about perceptrons and neural nets in 1963 while in graduate school at Stanford. At the time, he was doing research in mathematical psychology, which although it has lots of equations, is a different field, so he did not pay too much attention to neural nets. It wasn't until the early '70s that Rumelhart took neural nets more seriously. He was in pursuit of a more general framework to understand cognition. Mathematical psychology looked too much like a disconnected mosaic of ad-doc formulas for him. By the late '70s, Rumelhart was working at UC San Diego. He and some colleagues formed a study group about neural networks in cognitive science, that eventually evolved into what is known as the **\"Parallel Distributed Processing\" (PDP) research group**. Among the members of that group were Geoffrey Hinton, Terrence Sejnowski, Michael I. Jordan, Jeffrey L. Elman, and others that eventually became prominent researchers in the neural networks and artificial intelligence fields. \n",
    "\n",
    "The original intention of the PDP group was to create a compendium of the most important research on neural networks. Their enterprise eventually evolved into something larger, producing the famous two volumes book where the so-called **\"backpropagation\" algorithm was introduced**, along with other important models and ideas. Although most people today associate the invention of the gradient descent algorithm with Hinton, the person that came up the idea was David Rumelhart, and as in most things in science, it was just a small change to a previous idea. Rumelhart and James McClelland (another young professor at UC San Diego at the time) wanted to train a neural network with multiple layers and **sigmoidal units** instead of threshold units (as in the perceptron) or linear units (as in the ADALINE), but they did not how to train such a model. Rumelhart knew that you could use gradient descent to train networks with linear units, as Widrow and Hoff did, so he thought that he might as well **pretend that sigmoids units were linear units and see what happens**. It worked, but he realized that training the model took too many iterations, so the got discouraged and let the idea aside for a while.\n",
    "\n",
    "Backpropagation remained dormant for a couple of years until Hinton picked it up again. Rumelhart introduced the idea to Hinton, and **Hinton thought it was a terrible idea**. I could not work. He knew that backpropagation could not break the symmetry between weights and it will get stuck in local minima. He was passionate about energy-based systems known as [Boltzmann machines](https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf), which seemed to have nicer mathematical properties. Yet, as he failed to solve more and more problems with Boltzmann machines he decided to try out backpropagation, mostly out of frustration. It worked amazingly well, way better than Boltzmann machines. He got in touch with Rumelhart about their results and both decided to include a backpropagation chapter in the PDP book and published *Nature* paper along with Ronald Williams. The *Nature* paper became highly visible and **the interest in neural networks got reignited for at least the next decade**. And that is how backpropagation was introduced: by a mathematical psychologist with no training in neural nets modeling and a neural net researcher that thought it was a terrible idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcoming limitations and creating advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truth be told, \"multilayer perceptron\" is a terrible name for what Rumelhart, Hinton, and Williams introduced in the mid-'80s. It is a bad name because its most fundamental piece, the *training algorithm*, is completely different from [the one in the perceptron](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Learning-procedure). Therefore, a multilayer perceptron it is not simply \"a perceptron with multiple layers\" as the name suggests. True, it is a network composed of multiple neuron-like processing units but not every neuron-like processing unit is a perceptron. If you were to put together a bunch of Rossenblat's perceptron in sequence, you would obtain something very different from what most people today would call a multilayer perceptron. If anything, the multi-layer perceptron is more similar to the Widrow and Hoff ADALINE, and in fact, Widrow and Hoff did try multi-layer ADALINEs, known as MADALINEs (i.e., many ADALINEs), but they did not incorporate non-linear functions.\n",
    "\n",
    "\n",
    "Now, the main reason for the resurgence of interest in neural networks was that finally someone designed an architecture that could overcome the perceptron and ADALINE limitations: **to solve problems requiring non-linear solutions**. Problems like the famous [XOR (exclusive or)](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) function (to learn more about it, see the \"Limitations\" section in the [\"The Perceptron\"](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) and [\"The ADALINE\"](https://com-cog-book.github.io/com-cog-book/features/adaline.html#ADALINE-limitations) chapters). \n",
    "\n",
    "Further, a side effect of the capacity to use multiple layers of non-linear units is that neural networks can form **complex internal representations of entities**. The perceptron and ADALINE did not have this capacity. They both are linear models, therefore, it doesn't matter how many layers of processing units you concatenate together, the representation learned by the network will be a linear model. You may as well dropped all the extra layers and the network eventually would learn the same solution that with multiple layers (see [Why adding multiple layers of processing units does not work](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Why-adding-multiple-layers-of-processing-units-does-not-work) for an explanation). This capacity is important in so far **complex multi-level representation of phenomena** is -probably- what the human mind does when solving problems in language, perception, learning, etc. \n",
    "\n",
    "Finally, the backpropagation algorithm effectively **automates the so-called \"feature engineering\" process**. If you have ever done data analysis of any kind, you may have come across variables or features that were not in the original data but was **created by transforming or combining other variables**. For instance, you may have variables for income and education, and combine those to create a socio-economic status variable. That variable may have a predictive capacity above and beyond income and education in isolation. With a multilayer neural network with non-linear units trained with backpropagatio such a *transformation process happens automatically* in the intermediate or **\"hidden\" layers of the network**. Those intermediate representations often are hard or impossible to interpret for humans. They may make no sense whatsoever for us but somehow help to solve the pattern recognition problem at hand, so the network will learn that representation. Does this mean that neural nets learn different representations from the human brain? Maybe, maybe not. The problem is that we don't have direct access to the kind of representations learned by the brain either, and a neural net will seldom be trained with the same data that a human brain is trained in real life.\n",
    "\n",
    "The application of the backpropagation algorithm in multilayer neural network architectures was a major breakthrough in the artificial intelligence and cognitive science community, that catalyzed a new generation of research in cognitive science. Nonetheless, it took several decades of advance on computing and data availability before artificial neural networks became the dominant paradigm in the research landscape as it is today. Next, we will explore its mathematical formalization and application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical multilayer perceptron as introduced by Rumelhart, Hinton, and Williams, can be described by:\n",
    "\n",
    "- a *linear function* that aggregates the input values\n",
    "- a *sigmoid function*, also called *activation function*\n",
    "- a *threshold function* for classification process, and an *identity function* for regression problems\n",
    "- a *loss or cost* function that computes the overall error of the network\n",
    "- a *learning procedure* to adjust the weights of the network, i.e., the so-called *backpropagation* algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear aggregation function is the same as in the perceptron and the ADALINE. But, with a couple of differences that change the notation: now we are dealing multiple layers and processing units. The conventional way to represent this is with **linear algebra notation**. This is not a course of linear algebra, reason I won't cover the mathematics in detail. However, I'll introduce enough concepts and notation to understand the fundamental operations involved in the neural network calculation. The most important aspect is to understand what is a *matrix*, a *vector*, and how to *multiply* them together.\n",
    "\n",
    "A **vector** is a collection of *ordered numbers* or *scalars*. If you are familiar with data analysis, a vector is like a column or row in a dataframe. If you are familiar with programming, a vector is like an array or a list. A generic Vector $\\bf{x}$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/vector.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **matrix** is a *collection of vectors* or *lists of numbers*. In data analysis, this is equivalent to a 2-dimensional dataframe. In programming is equivalent to a multidimensional array or a list of lists. A generic matrix $W$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/matrix.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notation, let's look at a simplified example of a network with:\n",
    "- 3 inputs units\n",
    "- 1 hidden layer with 2 units\n",
    "\n",
    "Like the one in **Figure 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/simple-net.svg\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector for our first training example would look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\bf{x=}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 3 input units connecting to hidden 2 units we have 3x2 weights. This is represented with a matrix as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W=\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *output of the linear function equals to the multiplication of the vector $\\bf{x}$ and the matrix $W$*. To perform the multiplication in this case we need to transpose the matrix $W$ to match the number of columns in $W$ with the number of rows in $\\bf{x}$. Transposing means to \"flip\" the columns of $W$ such that the first column becomes the first row, the second column becomes the second row, and so forth. The matrix-vector multiplication equals to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\bf z=} \n",
    "W^T\\times {\\bf x=}\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\bf z=} \n",
    "W^T\\times {\\bf x=}\n",
    "\\begin{bmatrix}\n",
    "x_1w_{11} + x_2w_{12} + x_3w_{13}\\\\\n",
    "x_1w_{21} + x_2w_{22} + x_3w_{23}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_1 \\\\\n",
    "z_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous matrix operation in summation notation equals to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/linear-function-multi-perceptron.svg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $f$ is a function of each element of the vector $\\bf{x}$ and each element of the matrix $W$. The $m$ index identifies the rows in $W^T$ and the rows in $\\bf{z}$. The $n$ index indicates the columns in $W^T$ and the rows in $\\bf{x}$. Notice that we add a $b$ bias term, that has the role to simplify learning a proper threshold for the function. If you are curious about that [read this](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Linear-aggregation-function). In sum, the **linear function is a weighted sum of the inputs plus a bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the $\\bf{z}$ vector becomes an input for the sigmoid function $\\sigma$():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/sigmoid-function-multi-perceptron.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of $\\sigma(z_m)$ is another $m$ dimensional vector $a$, one entry for each unit in the hidden layer like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bf{a}=\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "a_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $a$ stands for \"activation\", which is a common way to refer to the output of hidden units. This sigmoid function \"wrapping\" the outcome of the linear function is commonly called **activation function**. The idea is that a unit gets \"activated\" in more or less the same manner that a neuron gets activated when a sufficiently strong input is received. The selection of a sigmoid is arbitrary. Many different non-linear functions could be selected at this stage in the network, like a [Tanh](https://mathworld.wolfram.com/HyperbolicTangent.html) or a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). Unfortunately, there is no principled way to chose activation functions for hidden layers. It is mostly a matter of trial and error.\n",
    "\n",
    "A nice property of sigmoid functions is they are \"mostly linear\" but they saturate as they approach 1 and 0 in the extremes. **Chart 1** shows the shape of a sigmoid function (blue line) and the point where the gradient is at its maximum (the red line connecting the blue line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-51a15a55061c48e1a9db3bea35a2d4ef\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-51a15a55061c48e1a9db3bea35a2d4ef\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z1\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a1\"}}}], \"data\": {\"name\": \"data-4ce8df9580f59e633b8d399e9190ac6d\"}, \"title\": \"Chart 1\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-4ce8df9580f59e633b8d399e9190ac6d\": [{\"a\": 0.0066928509242848554, \"z\": -5.0, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.007391541344281971, \"z\": -4.9, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.00816257115315989, \"z\": -4.800000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009013298652847815, \"z\": -4.700000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009951801866904308, \"z\": -4.600000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.010986942630593162, \"z\": -4.500000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.012128434984274213, \"z\": -4.400000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.013386917827664744, \"z\": -4.3000000000000025, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.014774031693273017, \"z\": -4.200000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01630249937144089, \"z\": -4.100000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.017986209962091496, \"z\": -4.0000000000000036, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01984030573407743, \"z\": -3.900000000000004, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.021881270936130383, \"z\": -3.8000000000000043, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.024127021417669092, \"z\": -3.7000000000000046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.026596993576865725, \"z\": -3.600000000000005, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.02931223075135617, \"z\": -3.5000000000000053, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03229546469845033, \"z\": -3.4000000000000057, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.035571189272635965, \"z\": -3.300000000000006, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03916572279676412, \"z\": -3.2000000000000064, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.043107254941085846, \"z\": -3.1000000000000068, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.04742587317756646, \"z\": -3.000000000000007, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05215356307841737, \"z\": -2.9000000000000075, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05732417589886832, \"z\": -2.800000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06297335605699601, \"z\": -2.700000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06913842034334627, \"z\": -2.6000000000000085, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.07585818002124294, \"z\": -2.500000000000009, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.08317269649392166, \"z\": -2.4000000000000092, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09112296101485534, \"z\": -2.3000000000000096, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09975048911968425, \"z\": -2.20000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.10909682119561194, \"z\": -2.1000000000000103, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.11920292202211644, \"z\": -2.0000000000000107, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1301084743629966, \"z\": -1.900000000000011, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1418510649004864, \"z\": -1.8000000000000114, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.15446526508353317, \"z\": -1.7000000000000117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.16798161486607383, \"z\": -1.600000000000012, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1824255238063545, \"z\": -1.5000000000000124, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.19781611144141623, \"z\": -1.4000000000000128, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.21416501695743917, \"z\": -1.3000000000000131, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.23147521650098, \"z\": -1.2000000000000135, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.24973989440487981, \"z\": -1.1000000000000139, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.26894142136999233, \"z\": -1.0000000000000142, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.28905049737499305, \"z\": -0.9000000000000146, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3100255188723844, \"z\": -0.8000000000000149, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3318122278318305, \"z\": -0.7000000000000153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.35434369377420094, \"z\": -0.6000000000000156, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3775406687981417, \"z\": -0.500000000000016, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.40131233988754406, \"z\": -0.40000000000001634, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.4255574831883369, \"z\": -0.3000000000000167, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.45016600268751783, \"z\": -0.20000000000001705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.47502081252105566, \"z\": -0.10000000000001741, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.49999999999999556, \"z\": -1.7763568394002505e-14, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5249791874789355, \"z\": 0.09999999999998188, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5498339973124733, \"z\": 0.19999999999998153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5744425168116544, \"z\": 0.29999999999998117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5986876601124473, \"z\": 0.3999999999999808, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.62245933120185, \"z\": 0.49999999999998046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6456563062257908, \"z\": 0.5999999999999801, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6681877721681616, \"z\": 0.6999999999999797, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6899744811276081, \"z\": 0.7999999999999794, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7109495026249997, \"z\": 0.899999999999979, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7310585786300007, \"z\": 0.9999999999999787, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7502601055951135, \"z\": 1.0999999999999783, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7685247834990137, \"z\": 1.199999999999978, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7858349830425548, \"z\": 1.2999999999999776, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8021838885585781, \"z\": 1.3999999999999773, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8175744761936402, \"z\": 1.499999999999977, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8320183851339212, \"z\": 1.5999999999999766, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8455347349164622, \"z\": 1.6999999999999762, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8581489350995093, \"z\": 1.7999999999999758, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8698915256369995, \"z\": 1.8999999999999755, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8807970779778798, \"z\": 1.9999999999999751, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8909031788043846, \"z\": 2.0999999999999748, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9002495108803125, \"z\": 2.1999999999999744, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9088770389851418, \"z\": 2.299999999999974, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9168273035060757, \"z\": 2.3999999999999737, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9241418199787546, \"z\": 2.4999999999999734, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9308615796566515, \"z\": 2.599999999999973, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.937026643943002, \"z\": 2.6999999999999726, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9426758241011297, \"z\": 2.7999999999999723, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.947846436921581, \"z\": 2.899999999999972, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9525741268224319, \"z\": 2.9999999999999716, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9568927450589126, \"z\": 3.0999999999999712, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9608342772032344, \"z\": 3.199999999999971, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9644288107273629, \"z\": 3.2999999999999705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9677045353015485, \"z\": 3.39999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9706877692486428, \"z\": 3.49999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9734030064231335, \"z\": 3.5999999999999694, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.97587297858233, \"z\": 3.699999999999969, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9781187290638689, \"z\": 3.7999999999999687, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9801596942659219, \"z\": 3.8999999999999684, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.982013790037908, \"z\": 3.999999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9836975006285584, \"z\": 4.099999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9852259683067265, \"z\": 4.199999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9866130821723347, \"z\": 4.299999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9878715650157253, \"z\": 4.399999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9890130573694065, \"z\": 4.499999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9900481981330953, \"z\": 4.599999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9909867013471519, \"z\": 4.6999999999999655, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9918374288468399, \"z\": 4.799999999999965, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9926084586557179, \"z\": 4.899999999999965, \"z1\": 0, \"a1\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "z = np.arange(-5.0,5.0, 0.1)\n",
    "a = expit(z)\n",
    "df = pd.DataFrame({\"a\":a, \"z\":z})\n",
    "df[\"z1\"] = 0\n",
    "df[\"a1\"] = 0.5\n",
    "sigmoid = alt.Chart(df).mark_line().encode(x=\"z\", y=\"a\")\n",
    "threshold = alt.Chart(df).mark_rule(color=\"red\").encode(x=\"z1\", y=\"a1\")\n",
    "(sigmoid + threshold).properties(title='Chart 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **binary classification problems** each output unit implements a **threshold function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} =\n",
    "f(a_m)\n",
    "\\begin{cases}\n",
    "+1, & \\text{if } a \\text{ > 0.5} \\\\\n",
    "-1, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **regression problems** (problems that require a real-valued output value like predicting income or test-scores) each output unit implements an **identity function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y}=f(a_m)=a_m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, an identity function returns the same value as the input. It does nothing. The point is that the $a$ is already the output of a linear function, therefore, it is the value that we need for this kind of problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **multiclass classification problems**, we can use a **softmax function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\sigma(a)_i = \\frac{e^{\\beta a_i}}{\\sum_{j=1}^{k}e^{\\beta z_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the **measure of \"goodness\" or \"badness\"** (depending on how you like to see things) of the network performance. This can be a confusing term. People sometimes call it *objective function*, *loss function*, or *error function*. Conventionally, *loss function* usually refers to the measure of error for a *single* training case, *cost function* to the aggregate error for the *entire* dataset, and *objective function* is a more generic term referring to any measure of the overall error in a network. For instance, \"mean squared error\", \"sum of squared error\", and \"binary cross-entropy\" are all *objective functions*. For our purposes, I'll use all those terms interchangeably: they all refer to the measure of performance of the network. \n",
    "\n",
    "Nowadays, you would probably want to use different cost functions for different types of problems. In their original work, Rumelhart, Hinton, and Williams used the **sum of squared errors** defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/cost-function.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All neural networks can be divided into two parts: a **forward propagation phase**, where the information \"flows\" forward to compute predictions and the error; and the **backward propagation phase**, where the *backpropagation algorithm* computes the error derivatives and update the network weights. **Figure 2** illustrate a network with 2 input units, 3 hidden units, and 1 output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 2 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/forward-pass.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *forward propagation* phase involves \"chaining\" all the steps we defined so far: the *linear function*, the *sigmoid function*, and the *threshold function*. Consider the network in **Figure 2**. Let's label the linear function as $\\lambda()$, the sigmoid function as $\\sigma()$, and the threshold function as $\\tau()$. Now, the network in **Figure 2** can be represented as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))\n",
    "$$\n",
    "\n",
    "All neural networks can be represented as a **composition of functions** where each step is nested in the next step. For instance, we can add an extra hidden layer to the network in **Figure 2** by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(3)}(\\lambda^{(3)}(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [ADALINE chapter](https://com-cog-book.github.io/com-cog-book/features/adaline.html#The-ADALINE-error-surface) I introduced the ideas of **searching for a set of weights that minimize the error via gradient descent**, and the difference between **convex and non-convex optimization**. If you have not read that section, I'll encourage you to read that first. Otherwise, the important part is to remember that since we are introducing nonlinearities in the network the error surface of the multilayer perceptron is [non-convex](https://arxiv.org/pdf/1712.07897.pdf). This means that there are multiple \"valleys\" with \"local minima\", along with the \"global minima\", and that backpropagation **is not guaranteed to find the global minima**. Remember that the \"global minima\" is the point where the error (i.e., the value of the cost function) is at its minimum, whereas the \"local minima\" is the point of minimum error for a sub-section of the error surface. **Figure 3** illustrates these concepts on a 3D surface. The vertical axis represents the error of the surface, and the other two axes represent different combinations of weights for the network. In the figure, you can observe how different combinations of weights produce different values of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 3 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/sse-nonconvex.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to **introduce the almighty backpropagation algorithm**. Remember that our goal is to learn **how the error changes as we change the weights of the network by tiny amount** and that the cost function was defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = \\frac{1}{2}\\sum_k(a_k - y_k)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one piece of notation I'll introduce to clarify where in the network are we at each step of the computation. I'll use the superscript $L$ to index the outermost function in the network. For example, $a^{(L)}$ index the last sigmoid activation function at the output layer, $a^{(L-1)}$ index the previous sigmoid activation function at the hidden layer, and $x^{(L-2)}$ index the features in the input layer (which are the only thing in that layer). Think about this as moving from the right at $(L)$ to the left at $(L-2)$ in the computational graph of the network in **Figure 4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for single unit multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, tracing the indices in backpropagation is the most confusing part, so I'll ignore the summation symbol and drop the subscript $k$ to make the math as clear as possible. You can think of this as having a network with a single input unit, a single hidden unit, and a single output unit, as in **Figure 4**. We will first work out backpropagation for this simplified network and then expand for the multi-neuron case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 4 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/single-unit.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole purpose of backpropagation is to answer the following question: **\"How does the error change when we change the weights by a tiny amount?\"** (be aware that I'll use the words \"derivatives\" and \"gradients\" interchangeably).\n",
    "\n",
    "To accomplish this you have to realize the following:\n",
    "\n",
    "1. The error $E$ depends on the value of the sigmoid activation function $a$. \n",
    "2. The value of the sigmoid function activation function $a$ depends on the value of the linear function $z$.\n",
    "3. The value of the linear function $z$ depends on the value of the weights $w$  \n",
    "\n",
    "Therefore, we can trace a change of dependence on the weights. This means we have to answer these three questions in a chain:\n",
    "\n",
    "1. How does the error $E$ change when we change the activation $a$ by a tiny amount  \n",
    "2. How does the activation $a$ change when we change the activation $z$ by a tiny amount  \n",
    "3. How does $z$ change when we change the weights $w$ by a tiny amount\n",
    "\n",
    "Such sequence can be mathematically expressed with the **chain-rule of calculus** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/chain-rule.svg\"  width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No deep knowledge of calculus is needed to understand the chain-rule. In essence, indicates **how to differentiate [composite functions](https://en.wikipedia.org/wiki/Function_composition)**, i.e.,  functions nested inside other functions. If you remember the section above this one, we showed that a multi-layer perceptron can be expressed as a composite function. Very convenient. The rule says that we take the derivative of the outermost function, and multiple by the derivative of the inside function, recursively. That's it.\n",
    "\n",
    "Good. Now, let's differentiate each part of $\\frac{\\partial E}{\\partial w^(L)}$. Let's begin from the outermost part. \n",
    "\n",
    "The derivative of the error with respect to (w.r.t) the sigmoid activation function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial a^{(L)}} = a^{(L)} - y \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the derivative of the sigmoid activation function w.r.t the linear function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} = a^{(L)}(1-a^{(L)}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the derivative of the linear function w.r.t the weights is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial z^{(L)}}{\\partial w^{(L)}} = a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put all the pieces together and replace we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have figured out how the error changes as we change the weight connecting the **hidden layer and the output layer $w^{(L)}$**. Amazing progress. We still need to know how the error changes as we adjust the weight connecting the **input layer and the hidden layer $w^{(L-1)}$**. Fortunately, this is pretty straightforward: we apply the chain-rule again, and again until we get there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}} \\times \\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}  \\times \\frac{\\partial z^{(L-1)}}{\\partial w^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, replacing with the actual derivatives this becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times w^{(L)} \\times a^{(L-1)}(1-a^{(L-1)}) \\times x^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic. There is one tiny piece we haven't mentioned: **the derivative of the error with respect to the bias term $b$**. There are two ways to approach this. One way is to treat the bias as another feature (usually with value 1) and add the corresponding weight to the matrix $W$. In such a case, the derivative of the weight for the bias is calculated along with the weights for the other features in the exact same manner. The other option is to compute the derivative separately as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial b^{(L)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know the values for the first two derivatives. We just need to figure out the derivative for $\\frac{\\partial z^{(L)}}{\\partial b^{(L)}}$. Now, remember that the *slope of $z$ does not depend at all from $b$*, because $b$ is just a constant value added at the end. Therefore, the derivative of the error w.r.t the bias reduces to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very convenient because it means we can reutilize part of the calculation for the derivative of the weights to compute the derivative of the biases.\n",
    "\n",
    "The last missing part is the derivative of the error w.r.t. the bias $b$ in the $(L-1)$ layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}} \\times \\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}  \\times \\frac{\\partial z^{(L-1)}}{\\partial b^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives for each expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times w^{(L)} \\times a^{(L-1)}(1-a^{(L-1)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we can reuse part of the calculation for the derivative of $w^{(L-1)}$ to solve this. Every time we train a neural net wit backpropagation we will need to **compute the derivatives for all the weight and biases as showed before**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for multiple unit multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all neural networks you'll find have more than one neuron. Until now, we have assumed a network with a single neuron per layer. The only difference between the expressions we have used so far and added more units is a couple of **extra indices**. For example, we can use the letter $j$ to index the units in the output layer, the letter $k$ to index the units in the hidden layer, and the letter $i$ to index the units in the input layer. We also need indices for the weights. For any network with multiple units, we will have more weights than units, which means we will need two subscripts to indicate each weight. This is visible in the weight matrix in **Figure 2**. We will index the weights as $w_{\\text{destination-units} \\text{, } \\text{origin-units}}$. For instance, weights in $(L)$ become $w_{jk}$.\n",
    "\n",
    "With all this notation in mind, our original equation for the derivative of the error w.r.t the weights in $(L)$ layer becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}_{jk}} = \\frac{\\partial E_i}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial w^{(L)}_{jk}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}_{jk}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times a^{(L-1)}_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second thing to consider. This time we have to take into account that each **sigmoid activation $a$ from  $(L-1)$ layers impacts the error via multiple pathways** (assuming a network with *multiple output units*). In **Figure 5** this is illustrated by blue and red connections to the output layer. To reflect this, we add a summation symbol and the expression for the derivative of the error w.r.t the sigmoid activation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial a^{(L-1)}_k} = \\sum_{j} \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, considering both the new subscripts and summation for $\\frac{\\partial E}{\\partial a^{(L-1)}_k}$, we can apply the chain-rule one more time to compute the error derivatives for $w$ in $(L-1)$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}_{ki}} = \\left(\\sum_{j} \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\\right)  \\times \\frac{\\partial a^{(L-1)}_k}{\\partial z^{(L-1)}_k} \\times \\frac{\\partial z^{(L-1)}_k}{\\partial w^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives for each expression we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}_{ki}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times w^{(L)}_{jk} \\times a^{(L-1)}_k(1-a^{(L-1)}_k) \\times x^{(L-1)}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the new indices, the derivative for the error w.r.t the bias $b$ becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b_j^{(L)}} = \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial b^{(L)}_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}_j}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, the expression for the bias $b$ at layer $(L-1)$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k} \\times \\frac{\\partial a^{(L-1)}_k}{\\partial z^{(L-1)}_k}  \\times \\frac{\\partial z^{(L-1)}_k}{\\partial b^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times w^{(L)}_{jk} \\times a^{(L-1)}_k(1-a^{(L-1)}_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! **Those are all the pieces for the backpropagation algorithm**. Probably, the hardest part is to track all the indices. To further clarify the notation you can look at the diagram in **Figure 5** that exemplifies where each piece of the equation is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 5 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/backprop.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation weight update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned how to compute the gradients for all the weights and biases. Now we just need to **use the computed gradients to update the weights and biases values**. This is actually when the **learning** happens. We do this by taking a portion of the gradient and substracting that to the current weight and bias value.\n",
    "\n",
    "For the wegiths $w_{jk}$ in the $(L)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{jk}^{L} = w_{jk}^{L} - \\eta \\times \\frac{\\partial E}{\\partial w_{jk}^{L}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the wegiths $w_{ki}$ in the $(L-1)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{ki}^{L-1} = w_{ki}^{L-1} - \\eta \\times \\frac{\\partial E}{\\partial w_{ki}^{L-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bias $b$ in the $(L)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b^{(L)} = b^{(L)} - \\eta \\times \\frac{\\partial E}{\\partial b^{(L)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bias $b$ in the $(L-1)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b^{(L-1)} = b^{(L-1)} - \\eta \\times \\frac{\\partial E}{\\partial b^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\eta$ is the *step size* or *learning rate*. \n",
    "\n",
    "If you are not familiar with the idea of a learning rate, you can review the ADALINE chapter where I briefly explain the concept [here](https://com-cog-book.github.io/com-cog-book/features/adaline.html#Learning-procedure). In brief, a learning rate controls **how fast we descend over the error surface given the computed gradient**. This is important because we want to give steps just large enough to reach the minima of the surface at any point we may be when searching for the weights. You can see a more deep explanation [here](https://en.wikipedia.org/wiki/Learning_rate).\n",
    "\n",
    "I don't know about you but I have to go over several rounds of carefully studying the equations behind backpropagation to finally understand them fully. This may or not be true for you, but I believe the effort pays off as **backpropagation is the engine of every neural network model today**. Regardless, the good news is the modern numerical computation libraries like `NumPy`, `Tensorflow`, and `Pytorch` provide all the necessary methods and abstractions to make the implementation of neural networks and backpropagation relatively easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will **implement a multilayer-perceptron with one hidden layer by translating all our equations into code**. One important thing to consider is that we won't implement all the loops that the summation notation implies. Loops are known for being highly inefficient computationally, so we want to avoid them. Fortunately, we can use **matrix operations to achieve the exact same result**. This means that all the computations will be \"vectorized\". If you are not familiar with [vectorization](https://www.geeksforgeeks.org/vectorization-in-python/) you just need to know that instead of looping over each row in our training dataset we compute the outcome for each row all at once using linear algebra operations. This makes computation in neural networks highly efficient compared to using loops. To do this, I'll only use `NumPy` which is the most popular library for matrix operations and linear algebra in Python.\n",
    "\n",
    "Remember that we need to computer the following operations in order:\n",
    "\n",
    "1. linear function aggregation $z$\n",
    "2. sigmoid function activation $a$\n",
    "3. cost function (error) calculation $E$\n",
    "4. derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L)$ layer\n",
    "5. derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L-1)$ layer\n",
    "6. weight and bias update for the $(L)$ layer\n",
    "7. weight and bias update for the $(L-1)$ layer\n",
    "\n",
    "Those operations over the entire dataset comprise a single \"iteration\" or \"epoch\". Generally, we need to perform multiple repetitions of that sequence to train the weights. That loop can't be avoided unfortunately and will be part of the \"fit\" function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n_features, n_neurons, n_output):\n",
    "    \"\"\"generate initial parameters sampled from an uniform distribution\n",
    "    \n",
    "    Args:\n",
    "        n_features (int): number of feature vectors \n",
    "        n_neurons (int): number of neurons in hidden layer\n",
    "        n_output (int): number of output neurons\n",
    "    \n",
    "    Returns:\n",
    "        parameters dictionary:\n",
    "            W1: weight matrix, shape = [n_features, n_neurons]\n",
    "            b1: bias vector, shape = [1, n_neurons]\n",
    "            W2: weight matrix, shape = [n_neurons, n_output]\n",
    "            b2: bias vector, shape = [1, n_output]\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(100) # for reproducibility\n",
    "    W1 = np.random.uniform(size=(n_features,n_neurons))\n",
    "    b1 = np.random.uniform(size=(1,n_neurons))\n",
    "    W2 = np.random.uniform(size=(n_neurons,n_output))\n",
    "    b2 = np.random.uniform(size=(1,n_output))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation is very sensitive to the initialization of parameters**. For instance, in the process of writing this tutorial I learned that this particular network has a hard time finding a solution if I sample the weights from a normal distribution with mean = 0 and standard deviation = 0.01, but it does much better sampling from a uniform distribution. In any case, it is common practice to initialize the values for the weights and biases to some small values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $z$: linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(W, X, b):\n",
    "    \"\"\"computes net input as dot product\n",
    "    \n",
    "    Args:\n",
    "        W (ndarray): weight matrix\n",
    "        X (ndarray): matrix of features\n",
    "        b (ndarray): vector of biases\n",
    "        \n",
    "    Returns:\n",
    "        Z (ndarray): weighted sum of features\n",
    "        \"\"\"\n",
    "    \n",
    "    return (X @ W)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $a$: sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(Z):\n",
    "    \"\"\"computes sigmoid activation element wise\n",
    "    \n",
    "    Args:\n",
    "        Z (ndarray): weighted sum of features\n",
    "    \n",
    "    Returns: \n",
    "        S (ndarray): neuron activation\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1/(1+np.exp(-Z)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cost (error) function $E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(A, y):\n",
    "    \"\"\"computes squared error\n",
    "    \n",
    "    Args:\n",
    "        A (ndarray): neuron activation\n",
    "        y (ndarray): vector of expected values\n",
    "    \n",
    "    Returns:\n",
    "        E (float): total squared error\"\"\"\n",
    "    \n",
    "    return (np.mean(np.power(A - y,2)))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions $\\hat{y}$ with learned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, W2, b1, b2):\n",
    "    \"\"\"computes predictions with learned parameters\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): matrix of features\n",
    "        W1 (ndarray): weight matrix for the first layer\n",
    "        W2 (ndarray): weight matrix for the second layer\n",
    "        b1 (ndarray): bias vector for the first layer\n",
    "        b2 (ndarray): bias vector for the second layer\n",
    "        \n",
    "    Returns:\n",
    "        d (ndarray): vector of predicted values\n",
    "    \"\"\"\n",
    "    \n",
    "    Z1 = linear_function(W1, X, b1)\n",
    "    S1 = sigmoid_function(Z1)\n",
    "    Z2 = linear_function(W2, S1, b2)\n",
    "    S2 = sigmoid_function(Z2)\n",
    "    return np.where(S2 >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I plan to solve a binary classification problem, we define a threshold function that takes the output of the last sigmoid activation function and returns a 0 or a 1 for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_features=2, n_neurons=3, n_output=1, iterations=10, eta=0.001):\n",
    "    \"\"\"Multi-layer perceptron trained with backpropagation\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): matrix of features\n",
    "        y (ndarray): vector of expected values\n",
    "        n_features (int): number of feature vectors \n",
    "        n_neurons (int): number of neurons in hidden layer\n",
    "        n_output (int): number of output neurons\n",
    "        iterations (int): number of iterations over the training set\n",
    "        eta (float): learning rate\n",
    "        \n",
    "    Returns: \n",
    "        errors (list): list of errors over iterations\n",
    "        param (dic): dictionary of learned parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    ## ~~ Initialize parameters ~~##\n",
    "    param = init_parameters(n_features=n_features, \n",
    "                            n_neurons=n_neurons, \n",
    "                            n_output=n_output)\n",
    "\n",
    "    ## ~~ storage errors after each iteration ~~##\n",
    "    errors = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        \n",
    "        ##~~ Forward-propagation ~~##\n",
    "        \n",
    "        Z1 = linear_function(param['W1'], X, param['b1'])\n",
    "        S1 = sigmoid_function(Z1)\n",
    "        Z2 = linear_function(param['W2'], S1, param['b2'])\n",
    "        S2 = sigmoid_function(Z2)\n",
    "        \n",
    "        ##~~ Error computation ~~##\n",
    "        error = cost_function(S2, y)\n",
    "        errors.append(error)\n",
    "        \n",
    "        ##~~ Backpropagation ~~##\n",
    "        \n",
    "        # update output weights\n",
    "        delta2 = (S2 - y)* S2*(1-S2)\n",
    "        W2_gradients = S1.T @ delta2\n",
    "        param[\"W2\"] = param[\"W2\"] - W2_gradients * eta\n",
    "\n",
    "        # update output bias\n",
    "        param[\"b2\"] = param[\"b2\"] - np.sum(delta2, axis=0, keepdims=True) * eta\n",
    "\n",
    "        # update hidden weights\n",
    "        delta1 = (delta2 @ param[\"W2\"].T )* S1*(1-S1)\n",
    "        W1_gradients = X.T @ delta1 \n",
    "        param[\"W1\"] = param[\"W1\"] - W1_gradients * eta\n",
    "\n",
    "        # update hidden bias\n",
    "        param[\"b1\"] = param[\"b1\"] - np.sum(delta1, axis=0, keepdims=True) * eta\n",
    "        \n",
    "    return errors, param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we put everything together to train the network. The first part of the function initializes the parameters by calling the `init_parameters` function. The loop (`for _ in range(iterations)`) in the second part of the function is where all the action happens:\n",
    "\n",
    "1. the **Forward-propagation** section chains the linear and sigmoid functions to compute the network output.\n",
    "2. the **Error computation** section computes the cost function value after each iteration.\n",
    "3. the **Backpropagation** section does two things:\n",
    "    - computes the gradients for the weights and biases in the $(L)$ and $(L-1)$ layers\n",
    "    - update the weights and biases in the $(L)$ and $(L-1)$ layers\n",
    "4. the `fit` function returns a list of the errors after each iteration and an updated dictionary with the learned weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: solving the XOR problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have read this and previous chapters, you should know by now that one of the problems that brought about the \"demise\" of the interest in neural network models was the infamous XOR (exclusive or) problem. This was just one example of a large class of problems that can't be solved with linear models as the perceptron and ADALINE. As an act of redemption for neural networks from this criticism, we will solve the XOR problem using our implementation of the multilayer-perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first is to generate the targets and features for the XOR problem. **Table 1** shows the matrix of values we need to generate, where $x_1$ and $x_2$ are the features and $y$ the expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1**: Truth Table For XOR Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $x_1$ | $x_2$ | $y$ |\n",
    "|---|---|--------|\n",
    "| 0 | 0 | 0      |\n",
    "| 0 | 1 | 1      |\n",
    "| 1 | 0 | 1      |\n",
    "| 1 | 1 | 0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected values\n",
    "y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "# features\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the network by running 5,000 iterations with a learning rate of $\\eta = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, param = fit(X, y, iterations=5000, eta=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron predictions and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X, param[\"W1\"], param[\"W2\"], param[\"b1\"], param[\"b2\"])\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-59190db2309646e7a355d25ab03e340e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-59190db2309646e7a355d25ab03e340e\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bf9f27abf3b922139836e40e6f41caa1\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"time-step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"errors\"}}, \"title\": \"Chart 2\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-bf9f27abf3b922139836e40e6f41caa1\": [{\"errors\": 0.17037699424952266, \"time-step\": 0}, {\"errors\": 0.16804892560495124, \"time-step\": 1}, {\"errors\": 0.16571393112397487, \"time-step\": 2}, {\"errors\": 0.16338264704264036, \"time-step\": 3}, {\"errors\": 0.1610662579543201, \"time-step\": 4}, {\"errors\": 0.15877627259708382, \"time-step\": 5}, {\"errors\": 0.1565242673859441, \"time-step\": 6}, {\"errors\": 0.1543216087576396, \"time-step\": 7}, {\"errors\": 0.15217916819896438, \"time-step\": 8}, {\"errors\": 0.15010704555098447, \"time-step\": 9}, {\"errors\": 0.14811431648219273, \"time-step\": 10}, {\"errors\": 0.14620881875104452, \"time-step\": 11}, {\"errors\": 0.14439698911305815, \"time-step\": 12}, {\"errors\": 0.1426837587838099, \"time-step\": 13}, {\"errors\": 0.14107251074295576, \"time-step\": 14}, {\"errors\": 0.13956509744306175, \"time-step\": 15}, {\"errors\": 0.13816191324024166, \"time-step\": 16}, {\"errors\": 0.13686201254529293, \"time-step\": 17}, {\"errors\": 0.135663262576654, \"time-step\": 18}, {\"errors\": 0.13456251874975783, \"time-step\": 19}, {\"errors\": 0.13355581104925907, \"time-step\": 20}, {\"errors\": 0.13263853095890948, \"time-step\": 21}, {\"errors\": 0.13180561036029864, \"time-step\": 22}, {\"errors\": 0.131051685942878, \"time-step\": 23}, {\"errors\": 0.13037124482129453, \"time-step\": 24}, {\"errors\": 0.12975874902740797, \"time-step\": 25}, {\"errors\": 0.12920873820454393, \"time-step\": 26}, {\"errors\": 0.1287159111213709, \"time-step\": 27}, {\"errors\": 0.1282751875384727, \"time-step\": 28}, {\"errors\": 0.12788175253641715, \"time-step\": 29}, {\"errors\": 0.12753108570555177, \"time-step\": 30}, {\"errors\": 0.12721897766859502, \"time-step\": 31}, {\"errors\": 0.12694153631952754, \"time-step\": 32}, {\"errors\": 0.12669518497121812, \"time-step\": 33}, {\"errors\": 0.12647665435446334, \"time-step\": 34}, {\"errors\": 0.12628297013687137, \"time-step\": 35}, {\"errors\": 0.12611143735561572, \"time-step\": 36}, {\"errors\": 0.12595962289952356, \"time-step\": 37}, {\"errors\": 0.1258253369426388, \"time-step\": 38}, {\"errors\": 0.12570661402779357, \"time-step\": 39}, {\"errors\": 0.125601694325875, \"time-step\": 40}, {\"errors\": 0.1255090054531816, \"time-step\": 41}, {\"errors\": 0.1254271451129971, \"time-step\": 42}, {\"errors\": 0.12535486473506974, \"time-step\": 43}, {\"errors\": 0.12529105421466827, \"time-step\": 44}, {\"errors\": 0.12523472779797296, \"time-step\": 45}, {\"errors\": 0.12518501111968122, \"time-step\": 46}, {\"errors\": 0.12514112936915028, \"time-step\": 47}, {\"errors\": 0.12510239654081265, \"time-step\": 48}, {\"errors\": 0.12506820571101648, \"time-step\": 49}, {\"errors\": 0.12503802027522573, \"time-step\": 50}, {\"errors\": 0.12501136607533925, \"time-step\": 51}, {\"errors\": 0.12498782434569705, \"time-step\": 52}, {\"errors\": 0.12496702540728763, \"time-step\": 53}, {\"errors\": 0.12494864304210929, \"time-step\": 54}, {\"errors\": 0.1249323894830601, \"time-step\": 55}, {\"errors\": 0.12491801095875943, \"time-step\": 56}, {\"errors\": 0.12490528373705131, \"time-step\": 57}, {\"errors\": 0.12489401061540381, \"time-step\": 58}, {\"errors\": 0.12488401781084196, \"time-step\": 59}, {\"errors\": 0.1248751522063403, \"time-step\": 60}, {\"errors\": 0.12486727891468291, \"time-step\": 61}, {\"errors\": 0.12486027912462828, \"time-step\": 62}, {\"errors\": 0.12485404819777907, \"time-step\": 63}, {\"errors\": 0.12484849398783454, \"time-step\": 64}, {\"errors\": 0.12484353535690637, \"time-step\": 65}, {\"errors\": 0.12483910086630588, \"time-step\": 66}, {\"errors\": 0.12483512762168453, \"time-step\": 67}, {\"errors\": 0.1248315602546366, \"time-step\": 68}, {\"errors\": 0.12482835002487688, \"time-step\": 69}, {\"errors\": 0.12482545402890177, \"time-step\": 70}, {\"errors\": 0.12482283450264597, \"time-step\": 71}, {\"errors\": 0.12482045820708018, \"time-step\": 72}, {\"errors\": 0.1248182958869694, \"time-step\": 73}, {\"errors\": 0.12481632179414603, \"time-step\": 74}, {\"errors\": 0.12481451326765822, \"time-step\": 75}, {\"errors\": 0.12481285036404699, \"time-step\": 76}, {\"errors\": 0.12481131553179806, \"time-step\": 77}, {\"errors\": 0.12480989332471248, \"time-step\": 78}, {\"errors\": 0.12480857014956259, \"time-step\": 79}, {\"errors\": 0.12480733404394578, \"time-step\": 80}, {\"errors\": 0.12480617448073301, \"time-step\": 81}, {\"errors\": 0.12480508219593676, \"time-step\": 82}, {\"errors\": 0.12480404903720019, \"time-step\": 83}, {\"errors\": 0.12480306783044212, \"time-step\": 84}, {\"errors\": 0.12480213226248582, \"time-step\": 85}, {\"errors\": 0.12480123677775917, \"time-step\": 86}, {\"errors\": 0.12480037648738115, \"time-step\": 87}, {\"errors\": 0.12479954708915163, \"time-step\": 88}, {\"errors\": 0.12479874479713798, \"time-step\": 89}, {\"errors\": 0.12479796627970868, \"time-step\": 90}, {\"errors\": 0.12479720860500113, \"time-step\": 91}, {\"errors\": 0.12479646919293283, \"time-step\": 92}, {\"errors\": 0.12479574577297092, \"time-step\": 93}, {\"errors\": 0.12479503634697006, \"time-step\": 94}, {\"errors\": 0.12479433915646981, \"time-step\": 95}, {\"errors\": 0.12479365265391765, \"time-step\": 96}, {\"errors\": 0.12479297547734565, \"time-step\": 97}, {\"errors\": 0.12479230642808714, \"time-step\": 98}, {\"errors\": 0.12479164445116839, \"time-step\": 99}, {\"errors\": 0.12479098861805385, \"time-step\": 100}, {\"errors\": 0.12479033811146312, \"time-step\": 101}, {\"errors\": 0.12478969221201064, \"time-step\": 102}, {\"errors\": 0.12478905028644971, \"time-step\": 103}, {\"errors\": 0.12478841177732727, \"time-step\": 104}, {\"errors\": 0.1247877761938817, \"time-step\": 105}, {\"errors\": 0.12478714310403269, \"time-step\": 106}, {\"errors\": 0.12478651212733347, \"time-step\": 107}, {\"errors\": 0.12478588292876899, \"time-step\": 108}, {\"errors\": 0.12478525521329914, \"time-step\": 109}, {\"errors\": 0.12478462872105672, \"time-step\": 110}, {\"errors\": 0.1247840032231226, \"time-step\": 111}, {\"errors\": 0.12478337851780788, \"time-step\": 112}, {\"errors\": 0.12478275442738253, \"time-step\": 113}, {\"errors\": 0.12478213079519716, \"time-step\": 114}, {\"errors\": 0.12478150748315013, \"time-step\": 115}, {\"errors\": 0.12478088436945906, \"time-step\": 116}, {\"errors\": 0.12478026134669988, \"time-step\": 117}, {\"errors\": 0.12477963832008138, \"time-step\": 118}, {\"errors\": 0.12477901520592714, \"time-step\": 119}, {\"errors\": 0.12477839193033967, \"time-step\": 120}, {\"errors\": 0.12477776842802496, \"time-step\": 121}, {\"errors\": 0.1247771446412583, \"time-step\": 122}, {\"errors\": 0.12477652051897434, \"time-step\": 123}, {\"errors\": 0.1247758960159664, \"time-step\": 124}, {\"errors\": 0.12477527109218191, \"time-step\": 125}, {\"errors\": 0.12477464571210263, \"time-step\": 126}, {\"errors\": 0.12477401984419925, \"time-step\": 127}, {\"errors\": 0.12477339346045138, \"time-step\": 128}, {\"errors\": 0.12477276653592548, \"time-step\": 129}, {\"errors\": 0.1247721390484033, \"time-step\": 130}, {\"errors\": 0.12477151097805492, \"time-step\": 131}, {\"errors\": 0.1247708823071513, \"time-step\": 132}, {\"errors\": 0.12477025301981115, \"time-step\": 133}, {\"errors\": 0.12476962310177833, \"time-step\": 134}, {\"errors\": 0.12476899254022594, \"time-step\": 135}, {\"errors\": 0.1247683613235839, \"time-step\": 136}, {\"errors\": 0.12476772944138759, \"time-step\": 137}, {\"errors\": 0.12476709688414411, \"time-step\": 138}, {\"errors\": 0.12476646364321507, \"time-step\": 139}, {\"errors\": 0.12476582971071333, \"time-step\": 140}, {\"errors\": 0.12476519507941201, \"time-step\": 141}, {\"errors\": 0.12476455974266487, \"time-step\": 142}, {\"errors\": 0.1247639236943355, \"time-step\": 143}, {\"errors\": 0.1247632869287359, \"time-step\": 144}, {\"errors\": 0.12476264944057175, \"time-step\": 145}, {\"errors\": 0.12476201122489476, \"time-step\": 146}, {\"errors\": 0.12476137227706025, \"time-step\": 147}, {\"errors\": 0.12476073259269024, \"time-step\": 148}, {\"errors\": 0.12476009216764103, \"time-step\": 149}, {\"errors\": 0.12475945099797411, \"time-step\": 150}, {\"errors\": 0.12475880907993124, \"time-step\": 151}, {\"errors\": 0.12475816640991215, \"time-step\": 152}, {\"errors\": 0.12475752298445497, \"time-step\": 153}, {\"errors\": 0.12475687880021905, \"time-step\": 154}, {\"errors\": 0.1247562338539699, \"time-step\": 155}, {\"errors\": 0.12475558814256588, \"time-step\": 156}, {\"errors\": 0.12475494166294643, \"time-step\": 157}, {\"errors\": 0.12475429441212191, \"time-step\": 158}, {\"errors\": 0.12475364638716444, \"time-step\": 159}, {\"errors\": 0.12475299758519993, \"time-step\": 160}, {\"errors\": 0.12475234800340114, \"time-step\": 161}, {\"errors\": 0.12475169763898157, \"time-step\": 162}, {\"errors\": 0.12475104648918978, \"time-step\": 163}, {\"errors\": 0.12475039455130497, \"time-step\": 164}, {\"errors\": 0.12474974182263254, \"time-step\": 165}, {\"errors\": 0.12474908830050044, \"time-step\": 166}, {\"errors\": 0.1247484339822561, \"time-step\": 167}, {\"errors\": 0.12474777886526325, \"time-step\": 168}, {\"errors\": 0.12474712294689963, \"time-step\": 169}, {\"errors\": 0.12474646622455492, \"time-step\": 170}, {\"errors\": 0.12474580869562829, \"time-step\": 171}, {\"errors\": 0.12474515035752733, \"time-step\": 172}, {\"errors\": 0.12474449120766598, \"time-step\": 173}, {\"errors\": 0.12474383124346361, \"time-step\": 174}, {\"errors\": 0.12474317046234354, \"time-step\": 175}, {\"errors\": 0.1247425088617323, \"time-step\": 176}, {\"errors\": 0.12474184643905854, \"time-step\": 177}, {\"errors\": 0.12474118319175224, \"time-step\": 178}, {\"errors\": 0.1247405191172441, \"time-step\": 179}, {\"errors\": 0.12473985421296485, \"time-step\": 180}, {\"errors\": 0.1247391884763447, \"time-step\": 181}, {\"errors\": 0.124738521904813, \"time-step\": 182}, {\"errors\": 0.12473785449579752, \"time-step\": 183}, {\"errors\": 0.12473718624672449, \"time-step\": 184}, {\"errors\": 0.12473651715501786, \"time-step\": 185}, {\"errors\": 0.12473584721809922, \"time-step\": 186}, {\"errors\": 0.12473517643338758, \"time-step\": 187}, {\"errors\": 0.12473450479829909, \"time-step\": 188}, {\"errors\": 0.1247338323102467, \"time-step\": 189}, {\"errors\": 0.12473315896664022, \"time-step\": 190}, {\"errors\": 0.12473248476488609, \"time-step\": 191}, {\"errors\": 0.12473180970238706, \"time-step\": 192}, {\"errors\": 0.12473113377654227, \"time-step\": 193}, {\"errors\": 0.1247304569847471, \"time-step\": 194}, {\"errors\": 0.12472977932439301, \"time-step\": 195}, {\"errors\": 0.1247291007928675, \"time-step\": 196}, {\"errors\": 0.12472842138755408, \"time-step\": 197}, {\"errors\": 0.12472774110583196, \"time-step\": 198}, {\"errors\": 0.12472705994507637, \"time-step\": 199}, {\"errors\": 0.12472637790265814, \"time-step\": 200}, {\"errors\": 0.1247256949759439, \"time-step\": 201}, {\"errors\": 0.12472501116229584, \"time-step\": 202}, {\"errors\": 0.12472432645907186, \"time-step\": 203}, {\"errors\": 0.12472364086362539, \"time-step\": 204}, {\"errors\": 0.12472295437330536, \"time-step\": 205}, {\"errors\": 0.12472226698545619, \"time-step\": 206}, {\"errors\": 0.12472157869741789, \"time-step\": 207}, {\"errors\": 0.12472088950652575, \"time-step\": 208}, {\"errors\": 0.12472019941011059, \"time-step\": 209}, {\"errors\": 0.12471950840549856, \"time-step\": 210}, {\"errors\": 0.12471881649001118, \"time-step\": 211}, {\"errors\": 0.12471812366096532, \"time-step\": 212}, {\"errors\": 0.12471742991567318, \"time-step\": 213}, {\"errors\": 0.1247167352514422, \"time-step\": 214}, {\"errors\": 0.1247160396655752, \"time-step\": 215}, {\"errors\": 0.12471534315537008, \"time-step\": 216}, {\"errors\": 0.12471464571812024, \"time-step\": 217}, {\"errors\": 0.12471394735111407, \"time-step\": 218}, {\"errors\": 0.12471324805163522, \"time-step\": 219}, {\"errors\": 0.12471254781696263, \"time-step\": 220}, {\"errors\": 0.12471184664437027, \"time-step\": 221}, {\"errors\": 0.12471114453112736, \"time-step\": 222}, {\"errors\": 0.1247104414744982, \"time-step\": 223}, {\"errors\": 0.12470973747174224, \"time-step\": 224}, {\"errors\": 0.12470903252011403, \"time-step\": 225}, {\"errors\": 0.12470832661686312, \"time-step\": 226}, {\"errors\": 0.12470761975923433, \"time-step\": 227}, {\"errors\": 0.12470691194446733, \"time-step\": 228}, {\"errors\": 0.12470620316979696, \"time-step\": 229}, {\"errors\": 0.12470549343245302, \"time-step\": 230}, {\"errors\": 0.12470478272966037, \"time-step\": 231}, {\"errors\": 0.12470407105863882, \"time-step\": 232}, {\"errors\": 0.12470335841660318, \"time-step\": 233}, {\"errors\": 0.12470264480076318, \"time-step\": 234}, {\"errors\": 0.1247019302083236, \"time-step\": 235}, {\"errors\": 0.12470121463648402, \"time-step\": 236}, {\"errors\": 0.1247004980824391, \"time-step\": 237}, {\"errors\": 0.12469978054337824, \"time-step\": 238}, {\"errors\": 0.1246990620164858, \"time-step\": 239}, {\"errors\": 0.12469834249894106, \"time-step\": 240}, {\"errors\": 0.12469762198791808, \"time-step\": 241}, {\"errors\": 0.12469690048058577, \"time-step\": 242}, {\"errors\": 0.1246961779741079, \"time-step\": 243}, {\"errors\": 0.12469545446564304, \"time-step\": 244}, {\"errors\": 0.12469472995234454, \"time-step\": 245}, {\"errors\": 0.12469400443136056, \"time-step\": 246}, {\"errors\": 0.12469327789983398, \"time-step\": 247}, {\"errors\": 0.12469255035490244, \"time-step\": 248}, {\"errors\": 0.12469182179369839, \"time-step\": 249}, {\"errors\": 0.12469109221334887, \"time-step\": 250}, {\"errors\": 0.12469036161097574, \"time-step\": 251}, {\"errors\": 0.12468962998369545, \"time-step\": 252}, {\"errors\": 0.12468889732861918, \"time-step\": 253}, {\"errors\": 0.12468816364285276, \"time-step\": 254}, {\"errors\": 0.12468742892349664, \"time-step\": 255}, {\"errors\": 0.12468669316764591, \"time-step\": 256}, {\"errors\": 0.12468595637239026, \"time-step\": 257}, {\"errors\": 0.12468521853481399, \"time-step\": 258}, {\"errors\": 0.12468447965199593, \"time-step\": 259}, {\"errors\": 0.12468373972100955, \"time-step\": 260}, {\"errors\": 0.12468299873892277, \"time-step\": 261}, {\"errors\": 0.1246822567027981, \"time-step\": 262}, {\"errors\": 0.12468151360969258, \"time-step\": 263}, {\"errors\": 0.12468076945665768, \"time-step\": 264}, {\"errors\": 0.12468002424073946, \"time-step\": 265}, {\"errors\": 0.12467927795897826, \"time-step\": 266}, {\"errors\": 0.12467853060840908, \"time-step\": 267}, {\"errors\": 0.12467778218606121, \"time-step\": 268}, {\"errors\": 0.12467703268895844, \"time-step\": 269}, {\"errors\": 0.1246762821141189, \"time-step\": 270}, {\"errors\": 0.12467553045855512, \"time-step\": 271}, {\"errors\": 0.12467477771927403, \"time-step\": 272}, {\"errors\": 0.12467402389327689, \"time-step\": 273}, {\"errors\": 0.12467326897755929, \"time-step\": 274}, {\"errors\": 0.12467251296911114, \"time-step\": 275}, {\"errors\": 0.12467175586491666, \"time-step\": 276}, {\"errors\": 0.12467099766195439, \"time-step\": 277}, {\"errors\": 0.12467023835719705, \"time-step\": 278}, {\"errors\": 0.12466947794761171, \"time-step\": 279}, {\"errors\": 0.12466871643015967, \"time-step\": 280}, {\"errors\": 0.12466795380179635, \"time-step\": 281}, {\"errors\": 0.12466719005947147, \"time-step\": 282}, {\"errors\": 0.12466642520012894, \"time-step\": 283}, {\"errors\": 0.1246656592207068, \"time-step\": 284}, {\"errors\": 0.12466489211813722, \"time-step\": 285}, {\"errors\": 0.12466412388934661, \"time-step\": 286}, {\"errors\": 0.1246633545312554, \"time-step\": 287}, {\"errors\": 0.12466258404077818, \"time-step\": 288}, {\"errors\": 0.12466181241482362, \"time-step\": 289}, {\"errors\": 0.1246610396502944, \"time-step\": 290}, {\"errors\": 0.12466026574408742, \"time-step\": 291}, {\"errors\": 0.12465949069309337, \"time-step\": 292}, {\"errors\": 0.1246587144941972, \"time-step\": 293}, {\"errors\": 0.1246579371442777, \"time-step\": 294}, {\"errors\": 0.12465715864020771, \"time-step\": 295}, {\"errors\": 0.12465637897885407, \"time-step\": 296}, {\"errors\": 0.12465559815707752, \"time-step\": 297}, {\"errors\": 0.12465481617173278, \"time-step\": 298}, {\"errors\": 0.12465403301966842, \"time-step\": 299}, {\"errors\": 0.12465324869772701, \"time-step\": 300}, {\"errors\": 0.1246524632027449, \"time-step\": 301}, {\"errors\": 0.12465167653155237, \"time-step\": 302}, {\"errors\": 0.12465088868097363, \"time-step\": 303}, {\"errors\": 0.12465009964782647, \"time-step\": 304}, {\"errors\": 0.12464930942892281, \"time-step\": 305}, {\"errors\": 0.12464851802106812, \"time-step\": 306}, {\"errors\": 0.12464772542106181, \"time-step\": 307}, {\"errors\": 0.12464693162569693, \"time-step\": 308}, {\"errors\": 0.1246461366317604, \"time-step\": 309}, {\"errors\": 0.12464534043603279, \"time-step\": 310}, {\"errors\": 0.1246445430352884, \"time-step\": 311}, {\"errors\": 0.12464374442629522, \"time-step\": 312}, {\"errors\": 0.1246429446058149, \"time-step\": 313}, {\"errors\": 0.12464214357060283, \"time-step\": 314}, {\"errors\": 0.12464134131740792, \"time-step\": 315}, {\"errors\": 0.1246405378429728, \"time-step\": 316}, {\"errors\": 0.12463973314403368, \"time-step\": 317}, {\"errors\": 0.12463892721732032, \"time-step\": 318}, {\"errors\": 0.12463812005955617, \"time-step\": 319}, {\"errors\": 0.12463731166745803, \"time-step\": 320}, {\"errors\": 0.12463650203773641, \"time-step\": 321}, {\"errors\": 0.12463569116709532, \"time-step\": 322}, {\"errors\": 0.12463487905223213, \"time-step\": 323}, {\"errors\": 0.12463406568983793, \"time-step\": 324}, {\"errors\": 0.12463325107659703, \"time-step\": 325}, {\"errors\": 0.1246324352091873, \"time-step\": 326}, {\"errors\": 0.12463161808428008, \"time-step\": 327}, {\"errors\": 0.12463079969854007, \"time-step\": 328}, {\"errors\": 0.12462998004862536, \"time-step\": 329}, {\"errors\": 0.12462915913118736, \"time-step\": 330}, {\"errors\": 0.12462833694287101, \"time-step\": 331}, {\"errors\": 0.1246275134803144, \"time-step\": 332}, {\"errors\": 0.124626688740149, \"time-step\": 333}, {\"errors\": 0.12462586271899967, \"time-step\": 334}, {\"errors\": 0.12462503541348444, \"time-step\": 335}, {\"errors\": 0.12462420682021463, \"time-step\": 336}, {\"errors\": 0.12462337693579484, \"time-step\": 337}, {\"errors\": 0.12462254575682293, \"time-step\": 338}, {\"errors\": 0.12462171327988983, \"time-step\": 339}, {\"errors\": 0.12462087950157982, \"time-step\": 340}, {\"errors\": 0.12462004441847027, \"time-step\": 341}, {\"errors\": 0.12461920802713172, \"time-step\": 342}, {\"errors\": 0.1246183703241279, \"time-step\": 343}, {\"errors\": 0.12461753130601555, \"time-step\": 344}, {\"errors\": 0.12461669096934466, \"time-step\": 345}, {\"errors\": 0.12461584931065806, \"time-step\": 346}, {\"errors\": 0.12461500632649192, \"time-step\": 347}, {\"errors\": 0.12461416201337527, \"time-step\": 348}, {\"errors\": 0.12461331636783027, \"time-step\": 349}, {\"errors\": 0.12461246938637201, \"time-step\": 350}, {\"errors\": 0.12461162106550856, \"time-step\": 351}, {\"errors\": 0.1246107714017411, \"time-step\": 352}, {\"errors\": 0.12460992039156356, \"time-step\": 353}, {\"errors\": 0.12460906803146293, \"time-step\": 354}, {\"errors\": 0.1246082143179191, \"time-step\": 355}, {\"errors\": 0.12460735924740482, \"time-step\": 356}, {\"errors\": 0.12460650281638573, \"time-step\": 357}, {\"errors\": 0.12460564502132031, \"time-step\": 358}, {\"errors\": 0.12460478585865996, \"time-step\": 359}, {\"errors\": 0.1246039253248487, \"time-step\": 360}, {\"errors\": 0.12460306341632359, \"time-step\": 361}, {\"errors\": 0.12460220012951431, \"time-step\": 362}, {\"errors\": 0.12460133546084337, \"time-step\": 363}, {\"errors\": 0.12460046940672602, \"time-step\": 364}, {\"errors\": 0.12459960196357012, \"time-step\": 365}, {\"errors\": 0.12459873312777643, \"time-step\": 366}, {\"errors\": 0.12459786289573818, \"time-step\": 367}, {\"errors\": 0.12459699126384147, \"time-step\": 368}, {\"errors\": 0.1245961182284649, \"time-step\": 369}, {\"errors\": 0.12459524378597972, \"time-step\": 370}, {\"errors\": 0.12459436793274983, \"time-step\": 371}, {\"errors\": 0.12459349066513165, \"time-step\": 372}, {\"errors\": 0.1245926119794743, \"time-step\": 373}, {\"errors\": 0.12459173187211925, \"time-step\": 374}, {\"errors\": 0.12459085033940066, \"time-step\": 375}, {\"errors\": 0.12458996737764516, \"time-step\": 376}, {\"errors\": 0.12458908298317176, \"time-step\": 377}, {\"errors\": 0.12458819715229213, \"time-step\": 378}, {\"errors\": 0.12458730988131023, \"time-step\": 379}, {\"errors\": 0.12458642116652249, \"time-step\": 380}, {\"errors\": 0.12458553100421779, \"time-step\": 381}, {\"errors\": 0.1245846393906774, \"time-step\": 382}, {\"errors\": 0.12458374632217488, \"time-step\": 383}, {\"errors\": 0.12458285179497625, \"time-step\": 384}, {\"errors\": 0.12458195580533973, \"time-step\": 385}, {\"errors\": 0.12458105834951595, \"time-step\": 386}, {\"errors\": 0.12458015942374785, \"time-step\": 387}, {\"errors\": 0.1245792590242705, \"time-step\": 388}, {\"errors\": 0.12457835714731141, \"time-step\": 389}, {\"errors\": 0.12457745378909016, \"time-step\": 390}, {\"errors\": 0.12457654894581861, \"time-step\": 391}, {\"errors\": 0.1245756426137008, \"time-step\": 392}, {\"errors\": 0.12457473478893293, \"time-step\": 393}, {\"errors\": 0.1245738254677034, \"time-step\": 394}, {\"errors\": 0.1245729146461926, \"time-step\": 395}, {\"errors\": 0.12457200232057325, \"time-step\": 396}, {\"errors\": 0.1245710884870099, \"time-step\": 397}, {\"errors\": 0.12457017314165941, \"time-step\": 398}, {\"errors\": 0.12456925628067048, \"time-step\": 399}, {\"errors\": 0.12456833790018398, \"time-step\": 400}, {\"errors\": 0.12456741799633275, \"time-step\": 401}, {\"errors\": 0.12456649656524152, \"time-step\": 402}, {\"errors\": 0.1245655736030272, \"time-step\": 403}, {\"errors\": 0.12456464910579837, \"time-step\": 404}, {\"errors\": 0.12456372306965577, \"time-step\": 405}, {\"errors\": 0.12456279549069188, \"time-step\": 406}, {\"errors\": 0.12456186636499118, \"time-step\": 407}, {\"errors\": 0.12456093568862993, \"time-step\": 408}, {\"errors\": 0.12456000345767625, \"time-step\": 409}, {\"errors\": 0.12455906966819008, \"time-step\": 410}, {\"errors\": 0.1245581343162232, \"time-step\": 411}, {\"errors\": 0.12455719739781912, \"time-step\": 412}, {\"errors\": 0.12455625890901309, \"time-step\": 413}, {\"errors\": 0.12455531884583214, \"time-step\": 414}, {\"errors\": 0.12455437720429503, \"time-step\": 415}, {\"errors\": 0.12455343398041216, \"time-step\": 416}, {\"errors\": 0.12455248917018558, \"time-step\": 417}, {\"errors\": 0.12455154276960914, \"time-step\": 418}, {\"errors\": 0.12455059477466808, \"time-step\": 419}, {\"errors\": 0.12454964518133951, \"time-step\": 420}, {\"errors\": 0.12454869398559192, \"time-step\": 421}, {\"errors\": 0.12454774118338546, \"time-step\": 422}, {\"errors\": 0.12454678677067182, \"time-step\": 423}, {\"errors\": 0.12454583074339425, \"time-step\": 424}, {\"errors\": 0.12454487309748738, \"time-step\": 425}, {\"errors\": 0.12454391382887742, \"time-step\": 426}, {\"errors\": 0.12454295293348205, \"time-step\": 427}, {\"errors\": 0.12454199040721031, \"time-step\": 428}, {\"errors\": 0.12454102624596274, \"time-step\": 429}, {\"errors\": 0.12454006044563119, \"time-step\": 430}, {\"errors\": 0.12453909300209892, \"time-step\": 431}, {\"errors\": 0.12453812391124061, \"time-step\": 432}, {\"errors\": 0.12453715316892214, \"time-step\": 433}, {\"errors\": 0.12453618077100079, \"time-step\": 434}, {\"errors\": 0.1245352067133251, \"time-step\": 435}, {\"errors\": 0.12453423099173483, \"time-step\": 436}, {\"errors\": 0.12453325360206105, \"time-step\": 437}, {\"errors\": 0.12453227454012605, \"time-step\": 438}, {\"errors\": 0.12453129380174327, \"time-step\": 439}, {\"errors\": 0.12453031138271733, \"time-step\": 440}, {\"errors\": 0.12452932727884403, \"time-step\": 441}, {\"errors\": 0.12452834148591027, \"time-step\": 442}, {\"errors\": 0.12452735399969411, \"time-step\": 443}, {\"errors\": 0.12452636481596466, \"time-step\": 444}, {\"errors\": 0.12452537393048205, \"time-step\": 445}, {\"errors\": 0.1245243813389976, \"time-step\": 446}, {\"errors\": 0.12452338703725346, \"time-step\": 447}, {\"errors\": 0.12452239102098298, \"time-step\": 448}, {\"errors\": 0.12452139328591028, \"time-step\": 449}, {\"errors\": 0.12452039382775057, \"time-step\": 450}, {\"errors\": 0.12451939264220994, \"time-step\": 451}, {\"errors\": 0.12451838972498544, \"time-step\": 452}, {\"errors\": 0.12451738507176492, \"time-step\": 453}, {\"errors\": 0.12451637867822721, \"time-step\": 454}, {\"errors\": 0.12451537054004178, \"time-step\": 455}, {\"errors\": 0.1245143606528692, \"time-step\": 456}, {\"errors\": 0.12451334901236058, \"time-step\": 457}, {\"errors\": 0.12451233561415798, \"time-step\": 458}, {\"errors\": 0.12451132045389407, \"time-step\": 459}, {\"errors\": 0.12451030352719239, \"time-step\": 460}, {\"errors\": 0.12450928482966706, \"time-step\": 461}, {\"errors\": 0.12450826435692293, \"time-step\": 462}, {\"errors\": 0.12450724210455552, \"time-step\": 463}, {\"errors\": 0.12450621806815096, \"time-step\": 464}, {\"errors\": 0.12450519224328604, \"time-step\": 465}, {\"errors\": 0.1245041646255281, \"time-step\": 466}, {\"errors\": 0.12450313521043506, \"time-step\": 467}, {\"errors\": 0.12450210399355532, \"time-step\": 468}, {\"errors\": 0.12450107097042791, \"time-step\": 469}, {\"errors\": 0.12450003613658228, \"time-step\": 470}, {\"errors\": 0.1244989994875384, \"time-step\": 471}, {\"errors\": 0.12449796101880664, \"time-step\": 472}, {\"errors\": 0.12449692072588783, \"time-step\": 473}, {\"errors\": 0.12449587860427322, \"time-step\": 474}, {\"errors\": 0.12449483464944443, \"time-step\": 475}, {\"errors\": 0.12449378885687337, \"time-step\": 476}, {\"errors\": 0.1244927412220224, \"time-step\": 477}, {\"errors\": 0.12449169174034408, \"time-step\": 478}, {\"errors\": 0.12449064040728129, \"time-step\": 479}, {\"errors\": 0.12448958721826725, \"time-step\": 480}, {\"errors\": 0.12448853216872531, \"time-step\": 481}, {\"errors\": 0.12448747525406909, \"time-step\": 482}, {\"errors\": 0.12448641646970243, \"time-step\": 483}, {\"errors\": 0.12448535581101924, \"time-step\": 484}, {\"errors\": 0.12448429327340366, \"time-step\": 485}, {\"errors\": 0.12448322885222995, \"time-step\": 486}, {\"errors\": 0.12448216254286237, \"time-step\": 487}, {\"errors\": 0.12448109434065541, \"time-step\": 488}, {\"errors\": 0.12448002424095342, \"time-step\": 489}, {\"errors\": 0.12447895223909099, \"time-step\": 490}, {\"errors\": 0.1244778783303925, \"time-step\": 491}, {\"errors\": 0.12447680251017246, \"time-step\": 492}, {\"errors\": 0.12447572477373524, \"time-step\": 493}, {\"errors\": 0.12447464511637518, \"time-step\": 494}, {\"errors\": 0.12447356353337649, \"time-step\": 495}, {\"errors\": 0.12447248002001336, \"time-step\": 496}, {\"errors\": 0.12447139457154965, \"time-step\": 497}, {\"errors\": 0.12447030718323923, \"time-step\": 498}, {\"errors\": 0.12446921785032572, \"time-step\": 499}, {\"errors\": 0.12446812656804243, \"time-step\": 500}, {\"errors\": 0.12446703333161255, \"time-step\": 501}, {\"errors\": 0.12446593813624893, \"time-step\": 502}, {\"errors\": 0.12446484097715416, \"time-step\": 503}, {\"errors\": 0.12446374184952053, \"time-step\": 504}, {\"errors\": 0.12446264074852995, \"time-step\": 505}, {\"errors\": 0.12446153766935397, \"time-step\": 506}, {\"errors\": 0.12446043260715378, \"time-step\": 507}, {\"errors\": 0.12445932555708011, \"time-step\": 508}, {\"errors\": 0.1244582165142733, \"time-step\": 509}, {\"errors\": 0.12445710547386316, \"time-step\": 510}, {\"errors\": 0.12445599243096903, \"time-step\": 511}, {\"errors\": 0.12445487738069982, \"time-step\": 512}, {\"errors\": 0.1244537603181538, \"time-step\": 513}, {\"errors\": 0.12445264123841869, \"time-step\": 514}, {\"errors\": 0.12445152013657165, \"time-step\": 515}, {\"errors\": 0.12445039700767922, \"time-step\": 516}, {\"errors\": 0.1244492718467973, \"time-step\": 517}, {\"errors\": 0.12444814464897105, \"time-step\": 518}, {\"errors\": 0.12444701540923511, \"time-step\": 519}, {\"errors\": 0.12444588412261318, \"time-step\": 520}, {\"errors\": 0.12444475078411843, \"time-step\": 521}, {\"errors\": 0.12444361538875312, \"time-step\": 522}, {\"errors\": 0.1244424779315088, \"time-step\": 523}, {\"errors\": 0.12444133840736611, \"time-step\": 524}, {\"errors\": 0.12444019681129499, \"time-step\": 525}, {\"errors\": 0.12443905313825433, \"time-step\": 526}, {\"errors\": 0.12443790738319231, \"time-step\": 527}, {\"errors\": 0.12443675954104608, \"time-step\": 528}, {\"errors\": 0.12443560960674184, \"time-step\": 529}, {\"errors\": 0.12443445757519486, \"time-step\": 530}, {\"errors\": 0.12443330344130941, \"time-step\": 531}, {\"errors\": 0.1244321471999787, \"time-step\": 532}, {\"errors\": 0.12443098884608494, \"time-step\": 533}, {\"errors\": 0.12442982837449926, \"time-step\": 534}, {\"errors\": 0.12442866578008158, \"time-step\": 535}, {\"errors\": 0.12442750105768087, \"time-step\": 536}, {\"errors\": 0.12442633420213486, \"time-step\": 537}, {\"errors\": 0.12442516520827004, \"time-step\": 538}, {\"errors\": 0.12442399407090182, \"time-step\": 539}, {\"errors\": 0.12442282078483427, \"time-step\": 540}, {\"errors\": 0.1244216453448603, \"time-step\": 541}, {\"errors\": 0.12442046774576145, \"time-step\": 542}, {\"errors\": 0.124419287982308, \"time-step\": 543}, {\"errors\": 0.12441810604925889, \"time-step\": 544}, {\"errors\": 0.12441692194136164, \"time-step\": 545}, {\"errors\": 0.12441573565335245, \"time-step\": 546}, {\"errors\": 0.1244145471799561, \"time-step\": 547}, {\"errors\": 0.12441335651588598, \"time-step\": 548}, {\"errors\": 0.12441216365584382, \"time-step\": 549}, {\"errors\": 0.12441096859452, \"time-step\": 550}, {\"errors\": 0.1244097713265934, \"time-step\": 551}, {\"errors\": 0.12440857184673126, \"time-step\": 552}, {\"errors\": 0.12440737014958939, \"time-step\": 553}, {\"errors\": 0.12440616622981182, \"time-step\": 554}, {\"errors\": 0.12440496008203103, \"time-step\": 555}, {\"errors\": 0.12440375170086784, \"time-step\": 556}, {\"errors\": 0.12440254108093148, \"time-step\": 557}, {\"errors\": 0.12440132821681929, \"time-step\": 558}, {\"errors\": 0.12440011310311704, \"time-step\": 559}, {\"errors\": 0.12439889573439859, \"time-step\": 560}, {\"errors\": 0.12439767610522617, \"time-step\": 561}, {\"errors\": 0.12439645421015011, \"time-step\": 562}, {\"errors\": 0.12439523004370878, \"time-step\": 563}, {\"errors\": 0.12439400360042893, \"time-step\": 564}, {\"errors\": 0.12439277487482517, \"time-step\": 565}, {\"errors\": 0.12439154386140033, \"time-step\": 566}, {\"errors\": 0.12439031055464528, \"time-step\": 567}, {\"errors\": 0.12438907494903882, \"time-step\": 568}, {\"errors\": 0.12438783703904785, \"time-step\": 569}, {\"errors\": 0.12438659681912709, \"time-step\": 570}, {\"errors\": 0.12438535428371934, \"time-step\": 571}, {\"errors\": 0.12438410942725525, \"time-step\": 572}, {\"errors\": 0.1243828622441534, \"time-step\": 573}, {\"errors\": 0.1243816127288201, \"time-step\": 574}, {\"errors\": 0.12438036087564959, \"time-step\": 575}, {\"errors\": 0.12437910667902394, \"time-step\": 576}, {\"errors\": 0.12437785013331286, \"time-step\": 577}, {\"errors\": 0.1243765912328739, \"time-step\": 578}, {\"errors\": 0.1243753299720523, \"time-step\": 579}, {\"errors\": 0.12437406634518107, \"time-step\": 580}, {\"errors\": 0.12437280034658066, \"time-step\": 581}, {\"errors\": 0.12437153197055939, \"time-step\": 582}, {\"errors\": 0.12437026121141304, \"time-step\": 583}, {\"errors\": 0.12436898806342502, \"time-step\": 584}, {\"errors\": 0.12436771252086626, \"time-step\": 585}, {\"errors\": 0.12436643457799522, \"time-step\": 586}, {\"errors\": 0.12436515422905792, \"time-step\": 587}, {\"errors\": 0.1243638714682877, \"time-step\": 588}, {\"errors\": 0.1243625862899054, \"time-step\": 589}, {\"errors\": 0.12436129868811935, \"time-step\": 590}, {\"errors\": 0.12436000865712513, \"time-step\": 591}, {\"errors\": 0.12435871619110574, \"time-step\": 592}, {\"errors\": 0.12435742128423144, \"time-step\": 593}, {\"errors\": 0.1243561239306599, \"time-step\": 594}, {\"errors\": 0.12435482412453588, \"time-step\": 595}, {\"errors\": 0.12435352185999154, \"time-step\": 596}, {\"errors\": 0.12435221713114616, \"time-step\": 597}, {\"errors\": 0.12435090993210622, \"time-step\": 598}, {\"errors\": 0.12434960025696529, \"time-step\": 599}, {\"errors\": 0.12434828809980422, \"time-step\": 600}, {\"errors\": 0.1243469734546907, \"time-step\": 601}, {\"errors\": 0.12434565631567975, \"time-step\": 602}, {\"errors\": 0.12434433667681317, \"time-step\": 603}, {\"errors\": 0.12434301453212002, \"time-step\": 604}, {\"errors\": 0.1243416898756161, \"time-step\": 605}, {\"errors\": 0.1243403627013043, \"time-step\": 606}, {\"errors\": 0.12433903300317442, \"time-step\": 607}, {\"errors\": 0.12433770077520306, \"time-step\": 608}, {\"errors\": 0.12433636601135375, \"time-step\": 609}, {\"errors\": 0.12433502870557686, \"time-step\": 610}, {\"errors\": 0.12433368885180945, \"time-step\": 611}, {\"errors\": 0.12433234644397556, \"time-step\": 612}, {\"errors\": 0.12433100147598575, \"time-step\": 613}, {\"errors\": 0.12432965394173737, \"time-step\": 614}, {\"errors\": 0.12432830383511453, \"time-step\": 615}, {\"errors\": 0.12432695114998785, \"time-step\": 616}, {\"errors\": 0.12432559588021477, \"time-step\": 617}, {\"errors\": 0.12432423801963907, \"time-step\": 618}, {\"errors\": 0.12432287756209134, \"time-step\": 619}, {\"errors\": 0.12432151450138854, \"time-step\": 620}, {\"errors\": 0.12432014883133415, \"time-step\": 621}, {\"errors\": 0.12431878054571824, \"time-step\": 622}, {\"errors\": 0.1243174096383172, \"time-step\": 623}, {\"errors\": 0.12431603610289388, \"time-step\": 624}, {\"errors\": 0.12431465993319751, \"time-step\": 625}, {\"errors\": 0.12431328112296369, \"time-step\": 626}, {\"errors\": 0.12431189966591438, \"time-step\": 627}, {\"errors\": 0.1243105155557577, \"time-step\": 628}, {\"errors\": 0.1243091287861882, \"time-step\": 629}, {\"errors\": 0.12430773935088657, \"time-step\": 630}, {\"errors\": 0.12430634724351966, \"time-step\": 631}, {\"errors\": 0.12430495245774065, \"time-step\": 632}, {\"errors\": 0.12430355498718876, \"time-step\": 633}, {\"errors\": 0.12430215482548926, \"time-step\": 634}, {\"errors\": 0.12430075196625362, \"time-step\": 635}, {\"errors\": 0.12429934640307935, \"time-step\": 636}, {\"errors\": 0.12429793812954992, \"time-step\": 637}, {\"errors\": 0.12429652713923478, \"time-step\": 638}, {\"errors\": 0.1242951134256895, \"time-step\": 639}, {\"errors\": 0.12429369698245535, \"time-step\": 640}, {\"errors\": 0.12429227780305968, \"time-step\": 641}, {\"errors\": 0.12429085588101563, \"time-step\": 642}, {\"errors\": 0.1242894312098222, \"time-step\": 643}, {\"errors\": 0.12428800378296415, \"time-step\": 644}, {\"errors\": 0.1242865735939121, \"time-step\": 645}, {\"errors\": 0.12428514063612232, \"time-step\": 646}, {\"errors\": 0.12428370490303696, \"time-step\": 647}, {\"errors\": 0.12428226638808362, \"time-step\": 648}, {\"errors\": 0.12428082508467572, \"time-step\": 649}, {\"errors\": 0.12427938098621227, \"time-step\": 650}, {\"errors\": 0.12427793408607785, \"time-step\": 651}, {\"errors\": 0.12427648437764258, \"time-step\": 652}, {\"errors\": 0.12427503185426217, \"time-step\": 653}, {\"errors\": 0.1242735765092778, \"time-step\": 654}, {\"errors\": 0.12427211833601604, \"time-step\": 655}, {\"errors\": 0.12427065732778902, \"time-step\": 656}, {\"errors\": 0.12426919347789422, \"time-step\": 657}, {\"errors\": 0.12426772677961447, \"time-step\": 658}, {\"errors\": 0.12426625722621795, \"time-step\": 659}, {\"errors\": 0.12426478481095818, \"time-step\": 660}, {\"errors\": 0.12426330952707393, \"time-step\": 661}, {\"errors\": 0.12426183136778918, \"time-step\": 662}, {\"errors\": 0.1242603503263132, \"time-step\": 663}, {\"errors\": 0.12425886639584037, \"time-step\": 664}, {\"errors\": 0.12425737956955032, \"time-step\": 665}, {\"errors\": 0.12425588984060772, \"time-step\": 666}, {\"errors\": 0.1242543972021623, \"time-step\": 667}, {\"errors\": 0.12425290164734892, \"time-step\": 668}, {\"errors\": 0.12425140316928743, \"time-step\": 669}, {\"errors\": 0.1242499017610826, \"time-step\": 670}, {\"errors\": 0.12424839741582433, \"time-step\": 671}, {\"errors\": 0.12424689012658734, \"time-step\": 672}, {\"errors\": 0.12424537988643114, \"time-step\": 673}, {\"errors\": 0.12424386668840035, \"time-step\": 674}, {\"errors\": 0.12424235052552418, \"time-step\": 675}, {\"errors\": 0.12424083139081687, \"time-step\": 676}, {\"errors\": 0.12423930927727718, \"time-step\": 677}, {\"errors\": 0.12423778417788875, \"time-step\": 678}, {\"errors\": 0.12423625608561992, \"time-step\": 679}, {\"errors\": 0.12423472499342367, \"time-step\": 680}, {\"errors\": 0.12423319089423762, \"time-step\": 681}, {\"errors\": 0.124231653780984, \"time-step\": 682}, {\"errors\": 0.12423011364656955, \"time-step\": 683}, {\"errors\": 0.12422857048388568, \"time-step\": 684}, {\"errors\": 0.1242270242858082, \"time-step\": 685}, {\"errors\": 0.1242254750451974, \"time-step\": 686}, {\"errors\": 0.12422392275489808, \"time-step\": 687}, {\"errors\": 0.12422236740773938, \"time-step\": 688}, {\"errors\": 0.12422080899653484, \"time-step\": 689}, {\"errors\": 0.12421924751408231, \"time-step\": 690}, {\"errors\": 0.12421768295316404, \"time-step\": 691}, {\"errors\": 0.12421611530654644, \"time-step\": 692}, {\"errors\": 0.12421454456698025, \"time-step\": 693}, {\"errors\": 0.12421297072720038, \"time-step\": 694}, {\"errors\": 0.1242113937799259, \"time-step\": 695}, {\"errors\": 0.1242098137178601, \"time-step\": 696}, {\"errors\": 0.1242082305336903, \"time-step\": 697}, {\"errors\": 0.12420664422008794, \"time-step\": 698}, {\"errors\": 0.12420505476970845, \"time-step\": 699}, {\"errors\": 0.12420346217519138, \"time-step\": 700}, {\"errors\": 0.12420186642916016, \"time-step\": 701}, {\"errors\": 0.12420026752422218, \"time-step\": 702}, {\"errors\": 0.12419866545296876, \"time-step\": 703}, {\"errors\": 0.12419706020797514, \"time-step\": 704}, {\"errors\": 0.12419545178180029, \"time-step\": 705}, {\"errors\": 0.12419384016698712, \"time-step\": 706}, {\"errors\": 0.1241922253560622, \"time-step\": 707}, {\"errors\": 0.12419060734153588, \"time-step\": 708}, {\"errors\": 0.12418898611590232, \"time-step\": 709}, {\"errors\": 0.12418736167163918, \"time-step\": 710}, {\"errors\": 0.1241857340012079, \"time-step\": 711}, {\"errors\": 0.12418410309705344, \"time-step\": 712}, {\"errors\": 0.12418246895160441, \"time-step\": 713}, {\"errors\": 0.12418083155727291, \"time-step\": 714}, {\"errors\": 0.1241791909064546, \"time-step\": 715}, {\"errors\": 0.12417754699152848, \"time-step\": 716}, {\"errors\": 0.12417589980485713, \"time-step\": 717}, {\"errors\": 0.12417424933878646, \"time-step\": 718}, {\"errors\": 0.12417259558564575, \"time-step\": 719}, {\"errors\": 0.12417093853774769, \"time-step\": 720}, {\"errors\": 0.12416927818738817, \"time-step\": 721}, {\"errors\": 0.12416761452684641, \"time-step\": 722}, {\"errors\": 0.12416594754838481, \"time-step\": 723}, {\"errors\": 0.12416427724424905, \"time-step\": 724}, {\"errors\": 0.12416260360666787, \"time-step\": 725}, {\"errors\": 0.1241609266278532, \"time-step\": 726}, {\"errors\": 0.1241592463000001, \"time-step\": 727}, {\"errors\": 0.12415756261528657, \"time-step\": 728}, {\"errors\": 0.12415587556587379, \"time-step\": 729}, {\"errors\": 0.12415418514390578, \"time-step\": 730}, {\"errors\": 0.1241524913415096, \"time-step\": 731}, {\"errors\": 0.12415079415079525, \"time-step\": 732}, {\"errors\": 0.1241490935638555, \"time-step\": 733}, {\"errors\": 0.12414738957276616, \"time-step\": 734}, {\"errors\": 0.12414568216958569, \"time-step\": 735}, {\"errors\": 0.12414397134635535, \"time-step\": 736}, {\"errors\": 0.12414225709509924, \"time-step\": 737}, {\"errors\": 0.12414053940782407, \"time-step\": 738}, {\"errors\": 0.12413881827651932, \"time-step\": 739}, {\"errors\": 0.12413709369315702, \"time-step\": 740}, {\"errors\": 0.12413536564969187, \"time-step\": 741}, {\"errors\": 0.12413363413806112, \"time-step\": 742}, {\"errors\": 0.1241318991501845, \"time-step\": 743}, {\"errors\": 0.12413016067796437, \"time-step\": 744}, {\"errors\": 0.12412841871328542, \"time-step\": 745}, {\"errors\": 0.12412667324801485, \"time-step\": 746}, {\"errors\": 0.12412492427400224, \"time-step\": 747}, {\"errors\": 0.12412317178307947, \"time-step\": 748}, {\"errors\": 0.12412141576706082, \"time-step\": 749}, {\"errors\": 0.12411965621774283, \"time-step\": 750}, {\"errors\": 0.1241178931269043, \"time-step\": 751}, {\"errors\": 0.12411612648630616, \"time-step\": 752}, {\"errors\": 0.12411435628769171, \"time-step\": 753}, {\"errors\": 0.12411258252278617, \"time-step\": 754}, {\"errors\": 0.12411080518329706, \"time-step\": 755}, {\"errors\": 0.12410902426091383, \"time-step\": 756}, {\"errors\": 0.12410723974730806, \"time-step\": 757}, {\"errors\": 0.12410545163413328, \"time-step\": 758}, {\"errors\": 0.12410365991302498, \"time-step\": 759}, {\"errors\": 0.12410186457560063, \"time-step\": 760}, {\"errors\": 0.12410006561345957, \"time-step\": 761}, {\"errors\": 0.12409826301818297, \"time-step\": 762}, {\"errors\": 0.12409645678133385, \"time-step\": 763}, {\"errors\": 0.12409464689445703, \"time-step\": 764}, {\"errors\": 0.12409283334907896, \"time-step\": 765}, {\"errors\": 0.12409101613670799, \"time-step\": 766}, {\"errors\": 0.124089195248834, \"time-step\": 767}, {\"errors\": 0.1240873706769286, \"time-step\": 768}, {\"errors\": 0.1240855424124449, \"time-step\": 769}, {\"errors\": 0.1240837104468177, \"time-step\": 770}, {\"errors\": 0.12408187477146322, \"time-step\": 771}, {\"errors\": 0.12408003537777924, \"time-step\": 772}, {\"errors\": 0.12407819225714498, \"time-step\": 773}, {\"errors\": 0.12407634540092108, \"time-step\": 774}, {\"errors\": 0.12407449480044955, \"time-step\": 775}, {\"errors\": 0.12407264044705374, \"time-step\": 776}, {\"errors\": 0.12407078233203836, \"time-step\": 777}, {\"errors\": 0.12406892044668937, \"time-step\": 778}, {\"errors\": 0.1240670547822739, \"time-step\": 779}, {\"errors\": 0.12406518533004036, \"time-step\": 780}, {\"errors\": 0.12406331208121832, \"time-step\": 781}, {\"errors\": 0.12406143502701844, \"time-step\": 782}, {\"errors\": 0.12405955415863247, \"time-step\": 783}, {\"errors\": 0.12405766946723323, \"time-step\": 784}, {\"errors\": 0.12405578094397457, \"time-step\": 785}, {\"errors\": 0.12405388857999121, \"time-step\": 786}, {\"errors\": 0.124051992366399, \"time-step\": 787}, {\"errors\": 0.1240500922942945, \"time-step\": 788}, {\"errors\": 0.12404818835475527, \"time-step\": 789}, {\"errors\": 0.12404628053883965, \"time-step\": 790}, {\"errors\": 0.12404436883758674, \"time-step\": 791}, {\"errors\": 0.12404245324201646, \"time-step\": 792}, {\"errors\": 0.12404053374312937, \"time-step\": 793}, {\"errors\": 0.12403861033190675, \"time-step\": 794}, {\"errors\": 0.1240366829993105, \"time-step\": 795}, {\"errors\": 0.1240347517362832, \"time-step\": 796}, {\"errors\": 0.12403281653374794, \"time-step\": 797}, {\"errors\": 0.12403087738260826, \"time-step\": 798}, {\"errors\": 0.1240289342737483, \"time-step\": 799}, {\"errors\": 0.12402698719803264, \"time-step\": 800}, {\"errors\": 0.12402503614630618, \"time-step\": 801}, {\"errors\": 0.12402308110939433, \"time-step\": 802}, {\"errors\": 0.12402112207810277, \"time-step\": 803}, {\"errors\": 0.12401915904321749, \"time-step\": 804}, {\"errors\": 0.12401719199550468, \"time-step\": 805}, {\"errors\": 0.12401522092571088, \"time-step\": 806}, {\"errors\": 0.12401324582456272, \"time-step\": 807}, {\"errors\": 0.12401126668276702, \"time-step\": 808}, {\"errors\": 0.12400928349101072, \"time-step\": 809}, {\"errors\": 0.12400729623996076, \"time-step\": 810}, {\"errors\": 0.12400530492026421, \"time-step\": 811}, {\"errors\": 0.12400330952254807, \"time-step\": 812}, {\"errors\": 0.12400131003741932, \"time-step\": 813}, {\"errors\": 0.12399930645546489, \"time-step\": 814}, {\"errors\": 0.12399729876725155, \"time-step\": 815}, {\"errors\": 0.12399528696332589, \"time-step\": 816}, {\"errors\": 0.12399327103421436, \"time-step\": 817}, {\"errors\": 0.12399125097042316, \"time-step\": 818}, {\"errors\": 0.12398922676243818, \"time-step\": 819}, {\"errors\": 0.12398719840072506, \"time-step\": 820}, {\"errors\": 0.12398516587572905, \"time-step\": 821}, {\"errors\": 0.12398312917787499, \"time-step\": 822}, {\"errors\": 0.12398108829756735, \"time-step\": 823}, {\"errors\": 0.12397904322519006, \"time-step\": 824}, {\"errors\": 0.12397699395110667, \"time-step\": 825}, {\"errors\": 0.12397494046566007, \"time-step\": 826}, {\"errors\": 0.12397288275917254, \"time-step\": 827}, {\"errors\": 0.12397082082194583, \"time-step\": 828}, {\"errors\": 0.12396875464426105, \"time-step\": 829}, {\"errors\": 0.1239666842163785, \"time-step\": 830}, {\"errors\": 0.12396460952853781, \"time-step\": 831}, {\"errors\": 0.12396253057095788, \"time-step\": 832}, {\"errors\": 0.12396044733383661, \"time-step\": 833}, {\"errors\": 0.12395835980735125, \"time-step\": 834}, {\"errors\": 0.12395626798165807, \"time-step\": 835}, {\"errors\": 0.12395417184689236, \"time-step\": 836}, {\"errors\": 0.12395207139316855, \"time-step\": 837}, {\"errors\": 0.12394996661057993, \"time-step\": 838}, {\"errors\": 0.1239478574891988, \"time-step\": 839}, {\"errors\": 0.12394574401907639, \"time-step\": 840}, {\"errors\": 0.12394362619024274, \"time-step\": 841}, {\"errors\": 0.12394150399270676, \"time-step\": 842}, {\"errors\": 0.12393937741645614, \"time-step\": 843}, {\"errors\": 0.12393724645145732, \"time-step\": 844}, {\"errors\": 0.12393511108765543, \"time-step\": 845}, {\"errors\": 0.12393297131497426, \"time-step\": 846}, {\"errors\": 0.12393082712331631, \"time-step\": 847}, {\"errors\": 0.12392867850256262, \"time-step\": 848}, {\"errors\": 0.12392652544257274, \"time-step\": 849}, {\"errors\": 0.12392436793318476, \"time-step\": 850}, {\"errors\": 0.12392220596421531, \"time-step\": 851}, {\"errors\": 0.12392003952545932, \"time-step\": 852}, {\"errors\": 0.12391786860669021, \"time-step\": 853}, {\"errors\": 0.12391569319765974, \"time-step\": 854}, {\"errors\": 0.12391351328809797, \"time-step\": 855}, {\"errors\": 0.12391132886771315, \"time-step\": 856}, {\"errors\": 0.12390913992619193, \"time-step\": 857}, {\"errors\": 0.12390694645319898, \"time-step\": 858}, {\"errors\": 0.12390474843837727, \"time-step\": 859}, {\"errors\": 0.12390254587134777, \"time-step\": 860}, {\"errors\": 0.12390033874170953, \"time-step\": 861}, {\"errors\": 0.12389812703903971, \"time-step\": 862}, {\"errors\": 0.12389591075289336, \"time-step\": 863}, {\"errors\": 0.12389368987280355, \"time-step\": 864}, {\"errors\": 0.12389146438828123, \"time-step\": 865}, {\"errors\": 0.12388923428881524, \"time-step\": 866}, {\"errors\": 0.12388699956387221, \"time-step\": 867}, {\"errors\": 0.12388476020289657, \"time-step\": 868}, {\"errors\": 0.12388251619531053, \"time-step\": 869}, {\"errors\": 0.12388026753051393, \"time-step\": 870}, {\"errors\": 0.12387801419788436, \"time-step\": 871}, {\"errors\": 0.12387575618677701, \"time-step\": 872}, {\"errors\": 0.12387349348652464, \"time-step\": 873}, {\"errors\": 0.12387122608643754, \"time-step\": 874}, {\"errors\": 0.12386895397580347, \"time-step\": 875}, {\"errors\": 0.1238666771438878, \"time-step\": 876}, {\"errors\": 0.12386439557993315, \"time-step\": 877}, {\"errors\": 0.1238621092731596, \"time-step\": 878}, {\"errors\": 0.12385981821276457, \"time-step\": 879}, {\"errors\": 0.12385752238792273, \"time-step\": 880}, {\"errors\": 0.1238552217877861, \"time-step\": 881}, {\"errors\": 0.12385291640148378, \"time-step\": 882}, {\"errors\": 0.12385060621812218, \"time-step\": 883}, {\"errors\": 0.12384829122678476, \"time-step\": 884}, {\"errors\": 0.12384597141653209, \"time-step\": 885}, {\"errors\": 0.1238436467764018, \"time-step\": 886}, {\"errors\": 0.1238413172954085, \"time-step\": 887}, {\"errors\": 0.12383898296254384, \"time-step\": 888}, {\"errors\": 0.1238366437667763, \"time-step\": 889}, {\"errors\": 0.12383429969705133, \"time-step\": 890}, {\"errors\": 0.12383195074229116, \"time-step\": 891}, {\"errors\": 0.12382959689139485, \"time-step\": 892}, {\"errors\": 0.12382723813323823, \"time-step\": 893}, {\"errors\": 0.12382487445667385, \"time-step\": 894}, {\"errors\": 0.1238225058505309, \"time-step\": 895}, {\"errors\": 0.12382013230361524, \"time-step\": 896}, {\"errors\": 0.1238177538047093, \"time-step\": 897}, {\"errors\": 0.12381537034257212, \"time-step\": 898}, {\"errors\": 0.12381298190593919, \"time-step\": 899}, {\"errors\": 0.12381058848352246, \"time-step\": 900}, {\"errors\": 0.12380819006401036, \"time-step\": 901}, {\"errors\": 0.12380578663606769, \"time-step\": 902}, {\"errors\": 0.12380337818833559, \"time-step\": 903}, {\"errors\": 0.12380096470943144, \"time-step\": 904}, {\"errors\": 0.12379854618794901, \"time-step\": 905}, {\"errors\": 0.12379612261245818, \"time-step\": 906}, {\"errors\": 0.12379369397150503, \"time-step\": 907}, {\"errors\": 0.12379126025361176, \"time-step\": 908}, {\"errors\": 0.12378882144727679, \"time-step\": 909}, {\"errors\": 0.12378637754097435, \"time-step\": 910}, {\"errors\": 0.12378392852315487, \"time-step\": 911}, {\"errors\": 0.12378147438224468, \"time-step\": 912}, {\"errors\": 0.12377901510664609, \"time-step\": 913}, {\"errors\": 0.12377655068473713, \"time-step\": 914}, {\"errors\": 0.12377408110487186, \"time-step\": 915}, {\"errors\": 0.12377160635538004, \"time-step\": 916}, {\"errors\": 0.12376912642456717, \"time-step\": 917}, {\"errors\": 0.12376664130071455, \"time-step\": 918}, {\"errors\": 0.12376415097207899, \"time-step\": 919}, {\"errors\": 0.12376165542689309, \"time-step\": 920}, {\"errors\": 0.12375915465336493, \"time-step\": 921}, {\"errors\": 0.12375664863967817, \"time-step\": 922}, {\"errors\": 0.12375413737399202, \"time-step\": 923}, {\"errors\": 0.12375162084444105, \"time-step\": 924}, {\"errors\": 0.12374909903913522, \"time-step\": 925}, {\"errors\": 0.12374657194616007, \"time-step\": 926}, {\"errors\": 0.12374403955357616, \"time-step\": 927}, {\"errors\": 0.1237415018494196, \"time-step\": 928}, {\"errors\": 0.1237389588217016, \"time-step\": 929}, {\"errors\": 0.12373641045840864, \"time-step\": 930}, {\"errors\": 0.12373385674750231, \"time-step\": 931}, {\"errors\": 0.12373129767691929, \"time-step\": 932}, {\"errors\": 0.12372873323457143, \"time-step\": 933}, {\"errors\": 0.1237261634083455, \"time-step\": 934}, {\"errors\": 0.12372358818610332, \"time-step\": 935}, {\"errors\": 0.1237210075556816, \"time-step\": 936}, {\"errors\": 0.1237184215048921, \"time-step\": 937}, {\"errors\": 0.12371583002152114, \"time-step\": 938}, {\"errors\": 0.12371323309333014, \"time-step\": 939}, {\"errors\": 0.12371063070805517, \"time-step\": 940}, {\"errors\": 0.123708022853407, \"time-step\": 941}, {\"errors\": 0.12370540951707112, \"time-step\": 942}, {\"errors\": 0.12370279068670773, \"time-step\": 943}, {\"errors\": 0.12370016634995146, \"time-step\": 944}, {\"errors\": 0.12369753649441159, \"time-step\": 945}, {\"errors\": 0.12369490110767199, \"time-step\": 946}, {\"errors\": 0.1236922601772908, \"time-step\": 947}, {\"errors\": 0.12368961369080078, \"time-step\": 948}, {\"errors\": 0.12368696163570893, \"time-step\": 949}, {\"errors\": 0.1236843039994967, \"time-step\": 950}, {\"errors\": 0.12368164076961968, \"time-step\": 951}, {\"errors\": 0.1236789719335079, \"time-step\": 952}, {\"errors\": 0.1236762974785654, \"time-step\": 953}, {\"errors\": 0.12367361739217053, \"time-step\": 954}, {\"errors\": 0.1236709316616757, \"time-step\": 955}, {\"errors\": 0.1236682402744074, \"time-step\": 956}, {\"errors\": 0.12366554321766615, \"time-step\": 957}, {\"errors\": 0.12366284047872644, \"time-step\": 958}, {\"errors\": 0.12366013204483672, \"time-step\": 959}, {\"errors\": 0.12365741790321932, \"time-step\": 960}, {\"errors\": 0.1236546980410705, \"time-step\": 961}, {\"errors\": 0.12365197244556028, \"time-step\": 962}, {\"errors\": 0.12364924110383234, \"time-step\": 963}, {\"errors\": 0.12364650400300427, \"time-step\": 964}, {\"errors\": 0.12364376113016723, \"time-step\": 965}, {\"errors\": 0.12364101247238607, \"time-step\": 966}, {\"errors\": 0.1236382580166992, \"time-step\": 967}, {\"errors\": 0.1236354977501185, \"time-step\": 968}, {\"errors\": 0.12363273165962956, \"time-step\": 969}, {\"errors\": 0.12362995973219121, \"time-step\": 970}, {\"errors\": 0.12362718195473585, \"time-step\": 971}, {\"errors\": 0.12362439831416915, \"time-step\": 972}, {\"errors\": 0.12362160879737018, \"time-step\": 973}, {\"errors\": 0.12361881339119124, \"time-step\": 974}, {\"errors\": 0.1236160120824579, \"time-step\": 975}, {\"errors\": 0.12361320485796892, \"time-step\": 976}, {\"errors\": 0.12361039170449623, \"time-step\": 977}, {\"errors\": 0.12360757260878477, \"time-step\": 978}, {\"errors\": 0.12360474755755269, \"time-step\": 979}, {\"errors\": 0.12360191653749103, \"time-step\": 980}, {\"errors\": 0.12359907953526389, \"time-step\": 981}, {\"errors\": 0.12359623653750826, \"time-step\": 982}, {\"errors\": 0.12359338753083396, \"time-step\": 983}, {\"errors\": 0.12359053250182381, \"time-step\": 984}, {\"errors\": 0.12358767143703323, \"time-step\": 985}, {\"errors\": 0.12358480432299052, \"time-step\": 986}, {\"errors\": 0.12358193114619662, \"time-step\": 987}, {\"errors\": 0.1235790518931252, \"time-step\": 988}, {\"errors\": 0.1235761665502225, \"time-step\": 989}, {\"errors\": 0.1235732751039073, \"time-step\": 990}, {\"errors\": 0.12357037754057099, \"time-step\": 991}, {\"errors\": 0.12356747384657735, \"time-step\": 992}, {\"errors\": 0.12356456400826273, \"time-step\": 993}, {\"errors\": 0.12356164801193573, \"time-step\": 994}, {\"errors\": 0.12355872584387737, \"time-step\": 995}, {\"errors\": 0.12355579749034093, \"time-step\": 996}, {\"errors\": 0.12355286293755201, \"time-step\": 997}, {\"errors\": 0.12354992217170845, \"time-step\": 998}, {\"errors\": 0.12354697517898017, \"time-step\": 999}, {\"errors\": 0.12354402194550917, \"time-step\": 1000}, {\"errors\": 0.12354106245740976, \"time-step\": 1001}, {\"errors\": 0.12353809670076801, \"time-step\": 1002}, {\"errors\": 0.12353512466164215, \"time-step\": 1003}, {\"errors\": 0.12353214632606237, \"time-step\": 1004}, {\"errors\": 0.12352916168003061, \"time-step\": 1005}, {\"errors\": 0.12352617070952082, \"time-step\": 1006}, {\"errors\": 0.1235231734004786, \"time-step\": 1007}, {\"errors\": 0.12352016973882157, \"time-step\": 1008}, {\"errors\": 0.12351715971043875, \"time-step\": 1009}, {\"errors\": 0.1235141433011911, \"time-step\": 1010}, {\"errors\": 0.12351112049691107, \"time-step\": 1011}, {\"errors\": 0.12350809128340276, \"time-step\": 1012}, {\"errors\": 0.12350505564644171, \"time-step\": 1013}, {\"errors\": 0.1235020135717751, \"time-step\": 1014}, {\"errors\": 0.12349896504512142, \"time-step\": 1015}, {\"errors\": 0.12349591005217067, \"time-step\": 1016}, {\"errors\": 0.12349284857858417, \"time-step\": 1017}, {\"errors\": 0.12348978060999452, \"time-step\": 1018}, {\"errors\": 0.12348670613200566, \"time-step\": 1019}, {\"errors\": 0.12348362513019259, \"time-step\": 1020}, {\"errors\": 0.1234805375901018, \"time-step\": 1021}, {\"errors\": 0.12347744349725054, \"time-step\": 1022}, {\"errors\": 0.12347434283712744, \"time-step\": 1023}, {\"errors\": 0.123471235595192, \"time-step\": 1024}, {\"errors\": 0.12346812175687483, \"time-step\": 1025}, {\"errors\": 0.1234650013075774, \"time-step\": 1026}, {\"errors\": 0.12346187423267208, \"time-step\": 1027}, {\"errors\": 0.12345874051750222, \"time-step\": 1028}, {\"errors\": 0.12345560014738186, \"time-step\": 1029}, {\"errors\": 0.12345245310759587, \"time-step\": 1030}, {\"errors\": 0.1234492993833998, \"time-step\": 1031}, {\"errors\": 0.12344613896001994, \"time-step\": 1032}, {\"errors\": 0.12344297182265318, \"time-step\": 1033}, {\"errors\": 0.12343979795646697, \"time-step\": 1034}, {\"errors\": 0.12343661734659937, \"time-step\": 1035}, {\"errors\": 0.12343342997815882, \"time-step\": 1036}, {\"errors\": 0.12343023583622435, \"time-step\": 1037}, {\"errors\": 0.12342703490584533, \"time-step\": 1038}, {\"errors\": 0.12342382717204145, \"time-step\": 1039}, {\"errors\": 0.1234206126198028, \"time-step\": 1040}, {\"errors\": 0.12341739123408962, \"time-step\": 1041}, {\"errors\": 0.12341416299983253, \"time-step\": 1042}, {\"errors\": 0.12341092790193217, \"time-step\": 1043}, {\"errors\": 0.12340768592525941, \"time-step\": 1044}, {\"errors\": 0.12340443705465519, \"time-step\": 1045}, {\"errors\": 0.12340118127493047, \"time-step\": 1046}, {\"errors\": 0.12339791857086618, \"time-step\": 1047}, {\"errors\": 0.12339464892721327, \"time-step\": 1048}, {\"errors\": 0.12339137232869254, \"time-step\": 1049}, {\"errors\": 0.12338808875999469, \"time-step\": 1050}, {\"errors\": 0.12338479820578013, \"time-step\": 1051}, {\"errors\": 0.12338150065067915, \"time-step\": 1052}, {\"errors\": 0.12337819607929176, \"time-step\": 1053}, {\"errors\": 0.12337488447618752, \"time-step\": 1054}, {\"errors\": 0.1233715658259058, \"time-step\": 1055}, {\"errors\": 0.12336824011295534, \"time-step\": 1056}, {\"errors\": 0.1233649073218146, \"time-step\": 1057}, {\"errors\": 0.12336156743693144, \"time-step\": 1058}, {\"errors\": 0.12335822044272324, \"time-step\": 1059}, {\"errors\": 0.12335486632357665, \"time-step\": 1060}, {\"errors\": 0.12335150506384783, \"time-step\": 1061}, {\"errors\": 0.12334813664786205, \"time-step\": 1062}, {\"errors\": 0.1233447610599141, \"time-step\": 1063}, {\"errors\": 0.12334137828426778, \"time-step\": 1064}, {\"errors\": 0.1233379883051561, \"time-step\": 1065}, {\"errors\": 0.1233345911067813, \"time-step\": 1066}, {\"errors\": 0.12333118667331457, \"time-step\": 1067}, {\"errors\": 0.12332777498889622, \"time-step\": 1068}, {\"errors\": 0.12332435603763545, \"time-step\": 1069}, {\"errors\": 0.12332092980361054, \"time-step\": 1070}, {\"errors\": 0.12331749627086858, \"time-step\": 1071}, {\"errors\": 0.12331405542342547, \"time-step\": 1072}, {\"errors\": 0.12331060724526605, \"time-step\": 1073}, {\"errors\": 0.12330715172034375, \"time-step\": 1074}, {\"errors\": 0.12330368883258086, \"time-step\": 1075}, {\"errors\": 0.12330021856586823, \"time-step\": 1076}, {\"errors\": 0.12329674090406537, \"time-step\": 1077}, {\"errors\": 0.12329325583100043, \"time-step\": 1078}, {\"errors\": 0.12328976333047001, \"time-step\": 1079}, {\"errors\": 0.12328626338623917, \"time-step\": 1080}, {\"errors\": 0.12328275598204147, \"time-step\": 1081}, {\"errors\": 0.1232792411015789, \"time-step\": 1082}, {\"errors\": 0.12327571872852167, \"time-step\": 1083}, {\"errors\": 0.12327218884650834, \"time-step\": 1084}, {\"errors\": 0.12326865143914582, \"time-step\": 1085}, {\"errors\": 0.1232651064900091, \"time-step\": 1086}, {\"errors\": 0.12326155398264142, \"time-step\": 1087}, {\"errors\": 0.12325799390055409, \"time-step\": 1088}, {\"errors\": 0.1232544262272265, \"time-step\": 1089}, {\"errors\": 0.12325085094610608, \"time-step\": 1090}, {\"errors\": 0.1232472680406082, \"time-step\": 1091}, {\"errors\": 0.12324367749411622, \"time-step\": 1092}, {\"errors\": 0.12324007928998137, \"time-step\": 1093}, {\"errors\": 0.12323647341152268, \"time-step\": 1094}, {\"errors\": 0.12323285984202706, \"time-step\": 1095}, {\"errors\": 0.1232292385647491, \"time-step\": 1096}, {\"errors\": 0.12322560956291112, \"time-step\": 1097}, {\"errors\": 0.1232219728197031, \"time-step\": 1098}, {\"errors\": 0.12321832831828264, \"time-step\": 1099}, {\"errors\": 0.12321467604177488, \"time-step\": 1100}, {\"errors\": 0.12321101597327254, \"time-step\": 1101}, {\"errors\": 0.12320734809583576, \"time-step\": 1102}, {\"errors\": 0.12320367239249218, \"time-step\": 1103}, {\"errors\": 0.1231999888462367, \"time-step\": 1104}, {\"errors\": 0.12319629744003173, \"time-step\": 1105}, {\"errors\": 0.1231925981568068, \"time-step\": 1106}, {\"errors\": 0.12318889097945884, \"time-step\": 1107}, {\"errors\": 0.12318517589085189, \"time-step\": 1108}, {\"errors\": 0.12318145287381721, \"time-step\": 1109}, {\"errors\": 0.12317772191115309, \"time-step\": 1110}, {\"errors\": 0.12317398298562499, \"time-step\": 1111}, {\"errors\": 0.12317023607996533, \"time-step\": 1112}, {\"errors\": 0.12316648117687351, \"time-step\": 1113}, {\"errors\": 0.12316271825901588, \"time-step\": 1114}, {\"errors\": 0.12315894730902566, \"time-step\": 1115}, {\"errors\": 0.12315516830950289, \"time-step\": 1116}, {\"errors\": 0.1231513812430145, \"time-step\": 1117}, {\"errors\": 0.12314758609209404, \"time-step\": 1118}, {\"errors\": 0.12314378283924186, \"time-step\": 1119}, {\"errors\": 0.1231399714669249, \"time-step\": 1120}, {\"errors\": 0.1231361519575768, \"time-step\": 1121}, {\"errors\": 0.12313232429359766, \"time-step\": 1122}, {\"errors\": 0.12312848845735422, \"time-step\": 1123}, {\"errors\": 0.1231246444311796, \"time-step\": 1124}, {\"errors\": 0.12312079219737343, \"time-step\": 1125}, {\"errors\": 0.12311693173820171, \"time-step\": 1126}, {\"errors\": 0.12311306303589671, \"time-step\": 1127}, {\"errors\": 0.12310918607265706, \"time-step\": 1128}, {\"errors\": 0.12310530083064768, \"time-step\": 1129}, {\"errors\": 0.12310140729199964, \"time-step\": 1130}, {\"errors\": 0.1230975054388102, \"time-step\": 1131}, {\"errors\": 0.1230935952531427, \"time-step\": 1132}, {\"errors\": 0.12308967671702663, \"time-step\": 1133}, {\"errors\": 0.1230857498124574, \"time-step\": 1134}, {\"errors\": 0.12308181452139652, \"time-step\": 1135}, {\"errors\": 0.1230778708257714, \"time-step\": 1136}, {\"errors\": 0.12307391870747528, \"time-step\": 1137}, {\"errors\": 0.12306995814836734, \"time-step\": 1138}, {\"errors\": 0.12306598913027252, \"time-step\": 1139}, {\"errors\": 0.1230620116349815, \"time-step\": 1140}, {\"errors\": 0.12305802564425075, \"time-step\": 1141}, {\"errors\": 0.12305403113980232, \"time-step\": 1142}, {\"errors\": 0.123050028103324, \"time-step\": 1143}, {\"errors\": 0.12304601651646904, \"time-step\": 1144}, {\"errors\": 0.1230419963608563, \"time-step\": 1145}, {\"errors\": 0.12303796761807012, \"time-step\": 1146}, {\"errors\": 0.12303393026966031, \"time-step\": 1147}, {\"errors\": 0.12302988429714208, \"time-step\": 1148}, {\"errors\": 0.12302582968199596, \"time-step\": 1149}, {\"errors\": 0.12302176640566781, \"time-step\": 1150}, {\"errors\": 0.12301769444956882, \"time-step\": 1151}, {\"errors\": 0.12301361379507537, \"time-step\": 1152}, {\"errors\": 0.12300952442352904, \"time-step\": 1153}, {\"errors\": 0.12300542631623648, \"time-step\": 1154}, {\"errors\": 0.12300131945446956, \"time-step\": 1155}, {\"errors\": 0.1229972038194651, \"time-step\": 1156}, {\"errors\": 0.12299307939242497, \"time-step\": 1157}, {\"errors\": 0.12298894615451605, \"time-step\": 1158}, {\"errors\": 0.1229848040868701, \"time-step\": 1159}, {\"errors\": 0.12298065317058371, \"time-step\": 1160}, {\"errors\": 0.1229764933867184, \"time-step\": 1161}, {\"errors\": 0.12297232471630046, \"time-step\": 1162}, {\"errors\": 0.12296814714032088, \"time-step\": 1163}, {\"errors\": 0.12296396063973537, \"time-step\": 1164}, {\"errors\": 0.1229597651954644, \"time-step\": 1165}, {\"errors\": 0.12295556078839286, \"time-step\": 1166}, {\"errors\": 0.12295134739937048, \"time-step\": 1167}, {\"errors\": 0.12294712500921126, \"time-step\": 1168}, {\"errors\": 0.12294289359869388, \"time-step\": 1169}, {\"errors\": 0.12293865314856141, \"time-step\": 1170}, {\"errors\": 0.1229344036395213, \"time-step\": 1171}, {\"errors\": 0.12293014505224532, \"time-step\": 1172}, {\"errors\": 0.12292587736736973, \"time-step\": 1173}, {\"errors\": 0.12292160056549487, \"time-step\": 1174}, {\"errors\": 0.12291731462718544, \"time-step\": 1175}, {\"errors\": 0.12291301953297032, \"time-step\": 1176}, {\"errors\": 0.12290871526334246, \"time-step\": 1177}, {\"errors\": 0.12290440179875897, \"time-step\": 1178}, {\"errors\": 0.12290007911964113, \"time-step\": 1179}, {\"errors\": 0.122895747206374, \"time-step\": 1180}, {\"errors\": 0.12289140603930687, \"time-step\": 1181}, {\"errors\": 0.12288705559875279, \"time-step\": 1182}, {\"errors\": 0.1228826958649889, \"time-step\": 1183}, {\"errors\": 0.12287832681825592, \"time-step\": 1184}, {\"errors\": 0.12287394843875869, \"time-step\": 1185}, {\"errors\": 0.12286956070666556, \"time-step\": 1186}, {\"errors\": 0.12286516360210883, \"time-step\": 1187}, {\"errors\": 0.12286075710518432, \"time-step\": 1188}, {\"errors\": 0.12285634119595157, \"time-step\": 1189}, {\"errors\": 0.12285191585443375, \"time-step\": 1190}, {\"errors\": 0.12284748106061755, \"time-step\": 1191}, {\"errors\": 0.12284303679445327, \"time-step\": 1192}, {\"errors\": 0.12283858303585457, \"time-step\": 1193}, {\"errors\": 0.12283411976469863, \"time-step\": 1194}, {\"errors\": 0.12282964696082607, \"time-step\": 1195}, {\"errors\": 0.12282516460404073, \"time-step\": 1196}, {\"errors\": 0.12282067267410998, \"time-step\": 1197}, {\"errors\": 0.12281617115076426, \"time-step\": 1198}, {\"errors\": 0.12281166001369742, \"time-step\": 1199}, {\"errors\": 0.1228071392425664, \"time-step\": 1200}, {\"errors\": 0.12280260881699138, \"time-step\": 1201}, {\"errors\": 0.12279806871655566, \"time-step\": 1202}, {\"errors\": 0.12279351892080552, \"time-step\": 1203}, {\"errors\": 0.12278895940925036, \"time-step\": 1204}, {\"errors\": 0.12278439016136267, \"time-step\": 1205}, {\"errors\": 0.12277981115657768, \"time-step\": 1206}, {\"errors\": 0.12277522237429378, \"time-step\": 1207}, {\"errors\": 0.12277062379387207, \"time-step\": 1208}, {\"errors\": 0.12276601539463665, \"time-step\": 1209}, {\"errors\": 0.12276139715587431, \"time-step\": 1210}, {\"errors\": 0.1227567690568346, \"time-step\": 1211}, {\"errors\": 0.12275213107672989, \"time-step\": 1212}, {\"errors\": 0.12274748319473514, \"time-step\": 1213}, {\"errors\": 0.12274282538998812, \"time-step\": 1214}, {\"errors\": 0.1227381576415891, \"time-step\": 1215}, {\"errors\": 0.12273347992860084, \"time-step\": 1216}, {\"errors\": 0.12272879223004882, \"time-step\": 1217}, {\"errors\": 0.122724094524921, \"time-step\": 1218}, {\"errors\": 0.1227193867921676, \"time-step\": 1219}, {\"errors\": 0.12271466901070155, \"time-step\": 1220}, {\"errors\": 0.12270994115939794, \"time-step\": 1221}, {\"errors\": 0.12270520321709438, \"time-step\": 1222}, {\"errors\": 0.12270045516259066, \"time-step\": 1223}, {\"errors\": 0.12269569697464894, \"time-step\": 1224}, {\"errors\": 0.12269092863199355, \"time-step\": 1225}, {\"errors\": 0.12268615011331108, \"time-step\": 1226}, {\"errors\": 0.12268136139725029, \"time-step\": 1227}, {\"errors\": 0.12267656246242203, \"time-step\": 1228}, {\"errors\": 0.1226717532873993, \"time-step\": 1229}, {\"errors\": 0.12266693385071709, \"time-step\": 1230}, {\"errors\": 0.12266210413087245, \"time-step\": 1231}, {\"errors\": 0.12265726410632441, \"time-step\": 1232}, {\"errors\": 0.12265241375549399, \"time-step\": 1233}, {\"errors\": 0.12264755305676411, \"time-step\": 1234}, {\"errors\": 0.12264268198847952, \"time-step\": 1235}, {\"errors\": 0.12263780052894685, \"time-step\": 1236}, {\"errors\": 0.12263290865643459, \"time-step\": 1237}, {\"errors\": 0.12262800634917301, \"time-step\": 1238}, {\"errors\": 0.12262309358535396, \"time-step\": 1239}, {\"errors\": 0.12261817034313122, \"time-step\": 1240}, {\"errors\": 0.1226132366006201, \"time-step\": 1241}, {\"errors\": 0.12260829233589765, \"time-step\": 1242}, {\"errors\": 0.1226033375270024, \"time-step\": 1243}, {\"errors\": 0.12259837215193464, \"time-step\": 1244}, {\"errors\": 0.122593396188656, \"time-step\": 1245}, {\"errors\": 0.12258840961508977, \"time-step\": 1246}, {\"errors\": 0.12258341240912063, \"time-step\": 1247}, {\"errors\": 0.12257840454859474, \"time-step\": 1248}, {\"errors\": 0.12257338601131965, \"time-step\": 1249}, {\"errors\": 0.12256835677506436, \"time-step\": 1250}, {\"errors\": 0.12256331681755905, \"time-step\": 1251}, {\"errors\": 0.12255826611649544, \"time-step\": 1252}, {\"errors\": 0.12255320464952635, \"time-step\": 1253}, {\"errors\": 0.12254813239426593, \"time-step\": 1254}, {\"errors\": 0.12254304932828955, \"time-step\": 1255}, {\"errors\": 0.12253795542913373, \"time-step\": 1256}, {\"errors\": 0.12253285067429623, \"time-step\": 1257}, {\"errors\": 0.12252773504123585, \"time-step\": 1258}, {\"errors\": 0.12252260850737248, \"time-step\": 1259}, {\"errors\": 0.12251747105008723, \"time-step\": 1260}, {\"errors\": 0.12251232264672204, \"time-step\": 1261}, {\"errors\": 0.12250716327458006, \"time-step\": 1262}, {\"errors\": 0.12250199291092523, \"time-step\": 1263}, {\"errors\": 0.1224968115329826, \"time-step\": 1264}, {\"errors\": 0.12249161911793802, \"time-step\": 1265}, {\"errors\": 0.12248641564293833, \"time-step\": 1266}, {\"errors\": 0.1224812010850912, \"time-step\": 1267}, {\"errors\": 0.12247597542146509, \"time-step\": 1268}, {\"errors\": 0.12247073862908936, \"time-step\": 1269}, {\"errors\": 0.12246549068495406, \"time-step\": 1270}, {\"errors\": 0.12246023156601005, \"time-step\": 1271}, {\"errors\": 0.12245496124916896, \"time-step\": 1272}, {\"errors\": 0.12244967971130297, \"time-step\": 1273}, {\"errors\": 0.12244438692924511, \"time-step\": 1274}, {\"errors\": 0.12243908287978894, \"time-step\": 1275}, {\"errors\": 0.12243376753968871, \"time-step\": 1276}, {\"errors\": 0.1224284408856592, \"time-step\": 1277}, {\"errors\": 0.12242310289437586, \"time-step\": 1278}, {\"errors\": 0.12241775354247457, \"time-step\": 1279}, {\"errors\": 0.12241239280655188, \"time-step\": 1280}, {\"errors\": 0.12240702066316465, \"time-step\": 1281}, {\"errors\": 0.12240163708883034, \"time-step\": 1282}, {\"errors\": 0.12239624206002689, \"time-step\": 1283}, {\"errors\": 0.12239083555319254, \"time-step\": 1284}, {\"errors\": 0.122385417544726, \"time-step\": 1285}, {\"errors\": 0.12237998801098642, \"time-step\": 1286}, {\"errors\": 0.12237454692829319, \"time-step\": 1287}, {\"errors\": 0.12236909427292611, \"time-step\": 1288}, {\"errors\": 0.12236363002112528, \"time-step\": 1289}, {\"errors\": 0.12235815414909108, \"time-step\": 1290}, {\"errors\": 0.12235266663298416, \"time-step\": 1291}, {\"errors\": 0.12234716744892546, \"time-step\": 1292}, {\"errors\": 0.12234165657299605, \"time-step\": 1293}, {\"errors\": 0.1223361339812373, \"time-step\": 1294}, {\"errors\": 0.12233059964965076, \"time-step\": 1295}, {\"errors\": 0.12232505355419807, \"time-step\": 1296}, {\"errors\": 0.12231949567080112, \"time-step\": 1297}, {\"errors\": 0.1223139259753419, \"time-step\": 1298}, {\"errors\": 0.1223083444436624, \"time-step\": 1299}, {\"errors\": 0.12230275105156485, \"time-step\": 1300}, {\"errors\": 0.12229714577481156, \"time-step\": 1301}, {\"errors\": 0.12229152858912475, \"time-step\": 1302}, {\"errors\": 0.12228589947018678, \"time-step\": 1303}, {\"errors\": 0.12228025839364004, \"time-step\": 1304}, {\"errors\": 0.12227460533508691, \"time-step\": 1305}, {\"errors\": 0.12226894027008972, \"time-step\": 1306}, {\"errors\": 0.12226326317417086, \"time-step\": 1307}, {\"errors\": 0.12225757402281254, \"time-step\": 1308}, {\"errors\": 0.12225187279145709, \"time-step\": 1309}, {\"errors\": 0.12224615945550663, \"time-step\": 1310}, {\"errors\": 0.1222404339903233, \"time-step\": 1311}, {\"errors\": 0.122234696371229, \"time-step\": 1312}, {\"errors\": 0.12222894657350566, \"time-step\": 1313}, {\"errors\": 0.12222318457239509, \"time-step\": 1314}, {\"errors\": 0.12221741034309881, \"time-step\": 1315}, {\"errors\": 0.12221162386077829, \"time-step\": 1316}, {\"errors\": 0.12220582510055487, \"time-step\": 1317}, {\"errors\": 0.12220001403750964, \"time-step\": 1318}, {\"errors\": 0.12219419064668358, \"time-step\": 1319}, {\"errors\": 0.12218835490307745, \"time-step\": 1320}, {\"errors\": 0.12218250678165173, \"time-step\": 1321}, {\"errors\": 0.1221766462573268, \"time-step\": 1322}, {\"errors\": 0.12217077330498277, \"time-step\": 1323}, {\"errors\": 0.12216488789945953, \"time-step\": 1324}, {\"errors\": 0.12215899001555666, \"time-step\": 1325}, {\"errors\": 0.12215307962803358, \"time-step\": 1326}, {\"errors\": 0.12214715671160947, \"time-step\": 1327}, {\"errors\": 0.1221412212409631, \"time-step\": 1328}, {\"errors\": 0.12213527319073314, \"time-step\": 1329}, {\"errors\": 0.12212931253551794, \"time-step\": 1330}, {\"errors\": 0.1221233392498755, \"time-step\": 1331}, {\"errors\": 0.12211735330832355, \"time-step\": 1332}, {\"errors\": 0.12211135468533967, \"time-step\": 1333}, {\"errors\": 0.12210534335536094, \"time-step\": 1334}, {\"errors\": 0.12209931929278425, \"time-step\": 1335}, {\"errors\": 0.12209328247196627, \"time-step\": 1336}, {\"errors\": 0.12208723286722316, \"time-step\": 1337}, {\"errors\": 0.12208117045283094, \"time-step\": 1338}, {\"errors\": 0.12207509520302526, \"time-step\": 1339}, {\"errors\": 0.12206900709200158, \"time-step\": 1340}, {\"errors\": 0.12206290609391479, \"time-step\": 1341}, {\"errors\": 0.12205679218287971, \"time-step\": 1342}, {\"errors\": 0.12205066533297079, \"time-step\": 1343}, {\"errors\": 0.12204452551822212, \"time-step\": 1344}, {\"errors\": 0.12203837271262753, \"time-step\": 1345}, {\"errors\": 0.12203220689014056, \"time-step\": 1346}, {\"errors\": 0.12202602802467438, \"time-step\": 1347}, {\"errors\": 0.12201983609010197, \"time-step\": 1348}, {\"errors\": 0.12201363106025592, \"time-step\": 1349}, {\"errors\": 0.12200741290892861, \"time-step\": 1350}, {\"errors\": 0.12200118160987204, \"time-step\": 1351}, {\"errors\": 0.12199493713679799, \"time-step\": 1352}, {\"errors\": 0.121988679463378, \"time-step\": 1353}, {\"errors\": 0.12198240856324331, \"time-step\": 1354}, {\"errors\": 0.12197612440998488, \"time-step\": 1355}, {\"errors\": 0.12196982697715344, \"time-step\": 1356}, {\"errors\": 0.12196351623825946, \"time-step\": 1357}, {\"errors\": 0.12195719216677325, \"time-step\": 1358}, {\"errors\": 0.1219508547361248, \"time-step\": 1359}, {\"errors\": 0.12194450391970393, \"time-step\": 1360}, {\"errors\": 0.12193813969086029, \"time-step\": 1361}, {\"errors\": 0.1219317620229032, \"time-step\": 1362}, {\"errors\": 0.12192537088910203, \"time-step\": 1363}, {\"errors\": 0.12191896626268581, \"time-step\": 1364}, {\"errors\": 0.12191254811684349, \"time-step\": 1365}, {\"errors\": 0.12190611642472379, \"time-step\": 1366}, {\"errors\": 0.12189967115943545, \"time-step\": 1367}, {\"errors\": 0.121893212294047, \"time-step\": 1368}, {\"errors\": 0.1218867398015869, \"time-step\": 1369}, {\"errors\": 0.1218802536550435, \"time-step\": 1370}, {\"errors\": 0.1218737538273652, \"time-step\": 1371}, {\"errors\": 0.12186724029146026, \"time-step\": 1372}, {\"errors\": 0.12186071302019695, \"time-step\": 1373}, {\"errors\": 0.12185417198640354, \"time-step\": 1374}, {\"errors\": 0.12184761716286827, \"time-step\": 1375}, {\"errors\": 0.12184104852233953, \"time-step\": 1376}, {\"errors\": 0.12183446603752565, \"time-step\": 1377}, {\"errors\": 0.1218278696810951, \"time-step\": 1378}, {\"errors\": 0.12182125942567648, \"time-step\": 1379}, {\"errors\": 0.1218146352438585, \"time-step\": 1380}, {\"errors\": 0.12180799710818993, \"time-step\": 1381}, {\"errors\": 0.12180134499117985, \"time-step\": 1382}, {\"errors\": 0.12179467886529749, \"time-step\": 1383}, {\"errors\": 0.12178799870297233, \"time-step\": 1384}, {\"errors\": 0.1217813044765941, \"time-step\": 1385}, {\"errors\": 0.12177459615851277, \"time-step\": 1386}, {\"errors\": 0.12176787372103866, \"time-step\": 1387}, {\"errors\": 0.12176113713644246, \"time-step\": 1388}, {\"errors\": 0.12175438637695526, \"time-step\": 1389}, {\"errors\": 0.12174762141476844, \"time-step\": 1390}, {\"errors\": 0.12174084222203391, \"time-step\": 1391}, {\"errors\": 0.12173404877086402, \"time-step\": 1392}, {\"errors\": 0.12172724103333168, \"time-step\": 1393}, {\"errors\": 0.12172041898147029, \"time-step\": 1394}, {\"errors\": 0.12171358258727374, \"time-step\": 1395}, {\"errors\": 0.12170673182269676, \"time-step\": 1396}, {\"errors\": 0.12169986665965447, \"time-step\": 1397}, {\"errors\": 0.12169298707002285, \"time-step\": 1398}, {\"errors\": 0.12168609302563853, \"time-step\": 1399}, {\"errors\": 0.12167918449829888, \"time-step\": 1400}, {\"errors\": 0.1216722614597622, \"time-step\": 1401}, {\"errors\": 0.12166532388174753, \"time-step\": 1402}, {\"errors\": 0.12165837173593476, \"time-step\": 1403}, {\"errors\": 0.12165140499396482, \"time-step\": 1404}, {\"errors\": 0.12164442362743949, \"time-step\": 1405}, {\"errors\": 0.12163742760792173, \"time-step\": 1406}, {\"errors\": 0.12163041690693539, \"time-step\": 1407}, {\"errors\": 0.12162339149596554, \"time-step\": 1408}, {\"errors\": 0.12161635134645843, \"time-step\": 1409}, {\"errors\": 0.12160929642982135, \"time-step\": 1410}, {\"errors\": 0.12160222671742303, \"time-step\": 1411}, {\"errors\": 0.12159514218059342, \"time-step\": 1412}, {\"errors\": 0.12158804279062385, \"time-step\": 1413}, {\"errors\": 0.121580928518767, \"time-step\": 1414}, {\"errors\": 0.12157379933623715, \"time-step\": 1415}, {\"errors\": 0.12156665521420987, \"time-step\": 1416}, {\"errors\": 0.12155949612382258, \"time-step\": 1417}, {\"errors\": 0.12155232203617405, \"time-step\": 1418}, {\"errors\": 0.12154513292232494, \"time-step\": 1419}, {\"errors\": 0.12153792875329752, \"time-step\": 1420}, {\"errors\": 0.12153070950007597, \"time-step\": 1421}, {\"errors\": 0.1215234751336062, \"time-step\": 1422}, {\"errors\": 0.12151622562479616, \"time-step\": 1423}, {\"errors\": 0.12150896094451571, \"time-step\": 1424}, {\"errors\": 0.12150168106359677, \"time-step\": 1425}, {\"errors\": 0.12149438595283342, \"time-step\": 1426}, {\"errors\": 0.1214870755829818, \"time-step\": 1427}, {\"errors\": 0.12147974992476035, \"time-step\": 1428}, {\"errors\": 0.12147240894884989, \"time-step\": 1429}, {\"errors\": 0.12146505262589355, \"time-step\": 1430}, {\"errors\": 0.12145768092649681, \"time-step\": 1431}, {\"errors\": 0.12145029382122781, \"time-step\": 1432}, {\"errors\": 0.12144289128061725, \"time-step\": 1433}, {\"errors\": 0.12143547327515843, \"time-step\": 1434}, {\"errors\": 0.12142803977530739, \"time-step\": 1435}, {\"errors\": 0.12142059075148302, \"time-step\": 1436}, {\"errors\": 0.12141312617406708, \"time-step\": 1437}, {\"errors\": 0.12140564601340424, \"time-step\": 1438}, {\"errors\": 0.12139815023980229, \"time-step\": 1439}, {\"errors\": 0.12139063882353203, \"time-step\": 1440}, {\"errors\": 0.12138311173482756, \"time-step\": 1441}, {\"errors\": 0.12137556894388621, \"time-step\": 1442}, {\"errors\": 0.12136801042086863, \"time-step\": 1443}, {\"errors\": 0.12136043613589902, \"time-step\": 1444}, {\"errors\": 0.12135284605906503, \"time-step\": 1445}, {\"errors\": 0.12134524016041791, \"time-step\": 1446}, {\"errors\": 0.12133761840997265, \"time-step\": 1447}, {\"errors\": 0.12132998077770804, \"time-step\": 1448}, {\"errors\": 0.12132232723356676, \"time-step\": 1449}, {\"errors\": 0.1213146577474554, \"time-step\": 1450}, {\"errors\": 0.12130697228924468, \"time-step\": 1451}, {\"errors\": 0.12129927082876946, \"time-step\": 1452}, {\"errors\": 0.1212915533358288, \"time-step\": 1453}, {\"errors\": 0.12128381978018621, \"time-step\": 1454}, {\"errors\": 0.12127607013156952, \"time-step\": 1455}, {\"errors\": 0.12126830435967126, \"time-step\": 1456}, {\"errors\": 0.12126052243414842, \"time-step\": 1457}, {\"errors\": 0.1212527243246229, \"time-step\": 1458}, {\"errors\": 0.12124491000068138, \"time-step\": 1459}, {\"errors\": 0.12123707943187546, \"time-step\": 1460}, {\"errors\": 0.12122923258772186, \"time-step\": 1461}, {\"errors\": 0.12122136943770243, \"time-step\": 1462}, {\"errors\": 0.12121348995126424, \"time-step\": 1463}, {\"errors\": 0.12120559409781984, \"time-step\": 1464}, {\"errors\": 0.1211976818467472, \"time-step\": 1465}, {\"errors\": 0.12118975316738995, \"time-step\": 1466}, {\"errors\": 0.12118180802905737, \"time-step\": 1467}, {\"errors\": 0.12117384640102462, \"time-step\": 1468}, {\"errors\": 0.12116586825253277, \"time-step\": 1469}, {\"errors\": 0.12115787355278891, \"time-step\": 1470}, {\"errors\": 0.12114986227096645, \"time-step\": 1471}, {\"errors\": 0.12114183437620499, \"time-step\": 1472}, {\"errors\": 0.12113378983761061, \"time-step\": 1473}, {\"errors\": 0.12112572862425586, \"time-step\": 1474}, {\"errors\": 0.12111765070517998, \"time-step\": 1475}, {\"errors\": 0.12110955604938915, \"time-step\": 1476}, {\"errors\": 0.12110144462585623, \"time-step\": 1477}, {\"errors\": 0.12109331640352135, \"time-step\": 1478}, {\"errors\": 0.12108517135129165, \"time-step\": 1479}, {\"errors\": 0.12107700943804177, \"time-step\": 1480}, {\"errors\": 0.12106883063261362, \"time-step\": 1481}, {\"errors\": 0.12106063490381674, \"time-step\": 1482}, {\"errors\": 0.1210524222204285, \"time-step\": 1483}, {\"errors\": 0.12104419255119395, \"time-step\": 1484}, {\"errors\": 0.12103594586482633, \"time-step\": 1485}, {\"errors\": 0.12102768213000681, \"time-step\": 1486}, {\"errors\": 0.12101940131538501, \"time-step\": 1487}, {\"errors\": 0.12101110338957885, \"time-step\": 1488}, {\"errors\": 0.12100278832117489, \"time-step\": 1489}, {\"errors\": 0.12099445607872841, \"time-step\": 1490}, {\"errors\": 0.1209861066307635, \"time-step\": 1491}, {\"errors\": 0.12097773994577332, \"time-step\": 1492}, {\"errors\": 0.12096935599222018, \"time-step\": 1493}, {\"errors\": 0.12096095473853569, \"time-step\": 1494}, {\"errors\": 0.1209525361531209, \"time-step\": 1495}, {\"errors\": 0.12094410020434664, \"time-step\": 1496}, {\"errors\": 0.12093564686055333, \"time-step\": 1497}, {\"errors\": 0.12092717609005149, \"time-step\": 1498}, {\"errors\": 0.12091868786112173, \"time-step\": 1499}, {\"errors\": 0.12091018214201486, \"time-step\": 1500}, {\"errors\": 0.12090165890095217, \"time-step\": 1501}, {\"errors\": 0.12089311810612569, \"time-step\": 1502}, {\"errors\": 0.12088455972569792, \"time-step\": 1503}, {\"errors\": 0.12087598372780264, \"time-step\": 1504}, {\"errors\": 0.12086739008054453, \"time-step\": 1505}, {\"errors\": 0.12085877875199962, \"time-step\": 1506}, {\"errors\": 0.12085014971021552, \"time-step\": 1507}, {\"errors\": 0.12084150292321125, \"time-step\": 1508}, {\"errors\": 0.12083283835897793, \"time-step\": 1509}, {\"errors\": 0.12082415598547842, \"time-step\": 1510}, {\"errors\": 0.120815455770648, \"time-step\": 1511}, {\"errors\": 0.12080673768239417, \"time-step\": 1512}, {\"errors\": 0.12079800168859704, \"time-step\": 1513}, {\"errors\": 0.12078924775710949, \"time-step\": 1514}, {\"errors\": 0.12078047585575727, \"time-step\": 1515}, {\"errors\": 0.12077168595233931, \"time-step\": 1516}, {\"errors\": 0.12076287801462787, \"time-step\": 1517}, {\"errors\": 0.12075405201036868, \"time-step\": 1518}, {\"errors\": 0.12074520790728122, \"time-step\": 1519}, {\"errors\": 0.12073634567305887, \"time-step\": 1520}, {\"errors\": 0.12072746527536918, \"time-step\": 1521}, {\"errors\": 0.12071856668185392, \"time-step\": 1522}, {\"errors\": 0.12070964986012944, \"time-step\": 1523}, {\"errors\": 0.12070071477778682, \"time-step\": 1524}, {\"errors\": 0.12069176140239202, \"time-step\": 1525}, {\"errors\": 0.12068278970148626, \"time-step\": 1526}, {\"errors\": 0.12067379964258601, \"time-step\": 1527}, {\"errors\": 0.12066479119318341, \"time-step\": 1528}, {\"errors\": 0.1206557643207463, \"time-step\": 1529}, {\"errors\": 0.12064671899271863, \"time-step\": 1530}, {\"errors\": 0.12063765517652045, \"time-step\": 1531}, {\"errors\": 0.12062857283954843, \"time-step\": 1532}, {\"errors\": 0.12061947194917574, \"time-step\": 1533}, {\"errors\": 0.12061035247275262, \"time-step\": 1534}, {\"errors\": 0.12060121437760636, \"time-step\": 1535}, {\"errors\": 0.1205920576310416, \"time-step\": 1536}, {\"errors\": 0.12058288220034055, \"time-step\": 1537}, {\"errors\": 0.12057368805276342, \"time-step\": 1538}, {\"errors\": 0.12056447515554827, \"time-step\": 1539}, {\"errors\": 0.1205552434759116, \"time-step\": 1540}, {\"errors\": 0.12054599298104843, \"time-step\": 1541}, {\"errors\": 0.12053672363813261, \"time-step\": 1542}, {\"errors\": 0.12052743541431687, \"time-step\": 1543}, {\"errors\": 0.12051812827673344, \"time-step\": 1544}, {\"errors\": 0.12050880219249395, \"time-step\": 1545}, {\"errors\": 0.12049945712868981, \"time-step\": 1546}, {\"errors\": 0.12049009305239253, \"time-step\": 1547}, {\"errors\": 0.12048070993065393, \"time-step\": 1548}, {\"errors\": 0.12047130773050632, \"time-step\": 1549}, {\"errors\": 0.12046188641896281, \"time-step\": 1550}, {\"errors\": 0.12045244596301763, \"time-step\": 1551}, {\"errors\": 0.12044298632964635, \"time-step\": 1552}, {\"errors\": 0.12043350748580618, \"time-step\": 1553}, {\"errors\": 0.12042400939843612, \"time-step\": 1554}, {\"errors\": 0.12041449203445737, \"time-step\": 1555}, {\"errors\": 0.12040495536077354, \"time-step\": 1556}, {\"errors\": 0.12039539934427096, \"time-step\": 1557}, {\"errors\": 0.12038582395181899, \"time-step\": 1558}, {\"errors\": 0.12037622915027005, \"time-step\": 1559}, {\"errors\": 0.12036661490646025, \"time-step\": 1560}, {\"errors\": 0.12035698118720956, \"time-step\": 1561}, {\"errors\": 0.12034732795932201, \"time-step\": 1562}, {\"errors\": 0.12033765518958595, \"time-step\": 1563}, {\"errors\": 0.12032796284477455, \"time-step\": 1564}, {\"errors\": 0.1203182508916459, \"time-step\": 1565}, {\"errors\": 0.12030851929694338, \"time-step\": 1566}, {\"errors\": 0.12029876802739599, \"time-step\": 1567}, {\"errors\": 0.12028899704971857, \"time-step\": 1568}, {\"errors\": 0.12027920633061218, \"time-step\": 1569}, {\"errors\": 0.12026939583676438, \"time-step\": 1570}, {\"errors\": 0.12025956553484947, \"time-step\": 1571}, {\"errors\": 0.12024971539152893, \"time-step\": 1572}, {\"errors\": 0.12023984537345168, \"time-step\": 1573}, {\"errors\": 0.12022995544725434, \"time-step\": 1574}, {\"errors\": 0.12022004557956165, \"time-step\": 1575}, {\"errors\": 0.12021011573698664, \"time-step\": 1576}, {\"errors\": 0.12020016588613111, \"time-step\": 1577}, {\"errors\": 0.12019019599358591, \"time-step\": 1578}, {\"errors\": 0.12018020602593124, \"time-step\": 1579}, {\"errors\": 0.12017019594973695, \"time-step\": 1580}, {\"errors\": 0.12016016573156296, \"time-step\": 1581}, {\"errors\": 0.12015011533795952, \"time-step\": 1582}, {\"errors\": 0.12014004473546766, \"time-step\": 1583}, {\"errors\": 0.12012995389061928, \"time-step\": 1584}, {\"errors\": 0.12011984276993791, \"time-step\": 1585}, {\"errors\": 0.12010971133993856, \"time-step\": 1586}, {\"errors\": 0.12009955956712848, \"time-step\": 1587}, {\"errors\": 0.12008938741800732, \"time-step\": 1588}, {\"errors\": 0.12007919485906746, \"time-step\": 1589}, {\"errors\": 0.12006898185679446, \"time-step\": 1590}, {\"errors\": 0.12005874837766738, \"time-step\": 1591}, {\"errors\": 0.12004849438815918, \"time-step\": 1592}, {\"errors\": 0.12003821985473694, \"time-step\": 1593}, {\"errors\": 0.1200279247438624, \"time-step\": 1594}, {\"errors\": 0.1200176090219923, \"time-step\": 1595}, {\"errors\": 0.12000727265557859, \"time-step\": 1596}, {\"errors\": 0.11999691561106904, \"time-step\": 1597}, {\"errors\": 0.11998653785490755, \"time-step\": 1598}, {\"errors\": 0.11997613935353427, \"time-step\": 1599}, {\"errors\": 0.11996572007338638, \"time-step\": 1600}, {\"errors\": 0.11995527998089828, \"time-step\": 1601}, {\"errors\": 0.1199448190425019, \"time-step\": 1602}, {\"errors\": 0.11993433722462726, \"time-step\": 1603}, {\"errors\": 0.11992383449370281, \"time-step\": 1604}, {\"errors\": 0.1199133108161557, \"time-step\": 1605}, {\"errors\": 0.11990276615841233, \"time-step\": 1606}, {\"errors\": 0.11989220048689876, \"time-step\": 1607}, {\"errors\": 0.11988161376804096, \"time-step\": 1608}, {\"errors\": 0.11987100596826541, \"time-step\": 1609}, {\"errors\": 0.11986037705399934, \"time-step\": 1610}, {\"errors\": 0.11984972699167128, \"time-step\": 1611}, {\"errors\": 0.11983905574771135, \"time-step\": 1612}, {\"errors\": 0.11982836328855179, \"time-step\": 1613}, {\"errors\": 0.1198176495806273, \"time-step\": 1614}, {\"errors\": 0.11980691459037557, \"time-step\": 1615}, {\"errors\": 0.11979615828423752, \"time-step\": 1616}, {\"errors\": 0.11978538062865793, \"time-step\": 1617}, {\"errors\": 0.1197745815900858, \"time-step\": 1618}, {\"errors\": 0.11976376113497471, \"time-step\": 1619}, {\"errors\": 0.11975291922978334, \"time-step\": 1620}, {\"errors\": 0.11974205584097596, \"time-step\": 1621}, {\"errors\": 0.1197311709350227, \"time-step\": 1622}, {\"errors\": 0.11972026447840015, \"time-step\": 1623}, {\"errors\": 0.11970933643759178, \"time-step\": 1624}, {\"errors\": 0.11969838677908838, \"time-step\": 1625}, {\"errors\": 0.11968741546938853, \"time-step\": 1626}, {\"errors\": 0.11967642247499896, \"time-step\": 1627}, {\"errors\": 0.1196654077624352, \"time-step\": 1628}, {\"errors\": 0.11965437129822183, \"time-step\": 1629}, {\"errors\": 0.11964331304889309, \"time-step\": 1630}, {\"errors\": 0.1196322329809934, \"time-step\": 1631}, {\"errors\": 0.11962113106107766, \"time-step\": 1632}, {\"errors\": 0.11961000725571183, \"time-step\": 1633}, {\"errors\": 0.1195988615314734, \"time-step\": 1634}, {\"errors\": 0.1195876938549518, \"time-step\": 1635}, {\"errors\": 0.11957650419274915, \"time-step\": 1636}, {\"errors\": 0.11956529251148039, \"time-step\": 1637}, {\"errors\": 0.11955405877777386, \"time-step\": 1638}, {\"errors\": 0.1195428029582721, \"time-step\": 1639}, {\"errors\": 0.1195315250196319, \"time-step\": 1640}, {\"errors\": 0.11952022492852507, \"time-step\": 1641}, {\"errors\": 0.11950890265163899, \"time-step\": 1642}, {\"errors\": 0.11949755815567689, \"time-step\": 1643}, {\"errors\": 0.1194861914073585, \"time-step\": 1644}, {\"errors\": 0.11947480237342062, \"time-step\": 1645}, {\"errors\": 0.11946339102061748, \"time-step\": 1646}, {\"errors\": 0.11945195731572134, \"time-step\": 1647}, {\"errors\": 0.1194405012255231, \"time-step\": 1648}, {\"errors\": 0.11942902271683262, \"time-step\": 1649}, {\"errors\": 0.11941752175647935, \"time-step\": 1650}, {\"errors\": 0.11940599831131311, \"time-step\": 1651}, {\"errors\": 0.11939445234820403, \"time-step\": 1652}, {\"errors\": 0.11938288383404372, \"time-step\": 1653}, {\"errors\": 0.1193712927357454, \"time-step\": 1654}, {\"errors\": 0.11935967902024464, \"time-step\": 1655}, {\"errors\": 0.11934804265449979, \"time-step\": 1656}, {\"errors\": 0.11933638360549254, \"time-step\": 1657}, {\"errors\": 0.11932470184022873, \"time-step\": 1658}, {\"errors\": 0.11931299732573838, \"time-step\": 1659}, {\"errors\": 0.11930127002907684, \"time-step\": 1660}, {\"errors\": 0.11928951991732485, \"time-step\": 1661}, {\"errors\": 0.11927774695758947, \"time-step\": 1662}, {\"errors\": 0.1192659511170044, \"time-step\": 1663}, {\"errors\": 0.11925413236273072, \"time-step\": 1664}, {\"errors\": 0.1192422906619574, \"time-step\": 1665}, {\"errors\": 0.11923042598190185, \"time-step\": 1666}, {\"errors\": 0.11921853828981047, \"time-step\": 1667}, {\"errors\": 0.11920662755295938, \"time-step\": 1668}, {\"errors\": 0.1191946937386549, \"time-step\": 1669}, {\"errors\": 0.11918273681423412, \"time-step\": 1670}, {\"errors\": 0.11917075674706547, \"time-step\": 1671}, {\"errors\": 0.11915875350454957, \"time-step\": 1672}, {\"errors\": 0.11914672705411938, \"time-step\": 1673}, {\"errors\": 0.11913467736324125, \"time-step\": 1674}, {\"errors\": 0.11912260439941522, \"time-step\": 1675}, {\"errors\": 0.11911050813017579, \"time-step\": 1676}, {\"errors\": 0.11909838852309254, \"time-step\": 1677}, {\"errors\": 0.1190862455457705, \"time-step\": 1678}, {\"errors\": 0.11907407916585117, \"time-step\": 1679}, {\"errors\": 0.11906188935101272, \"time-step\": 1680}, {\"errors\": 0.11904967606897107, \"time-step\": 1681}, {\"errors\": 0.11903743928747995, \"time-step\": 1682}, {\"errors\": 0.11902517897433218, \"time-step\": 1683}, {\"errors\": 0.11901289509735972, \"time-step\": 1684}, {\"errors\": 0.1190005876244347, \"time-step\": 1685}, {\"errors\": 0.11898825652346985, \"time-step\": 1686}, {\"errors\": 0.11897590176241926, \"time-step\": 1687}, {\"errors\": 0.11896352330927892, \"time-step\": 1688}, {\"errors\": 0.11895112113208753, \"time-step\": 1689}, {\"errors\": 0.11893869519892697, \"time-step\": 1690}, {\"errors\": 0.11892624547792302, \"time-step\": 1691}, {\"errors\": 0.11891377193724614, \"time-step\": 1692}, {\"errors\": 0.11890127454511193, \"time-step\": 1693}, {\"errors\": 0.11888875326978196, \"time-step\": 1694}, {\"errors\": 0.11887620807956434, \"time-step\": 1695}, {\"errors\": 0.11886363894281443, \"time-step\": 1696}, {\"errors\": 0.11885104582793554, \"time-step\": 1697}, {\"errors\": 0.1188384287033796, \"time-step\": 1698}, {\"errors\": 0.11882578753764775, \"time-step\": 1699}, {\"errors\": 0.1188131222992911, \"time-step\": 1700}, {\"errors\": 0.11880043295691146, \"time-step\": 1701}, {\"errors\": 0.11878771947916206, \"time-step\": 1702}, {\"errors\": 0.118774981834748, \"time-step\": 1703}, {\"errors\": 0.11876221999242714, \"time-step\": 1704}, {\"errors\": 0.11874943392101098, \"time-step\": 1705}, {\"errors\": 0.11873662358936493, \"time-step\": 1706}, {\"errors\": 0.11872378896640928, \"time-step\": 1707}, {\"errors\": 0.11871093002112004, \"time-step\": 1708}, {\"errors\": 0.11869804672252926, \"time-step\": 1709}, {\"errors\": 0.1186851390397262, \"time-step\": 1710}, {\"errors\": 0.11867220694185765, \"time-step\": 1711}, {\"errors\": 0.11865925039812891, \"time-step\": 1712}, {\"errors\": 0.11864626937780434, \"time-step\": 1713}, {\"errors\": 0.11863326385020834, \"time-step\": 1714}, {\"errors\": 0.11862023378472575, \"time-step\": 1715}, {\"errors\": 0.1186071791508029, \"time-step\": 1716}, {\"errors\": 0.11859409991794806, \"time-step\": 1717}, {\"errors\": 0.11858099605573248, \"time-step\": 1718}, {\"errors\": 0.11856786753379084, \"time-step\": 1719}, {\"errors\": 0.11855471432182214, \"time-step\": 1720}, {\"errors\": 0.11854153638959056, \"time-step\": 1721}, {\"errors\": 0.11852833370692596, \"time-step\": 1722}, {\"errors\": 0.11851510624372491, \"time-step\": 1723}, {\"errors\": 0.11850185396995117, \"time-step\": 1724}, {\"errors\": 0.11848857685563663, \"time-step\": 1725}, {\"errors\": 0.11847527487088211, \"time-step\": 1726}, {\"errors\": 0.11846194798585798, \"time-step\": 1727}, {\"errors\": 0.11844859617080498, \"time-step\": 1728}, {\"errors\": 0.11843521939603513, \"time-step\": 1729}, {\"errors\": 0.11842181763193228, \"time-step\": 1730}, {\"errors\": 0.11840839084895308, \"time-step\": 1731}, {\"errors\": 0.1183949390176277, \"time-step\": 1732}, {\"errors\": 0.11838146210856042, \"time-step\": 1733}, {\"errors\": 0.11836796009243084, \"time-step\": 1734}, {\"errors\": 0.11835443293999437, \"time-step\": 1735}, {\"errors\": 0.118340880622083, \"time-step\": 1736}, {\"errors\": 0.11832730310960622, \"time-step\": 1737}, {\"errors\": 0.1183137003735518, \"time-step\": 1738}, {\"errors\": 0.11830007238498663, \"time-step\": 1739}, {\"errors\": 0.11828641911505738, \"time-step\": 1740}, {\"errors\": 0.11827274053499143, \"time-step\": 1741}, {\"errors\": 0.11825903661609768, \"time-step\": 1742}, {\"errors\": 0.11824530732976729, \"time-step\": 1743}, {\"errors\": 0.11823155264747463, \"time-step\": 1744}, {\"errors\": 0.11821777254077795, \"time-step\": 1745}, {\"errors\": 0.1182039669813202, \"time-step\": 1746}, {\"errors\": 0.11819013594083011, \"time-step\": 1747}, {\"errors\": 0.11817627939112262, \"time-step\": 1748}, {\"errors\": 0.11816239730410008, \"time-step\": 1749}, {\"errors\": 0.1181484896517529, \"time-step\": 1750}, {\"errors\": 0.1181345564061603, \"time-step\": 1751}, {\"errors\": 0.11812059753949139, \"time-step\": 1752}, {\"errors\": 0.11810661302400582, \"time-step\": 1753}, {\"errors\": 0.1180926028320547, \"time-step\": 1754}, {\"errors\": 0.11807856693608144, \"time-step\": 1755}, {\"errors\": 0.11806450530862259, \"time-step\": 1756}, {\"errors\": 0.11805041792230872, \"time-step\": 1757}, {\"errors\": 0.11803630474986518, \"time-step\": 1758}, {\"errors\": 0.11802216576411315, \"time-step\": 1759}, {\"errors\": 0.11800800093797027, \"time-step\": 1760}, {\"errors\": 0.11799381024445163, \"time-step\": 1761}, {\"errors\": 0.1179795936566707, \"time-step\": 1762}, {\"errors\": 0.11796535114783999, \"time-step\": 1763}, {\"errors\": 0.11795108269127211, \"time-step\": 1764}, {\"errors\": 0.11793678826038065, \"time-step\": 1765}, {\"errors\": 0.11792246782868085, \"time-step\": 1766}, {\"errors\": 0.11790812136979066, \"time-step\": 1767}, {\"errors\": 0.11789374885743166, \"time-step\": 1768}, {\"errors\": 0.1178793502654297, \"time-step\": 1769}, {\"errors\": 0.11786492556771608, \"time-step\": 1770}, {\"errors\": 0.11785047473832812, \"time-step\": 1771}, {\"errors\": 0.11783599775141047, \"time-step\": 1772}, {\"errors\": 0.11782149458121552, \"time-step\": 1773}, {\"errors\": 0.11780696520210468, \"time-step\": 1774}, {\"errors\": 0.11779240958854909, \"time-step\": 1775}, {\"errors\": 0.11777782771513054, \"time-step\": 1776}, {\"errors\": 0.11776321955654231, \"time-step\": 1777}, {\"errors\": 0.11774858508759031, \"time-step\": 1778}, {\"errors\": 0.1177339242831937, \"time-step\": 1779}, {\"errors\": 0.11771923711838603, \"time-step\": 1780}, {\"errors\": 0.1177045235683159, \"time-step\": 1781}, {\"errors\": 0.11768978360824814, \"time-step\": 1782}, {\"errors\": 0.11767501721356445, \"time-step\": 1783}, {\"errors\": 0.11766022435976467, \"time-step\": 1784}, {\"errors\": 0.11764540502246731, \"time-step\": 1785}, {\"errors\": 0.11763055917741069, \"time-step\": 1786}, {\"errors\": 0.1176156868004539, \"time-step\": 1787}, {\"errors\": 0.11760078786757758, \"time-step\": 1788}, {\"errors\": 0.11758586235488486, \"time-step\": 1789}, {\"errors\": 0.11757091023860243, \"time-step\": 1790}, {\"errors\": 0.1175559314950813, \"time-step\": 1791}, {\"errors\": 0.11754092610079792, \"time-step\": 1792}, {\"errors\": 0.11752589403235483, \"time-step\": 1793}, {\"errors\": 0.11751083526648193, \"time-step\": 1794}, {\"errors\": 0.11749574978003717, \"time-step\": 1795}, {\"errors\": 0.11748063755000754, \"time-step\": 1796}, {\"errors\": 0.1174654985535101, \"time-step\": 1797}, {\"errors\": 0.11745033276779288, \"time-step\": 1798}, {\"errors\": 0.11743514017023562, \"time-step\": 1799}, {\"errors\": 0.11741992073835122, \"time-step\": 1800}, {\"errors\": 0.11740467444978608, \"time-step\": 1801}, {\"errors\": 0.11738940128232142, \"time-step\": 1802}, {\"errors\": 0.11737410121387422, \"time-step\": 1803}, {\"errors\": 0.11735877422249802, \"time-step\": 1804}, {\"errors\": 0.11734342028638389, \"time-step\": 1805}, {\"errors\": 0.1173280393838616, \"time-step\": 1806}, {\"errors\": 0.11731263149340022, \"time-step\": 1807}, {\"errors\": 0.1172971965936094, \"time-step\": 1808}, {\"errors\": 0.11728173466324021, \"time-step\": 1809}, {\"errors\": 0.11726624568118596, \"time-step\": 1810}, {\"errors\": 0.11725072962648342, \"time-step\": 1811}, {\"errors\": 0.1172351864783136, \"time-step\": 1812}, {\"errors\": 0.11721961621600271, \"time-step\": 1813}, {\"errors\": 0.11720401881902323, \"time-step\": 1814}, {\"errors\": 0.11718839426699486, \"time-step\": 1815}, {\"errors\": 0.11717274253968529, \"time-step\": 1816}, {\"errors\": 0.1171570636170115, \"time-step\": 1817}, {\"errors\": 0.11714135747904045, \"time-step\": 1818}, {\"errors\": 0.11712562410599023, \"time-step\": 1819}, {\"errors\": 0.11710986347823077, \"time-step\": 1820}, {\"errors\": 0.11709407557628522, \"time-step\": 1821}, {\"errors\": 0.11707826038083055, \"time-step\": 1822}, {\"errors\": 0.11706241787269869, \"time-step\": 1823}, {\"errors\": 0.11704654803287745, \"time-step\": 1824}, {\"errors\": 0.1170306508425116, \"time-step\": 1825}, {\"errors\": 0.11701472628290369, \"time-step\": 1826}, {\"errors\": 0.11699877433551513, \"time-step\": 1827}, {\"errors\": 0.11698279498196709, \"time-step\": 1828}, {\"errors\": 0.11696678820404163, \"time-step\": 1829}, {\"errors\": 0.11695075398368249, \"time-step\": 1830}, {\"errors\": 0.11693469230299611, \"time-step\": 1831}, {\"errors\": 0.1169186031442527, \"time-step\": 1832}, {\"errors\": 0.11690248648988719, \"time-step\": 1833}, {\"errors\": 0.11688634232250011, \"time-step\": 1834}, {\"errors\": 0.11687017062485863, \"time-step\": 1835}, {\"errors\": 0.11685397137989773, \"time-step\": 1836}, {\"errors\": 0.11683774457072071, \"time-step\": 1837}, {\"errors\": 0.11682149018060067, \"time-step\": 1838}, {\"errors\": 0.11680520819298121, \"time-step\": 1839}, {\"errors\": 0.11678889859147748, \"time-step\": 1840}, {\"errors\": 0.11677256135987714, \"time-step\": 1841}, {\"errors\": 0.11675619648214135, \"time-step\": 1842}, {\"errors\": 0.11673980394240585, \"time-step\": 1843}, {\"errors\": 0.11672338372498173, \"time-step\": 1844}, {\"errors\": 0.11670693581435648, \"time-step\": 1845}, {\"errors\": 0.1166904601951953, \"time-step\": 1846}, {\"errors\": 0.11667395685234147, \"time-step\": 1847}, {\"errors\": 0.11665742577081778, \"time-step\": 1848}, {\"errors\": 0.11664086693582744, \"time-step\": 1849}, {\"errors\": 0.1166242803327549, \"time-step\": 1850}, {\"errors\": 0.11660766594716704, \"time-step\": 1851}, {\"errors\": 0.11659102376481387, \"time-step\": 1852}, {\"errors\": 0.11657435377162986, \"time-step\": 1853}, {\"errors\": 0.1165576559537346, \"time-step\": 1854}, {\"errors\": 0.11654093029743394, \"time-step\": 1855}, {\"errors\": 0.11652417678922097, \"time-step\": 1856}, {\"errors\": 0.1165073954157769, \"time-step\": 1857}, {\"errors\": 0.11649058616397209, \"time-step\": 1858}, {\"errors\": 0.11647374902086709, \"time-step\": 1859}, {\"errors\": 0.11645688397371345, \"time-step\": 1860}, {\"errors\": 0.11643999100995484, \"time-step\": 1861}, {\"errors\": 0.11642307011722791, \"time-step\": 1862}, {\"errors\": 0.11640612128336342, \"time-step\": 1863}, {\"errors\": 0.11638914449638699, \"time-step\": 1864}, {\"errors\": 0.11637213974452026, \"time-step\": 1865}, {\"errors\": 0.11635510701618176, \"time-step\": 1866}, {\"errors\": 0.11633804629998776, \"time-step\": 1867}, {\"errors\": 0.11632095758475361, \"time-step\": 1868}, {\"errors\": 0.11630384085949425, \"time-step\": 1869}, {\"errors\": 0.11628669611342538, \"time-step\": 1870}, {\"errors\": 0.11626952333596458, \"time-step\": 1871}, {\"errors\": 0.1162523225167319, \"time-step\": 1872}, {\"errors\": 0.11623509364555121, \"time-step\": 1873}, {\"errors\": 0.11621783671245081, \"time-step\": 1874}, {\"errors\": 0.11620055170766458, \"time-step\": 1875}, {\"errors\": 0.11618323862163296, \"time-step\": 1876}, {\"errors\": 0.11616589744500377, \"time-step\": 1877}, {\"errors\": 0.11614852816863314, \"time-step\": 1878}, {\"errors\": 0.11613113078358664, \"time-step\": 1879}, {\"errors\": 0.11611370528114015, \"time-step\": 1880}, {\"errors\": 0.11609625165278062, \"time-step\": 1881}, {\"errors\": 0.11607876989020723, \"time-step\": 1882}, {\"errors\": 0.11606125998533229, \"time-step\": 1883}, {\"errors\": 0.11604372193028209, \"time-step\": 1884}, {\"errors\": 0.1160261557173979, \"time-step\": 1885}, {\"errors\": 0.11600856133923691, \"time-step\": 1886}, {\"errors\": 0.11599093878857311, \"time-step\": 1887}, {\"errors\": 0.11597328805839822, \"time-step\": 1888}, {\"errors\": 0.11595560914192268, \"time-step\": 1889}, {\"errors\": 0.11593790203257648, \"time-step\": 1890}, {\"errors\": 0.11592016672401016, \"time-step\": 1891}, {\"errors\": 0.11590240321009565, \"time-step\": 1892}, {\"errors\": 0.11588461148492732, \"time-step\": 1893}, {\"errors\": 0.11586679154282273, \"time-step\": 1894}, {\"errors\": 0.1158489433783235, \"time-step\": 1895}, {\"errors\": 0.11583106698619655, \"time-step\": 1896}, {\"errors\": 0.1158131623614346, \"time-step\": 1897}, {\"errors\": 0.11579522949925725, \"time-step\": 1898}, {\"errors\": 0.11577726839511204, \"time-step\": 1899}, {\"errors\": 0.11575927904467495, \"time-step\": 1900}, {\"errors\": 0.1157412614438516, \"time-step\": 1901}, {\"errors\": 0.11572321558877813, \"time-step\": 1902}, {\"errors\": 0.11570514147582187, \"time-step\": 1903}, {\"errors\": 0.11568703910158243, \"time-step\": 1904}, {\"errors\": 0.11566890846289249, \"time-step\": 1905}, {\"errors\": 0.11565074955681873, \"time-step\": 1906}, {\"errors\": 0.11563256238066252, \"time-step\": 1907}, {\"errors\": 0.1156143469319611, \"time-step\": 1908}, {\"errors\": 0.11559610320848812, \"time-step\": 1909}, {\"errors\": 0.11557783120825471, \"time-step\": 1910}, {\"errors\": 0.11555953092951027, \"time-step\": 1911}, {\"errors\": 0.11554120237074325, \"time-step\": 1912}, {\"errors\": 0.11552284553068223, \"time-step\": 1913}, {\"errors\": 0.11550446040829643, \"time-step\": 1914}, {\"errors\": 0.1154860470027968, \"time-step\": 1915}, {\"errors\": 0.11546760531363673, \"time-step\": 1916}, {\"errors\": 0.11544913534051307, \"time-step\": 1917}, {\"errors\": 0.11543063708336662, \"time-step\": 1918}, {\"errors\": 0.11541211054238332, \"time-step\": 1919}, {\"errors\": 0.11539355571799471, \"time-step\": 1920}, {\"errors\": 0.11537497261087916, \"time-step\": 1921}, {\"errors\": 0.11535636122196227, \"time-step\": 1922}, {\"errors\": 0.11533772155241798, \"time-step\": 1923}, {\"errors\": 0.1153190536036691, \"time-step\": 1924}, {\"errors\": 0.11530035737738839, \"time-step\": 1925}, {\"errors\": 0.11528163287549922, \"time-step\": 1926}, {\"errors\": 0.11526288010017627, \"time-step\": 1927}, {\"errors\": 0.11524409905384642, \"time-step\": 1928}, {\"errors\": 0.11522528973918952, \"time-step\": 1929}, {\"errors\": 0.11520645215913916, \"time-step\": 1930}, {\"errors\": 0.11518758631688336, \"time-step\": 1931}, {\"errors\": 0.11516869221586543, \"time-step\": 1932}, {\"errors\": 0.1151497698597847, \"time-step\": 1933}, {\"errors\": 0.11513081925259723, \"time-step\": 1934}, {\"errors\": 0.11511184039851666, \"time-step\": 1935}, {\"errors\": 0.1150928333020147, \"time-step\": 1936}, {\"errors\": 0.11507379796782226, \"time-step\": 1937}, {\"errors\": 0.11505473440092986, \"time-step\": 1938}, {\"errors\": 0.11503564260658838, \"time-step\": 1939}, {\"errors\": 0.11501652259031003, \"time-step\": 1940}, {\"errors\": 0.11499737435786875, \"time-step\": 1941}, {\"errors\": 0.11497819791530112, \"time-step\": 1942}, {\"errors\": 0.11495899326890695, \"time-step\": 1943}, {\"errors\": 0.11493976042525006, \"time-step\": 1944}, {\"errors\": 0.11492049939115892, \"time-step\": 1945}, {\"errors\": 0.11490121017372738, \"time-step\": 1946}, {\"errors\": 0.11488189278031521, \"time-step\": 1947}, {\"errors\": 0.1148625472185491, \"time-step\": 1948}, {\"errors\": 0.11484317349632278, \"time-step\": 1949}, {\"errors\": 0.11482377162179824, \"time-step\": 1950}, {\"errors\": 0.11480434160340611, \"time-step\": 1951}, {\"errors\": 0.11478488344984628, \"time-step\": 1952}, {\"errors\": 0.11476539717008866, \"time-step\": 1953}, {\"errors\": 0.1147458827733736, \"time-step\": 1954}, {\"errors\": 0.11472634026921294, \"time-step\": 1955}, {\"errors\": 0.11470676966739016, \"time-step\": 1956}, {\"errors\": 0.11468717097796115, \"time-step\": 1957}, {\"errors\": 0.1146675442112551, \"time-step\": 1958}, {\"errors\": 0.11464788937787468, \"time-step\": 1959}, {\"errors\": 0.11462820648869682, \"time-step\": 1960}, {\"errors\": 0.11460849555487336, \"time-step\": 1961}, {\"errors\": 0.11458875658783152, \"time-step\": 1962}, {\"errors\": 0.1145689895992745, \"time-step\": 1963}, {\"errors\": 0.11454919460118215, \"time-step\": 1964}, {\"errors\": 0.11452937160581128, \"time-step\": 1965}, {\"errors\": 0.11450952062569653, \"time-step\": 1966}, {\"errors\": 0.11448964167365064, \"time-step\": 1967}, {\"errors\": 0.11446973476276509, \"time-step\": 1968}, {\"errors\": 0.1144497999064108, \"time-step\": 1969}, {\"errors\": 0.11442983711823826, \"time-step\": 1970}, {\"errors\": 0.11440984641217841, \"time-step\": 1971}, {\"errors\": 0.11438982780244299, \"time-step\": 1972}, {\"errors\": 0.11436978130352501, \"time-step\": 1973}, {\"errors\": 0.11434970693019933, \"time-step\": 1974}, {\"errors\": 0.11432960469752312, \"time-step\": 1975}, {\"errors\": 0.11430947462083621, \"time-step\": 1976}, {\"errors\": 0.11428931671576179, \"time-step\": 1977}, {\"errors\": 0.1142691309982066, \"time-step\": 1978}, {\"errors\": 0.11424891748436164, \"time-step\": 1979}, {\"errors\": 0.11422867619070248, \"time-step\": 1980}, {\"errors\": 0.11420840713398965, \"time-step\": 1981}, {\"errors\": 0.11418811033126916, \"time-step\": 1982}, {\"errors\": 0.1141677857998729, \"time-step\": 1983}, {\"errors\": 0.11414743355741896, \"time-step\": 1984}, {\"errors\": 0.11412705362181223, \"time-step\": 1985}, {\"errors\": 0.11410664601124457, \"time-step\": 1986}, {\"errors\": 0.11408621074419531, \"time-step\": 1987}, {\"errors\": 0.11406574783943163, \"time-step\": 1988}, {\"errors\": 0.11404525731600895, \"time-step\": 1989}, {\"errors\": 0.11402473919327114, \"time-step\": 1990}, {\"errors\": 0.1140041934908511, \"time-step\": 1991}, {\"errors\": 0.11398362022867088, \"time-step\": 1992}, {\"errors\": 0.11396301942694217, \"time-step\": 1993}, {\"errors\": 0.11394239110616654, \"time-step\": 1994}, {\"errors\": 0.11392173528713576, \"time-step\": 1995}, {\"errors\": 0.1139010519909322, \"time-step\": 1996}, {\"errors\": 0.11388034123892901, \"time-step\": 1997}, {\"errors\": 0.11385960305279043, \"time-step\": 1998}, {\"errors\": 0.11383883745447218, \"time-step\": 1999}, {\"errors\": 0.11381804446622155, \"time-step\": 2000}, {\"errors\": 0.11379722411057774, \"time-step\": 2001}, {\"errors\": 0.1137763764103722, \"time-step\": 2002}, {\"errors\": 0.11375550138872875, \"time-step\": 2003}, {\"errors\": 0.11373459906906394, \"time-step\": 2004}, {\"errors\": 0.11371366947508699, \"time-step\": 2005}, {\"errors\": 0.11369271263080044, \"time-step\": 2006}, {\"errors\": 0.11367172856050001, \"time-step\": 2007}, {\"errors\": 0.11365071728877482, \"time-step\": 2008}, {\"errors\": 0.11362967884050783, \"time-step\": 2009}, {\"errors\": 0.11360861324087573, \"time-step\": 2010}, {\"errors\": 0.11358752051534923, \"time-step\": 2011}, {\"errors\": 0.11356640068969324, \"time-step\": 2012}, {\"errors\": 0.113545253789967, \"time-step\": 2013}, {\"errors\": 0.11352407984252409, \"time-step\": 2014}, {\"errors\": 0.11350287887401278, \"time-step\": 2015}, {\"errors\": 0.11348165091137594, \"time-step\": 2016}, {\"errors\": 0.11346039598185134, \"time-step\": 2017}, {\"errors\": 0.1134391141129715, \"time-step\": 2018}, {\"errors\": 0.1134178053325641, \"time-step\": 2019}, {\"errors\": 0.11339646966875169, \"time-step\": 2020}, {\"errors\": 0.11337510714995205, \"time-step\": 2021}, {\"errors\": 0.11335371780487812, \"time-step\": 2022}, {\"errors\": 0.11333230166253803, \"time-step\": 2023}, {\"errors\": 0.11331085875223526, \"time-step\": 2024}, {\"errors\": 0.11328938910356838, \"time-step\": 2025}, {\"errors\": 0.11326789274643147, \"time-step\": 2026}, {\"errors\": 0.11324636971101378, \"time-step\": 2027}, {\"errors\": 0.11322482002779996, \"time-step\": 2028}, {\"errors\": 0.11320324372756978, \"time-step\": 2029}, {\"errors\": 0.11318164084139841, \"time-step\": 2030}, {\"errors\": 0.11316001140065618, \"time-step\": 2031}, {\"errors\": 0.11313835543700859, \"time-step\": 2032}, {\"errors\": 0.1131166729824162, \"time-step\": 2033}, {\"errors\": 0.11309496406913466, \"time-step\": 2034}, {\"errors\": 0.11307322872971465, \"time-step\": 2035}, {\"errors\": 0.11305146699700153, \"time-step\": 2036}, {\"errors\": 0.11302967890413557, \"time-step\": 2037}, {\"errors\": 0.11300786448455169, \"time-step\": 2038}, {\"errors\": 0.11298602377197928, \"time-step\": 2039}, {\"errors\": 0.11296415680044206, \"time-step\": 2040}, {\"errors\": 0.11294226360425824, \"time-step\": 2041}, {\"errors\": 0.11292034421803986, \"time-step\": 2042}, {\"errors\": 0.11289839867669305, \"time-step\": 2043}, {\"errors\": 0.11287642701541771, \"time-step\": 2044}, {\"errors\": 0.11285442926970712, \"time-step\": 2045}, {\"errors\": 0.11283240547534819, \"time-step\": 2046}, {\"errors\": 0.11281035566842072, \"time-step\": 2047}, {\"errors\": 0.1127882798852976, \"time-step\": 2048}, {\"errors\": 0.11276617816264443, \"time-step\": 2049}, {\"errors\": 0.11274405053741918, \"time-step\": 2050}, {\"errors\": 0.11272189704687208, \"time-step\": 2051}, {\"errors\": 0.11269971772854526, \"time-step\": 2052}, {\"errors\": 0.11267751262027262, \"time-step\": 2053}, {\"errors\": 0.11265528176017922, \"time-step\": 2054}, {\"errors\": 0.11263302518668139, \"time-step\": 2055}, {\"errors\": 0.11261074293848615, \"time-step\": 2056}, {\"errors\": 0.11258843505459093, \"time-step\": 2057}, {\"errors\": 0.11256610157428329, \"time-step\": 2058}, {\"errors\": 0.11254374253714063, \"time-step\": 2059}, {\"errors\": 0.11252135798302966, \"time-step\": 2060}, {\"errors\": 0.11249894795210613, \"time-step\": 2061}, {\"errors\": 0.11247651248481452, \"time-step\": 2062}, {\"errors\": 0.11245405162188754, \"time-step\": 2063}, {\"errors\": 0.11243156540434575, \"time-step\": 2064}, {\"errors\": 0.11240905387349728, \"time-step\": 2065}, {\"errors\": 0.11238651707093718, \"time-step\": 2066}, {\"errors\": 0.11236395503854715, \"time-step\": 2067}, {\"errors\": 0.11234136781849513, \"time-step\": 2068}, {\"errors\": 0.11231875545323455, \"time-step\": 2069}, {\"errors\": 0.11229611798550435, \"time-step\": 2070}, {\"errors\": 0.1122734554583279, \"time-step\": 2071}, {\"errors\": 0.11225076791501315, \"time-step\": 2072}, {\"errors\": 0.11222805539915164, \"time-step\": 2073}, {\"errors\": 0.1122053179546181, \"time-step\": 2074}, {\"errors\": 0.11218255562557017, \"time-step\": 2075}, {\"errors\": 0.11215976845644748, \"time-step\": 2076}, {\"errors\": 0.11213695649197143, \"time-step\": 2077}, {\"errors\": 0.11211411977714439, \"time-step\": 2078}, {\"errors\": 0.11209125835724928, \"time-step\": 2079}, {\"errors\": 0.11206837227784894, \"time-step\": 2080}, {\"errors\": 0.11204546158478558, \"time-step\": 2081}, {\"errors\": 0.11202252632417997, \"time-step\": 2082}, {\"errors\": 0.11199956654243115, \"time-step\": 2083}, {\"errors\": 0.11197658228621557, \"time-step\": 2084}, {\"errors\": 0.11195357360248653, \"time-step\": 2085}, {\"errors\": 0.11193054053847346, \"time-step\": 2086}, {\"errors\": 0.11190748314168139, \"time-step\": 2087}, {\"errors\": 0.11188440145989013, \"time-step\": 2088}, {\"errors\": 0.11186129554115368, \"time-step\": 2089}, {\"errors\": 0.11183816543379949, \"time-step\": 2090}, {\"errors\": 0.11181501118642774, \"time-step\": 2091}, {\"errors\": 0.11179183284791078, \"time-step\": 2092}, {\"errors\": 0.11176863046739208, \"time-step\": 2093}, {\"errors\": 0.11174540409428571, \"time-step\": 2094}, {\"errors\": 0.11172215377827577, \"time-step\": 2095}, {\"errors\": 0.11169887956931507, \"time-step\": 2096}, {\"errors\": 0.11167558151762494, \"time-step\": 2097}, {\"errors\": 0.11165225967369408, \"time-step\": 2098}, {\"errors\": 0.11162891408827792, \"time-step\": 2099}, {\"errors\": 0.1116055448123977, \"time-step\": 2100}, {\"errors\": 0.11158215189733978, \"time-step\": 2101}, {\"errors\": 0.11155873539465468, \"time-step\": 2102}, {\"errors\": 0.11153529535615639, \"time-step\": 2103}, {\"errors\": 0.11151183183392133, \"time-step\": 2104}, {\"errors\": 0.11148834488028767, \"time-step\": 2105}, {\"errors\": 0.11146483454785416, \"time-step\": 2106}, {\"errors\": 0.11144130088947973, \"time-step\": 2107}, {\"errors\": 0.11141774395828213, \"time-step\": 2108}, {\"errors\": 0.11139416380763714, \"time-step\": 2109}, {\"errors\": 0.11137056049117791, \"time-step\": 2110}, {\"errors\": 0.11134693406279353, \"time-step\": 2111}, {\"errors\": 0.11132328457662867, \"time-step\": 2112}, {\"errors\": 0.11129961208708217, \"time-step\": 2113}, {\"errors\": 0.1112759166488062, \"time-step\": 2114}, {\"errors\": 0.1112521983167055, \"time-step\": 2115}, {\"errors\": 0.11122845714593604, \"time-step\": 2116}, {\"errors\": 0.11120469319190426, \"time-step\": 2117}, {\"errors\": 0.11118090651026602, \"time-step\": 2118}, {\"errors\": 0.1111570971569256, \"time-step\": 2119}, {\"errors\": 0.11113326518803446, \"time-step\": 2120}, {\"errors\": 0.11110941065999058, \"time-step\": 2121}, {\"errors\": 0.11108553362943707, \"time-step\": 2122}, {\"errors\": 0.11106163415326126, \"time-step\": 2123}, {\"errors\": 0.11103771228859366, \"time-step\": 2124}, {\"errors\": 0.11101376809280673, \"time-step\": 2125}, {\"errors\": 0.11098980162351396, \"time-step\": 2126}, {\"errors\": 0.11096581293856858, \"time-step\": 2127}, {\"errors\": 0.11094180209606276, \"time-step\": 2128}, {\"errors\": 0.11091776915432602, \"time-step\": 2129}, {\"errors\": 0.11089371417192445, \"time-step\": 2130}, {\"errors\": 0.11086963720765958, \"time-step\": 2131}, {\"errors\": 0.11084553832056696, \"time-step\": 2132}, {\"errors\": 0.11082141756991515, \"time-step\": 2133}, {\"errors\": 0.11079727501520463, \"time-step\": 2134}, {\"errors\": 0.11077311071616648, \"time-step\": 2135}, {\"errors\": 0.11074892473276116, \"time-step\": 2136}, {\"errors\": 0.11072471712517742, \"time-step\": 2137}, {\"errors\": 0.11070048795383111, \"time-step\": 2138}, {\"errors\": 0.11067623727936372, \"time-step\": 2139}, {\"errors\": 0.11065196516264136, \"time-step\": 2140}, {\"errors\": 0.1106276716647536, \"time-step\": 2141}, {\"errors\": 0.11060335684701178, \"time-step\": 2142}, {\"errors\": 0.11057902077094822, \"time-step\": 2143}, {\"errors\": 0.11055466349831478, \"time-step\": 2144}, {\"errors\": 0.11053028509108145, \"time-step\": 2145}, {\"errors\": 0.11050588561143516, \"time-step\": 2146}, {\"errors\": 0.11048146512177853, \"time-step\": 2147}, {\"errors\": 0.1104570236847285, \"time-step\": 2148}, {\"errors\": 0.11043256136311494, \"time-step\": 2149}, {\"errors\": 0.11040807821997944, \"time-step\": 2150}, {\"errors\": 0.1103835743185739, \"time-step\": 2151}, {\"errors\": 0.11035904972235916, \"time-step\": 2152}, {\"errors\": 0.11033450449500369, \"time-step\": 2153}, {\"errors\": 0.11030993870038217, \"time-step\": 2154}, {\"errors\": 0.11028535240257423, \"time-step\": 2155}, {\"errors\": 0.11026074566586286, \"time-step\": 2156}, {\"errors\": 0.11023611855473321, \"time-step\": 2157}, {\"errors\": 0.11021147113387106, \"time-step\": 2158}, {\"errors\": 0.11018680346816144, \"time-step\": 2159}, {\"errors\": 0.11016211562268727, \"time-step\": 2160}, {\"errors\": 0.11013740766272778, \"time-step\": 2161}, {\"errors\": 0.11011267965375729, \"time-step\": 2162}, {\"errors\": 0.11008793166144355, \"time-step\": 2163}, {\"errors\": 0.11006316375164633, \"time-step\": 2164}, {\"errors\": 0.1100383759904161, \"time-step\": 2165}, {\"errors\": 0.11001356844399235, \"time-step\": 2166}, {\"errors\": 0.10998874117880224, \"time-step\": 2167}, {\"errors\": 0.10996389426145911, \"time-step\": 2168}, {\"errors\": 0.10993902775876083, \"time-step\": 2169}, {\"errors\": 0.10991414173768858, \"time-step\": 2170}, {\"errors\": 0.10988923626540502, \"time-step\": 2171}, {\"errors\": 0.10986431140925298, \"time-step\": 2172}, {\"errors\": 0.10983936723675379, \"time-step\": 2173}, {\"errors\": 0.1098144038156059, \"time-step\": 2174}, {\"errors\": 0.1097894212136832, \"time-step\": 2175}, {\"errors\": 0.10976441949903347, \"time-step\": 2176}, {\"errors\": 0.1097393987398769, \"time-step\": 2177}, {\"errors\": 0.10971435900460452, \"time-step\": 2178}, {\"errors\": 0.10968930036177649, \"time-step\": 2179}, {\"errors\": 0.10966422288012068, \"time-step\": 2180}, {\"errors\": 0.10963912662853095, \"time-step\": 2181}, {\"errors\": 0.10961401167606556, \"time-step\": 2182}, {\"errors\": 0.10958887809194584, \"time-step\": 2183}, {\"errors\": 0.10956372594555405, \"time-step\": 2184}, {\"errors\": 0.10953855530643229, \"time-step\": 2185}, {\"errors\": 0.10951336624428053, \"time-step\": 2186}, {\"errors\": 0.10948815882895507, \"time-step\": 2187}, {\"errors\": 0.10946293313046701, \"time-step\": 2188}, {\"errors\": 0.10943768921898037, \"time-step\": 2189}, {\"errors\": 0.10941242716481073, \"time-step\": 2190}, {\"errors\": 0.10938714703842337, \"time-step\": 2191}, {\"errors\": 0.10936184891043157, \"time-step\": 2192}, {\"errors\": 0.10933653285159513, \"time-step\": 2193}, {\"errors\": 0.10931119893281846, \"time-step\": 2194}, {\"errors\": 0.10928584722514913, \"time-step\": 2195}, {\"errors\": 0.1092604777997759, \"time-step\": 2196}, {\"errors\": 0.10923509072802745, \"time-step\": 2197}, {\"errors\": 0.10920968608137016, \"time-step\": 2198}, {\"errors\": 0.10918426393140672, \"time-step\": 2199}, {\"errors\": 0.10915882434987444, \"time-step\": 2200}, {\"errors\": 0.10913336740864321, \"time-step\": 2201}, {\"errors\": 0.10910789317971427, \"time-step\": 2202}, {\"errors\": 0.10908240173521805, \"time-step\": 2203}, {\"errors\": 0.10905689314741258, \"time-step\": 2204}, {\"errors\": 0.10903136748868186, \"time-step\": 2205}, {\"errors\": 0.10900582483153387, \"time-step\": 2206}, {\"errors\": 0.10898026524859904, \"time-step\": 2207}, {\"errors\": 0.10895468881262842, \"time-step\": 2208}, {\"errors\": 0.10892909559649183, \"time-step\": 2209}, {\"errors\": 0.10890348567317626, \"time-step\": 2210}, {\"errors\": 0.1088778591157839, \"time-step\": 2211}, {\"errors\": 0.1088522159975305, \"time-step\": 2212}, {\"errors\": 0.10882655639174357, \"time-step\": 2213}, {\"errors\": 0.10880088037186056, \"time-step\": 2214}, {\"errors\": 0.10877518801142716, \"time-step\": 2215}, {\"errors\": 0.10874947938409525, \"time-step\": 2216}, {\"errors\": 0.1087237545636214, \"time-step\": 2217}, {\"errors\": 0.10869801362386494, \"time-step\": 2218}, {\"errors\": 0.10867225663878613, \"time-step\": 2219}, {\"errors\": 0.1086464836824444, \"time-step\": 2220}, {\"errors\": 0.10862069482899644, \"time-step\": 2221}, {\"errors\": 0.10859489015269448, \"time-step\": 2222}, {\"errors\": 0.10856906972788442, \"time-step\": 2223}, {\"errors\": 0.10854323362900407, \"time-step\": 2224}, {\"errors\": 0.10851738193058116, \"time-step\": 2225}, {\"errors\": 0.1084915147072317, \"time-step\": 2226}, {\"errors\": 0.108465632033658, \"time-step\": 2227}, {\"errors\": 0.10843973398464686, \"time-step\": 2228}, {\"errors\": 0.1084138206350678, \"time-step\": 2229}, {\"errors\": 0.1083878920598711, \"time-step\": 2230}, {\"errors\": 0.108361948334086, \"time-step\": 2231}, {\"errors\": 0.10833598953281887, \"time-step\": 2232}, {\"errors\": 0.10831001573125137, \"time-step\": 2233}, {\"errors\": 0.10828402700463848, \"time-step\": 2234}, {\"errors\": 0.10825802342830679, \"time-step\": 2235}, {\"errors\": 0.10823200507765246, \"time-step\": 2236}, {\"errors\": 0.10820597202813952, \"time-step\": 2237}, {\"errors\": 0.10817992435529791, \"time-step\": 2238}, {\"errors\": 0.10815386213472164, \"time-step\": 2239}, {\"errors\": 0.10812778544206689, \"time-step\": 2240}, {\"errors\": 0.10810169435305009, \"time-step\": 2241}, {\"errors\": 0.1080755889434462, \"time-step\": 2242}, {\"errors\": 0.10804946928908671, \"time-step\": 2243}, {\"errors\": 0.10802333546585774, \"time-step\": 2244}, {\"errors\": 0.1079971875496982, \"time-step\": 2245}, {\"errors\": 0.10797102561659787, \"time-step\": 2246}, {\"errors\": 0.10794484974259562, \"time-step\": 2247}, {\"errors\": 0.1079186600037774, \"time-step\": 2248}, {\"errors\": 0.10789245647627435, \"time-step\": 2249}, {\"errors\": 0.10786623923626104, \"time-step\": 2250}, {\"errors\": 0.10784000835995343, \"time-step\": 2251}, {\"errors\": 0.10781376392360704, \"time-step\": 2252}, {\"errors\": 0.10778750600351514, \"time-step\": 2253}, {\"errors\": 0.1077612346760066, \"time-step\": 2254}, {\"errors\": 0.10773495001744433, \"time-step\": 2255}, {\"errors\": 0.10770865210422303, \"time-step\": 2256}, {\"errors\": 0.10768234101276768, \"time-step\": 2257}, {\"errors\": 0.10765601681953131, \"time-step\": 2258}, {\"errors\": 0.10762967960099329, \"time-step\": 2259}, {\"errors\": 0.10760332943365736, \"time-step\": 2260}, {\"errors\": 0.10757696639404965, \"time-step\": 2261}, {\"errors\": 0.10755059055871703, \"time-step\": 2262}, {\"errors\": 0.107524202004225, \"time-step\": 2263}, {\"errors\": 0.10749780080715576, \"time-step\": 2264}, {\"errors\": 0.10747138704410646, \"time-step\": 2265}, {\"errors\": 0.10744496079168733, \"time-step\": 2266}, {\"errors\": 0.10741852212651944, \"time-step\": 2267}, {\"errors\": 0.10739207112523337, \"time-step\": 2268}, {\"errors\": 0.1073656078644667, \"time-step\": 2269}, {\"errors\": 0.1073391324208626, \"time-step\": 2270}, {\"errors\": 0.10731264487106759, \"time-step\": 2271}, {\"errors\": 0.10728614529173001, \"time-step\": 2272}, {\"errors\": 0.10725963375949765, \"time-step\": 2273}, {\"errors\": 0.10723311035101621, \"time-step\": 2274}, {\"errors\": 0.10720657514292739, \"time-step\": 2275}, {\"errors\": 0.10718002821186678, \"time-step\": 2276}, {\"errors\": 0.10715346963446222, \"time-step\": 2277}, {\"errors\": 0.1071268994873317, \"time-step\": 2278}, {\"errors\": 0.10710031784708168, \"time-step\": 2279}, {\"errors\": 0.10707372479030487, \"time-step\": 2280}, {\"errors\": 0.10704712039357886, \"time-step\": 2281}, {\"errors\": 0.10702050473346364, \"time-step\": 2282}, {\"errors\": 0.10699387788650021, \"time-step\": 2283}, {\"errors\": 0.10696723992920851, \"time-step\": 2284}, {\"errors\": 0.10694059093808536, \"time-step\": 2285}, {\"errors\": 0.10691393098960295, \"time-step\": 2286}, {\"errors\": 0.10688726016020662, \"time-step\": 2287}, {\"errors\": 0.10686057852631327, \"time-step\": 2288}, {\"errors\": 0.10683388616430922, \"time-step\": 2289}, {\"errors\": 0.10680718315054863, \"time-step\": 2290}, {\"errors\": 0.10678046956135132, \"time-step\": 2291}, {\"errors\": 0.10675374547300118, \"time-step\": 2292}, {\"errors\": 0.10672701096174422, \"time-step\": 2293}, {\"errors\": 0.10670026610378655, \"time-step\": 2294}, {\"errors\": 0.10667351097529282, \"time-step\": 2295}, {\"errors\": 0.10664674565238408, \"time-step\": 2296}, {\"errors\": 0.10661997021113613, \"time-step\": 2297}, {\"errors\": 0.10659318472757759, \"time-step\": 2298}, {\"errors\": 0.10656638927768804, \"time-step\": 2299}, {\"errors\": 0.10653958393739621, \"time-step\": 2300}, {\"errors\": 0.10651276878257815, \"time-step\": 2301}, {\"errors\": 0.10648594388905541, \"time-step\": 2302}, {\"errors\": 0.10645910933259306, \"time-step\": 2303}, {\"errors\": 0.10643226518889812, \"time-step\": 2304}, {\"errors\": 0.10640541153361743, \"time-step\": 2305}, {\"errors\": 0.10637854844233618, \"time-step\": 2306}, {\"errors\": 0.10635167599057582, \"time-step\": 2307}, {\"errors\": 0.10632479425379227, \"time-step\": 2308}, {\"errors\": 0.10629790330737418, \"time-step\": 2309}, {\"errors\": 0.10627100322664124, \"time-step\": 2310}, {\"errors\": 0.10624409408684204, \"time-step\": 2311}, {\"errors\": 0.10621717596315267, \"time-step\": 2312}, {\"errors\": 0.10619024893067461, \"time-step\": 2313}, {\"errors\": 0.10616331306443308, \"time-step\": 2314}, {\"errors\": 0.10613636843937535, \"time-step\": 2315}, {\"errors\": 0.10610941513036862, \"time-step\": 2316}, {\"errors\": 0.1060824532121987, \"time-step\": 2317}, {\"errors\": 0.1060554827595678, \"time-step\": 2318}, {\"errors\": 0.10602850384709311, \"time-step\": 2319}, {\"errors\": 0.10600151654930479, \"time-step\": 2320}, {\"errors\": 0.10597452094064434, \"time-step\": 2321}, {\"errors\": 0.10594751709546285, \"time-step\": 2322}, {\"errors\": 0.10592050508801912, \"time-step\": 2323}, {\"errors\": 0.10589348499247814, \"time-step\": 2324}, {\"errors\": 0.105866456882909, \"time-step\": 2325}, {\"errors\": 0.10583942083328357, \"time-step\": 2326}, {\"errors\": 0.10581237691747444, \"time-step\": 2327}, {\"errors\": 0.10578532520925346, \"time-step\": 2328}, {\"errors\": 0.10575826578228961, \"time-step\": 2329}, {\"errors\": 0.10573119871014786, \"time-step\": 2330}, {\"errors\": 0.1057041240662869, \"time-step\": 2331}, {\"errors\": 0.10567704192405789, \"time-step\": 2332}, {\"errors\": 0.10564995235670235, \"time-step\": 2333}, {\"errors\": 0.1056228554373509, \"time-step\": 2334}, {\"errors\": 0.10559575123902105, \"time-step\": 2335}, {\"errors\": 0.10556863983461615, \"time-step\": 2336}, {\"errors\": 0.10554152129692315, \"time-step\": 2337}, {\"errors\": 0.1055143956986111, \"time-step\": 2338}, {\"errors\": 0.1054872631122297, \"time-step\": 2339}, {\"errors\": 0.10546012361020736, \"time-step\": 2340}, {\"errors\": 0.10543297726484974, \"time-step\": 2341}, {\"errors\": 0.1054058241483379, \"time-step\": 2342}, {\"errors\": 0.10537866433272688, \"time-step\": 2343}, {\"errors\": 0.1053514978899439, \"time-step\": 2344}, {\"errors\": 0.10532432489178686, \"time-step\": 2345}, {\"errors\": 0.10529714540992244, \"time-step\": 2346}, {\"errors\": 0.105269959515885, \"time-step\": 2347}, {\"errors\": 0.10524276728107437, \"time-step\": 2348}, {\"errors\": 0.10521556877675467, \"time-step\": 2349}, {\"errors\": 0.10518836407405258, \"time-step\": 2350}, {\"errors\": 0.1051611532439555, \"time-step\": 2351}, {\"errors\": 0.10513393635731061, \"time-step\": 2352}, {\"errors\": 0.10510671348482245, \"time-step\": 2353}, {\"errors\": 0.10507948469705206, \"time-step\": 2354}, {\"errors\": 0.10505225006441499, \"time-step\": 2355}, {\"errors\": 0.1050250096571799, \"time-step\": 2356}, {\"errors\": 0.10499776354546697, \"time-step\": 2357}, {\"errors\": 0.10497051179924642, \"time-step\": 2358}, {\"errors\": 0.10494325448833686, \"time-step\": 2359}, {\"errors\": 0.10491599168240379, \"time-step\": 2360}, {\"errors\": 0.10488872345095802, \"time-step\": 2361}, {\"errors\": 0.10486144986335452, \"time-step\": 2362}, {\"errors\": 0.10483417098879022, \"time-step\": 2363}, {\"errors\": 0.10480688689630316, \"time-step\": 2364}, {\"errors\": 0.10477959765477053, \"time-step\": 2365}, {\"errors\": 0.10475230333290764, \"time-step\": 2366}, {\"errors\": 0.1047250039992659, \"time-step\": 2367}, {\"errors\": 0.10469769972223171, \"time-step\": 2368}, {\"errors\": 0.10467039057002489, \"time-step\": 2369}, {\"errors\": 0.10464307661069719, \"time-step\": 2370}, {\"errors\": 0.10461575791213093, \"time-step\": 2371}, {\"errors\": 0.10458843454203742, \"time-step\": 2372}, {\"errors\": 0.1045611065679555, \"time-step\": 2373}, {\"errors\": 0.10453377405725037, \"time-step\": 2374}, {\"errors\": 0.10450643707711185, \"time-step\": 2375}, {\"errors\": 0.10447909569455309, \"time-step\": 2376}, {\"errors\": 0.10445174997640923, \"time-step\": 2377}, {\"errors\": 0.1044243999893358, \"time-step\": 2378}, {\"errors\": 0.10439704579980758, \"time-step\": 2379}, {\"errors\": 0.10436968747411701, \"time-step\": 2380}, {\"errors\": 0.1043423250783729, \"time-step\": 2381}, {\"errors\": 0.10431495867849902, \"time-step\": 2382}, {\"errors\": 0.10428758834023269, \"time-step\": 2383}, {\"errors\": 0.10426021412912356, \"time-step\": 2384}, {\"errors\": 0.10423283611053213, \"time-step\": 2385}, {\"errors\": 0.10420545434962852, \"time-step\": 2386}, {\"errors\": 0.10417806891139095, \"time-step\": 2387}, {\"errors\": 0.10415067986060467, \"time-step\": 2388}, {\"errors\": 0.10412328726186035, \"time-step\": 2389}, {\"errors\": 0.10409589117955308, \"time-step\": 2390}, {\"errors\": 0.10406849167788079, \"time-step\": 2391}, {\"errors\": 0.10404108882084306, \"time-step\": 2392}, {\"errors\": 0.10401368267223998, \"time-step\": 2393}, {\"errors\": 0.1039862732956706, \"time-step\": 2394}, {\"errors\": 0.10395886075453178, \"time-step\": 2395}, {\"errors\": 0.10393144511201707, \"time-step\": 2396}, {\"errors\": 0.10390402643111514, \"time-step\": 2397}, {\"errors\": 0.10387660477460893, \"time-step\": 2398}, {\"errors\": 0.1038491802050739, \"time-step\": 2399}, {\"errors\": 0.1038217527848774, \"time-step\": 2400}, {\"errors\": 0.10379432257617698, \"time-step\": 2401}, {\"errors\": 0.10376688964091925, \"time-step\": 2402}, {\"errors\": 0.10373945404083887, \"time-step\": 2403}, {\"errors\": 0.10371201583745726, \"time-step\": 2404}, {\"errors\": 0.10368457509208134, \"time-step\": 2405}, {\"errors\": 0.1036571318658023, \"time-step\": 2406}, {\"errors\": 0.10362968621949466, \"time-step\": 2407}, {\"errors\": 0.10360223821381483, \"time-step\": 2408}, {\"errors\": 0.10357478790920013, \"time-step\": 2409}, {\"errors\": 0.10354733536586765, \"time-step\": 2410}, {\"errors\": 0.10351988064381296, \"time-step\": 2411}, {\"errors\": 0.10349242380280907, \"time-step\": 2412}, {\"errors\": 0.10346496490240539, \"time-step\": 2413}, {\"errors\": 0.1034375040019263, \"time-step\": 2414}, {\"errors\": 0.10341004116047053, \"time-step\": 2415}, {\"errors\": 0.10338257643690961, \"time-step\": 2416}, {\"errors\": 0.10335510988988705, \"time-step\": 2417}, {\"errors\": 0.10332764157781701, \"time-step\": 2418}, {\"errors\": 0.1033001715588836, \"time-step\": 2419}, {\"errors\": 0.10327269989103945, \"time-step\": 2420}, {\"errors\": 0.10324522663200483, \"time-step\": 2421}, {\"errors\": 0.10321775183926649, \"time-step\": 2422}, {\"errors\": 0.10319027557007679, \"time-step\": 2423}, {\"errors\": 0.10316279788145244, \"time-step\": 2424}, {\"errors\": 0.10313531883017381, \"time-step\": 2425}, {\"errors\": 0.1031078384727834, \"time-step\": 2426}, {\"errors\": 0.10308035686558538, \"time-step\": 2427}, {\"errors\": 0.10305287406464418, \"time-step\": 2428}, {\"errors\": 0.1030253901257838, \"time-step\": 2429}, {\"errors\": 0.10299790510458655, \"time-step\": 2430}, {\"errors\": 0.10297041905639227, \"time-step\": 2431}, {\"errors\": 0.10294293203629726, \"time-step\": 2432}, {\"errors\": 0.10291544409915342, \"time-step\": 2433}, {\"errors\": 0.10288795529956724, \"time-step\": 2434}, {\"errors\": 0.10286046569189874, \"time-step\": 2435}, {\"errors\": 0.10283297533026076, \"time-step\": 2436}, {\"errors\": 0.10280548426851788, \"time-step\": 2437}, {\"errors\": 0.10277799256028565, \"time-step\": 2438}, {\"errors\": 0.10275050025892941, \"time-step\": 2439}, {\"errors\": 0.1027230074175637, \"time-step\": 2440}, {\"errors\": 0.10269551408905114, \"time-step\": 2441}, {\"errors\": 0.1026680203260017, \"time-step\": 2442}, {\"errors\": 0.10264052618077169, \"time-step\": 2443}, {\"errors\": 0.10261303170546299, \"time-step\": 2444}, {\"errors\": 0.10258553695192224, \"time-step\": 2445}, {\"errors\": 0.10255804197173973, \"time-step\": 2446}, {\"errors\": 0.10253054681624882, \"time-step\": 2447}, {\"errors\": 0.10250305153652522, \"time-step\": 2448}, {\"errors\": 0.10247555618338558, \"time-step\": 2449}, {\"errors\": 0.10244806080738741, \"time-step\": 2450}, {\"errors\": 0.10242056545882766, \"time-step\": 2451}, {\"errors\": 0.1023930701877424, \"time-step\": 2452}, {\"errors\": 0.10236557504390559, \"time-step\": 2453}, {\"errors\": 0.1023380800768287, \"time-step\": 2454}, {\"errors\": 0.10231058533575961, \"time-step\": 2455}, {\"errors\": 0.10228309086968201, \"time-step\": 2456}, {\"errors\": 0.10225559672731466, \"time-step\": 2457}, {\"errors\": 0.10222810295711049, \"time-step\": 2458}, {\"errors\": 0.102200609607256, \"time-step\": 2459}, {\"errors\": 0.10217311672567043, \"time-step\": 2460}, {\"errors\": 0.1021456243600052, \"time-step\": 2461}, {\"errors\": 0.10211813255764282, \"time-step\": 2462}, {\"errors\": 0.10209064136569672, \"time-step\": 2463}, {\"errors\": 0.10206315083100997, \"time-step\": 2464}, {\"errors\": 0.10203566100015506, \"time-step\": 2465}, {\"errors\": 0.10200817191943296, \"time-step\": 2466}, {\"errors\": 0.10198068363487234, \"time-step\": 2467}, {\"errors\": 0.1019531961922293, \"time-step\": 2468}, {\"errors\": 0.10192570963698636, \"time-step\": 2469}, {\"errors\": 0.10189822401435182, \"time-step\": 2470}, {\"errors\": 0.10187073936925932, \"time-step\": 2471}, {\"errors\": 0.10184325574636696, \"time-step\": 2472}, {\"errors\": 0.10181577319005694, \"time-step\": 2473}, {\"errors\": 0.1017882917444346, \"time-step\": 2474}, {\"errors\": 0.10176081145332812, \"time-step\": 2475}, {\"errors\": 0.1017333323602877, \"time-step\": 2476}, {\"errors\": 0.10170585450858502, \"time-step\": 2477}, {\"errors\": 0.10167837794121276, \"time-step\": 2478}, {\"errors\": 0.10165090270088384, \"time-step\": 2479}, {\"errors\": 0.10162342883003089, \"time-step\": 2480}, {\"errors\": 0.10159595637080583, \"time-step\": 2481}, {\"errors\": 0.10156848536507912, \"time-step\": 2482}, {\"errors\": 0.10154101585443913, \"time-step\": 2483}, {\"errors\": 0.10151354788019198, \"time-step\": 2484}, {\"errors\": 0.10148608148336066, \"time-step\": 2485}, {\"errors\": 0.10145861670468462, \"time-step\": 2486}, {\"errors\": 0.10143115358461902, \"time-step\": 2487}, {\"errors\": 0.10140369216333475, \"time-step\": 2488}, {\"errors\": 0.10137623248071735, \"time-step\": 2489}, {\"errors\": 0.10134877457636682, \"time-step\": 2490}, {\"errors\": 0.10132131848959709, \"time-step\": 2491}, {\"errors\": 0.10129386425943544, \"time-step\": 2492}, {\"errors\": 0.10126641192462203, \"time-step\": 2493}, {\"errors\": 0.10123896152360971, \"time-step\": 2494}, {\"errors\": 0.10121151309456292, \"time-step\": 2495}, {\"errors\": 0.10118406667535798, \"time-step\": 2496}, {\"errors\": 0.10115662230358227, \"time-step\": 2497}, {\"errors\": 0.10112918001653358, \"time-step\": 2498}, {\"errors\": 0.10110173985122006, \"time-step\": 2499}, {\"errors\": 0.10107430184435964, \"time-step\": 2500}, {\"errors\": 0.10104686603237965, \"time-step\": 2501}, {\"errors\": 0.10101943245141631, \"time-step\": 2502}, {\"errors\": 0.10099200113731421, \"time-step\": 2503}, {\"errors\": 0.10096457212562643, \"time-step\": 2504}, {\"errors\": 0.10093714545161352, \"time-step\": 2505}, {\"errors\": 0.10090972115024349, \"time-step\": 2506}, {\"errors\": 0.10088229925619133, \"time-step\": 2507}, {\"errors\": 0.10085487980383864, \"time-step\": 2508}, {\"errors\": 0.10082746282727323, \"time-step\": 2509}, {\"errors\": 0.10080004836028886, \"time-step\": 2510}, {\"errors\": 0.10077263643638473, \"time-step\": 2511}, {\"errors\": 0.10074522708876538, \"time-step\": 2512}, {\"errors\": 0.10071782035034006, \"time-step\": 2513}, {\"errors\": 0.1006904162537227, \"time-step\": 2514}, {\"errors\": 0.10066301483123116, \"time-step\": 2515}, {\"errors\": 0.10063561611488758, \"time-step\": 2516}, {\"errors\": 0.10060822013641726, \"time-step\": 2517}, {\"errors\": 0.10058082692724912, \"time-step\": 2518}, {\"errors\": 0.10055343651851484, \"time-step\": 2519}, {\"errors\": 0.10052604894104882, \"time-step\": 2520}, {\"errors\": 0.10049866422538796, \"time-step\": 2521}, {\"errors\": 0.10047128240177115, \"time-step\": 2522}, {\"errors\": 0.10044390350013926, \"time-step\": 2523}, {\"errors\": 0.10041652755013458, \"time-step\": 2524}, {\"errors\": 0.10038915458110094, \"time-step\": 2525}, {\"errors\": 0.10036178462208298, \"time-step\": 2526}, {\"errors\": 0.10033441770182638, \"time-step\": 2527}, {\"errors\": 0.10030705384877746, \"time-step\": 2528}, {\"errors\": 0.10027969309108253, \"time-step\": 2529}, {\"errors\": 0.10025233545658851, \"time-step\": 2530}, {\"errors\": 0.10022498097284194, \"time-step\": 2531}, {\"errors\": 0.100197629667089, \"time-step\": 2532}, {\"errors\": 0.10017028156627567, \"time-step\": 2533}, {\"errors\": 0.10014293669704685, \"time-step\": 2534}, {\"errors\": 0.10011559508574669, \"time-step\": 2535}, {\"errors\": 0.10008825675841831, \"time-step\": 2536}, {\"errors\": 0.10006092174080344, \"time-step\": 2537}, {\"errors\": 0.1000335900583423, \"time-step\": 2538}, {\"errors\": 0.10000626173617364, \"time-step\": 2539}, {\"errors\": 0.09997893679913412, \"time-step\": 2540}, {\"errors\": 0.09995161527175878, \"time-step\": 2541}, {\"errors\": 0.09992429717828026, \"time-step\": 2542}, {\"errors\": 0.09989698254262902, \"time-step\": 2543}, {\"errors\": 0.09986967138843306, \"time-step\": 2544}, {\"errors\": 0.0998423637390179, \"time-step\": 2545}, {\"errors\": 0.0998150596174063, \"time-step\": 2546}, {\"errors\": 0.09978775904631823, \"time-step\": 2547}, {\"errors\": 0.09976046204817077, \"time-step\": 2548}, {\"errors\": 0.0997331686450777, \"time-step\": 2549}, {\"errors\": 0.09970587885884993, \"time-step\": 2550}, {\"errors\": 0.09967859271099505, \"time-step\": 2551}, {\"errors\": 0.09965131022271698, \"time-step\": 2552}, {\"errors\": 0.09962403141491652, \"time-step\": 2553}, {\"errors\": 0.09959675630819073, \"time-step\": 2554}, {\"errors\": 0.09956948492283302, \"time-step\": 2555}, {\"errors\": 0.09954221727883317, \"time-step\": 2556}, {\"errors\": 0.09951495339587707, \"time-step\": 2557}, {\"errors\": 0.09948769329334674, \"time-step\": 2558}, {\"errors\": 0.09946043699032027, \"time-step\": 2559}, {\"errors\": 0.09943318450557186, \"time-step\": 2560}, {\"errors\": 0.09940593585757149, \"time-step\": 2561}, {\"errors\": 0.09937869106448516, \"time-step\": 2562}, {\"errors\": 0.09935145014417465, \"time-step\": 2563}, {\"errors\": 0.09932421311419769, \"time-step\": 2564}, {\"errors\": 0.09929697999180762, \"time-step\": 2565}, {\"errors\": 0.09926975079395359, \"time-step\": 2566}, {\"errors\": 0.09924252553728061, \"time-step\": 2567}, {\"errors\": 0.09921530423812913, \"time-step\": 2568}, {\"errors\": 0.09918808691253561, \"time-step\": 2569}, {\"errors\": 0.09916087357623188, \"time-step\": 2570}, {\"errors\": 0.09913366424464569, \"time-step\": 2571}, {\"errors\": 0.0991064589329003, \"time-step\": 2572}, {\"errors\": 0.09907925765581468, \"time-step\": 2573}, {\"errors\": 0.09905206042790352, \"time-step\": 2574}, {\"errors\": 0.09902486726337713, \"time-step\": 2575}, {\"errors\": 0.09899767817614166, \"time-step\": 2576}, {\"errors\": 0.09897049317979878, \"time-step\": 2577}, {\"errors\": 0.0989433122876461, \"time-step\": 2578}, {\"errors\": 0.09891613551267692, \"time-step\": 2579}, {\"errors\": 0.09888896286758032, \"time-step\": 2580}, {\"errors\": 0.09886179436474124, \"time-step\": 2581}, {\"errors\": 0.09883463001624056, \"time-step\": 2582}, {\"errors\": 0.09880746983385508, \"time-step\": 2583}, {\"errors\": 0.09878031382905751, \"time-step\": 2584}, {\"errors\": 0.09875316201301665, \"time-step\": 2585}, {\"errors\": 0.09872601439659737, \"time-step\": 2586}, {\"errors\": 0.09869887099036075, \"time-step\": 2587}, {\"errors\": 0.09867173180456393, \"time-step\": 2588}, {\"errors\": 0.09864459684916055, \"time-step\": 2589}, {\"errors\": 0.09861746613380042, \"time-step\": 2590}, {\"errors\": 0.09859033966782982, \"time-step\": 2591}, {\"errors\": 0.09856321746029167, \"time-step\": 2592}, {\"errors\": 0.09853609951992531, \"time-step\": 2593}, {\"errors\": 0.09850898585516688, \"time-step\": 2594}, {\"errors\": 0.09848187647414916, \"time-step\": 2595}, {\"errors\": 0.0984547713847019, \"time-step\": 2596}, {\"errors\": 0.09842767059435188, \"time-step\": 2597}, {\"errors\": 0.09840057411032277, \"time-step\": 2598}, {\"errors\": 0.09837348193953549, \"time-step\": 2599}, {\"errors\": 0.09834639408860828, \"time-step\": 2600}, {\"errors\": 0.09831931056385662, \"time-step\": 2601}, {\"errors\": 0.09829223137129375, \"time-step\": 2602}, {\"errors\": 0.09826515651663019, \"time-step\": 2603}, {\"errors\": 0.0982380860052745, \"time-step\": 2604}, {\"errors\": 0.09821101984233292, \"time-step\": 2605}, {\"errors\": 0.09818395803260974, \"time-step\": 2606}, {\"errors\": 0.09815690058060739, \"time-step\": 2607}, {\"errors\": 0.09812984749052647, \"time-step\": 2608}, {\"errors\": 0.09810279876626612, \"time-step\": 2609}, {\"errors\": 0.09807575441142383, \"time-step\": 2610}, {\"errors\": 0.0980487144292959, \"time-step\": 2611}, {\"errors\": 0.09802167882287727, \"time-step\": 2612}, {\"errors\": 0.09799464759486212, \"time-step\": 2613}, {\"errors\": 0.09796762074764351, \"time-step\": 2614}, {\"errors\": 0.0979405982833138, \"time-step\": 2615}, {\"errors\": 0.09791358020366489, \"time-step\": 2616}, {\"errors\": 0.09788656651018812, \"time-step\": 2617}, {\"errors\": 0.09785955720407463, \"time-step\": 2618}, {\"errors\": 0.09783255228621551, \"time-step\": 2619}, {\"errors\": 0.0978055517572019, \"time-step\": 2620}, {\"errors\": 0.09777855561732512, \"time-step\": 2621}, {\"errors\": 0.09775156386657699, \"time-step\": 2622}, {\"errors\": 0.09772457650464983, \"time-step\": 2623}, {\"errors\": 0.09769759353093684, \"time-step\": 2624}, {\"errors\": 0.09767061494453204, \"time-step\": 2625}, {\"errors\": 0.09764364074423063, \"time-step\": 2626}, {\"errors\": 0.09761667092852915, \"time-step\": 2627}, {\"errors\": 0.0975897054956256, \"time-step\": 2628}, {\"errors\": 0.09756274444341959, \"time-step\": 2629}, {\"errors\": 0.09753578776951277, \"time-step\": 2630}, {\"errors\": 0.0975088354712087, \"time-step\": 2631}, {\"errors\": 0.09748188754551321, \"time-step\": 2632}, {\"errors\": 0.0974549439891347, \"time-step\": 2633}, {\"errors\": 0.09742800479848418, \"time-step\": 2634}, {\"errors\": 0.09740106996967532, \"time-step\": 2635}, {\"errors\": 0.09737413949852519, \"time-step\": 2636}, {\"errors\": 0.09734721338055383, \"time-step\": 2637}, {\"errors\": 0.09732029161098485, \"time-step\": 2638}, {\"errors\": 0.09729337418474557, \"time-step\": 2639}, {\"errors\": 0.09726646109646711, \"time-step\": 2640}, {\"errors\": 0.09723955234048476, \"time-step\": 2641}, {\"errors\": 0.09721264791083807, \"time-step\": 2642}, {\"errors\": 0.0971857478012711, \"time-step\": 2643}, {\"errors\": 0.09715885200523272, \"time-step\": 2644}, {\"errors\": 0.09713196051587661, \"time-step\": 2645}, {\"errors\": 0.0971050733260618, \"time-step\": 2646}, {\"errors\": 0.09707819042835267, \"time-step\": 2647}, {\"errors\": 0.09705131181501911, \"time-step\": 2648}, {\"errors\": 0.09702443747803695, \"time-step\": 2649}, {\"errors\": 0.09699756740908805, \"time-step\": 2650}, {\"errors\": 0.0969707015995607, \"time-step\": 2651}, {\"errors\": 0.0969438400405494, \"time-step\": 2652}, {\"errors\": 0.0969169827228557, \"time-step\": 2653}, {\"errors\": 0.09689012963698805, \"time-step\": 2654}, {\"errors\": 0.09686328077316211, \"time-step\": 2655}, {\"errors\": 0.09683643612130091, \"time-step\": 2656}, {\"errors\": 0.09680959567103525, \"time-step\": 2657}, {\"errors\": 0.09678275941170385, \"time-step\": 2658}, {\"errors\": 0.09675592733235353, \"time-step\": 2659}, {\"errors\": 0.09672909942173952, \"time-step\": 2660}, {\"errors\": 0.09670227566832579, \"time-step\": 2661}, {\"errors\": 0.09667545606028499, \"time-step\": 2662}, {\"errors\": 0.09664864058549899, \"time-step\": 2663}, {\"errors\": 0.09662182923155901, \"time-step\": 2664}, {\"errors\": 0.09659502198576586, \"time-step\": 2665}, {\"errors\": 0.09656821883513018, \"time-step\": 2666}, {\"errors\": 0.09654141976637273, \"time-step\": 2667}, {\"errors\": 0.0965146247659245, \"time-step\": 2668}, {\"errors\": 0.09648783381992718, \"time-step\": 2669}, {\"errors\": 0.09646104691423316, \"time-step\": 2670}, {\"errors\": 0.09643426403440598, \"time-step\": 2671}, {\"errors\": 0.09640748516572042, \"time-step\": 2672}, {\"errors\": 0.09638071029316299, \"time-step\": 2673}, {\"errors\": 0.09635393940143175, \"time-step\": 2674}, {\"errors\": 0.09632717247493706, \"time-step\": 2675}, {\"errors\": 0.09630040949780137, \"time-step\": 2676}, {\"errors\": 0.09627365045386, \"time-step\": 2677}, {\"errors\": 0.0962468953266607, \"time-step\": 2678}, {\"errors\": 0.09622014409946454, \"time-step\": 2679}, {\"errors\": 0.09619339675524585, \"time-step\": 2680}, {\"errors\": 0.09616665327669251, \"time-step\": 2681}, {\"errors\": 0.09613991364620625, \"time-step\": 2682}, {\"errors\": 0.09611317784590281, \"time-step\": 2683}, {\"errors\": 0.09608644585761231, \"time-step\": 2684}, {\"errors\": 0.09605971766287932, \"time-step\": 2685}, {\"errors\": 0.09603299324296352, \"time-step\": 2686}, {\"errors\": 0.0960062725788394, \"time-step\": 2687}, {\"errors\": 0.0959795556511969, \"time-step\": 2688}, {\"errors\": 0.09595284244044153, \"time-step\": 2689}, {\"errors\": 0.09592613292669461, \"time-step\": 2690}, {\"errors\": 0.09589942708979364, \"time-step\": 2691}, {\"errors\": 0.09587272490929247, \"time-step\": 2692}, {\"errors\": 0.09584602636446135, \"time-step\": 2693}, {\"errors\": 0.09581933143428778, \"time-step\": 2694}, {\"errors\": 0.09579264009747598, \"time-step\": 2695}, {\"errors\": 0.09576595233244783, \"time-step\": 2696}, {\"errors\": 0.09573926811734257, \"time-step\": 2697}, {\"errors\": 0.09571258743001756, \"time-step\": 2698}, {\"errors\": 0.09568591024804814, \"time-step\": 2699}, {\"errors\": 0.09565923654872799, \"time-step\": 2700}, {\"errors\": 0.09563256630906963, \"time-step\": 2701}, {\"errors\": 0.0956058995058042, \"time-step\": 2702}, {\"errors\": 0.09557923611538216, \"time-step\": 2703}, {\"errors\": 0.0955525761139733, \"time-step\": 2704}, {\"errors\": 0.09552591947746703, \"time-step\": 2705}, {\"errors\": 0.09549926618147261, \"time-step\": 2706}, {\"errors\": 0.09547261620131967, \"time-step\": 2707}, {\"errors\": 0.09544596951205782, \"time-step\": 2708}, {\"errors\": 0.09541932608845774, \"time-step\": 2709}, {\"errors\": 0.09539268590501071, \"time-step\": 2710}, {\"errors\": 0.09536604893592922, \"time-step\": 2711}, {\"errors\": 0.09533941515514724, \"time-step\": 2712}, {\"errors\": 0.09531278453632022, \"time-step\": 2713}, {\"errors\": 0.09528615705282556, \"time-step\": 2714}, {\"errors\": 0.0952595326777629, \"time-step\": 2715}, {\"errors\": 0.09523291138395393, \"time-step\": 2716}, {\"errors\": 0.0952062931439433, \"time-step\": 2717}, {\"errors\": 0.09517967792999835, \"time-step\": 2718}, {\"errors\": 0.09515306571410953, \"time-step\": 2719}, {\"errors\": 0.09512645646799066, \"time-step\": 2720}, {\"errors\": 0.09509985016307912, \"time-step\": 2721}, {\"errors\": 0.09507324677053616, \"time-step\": 2722}, {\"errors\": 0.09504664626124701, \"time-step\": 2723}, {\"errors\": 0.09502004860582133, \"time-step\": 2724}, {\"errors\": 0.0949934537745932, \"time-step\": 2725}, {\"errors\": 0.0949668617376215, \"time-step\": 2726}, {\"errors\": 0.09494027246469026, \"time-step\": 2727}, {\"errors\": 0.09491368592530855, \"time-step\": 2728}, {\"errors\": 0.09488710208871112, \"time-step\": 2729}, {\"errors\": 0.09486052092385835, \"time-step\": 2730}, {\"errors\": 0.09483394239943652, \"time-step\": 2731}, {\"errors\": 0.09480736648385821, \"time-step\": 2732}, {\"errors\": 0.0947807931452623, \"time-step\": 2733}, {\"errors\": 0.0947542223515144, \"time-step\": 2734}, {\"errors\": 0.09472765407020699, \"time-step\": 2735}, {\"errors\": 0.0947010882686595, \"time-step\": 2736}, {\"errors\": 0.09467452491391891, \"time-step\": 2737}, {\"errors\": 0.09464796397275961, \"time-step\": 2738}, {\"errors\": 0.09462140541168373, \"time-step\": 2739}, {\"errors\": 0.09459484919692146, \"time-step\": 2740}, {\"errors\": 0.09456829529443127, \"time-step\": 2741}, {\"errors\": 0.09454174366989984, \"time-step\": 2742}, {\"errors\": 0.09451519428874271, \"time-step\": 2743}, {\"errors\": 0.09448864711610426, \"time-step\": 2744}, {\"errors\": 0.09446210211685782, \"time-step\": 2745}, {\"errors\": 0.09443555925560612, \"time-step\": 2746}, {\"errors\": 0.09440901849668144, \"time-step\": 2747}, {\"errors\": 0.09438247980414566, \"time-step\": 2748}, {\"errors\": 0.09435594314179066, \"time-step\": 2749}, {\"errors\": 0.09432940847313848, \"time-step\": 2750}, {\"errors\": 0.09430287576144142, \"time-step\": 2751}, {\"errors\": 0.09427634496968249, \"time-step\": 2752}, {\"errors\": 0.09424981606057514, \"time-step\": 2753}, {\"errors\": 0.0942232889965642, \"time-step\": 2754}, {\"errors\": 0.09419676373982534, \"time-step\": 2755}, {\"errors\": 0.09417024025226571, \"time-step\": 2756}, {\"errors\": 0.09414371849552394, \"time-step\": 2757}, {\"errors\": 0.09411719843097055, \"time-step\": 2758}, {\"errors\": 0.09409068001970781, \"time-step\": 2759}, {\"errors\": 0.09406416322257036, \"time-step\": 2760}, {\"errors\": 0.0940376480001249, \"time-step\": 2761}, {\"errors\": 0.09401113431267087, \"time-step\": 2762}, {\"errors\": 0.09398462212024032, \"time-step\": 2763}, {\"errors\": 0.09395811138259819, \"time-step\": 2764}, {\"errors\": 0.0939316020592425, \"time-step\": 2765}, {\"errors\": 0.09390509410940459, \"time-step\": 2766}, {\"errors\": 0.09387858749204916, \"time-step\": 2767}, {\"errors\": 0.09385208216587451, \"time-step\": 2768}, {\"errors\": 0.09382557808931286, \"time-step\": 2769}, {\"errors\": 0.09379907522053019, \"time-step\": 2770}, {\"errors\": 0.09377257351742692, \"time-step\": 2771}, {\"errors\": 0.09374607293763752, \"time-step\": 2772}, {\"errors\": 0.09371957343853109, \"time-step\": 2773}, {\"errors\": 0.0936930749772113, \"time-step\": 2774}, {\"errors\": 0.09366657751051669, \"time-step\": 2775}, {\"errors\": 0.09364008099502076, \"time-step\": 2776}, {\"errors\": 0.09361358538703227, \"time-step\": 2777}, {\"errors\": 0.09358709064259502, \"time-step\": 2778}, {\"errors\": 0.09356059671748854, \"time-step\": 2779}, {\"errors\": 0.09353410356722792, \"time-step\": 2780}, {\"errors\": 0.09350761114706391, \"time-step\": 2781}, {\"errors\": 0.0934811194119833, \"time-step\": 2782}, {\"errors\": 0.09345462831670892, \"time-step\": 2783}, {\"errors\": 0.09342813781569989, \"time-step\": 2784}, {\"errors\": 0.09340164786315155, \"time-step\": 2785}, {\"errors\": 0.09337515841299593, \"time-step\": 2786}, {\"errors\": 0.0933486694189016, \"time-step\": 2787}, {\"errors\": 0.0933221808342741, \"time-step\": 2788}, {\"errors\": 0.09329569261225562, \"time-step\": 2789}, {\"errors\": 0.09326920470572574, \"time-step\": 2790}, {\"errors\": 0.09324271706730097, \"time-step\": 2791}, {\"errors\": 0.09321622964933539, \"time-step\": 2792}, {\"errors\": 0.09318974240392043, \"time-step\": 2793}, {\"errors\": 0.09316325528288516, \"time-step\": 2794}, {\"errors\": 0.09313676823779635, \"time-step\": 2795}, {\"errors\": 0.09311028121995861, \"time-step\": 2796}, {\"errors\": 0.09308379418041454, \"time-step\": 2797}, {\"errors\": 0.09305730706994483, \"time-step\": 2798}, {\"errors\": 0.09303081983906844, \"time-step\": 2799}, {\"errors\": 0.09300433243804246, \"time-step\": 2800}, {\"errors\": 0.09297784481686264, \"time-step\": 2801}, {\"errors\": 0.09295135692526305, \"time-step\": 2802}, {\"errors\": 0.09292486871271657, \"time-step\": 2803}, {\"errors\": 0.09289838012843486, \"time-step\": 2804}, {\"errors\": 0.09287189112136829, \"time-step\": 2805}, {\"errors\": 0.09284540164020626, \"time-step\": 2806}, {\"errors\": 0.0928189116333773, \"time-step\": 2807}, {\"errors\": 0.09279242104904895, \"time-step\": 2808}, {\"errors\": 0.09276592983512816, \"time-step\": 2809}, {\"errors\": 0.09273943793926116, \"time-step\": 2810}, {\"errors\": 0.09271294530883348, \"time-step\": 2811}, {\"errors\": 0.0926864518909704, \"time-step\": 2812}, {\"errors\": 0.09265995763253665, \"time-step\": 2813}, {\"errors\": 0.09263346248013671, \"time-step\": 2814}, {\"errors\": 0.09260696638011476, \"time-step\": 2815}, {\"errors\": 0.09258046927855491, \"time-step\": 2816}, {\"errors\": 0.09255397112128123, \"time-step\": 2817}, {\"errors\": 0.09252747185385762, \"time-step\": 2818}, {\"errors\": 0.09250097142158814, \"time-step\": 2819}, {\"errors\": 0.09247446976951713, \"time-step\": 2820}, {\"errors\": 0.09244796684242883, \"time-step\": 2821}, {\"errors\": 0.09242146258484799, \"time-step\": 2822}, {\"errors\": 0.0923949569410396, \"time-step\": 2823}, {\"errors\": 0.09236844985500908, \"time-step\": 2824}, {\"errors\": 0.09234194127050217, \"time-step\": 2825}, {\"errors\": 0.09231543113100531, \"time-step\": 2826}, {\"errors\": 0.09228891937974534, \"time-step\": 2827}, {\"errors\": 0.09226240595968979, \"time-step\": 2828}, {\"errors\": 0.09223589081354674, \"time-step\": 2829}, {\"errors\": 0.09220937388376513, \"time-step\": 2830}, {\"errors\": 0.0921828551125344, \"time-step\": 2831}, {\"errors\": 0.092156334441785, \"time-step\": 2832}, {\"errors\": 0.09212981181318806, \"time-step\": 2833}, {\"errors\": 0.09210328716815566, \"time-step\": 2834}, {\"errors\": 0.09207676044784066, \"time-step\": 2835}, {\"errors\": 0.09205023159313686, \"time-step\": 2836}, {\"errors\": 0.09202370054467907, \"time-step\": 2837}, {\"errors\": 0.09199716724284304, \"time-step\": 2838}, {\"errors\": 0.09197063162774544, \"time-step\": 2839}, {\"errors\": 0.09194409363924408, \"time-step\": 2840}, {\"errors\": 0.09191755321693774, \"time-step\": 2841}, {\"errors\": 0.0918910103001662, \"time-step\": 2842}, {\"errors\": 0.09186446482801039, \"time-step\": 2843}, {\"errors\": 0.09183791673929224, \"time-step\": 2844}, {\"errors\": 0.09181136597257486, \"time-step\": 2845}, {\"errors\": 0.09178481246616238, \"time-step\": 2846}, {\"errors\": 0.09175825615810007, \"time-step\": 2847}, {\"errors\": 0.09173169698617423, \"time-step\": 2848}, {\"errors\": 0.09170513488791229, \"time-step\": 2849}, {\"errors\": 0.09167856980058275, \"time-step\": 2850}, {\"errors\": 0.09165200166119533, \"time-step\": 2851}, {\"errors\": 0.09162543040650059, \"time-step\": 2852}, {\"errors\": 0.09159885597299045, \"time-step\": 2853}, {\"errors\": 0.09157227829689757, \"time-step\": 2854}, {\"errors\": 0.09154569731419594, \"time-step\": 2855}, {\"errors\": 0.09151911296060045, \"time-step\": 2856}, {\"errors\": 0.09149252517156695, \"time-step\": 2857}, {\"errors\": 0.09146593388229234, \"time-step\": 2858}, {\"errors\": 0.09143933902771445, \"time-step\": 2859}, {\"errors\": 0.09141274054251217, \"time-step\": 2860}, {\"errors\": 0.09138613836110504, \"time-step\": 2861}, {\"errors\": 0.09135953241765368, \"time-step\": 2862}, {\"errors\": 0.0913329226460595, \"time-step\": 2863}, {\"errors\": 0.09130630897996461, \"time-step\": 2864}, {\"errors\": 0.0912796913527521, \"time-step\": 2865}, {\"errors\": 0.09125306969754554, \"time-step\": 2866}, {\"errors\": 0.09122644394720938, \"time-step\": 2867}, {\"errors\": 0.09119981403434856, \"time-step\": 2868}, {\"errors\": 0.09117317989130869, \"time-step\": 2869}, {\"errors\": 0.09114654145017591, \"time-step\": 2870}, {\"errors\": 0.09111989864277678, \"time-step\": 2871}, {\"errors\": 0.09109325140067831, \"time-step\": 2872}, {\"errors\": 0.09106659965518804, \"time-step\": 2873}, {\"errors\": 0.0910399433373536, \"time-step\": 2874}, {\"errors\": 0.09101328237796297, \"time-step\": 2875}, {\"errors\": 0.09098661670754431, \"time-step\": 2876}, {\"errors\": 0.090959946256366, \"time-step\": 2877}, {\"errors\": 0.09093327095443623, \"time-step\": 2878}, {\"errors\": 0.09090659073150341, \"time-step\": 2879}, {\"errors\": 0.0908799055170558, \"time-step\": 2880}, {\"errors\": 0.09085321524032142, \"time-step\": 2881}, {\"errors\": 0.0908265198302681, \"time-step\": 2882}, {\"errors\": 0.09079981921560351, \"time-step\": 2883}, {\"errors\": 0.09077311332477457, \"time-step\": 2884}, {\"errors\": 0.09074640208596799, \"time-step\": 2885}, {\"errors\": 0.09071968542710986, \"time-step\": 2886}, {\"errors\": 0.09069296327586557, \"time-step\": 2887}, {\"errors\": 0.09066623555963982, \"time-step\": 2888}, {\"errors\": 0.09063950220557632, \"time-step\": 2889}, {\"errors\": 0.09061276314055808, \"time-step\": 2890}, {\"errors\": 0.09058601829120695, \"time-step\": 2891}, {\"errors\": 0.09055926758388366, \"time-step\": 2892}, {\"errors\": 0.09053251094468767, \"time-step\": 2893}, {\"errors\": 0.09050574829945723, \"time-step\": 2894}, {\"errors\": 0.09047897957376909, \"time-step\": 2895}, {\"errors\": 0.09045220469293841, \"time-step\": 2896}, {\"errors\": 0.09042542358201881, \"time-step\": 2897}, {\"errors\": 0.09039863616580208, \"time-step\": 2898}, {\"errors\": 0.09037184236881823, \"time-step\": 2899}, {\"errors\": 0.0903450421153352, \"time-step\": 2900}, {\"errors\": 0.09031823532935879, \"time-step\": 2901}, {\"errors\": 0.09029142193463274, \"time-step\": 2902}, {\"errors\": 0.09026460185463839, \"time-step\": 2903}, {\"errors\": 0.09023777501259451, \"time-step\": 2904}, {\"errors\": 0.09021094133145749, \"time-step\": 2905}, {\"errors\": 0.09018410073392086, \"time-step\": 2906}, {\"errors\": 0.09015725314241543, \"time-step\": 2907}, {\"errors\": 0.09013039847910895, \"time-step\": 2908}, {\"errors\": 0.09010353666590615, \"time-step\": 2909}, {\"errors\": 0.0900766676244486, \"time-step\": 2910}, {\"errors\": 0.09004979127611437, \"time-step\": 2911}, {\"errors\": 0.0900229075420181, \"time-step\": 2912}, {\"errors\": 0.08999601634301088, \"time-step\": 2913}, {\"errors\": 0.08996911759968002, \"time-step\": 2914}, {\"errors\": 0.0899422112323488, \"time-step\": 2915}, {\"errors\": 0.08991529716107655, \"time-step\": 2916}, {\"errors\": 0.08988837530565845, \"time-step\": 2917}, {\"errors\": 0.08986144558562534, \"time-step\": 2918}, {\"errors\": 0.0898345079202435, \"time-step\": 2919}, {\"errors\": 0.08980756222851469, \"time-step\": 2920}, {\"errors\": 0.08978060842917575, \"time-step\": 2921}, {\"errors\": 0.08975364644069883, \"time-step\": 2922}, {\"errors\": 0.08972667618129074, \"time-step\": 2923}, {\"errors\": 0.08969969756889326, \"time-step\": 2924}, {\"errors\": 0.08967271052118267, \"time-step\": 2925}, {\"errors\": 0.08964571495556972, \"time-step\": 2926}, {\"errors\": 0.08961871078919967, \"time-step\": 2927}, {\"errors\": 0.08959169793895164, \"time-step\": 2928}, {\"errors\": 0.0895646763214388, \"time-step\": 2929}, {\"errors\": 0.08953764585300832, \"time-step\": 2930}, {\"errors\": 0.08951060644974082, \"time-step\": 2931}, {\"errors\": 0.08948355802745057, \"time-step\": 2932}, {\"errors\": 0.08945650050168517, \"time-step\": 2933}, {\"errors\": 0.08942943378772525, \"time-step\": 2934}, {\"errors\": 0.08940235780058461, \"time-step\": 2935}, {\"errors\": 0.08937527245500985, \"time-step\": 2936}, {\"errors\": 0.08934817766548014, \"time-step\": 2937}, {\"errors\": 0.0893210733462074, \"time-step\": 2938}, {\"errors\": 0.08929395941113555, \"time-step\": 2939}, {\"errors\": 0.08926683577394091, \"time-step\": 2940}, {\"errors\": 0.08923970234803176, \"time-step\": 2941}, {\"errors\": 0.08921255904654812, \"time-step\": 2942}, {\"errors\": 0.08918540578236178, \"time-step\": 2943}, {\"errors\": 0.08915824246807583, \"time-step\": 2944}, {\"errors\": 0.08913106901602483, \"time-step\": 2945}, {\"errors\": 0.0891038853382744, \"time-step\": 2946}, {\"errors\": 0.08907669134662108, \"time-step\": 2947}, {\"errors\": 0.08904948695259227, \"time-step\": 2948}, {\"errors\": 0.08902227206744585, \"time-step\": 2949}, {\"errors\": 0.08899504660217025, \"time-step\": 2950}, {\"errors\": 0.08896781046748403, \"time-step\": 2951}, {\"errors\": 0.08894056357383587, \"time-step\": 2952}, {\"errors\": 0.08891330583140433, \"time-step\": 2953}, {\"errors\": 0.08888603715009775, \"time-step\": 2954}, {\"errors\": 0.08885875743955393, \"time-step\": 2955}, {\"errors\": 0.08883146660913997, \"time-step\": 2956}, {\"errors\": 0.08880416456795226, \"time-step\": 2957}, {\"errors\": 0.08877685122481616, \"time-step\": 2958}, {\"errors\": 0.08874952648828571, \"time-step\": 2959}, {\"errors\": 0.08872219026664388, \"time-step\": 2960}, {\"errors\": 0.0886948424679018, \"time-step\": 2961}, {\"errors\": 0.08866748299979907, \"time-step\": 2962}, {\"errors\": 0.08864011176980328, \"time-step\": 2963}, {\"errors\": 0.08861272868511003, \"time-step\": 2964}, {\"errors\": 0.0885853336526426, \"time-step\": 2965}, {\"errors\": 0.08855792657905193, \"time-step\": 2966}, {\"errors\": 0.08853050737071622, \"time-step\": 2967}, {\"errors\": 0.08850307593374093, \"time-step\": 2968}, {\"errors\": 0.08847563217395873, \"time-step\": 2969}, {\"errors\": 0.08844817599692882, \"time-step\": 2970}, {\"errors\": 0.08842070730793739, \"time-step\": 2971}, {\"errors\": 0.08839322601199692, \"time-step\": 2972}, {\"errors\": 0.08836573201384643, \"time-step\": 2973}, {\"errors\": 0.0883382252179509, \"time-step\": 2974}, {\"errors\": 0.0883107055285014, \"time-step\": 2975}, {\"errors\": 0.08828317284941486, \"time-step\": 2976}, {\"errors\": 0.08825562708433371, \"time-step\": 2977}, {\"errors\": 0.08822806813662602, \"time-step\": 2978}, {\"errors\": 0.08820049590938506, \"time-step\": 2979}, {\"errors\": 0.08817291030542927, \"time-step\": 2980}, {\"errors\": 0.08814531122730207, \"time-step\": 2981}, {\"errors\": 0.08811769857727161, \"time-step\": 2982}, {\"errors\": 0.0880900722573308, \"time-step\": 2983}, {\"errors\": 0.08806243216919693, \"time-step\": 2984}, {\"errors\": 0.08803477821431166, \"time-step\": 2985}, {\"errors\": 0.0880071102938407, \"time-step\": 2986}, {\"errors\": 0.08797942830867389, \"time-step\": 2987}, {\"errors\": 0.08795173215942483, \"time-step\": 2988}, {\"errors\": 0.08792402174643088, \"time-step\": 2989}, {\"errors\": 0.08789629696975274, \"time-step\": 2990}, {\"errors\": 0.0878685577291746, \"time-step\": 2991}, {\"errors\": 0.08784080392420396, \"time-step\": 2992}, {\"errors\": 0.08781303545407129, \"time-step\": 2993}, {\"errors\": 0.08778525221772987, \"time-step\": 2994}, {\"errors\": 0.08775745411385603, \"time-step\": 2995}, {\"errors\": 0.08772964104084854, \"time-step\": 2996}, {\"errors\": 0.08770181289682871, \"time-step\": 2997}, {\"errors\": 0.08767396957964022, \"time-step\": 2998}, {\"errors\": 0.08764611098684894, \"time-step\": 2999}, {\"errors\": 0.08761823701574281, \"time-step\": 3000}, {\"errors\": 0.08759034756333195, \"time-step\": 3001}, {\"errors\": 0.08756244252634794, \"time-step\": 3002}, {\"errors\": 0.08753452180124432, \"time-step\": 3003}, {\"errors\": 0.08750658528419614, \"time-step\": 3004}, {\"errors\": 0.08747863287109989, \"time-step\": 3005}, {\"errors\": 0.08745066445757338, \"time-step\": 3006}, {\"errors\": 0.08742267993895578, \"time-step\": 3007}, {\"errors\": 0.08739467921030708, \"time-step\": 3008}, {\"errors\": 0.08736666216640866, \"time-step\": 3009}, {\"errors\": 0.08733862870176241, \"time-step\": 3010}, {\"errors\": 0.08731057871059131, \"time-step\": 3011}, {\"errors\": 0.08728251208683895, \"time-step\": 3012}, {\"errors\": 0.08725442872416936, \"time-step\": 3013}, {\"errors\": 0.08722632851596734, \"time-step\": 3014}, {\"errors\": 0.08719821135533783, \"time-step\": 3015}, {\"errors\": 0.08717007713510638, \"time-step\": 3016}, {\"errors\": 0.0871419257478186, \"time-step\": 3017}, {\"errors\": 0.08711375708574035, \"time-step\": 3018}, {\"errors\": 0.08708557104085748, \"time-step\": 3019}, {\"errors\": 0.0870573675048761, \"time-step\": 3020}, {\"errors\": 0.08702914636922202, \"time-step\": 3021}, {\"errors\": 0.08700090752504118, \"time-step\": 3022}, {\"errors\": 0.08697265086319915, \"time-step\": 3023}, {\"errors\": 0.0869443762742815, \"time-step\": 3024}, {\"errors\": 0.08691608364859335, \"time-step\": 3025}, {\"errors\": 0.0868877728761597, \"time-step\": 3026}, {\"errors\": 0.08685944384672513, \"time-step\": 3027}, {\"errors\": 0.08683109644975376, \"time-step\": 3028}, {\"errors\": 0.08680273057442951, \"time-step\": 3029}, {\"errors\": 0.08677434610965562, \"time-step\": 3030}, {\"errors\": 0.08674594294405512, \"time-step\": 3031}, {\"errors\": 0.08671752096597046, \"time-step\": 3032}, {\"errors\": 0.08668908006346367, \"time-step\": 3033}, {\"errors\": 0.08666062012431619, \"time-step\": 3034}, {\"errors\": 0.0866321410360291, \"time-step\": 3035}, {\"errors\": 0.08660364268582293, \"time-step\": 3036}, {\"errors\": 0.08657512496063799, \"time-step\": 3037}, {\"errors\": 0.08654658774713378, \"time-step\": 3038}, {\"errors\": 0.08651803093168972, \"time-step\": 3039}, {\"errors\": 0.08648945440040465, \"time-step\": 3040}, {\"errors\": 0.08646085803909709, \"time-step\": 3041}, {\"errors\": 0.08643224173330541, \"time-step\": 3042}, {\"errors\": 0.08640360536828756, \"time-step\": 3043}, {\"errors\": 0.08637494882902136, \"time-step\": 3044}, {\"errors\": 0.08634627200020445, \"time-step\": 3045}, {\"errors\": 0.0863175747662545, \"time-step\": 3046}, {\"errors\": 0.08628885701130914, \"time-step\": 3047}, {\"errors\": 0.08626011861922597, \"time-step\": 3048}, {\"errors\": 0.08623135947358296, \"time-step\": 3049}, {\"errors\": 0.08620257945767823, \"time-step\": 3050}, {\"errors\": 0.08617377845453036, \"time-step\": 3051}, {\"errors\": 0.08614495634687828, \"time-step\": 3052}, {\"errors\": 0.08611611301718174, \"time-step\": 3053}, {\"errors\": 0.08608724834762098, \"time-step\": 3054}, {\"errors\": 0.08605836222009733, \"time-step\": 3055}, {\"errors\": 0.08602945451623287, \"time-step\": 3056}, {\"errors\": 0.08600052511737112, \"time-step\": 3057}, {\"errors\": 0.08597157390457663, \"time-step\": 3058}, {\"errors\": 0.0859426007586356, \"time-step\": 3059}, {\"errors\": 0.08591360556005588, \"time-step\": 3060}, {\"errors\": 0.08588458818906697, \"time-step\": 3061}, {\"errors\": 0.08585554852562065, \"time-step\": 3062}, {\"errors\": 0.0858264864493907, \"time-step\": 3063}, {\"errors\": 0.08579740183977333, \"time-step\": 3064}, {\"errors\": 0.08576829457588755, \"time-step\": 3065}, {\"errors\": 0.0857391645365751, \"time-step\": 3066}, {\"errors\": 0.08571001160040084, \"time-step\": 3067}, {\"errors\": 0.08568083564565296, \"time-step\": 3068}, {\"errors\": 0.08565163655034325, \"time-step\": 3069}, {\"errors\": 0.08562241419220737, \"time-step\": 3070}, {\"errors\": 0.08559316844870507, \"time-step\": 3071}, {\"errors\": 0.08556389919702052, \"time-step\": 3072}, {\"errors\": 0.08553460631406266, \"time-step\": 3073}, {\"errors\": 0.08550528967646535, \"time-step\": 3074}, {\"errors\": 0.08547594916058768, \"time-step\": 3075}, {\"errors\": 0.08544658464251459, \"time-step\": 3076}, {\"errors\": 0.08541719599805674, \"time-step\": 3077}, {\"errors\": 0.08538778310275132, \"time-step\": 3078}, {\"errors\": 0.085358345831862, \"time-step\": 3079}, {\"errors\": 0.08532888406037961, \"time-step\": 3080}, {\"errors\": 0.08529939766302227, \"time-step\": 3081}, {\"errors\": 0.085269886514236, \"time-step\": 3082}, {\"errors\": 0.08524035048819499, \"time-step\": 3083}, {\"errors\": 0.0852107894588019, \"time-step\": 3084}, {\"errors\": 0.08518120329968851, \"time-step\": 3085}, {\"errors\": 0.08515159188421603, \"time-step\": 3086}, {\"errors\": 0.0851219550854756, \"time-step\": 3087}, {\"errors\": 0.08509229277628866, \"time-step\": 3088}, {\"errors\": 0.08506260482920747, \"time-step\": 3089}, {\"errors\": 0.08503289111651563, \"time-step\": 3090}, {\"errors\": 0.08500315151022844, \"time-step\": 3091}, {\"errors\": 0.08497338588209374, \"time-step\": 3092}, {\"errors\": 0.08494359410359181, \"time-step\": 3093}, {\"errors\": 0.08491377604593664, \"time-step\": 3094}, {\"errors\": 0.0848839315800759, \"time-step\": 3095}, {\"errors\": 0.08485406057669176, \"time-step\": 3096}, {\"errors\": 0.08482416290620147, \"time-step\": 3097}, {\"errors\": 0.08479423843875782, \"time-step\": 3098}, {\"errors\": 0.08476428704424988, \"time-step\": 3099}, {\"errors\": 0.08473430859230352, \"time-step\": 3100}, {\"errors\": 0.08470430295228198, \"time-step\": 3101}, {\"errors\": 0.08467426999328663, \"time-step\": 3102}, {\"errors\": 0.08464420958415765, \"time-step\": 3103}, {\"errors\": 0.08461412159347459, \"time-step\": 3104}, {\"errors\": 0.08458400588955707, \"time-step\": 3105}, {\"errors\": 0.08455386234046545, \"time-step\": 3106}, {\"errors\": 0.08452369081400174, \"time-step\": 3107}, {\"errors\": 0.08449349117771011, \"time-step\": 3108}, {\"errors\": 0.08446326329887768, \"time-step\": 3109}, {\"errors\": 0.08443300704453534, \"time-step\": 3110}, {\"errors\": 0.08440272228145848, \"time-step\": 3111}, {\"errors\": 0.08437240887616786, \"time-step\": 3112}, {\"errors\": 0.08434206669493025, \"time-step\": 3113}, {\"errors\": 0.08431169560375945, \"time-step\": 3114}, {\"errors\": 0.08428129546841688, \"time-step\": 3115}, {\"errors\": 0.08425086615441281, \"time-step\": 3116}, {\"errors\": 0.08422040752700677, \"time-step\": 3117}, {\"errors\": 0.08418991945120888, \"time-step\": 3118}, {\"errors\": 0.08415940179178044, \"time-step\": 3119}, {\"errors\": 0.08412885441323492, \"time-step\": 3120}, {\"errors\": 0.08409827717983906, \"time-step\": 3121}, {\"errors\": 0.08406766995561367, \"time-step\": 3122}, {\"errors\": 0.0840370326043346, \"time-step\": 3123}, {\"errors\": 0.08400636498953384, \"time-step\": 3124}, {\"errors\": 0.08397566697450037, \"time-step\": 3125}, {\"errors\": 0.08394493842228132, \"time-step\": 3126}, {\"errors\": 0.0839141791956831, \"time-step\": 3127}, {\"errors\": 0.08388338915727224, \"time-step\": 3128}, {\"errors\": 0.08385256816937647, \"time-step\": 3129}, {\"errors\": 0.08382171609408613, \"time-step\": 3130}, {\"errors\": 0.08379083279325497, \"time-step\": 3131}, {\"errors\": 0.08375991812850145, \"time-step\": 3132}, {\"errors\": 0.08372897196120976, \"time-step\": 3133}, {\"errors\": 0.08369799415253133, \"time-step\": 3134}, {\"errors\": 0.08366698456338553, \"time-step\": 3135}, {\"errors\": 0.08363594305446129, \"time-step\": 3136}, {\"errors\": 0.08360486948621815, \"time-step\": 3137}, {\"errors\": 0.08357376371888758, \"time-step\": 3138}, {\"errors\": 0.08354262561247427, \"time-step\": 3139}, {\"errors\": 0.08351145502675739, \"time-step\": 3140}, {\"errors\": 0.08348025182129187, \"time-step\": 3141}, {\"errors\": 0.08344901585540984, \"time-step\": 3142}, {\"errors\": 0.08341774698822202, \"time-step\": 3143}, {\"errors\": 0.08338644507861878, \"time-step\": 3144}, {\"errors\": 0.08335510998527208, \"time-step\": 3145}, {\"errors\": 0.08332374156663641, \"time-step\": 3146}, {\"errors\": 0.08329233968095043, \"time-step\": 3147}, {\"errors\": 0.08326090418623852, \"time-step\": 3148}, {\"errors\": 0.08322943494031214, \"time-step\": 3149}, {\"errors\": 0.08319793180077134, \"time-step\": 3150}, {\"errors\": 0.08316639462500647, \"time-step\": 3151}, {\"errors\": 0.08313482327019947, \"time-step\": 3152}, {\"errors\": 0.08310321759332562, \"time-step\": 3153}, {\"errors\": 0.0830715774511552, \"time-step\": 3154}, {\"errors\": 0.08303990270025491, \"time-step\": 3155}, {\"errors\": 0.08300819319698965, \"time-step\": 3156}, {\"errors\": 0.08297644879752425, \"time-step\": 3157}, {\"errors\": 0.082944669357825, \"time-step\": 3158}, {\"errors\": 0.08291285473366149, \"time-step\": 3159}, {\"errors\": 0.08288100478060834, \"time-step\": 3160}, {\"errors\": 0.08284911935404693, \"time-step\": 3161}, {\"errors\": 0.08281719830916724, \"time-step\": 3162}, {\"errors\": 0.08278524150096955, \"time-step\": 3163}, {\"errors\": 0.08275324878426644, \"time-step\": 3164}, {\"errors\": 0.08272122001368457, \"time-step\": 3165}, {\"errors\": 0.0826891550436666, \"time-step\": 3166}, {\"errors\": 0.08265705372847296, \"time-step\": 3167}, {\"errors\": 0.08262491592218404, \"time-step\": 3168}, {\"errors\": 0.08259274147870205, \"time-step\": 3169}, {\"errors\": 0.08256053025175285, \"time-step\": 3170}, {\"errors\": 0.08252828209488824, \"time-step\": 3171}, {\"errors\": 0.08249599686148776, \"time-step\": 3172}, {\"errors\": 0.0824636744047609, \"time-step\": 3173}, {\"errors\": 0.0824313145777492, \"time-step\": 3174}, {\"errors\": 0.08239891723332833, \"time-step\": 3175}, {\"errors\": 0.08236648222421013, \"time-step\": 3176}, {\"errors\": 0.08233400940294502, \"time-step\": 3177}, {\"errors\": 0.08230149862192393, \"time-step\": 3178}, {\"errors\": 0.08226894973338084, \"time-step\": 3179}, {\"errors\": 0.08223636258939476, \"time-step\": 3180}, {\"errors\": 0.08220373704189211, \"time-step\": 3181}, {\"errors\": 0.08217107294264904, \"time-step\": 3182}, {\"errors\": 0.08213837014329378, \"time-step\": 3183}, {\"errors\": 0.082105628495309, \"time-step\": 3184}, {\"errors\": 0.08207284785003402, \"time-step\": 3185}, {\"errors\": 0.08204002805866772, \"time-step\": 3186}, {\"errors\": 0.08200716897227037, \"time-step\": 3187}, {\"errors\": 0.08197427044176653, \"time-step\": 3188}, {\"errors\": 0.0819413323179474, \"time-step\": 3189}, {\"errors\": 0.08190835445147342, \"time-step\": 3190}, {\"errors\": 0.08187533669287674, \"time-step\": 3191}, {\"errors\": 0.08184227889256385, \"time-step\": 3192}, {\"errors\": 0.08180918090081829, \"time-step\": 3193}, {\"errors\": 0.08177604256780327, \"time-step\": 3194}, {\"errors\": 0.08174286374356404, \"time-step\": 3195}, {\"errors\": 0.08170964427803118, \"time-step\": 3196}, {\"errors\": 0.08167638402102281, \"time-step\": 3197}, {\"errors\": 0.08164308282224766, \"time-step\": 3198}, {\"errors\": 0.0816097405313077, \"time-step\": 3199}, {\"errors\": 0.08157635699770122, \"time-step\": 3200}, {\"errors\": 0.08154293207082522, \"time-step\": 3201}, {\"errors\": 0.08150946559997888, \"time-step\": 3202}, {\"errors\": 0.081475957434366, \"time-step\": 3203}, {\"errors\": 0.08144240742309819, \"time-step\": 3204}, {\"errors\": 0.08140881541519776, \"time-step\": 3205}, {\"errors\": 0.08137518125960082, \"time-step\": 3206}, {\"errors\": 0.08134150480516017, \"time-step\": 3207}, {\"errors\": 0.08130778590064856, \"time-step\": 3208}, {\"errors\": 0.08127402439476163, \"time-step\": 3209}, {\"errors\": 0.08124022013612114, \"time-step\": 3210}, {\"errors\": 0.08120637297327808, \"time-step\": 3211}, {\"errors\": 0.08117248275471589, \"time-step\": 3212}, {\"errors\": 0.08113854932885364, \"time-step\": 3213}, {\"errors\": 0.08110457254404946, \"time-step\": 3214}, {\"errors\": 0.08107055224860352, \"time-step\": 3215}, {\"errors\": 0.08103648829076165, \"time-step\": 3216}, {\"errors\": 0.08100238051871865, \"time-step\": 3217}, {\"errors\": 0.08096822878062138, \"time-step\": 3218}, {\"errors\": 0.08093403292457255, \"time-step\": 3219}, {\"errors\": 0.08089979279863407, \"time-step\": 3220}, {\"errors\": 0.08086550825083025, \"time-step\": 3221}, {\"errors\": 0.08083117912915182, \"time-step\": 3222}, {\"errors\": 0.08079680528155903, \"time-step\": 3223}, {\"errors\": 0.08076238655598539, \"time-step\": 3224}, {\"errors\": 0.08072792280034137, \"time-step\": 3225}, {\"errors\": 0.08069341386251797, \"time-step\": 3226}, {\"errors\": 0.08065885959039021, \"time-step\": 3227}, {\"errors\": 0.08062425983182124, \"time-step\": 3228}, {\"errors\": 0.0805896144346657, \"time-step\": 3229}, {\"errors\": 0.08055492324677369, \"time-step\": 3230}, {\"errors\": 0.0805201861159946, \"time-step\": 3231}, {\"errors\": 0.0804854028901807, \"time-step\": 3232}, {\"errors\": 0.08045057341719139, \"time-step\": 3233}, {\"errors\": 0.08041569754489683, \"time-step\": 3234}, {\"errors\": 0.08038077512118187, \"time-step\": 3235}, {\"errors\": 0.08034580599395028, \"time-step\": 3236}, {\"errors\": 0.08031079001112834, \"time-step\": 3237}, {\"errors\": 0.0802757270206693, \"time-step\": 3238}, {\"errors\": 0.08024061687055725, \"time-step\": 3239}, {\"errors\": 0.08020545940881121, \"time-step\": 3240}, {\"errors\": 0.08017025448348912, \"time-step\": 3241}, {\"errors\": 0.08013500194269242, \"time-step\": 3242}, {\"errors\": 0.08009970163456992, \"time-step\": 3243}, {\"errors\": 0.08006435340732201, \"time-step\": 3244}, {\"errors\": 0.08002895710920516, \"time-step\": 3245}, {\"errors\": 0.07999351258853615, \"time-step\": 3246}, {\"errors\": 0.07995801969369615, \"time-step\": 3247}, {\"errors\": 0.07992247827313545, \"time-step\": 3248}, {\"errors\": 0.07988688817537769, \"time-step\": 3249}, {\"errors\": 0.07985124924902415, \"time-step\": 3250}, {\"errors\": 0.07981556134275852, \"time-step\": 3251}, {\"errors\": 0.07977982430535119, \"time-step\": 3252}, {\"errors\": 0.07974403798566373, \"time-step\": 3253}, {\"errors\": 0.07970820223265379, \"time-step\": 3254}, {\"errors\": 0.07967231689537921, \"time-step\": 3255}, {\"errors\": 0.07963638182300299, \"time-step\": 3256}, {\"errors\": 0.07960039686479789, \"time-step\": 3257}, {\"errors\": 0.07956436187015106, \"time-step\": 3258}, {\"errors\": 0.07952827668856885, \"time-step\": 3259}, {\"errors\": 0.0794921411696814, \"time-step\": 3260}, {\"errors\": 0.07945595516324772, \"time-step\": 3261}, {\"errors\": 0.07941971851916022, \"time-step\": 3262}, {\"errors\": 0.07938343108744976, \"time-step\": 3263}, {\"errors\": 0.07934709271829041, \"time-step\": 3264}, {\"errors\": 0.07931070326200446, \"time-step\": 3265}, {\"errors\": 0.07927426256906736, \"time-step\": 3266}, {\"errors\": 0.07923777049011266, \"time-step\": 3267}, {\"errors\": 0.07920122687593714, \"time-step\": 3268}, {\"errors\": 0.07916463157750567, \"time-step\": 3269}, {\"errors\": 0.0791279844459564, \"time-step\": 3270}, {\"errors\": 0.07909128533260593, \"time-step\": 3271}, {\"errors\": 0.07905453408895438, \"time-step\": 3272}, {\"errors\": 0.07901773056669051, \"time-step\": 3273}, {\"errors\": 0.07898087461769702, \"time-step\": 3274}, {\"errors\": 0.07894396609405582, \"time-step\": 3275}, {\"errors\": 0.07890700484805314, \"time-step\": 3276}, {\"errors\": 0.07886999073218492, \"time-step\": 3277}, {\"errors\": 0.07883292359916225, \"time-step\": 3278}, {\"errors\": 0.07879580330191646, \"time-step\": 3279}, {\"errors\": 0.07875862969360481, \"time-step\": 3280}, {\"errors\": 0.07872140262761562, \"time-step\": 3281}, {\"errors\": 0.078684121957574, \"time-step\": 3282}, {\"errors\": 0.07864678753734705, \"time-step\": 3283}, {\"errors\": 0.07860939922104965, \"time-step\": 3284}, {\"errors\": 0.07857195686304971, \"time-step\": 3285}, {\"errors\": 0.07853446031797406, \"time-step\": 3286}, {\"errors\": 0.07849690944071375, \"time-step\": 3287}, {\"errors\": 0.07845930408642973, \"time-step\": 3288}, {\"errors\": 0.07842164411055878, \"time-step\": 3289}, {\"errors\": 0.07838392936881877, \"time-step\": 3290}, {\"errors\": 0.07834615971721459, \"time-step\": 3291}, {\"errors\": 0.07830833501204401, \"time-step\": 3292}, {\"errors\": 0.0782704551099032, \"time-step\": 3293}, {\"errors\": 0.07823251986769264, \"time-step\": 3294}, {\"errors\": 0.07819452914262301, \"time-step\": 3295}, {\"errors\": 0.07815648279222084, \"time-step\": 3296}, {\"errors\": 0.07811838067433459, \"time-step\": 3297}, {\"errors\": 0.07808022264714037, \"time-step\": 3298}, {\"errors\": 0.07804200856914795, \"time-step\": 3299}, {\"errors\": 0.07800373829920688, \"time-step\": 3300}, {\"errors\": 0.0779654116965121, \"time-step\": 3301}, {\"errors\": 0.0779270286206103, \"time-step\": 3302}, {\"errors\": 0.07788858893140557, \"time-step\": 3303}, {\"errors\": 0.07785009248916591, \"time-step\": 3304}, {\"errors\": 0.07781153915452901, \"time-step\": 3305}, {\"errors\": 0.07777292878850832, \"time-step\": 3306}, {\"errors\": 0.07773426125249938, \"time-step\": 3307}, {\"errors\": 0.07769553640828569, \"time-step\": 3308}, {\"errors\": 0.07765675411804525, \"time-step\": 3309}, {\"errors\": 0.0776179142443564, \"time-step\": 3310}, {\"errors\": 0.07757901665020417, \"time-step\": 3311}, {\"errors\": 0.07754006119898667, \"time-step\": 3312}, {\"errors\": 0.07750104775452113, \"time-step\": 3313}, {\"errors\": 0.07746197618105022, \"time-step\": 3314}, {\"errors\": 0.07742284634324847, \"time-step\": 3315}, {\"errors\": 0.07738365810622855, \"time-step\": 3316}, {\"errors\": 0.07734441133554751, \"time-step\": 3317}, {\"errors\": 0.07730510589721327, \"time-step\": 3318}, {\"errors\": 0.07726574165769098, \"time-step\": 3319}, {\"errors\": 0.07722631848390936, \"time-step\": 3320}, {\"errors\": 0.07718683624326711, \"time-step\": 3321}, {\"errors\": 0.07714729480363966, \"time-step\": 3322}, {\"errors\": 0.07710769403338502, \"time-step\": 3323}, {\"errors\": 0.07706803380135091, \"time-step\": 3324}, {\"errors\": 0.07702831397688086, \"time-step\": 3325}, {\"errors\": 0.07698853442982076, \"time-step\": 3326}, {\"errors\": 0.07694869503052555, \"time-step\": 3327}, {\"errors\": 0.07690879564986564, \"time-step\": 3328}, {\"errors\": 0.07686883615923348, \"time-step\": 3329}, {\"errors\": 0.0768288164305501, \"time-step\": 3330}, {\"errors\": 0.07678873633627195, \"time-step\": 3331}, {\"errors\": 0.07674859574939717, \"time-step\": 3332}, {\"errors\": 0.07670839454347224, \"time-step\": 3333}, {\"errors\": 0.076668132592599, \"time-step\": 3334}, {\"errors\": 0.07662780977144082, \"time-step\": 3335}, {\"errors\": 0.07658742595522955, \"time-step\": 3336}, {\"errors\": 0.07654698101977198, \"time-step\": 3337}, {\"errors\": 0.0765064748414568, \"time-step\": 3338}, {\"errors\": 0.07646590729726108, \"time-step\": 3339}, {\"errors\": 0.07642527826475687, \"time-step\": 3340}, {\"errors\": 0.07638458762211847, \"time-step\": 3341}, {\"errors\": 0.07634383524812832, \"time-step\": 3342}, {\"errors\": 0.07630302102218445, \"time-step\": 3343}, {\"errors\": 0.07626214482430696, \"time-step\": 3344}, {\"errors\": 0.0762212065351445, \"time-step\": 3345}, {\"errors\": 0.07618020603598155, \"time-step\": 3346}, {\"errors\": 0.0761391432087449, \"time-step\": 3347}, {\"errors\": 0.07609801793601029, \"time-step\": 3348}, {\"errors\": 0.07605683010100955, \"time-step\": 3349}, {\"errors\": 0.07601557958763697, \"time-step\": 3350}, {\"errors\": 0.07597426628045648, \"time-step\": 3351}, {\"errors\": 0.07593289006470827, \"time-step\": 3352}, {\"errors\": 0.07589145082631549, \"time-step\": 3353}, {\"errors\": 0.07584994845189115, \"time-step\": 3354}, {\"errors\": 0.07580838282874502, \"time-step\": 3355}, {\"errors\": 0.07576675384489037, \"time-step\": 3356}, {\"errors\": 0.07572506138905064, \"time-step\": 3357}, {\"errors\": 0.07568330535066645, \"time-step\": 3358}, {\"errors\": 0.07564148561990239, \"time-step\": 3359}, {\"errors\": 0.07559960208765358, \"time-step\": 3360}, {\"errors\": 0.07555765464555297, \"time-step\": 3361}, {\"errors\": 0.07551564318597767, \"time-step\": 3362}, {\"errors\": 0.07547356760205606, \"time-step\": 3363}, {\"errors\": 0.0754314277876744, \"time-step\": 3364}, {\"errors\": 0.07538922363748388, \"time-step\": 3365}, {\"errors\": 0.07534695504690714, \"time-step\": 3366}, {\"errors\": 0.07530462191214546, \"time-step\": 3367}, {\"errors\": 0.07526222413018496, \"time-step\": 3368}, {\"errors\": 0.07521976159880411, \"time-step\": 3369}, {\"errors\": 0.07517723421657982, \"time-step\": 3370}, {\"errors\": 0.07513464188289493, \"time-step\": 3371}, {\"errors\": 0.0750919844979443, \"time-step\": 3372}, {\"errors\": 0.07504926196274204, \"time-step\": 3373}, {\"errors\": 0.07500647417912812, \"time-step\": 3374}, {\"errors\": 0.07496362104977507, \"time-step\": 3375}, {\"errors\": 0.07492070247819488, \"time-step\": 3376}, {\"errors\": 0.0748777183687456, \"time-step\": 3377}, {\"errors\": 0.07483466862663807, \"time-step\": 3378}, {\"errors\": 0.07479155315794264, \"time-step\": 3379}, {\"errors\": 0.07474837186959604, \"time-step\": 3380}, {\"errors\": 0.07470512466940779, \"time-step\": 3381}, {\"errors\": 0.07466181146606715, \"time-step\": 3382}, {\"errors\": 0.07461843216914954, \"time-step\": 3383}, {\"errors\": 0.07457498668912349, \"time-step\": 3384}, {\"errors\": 0.07453147493735685, \"time-step\": 3385}, {\"errors\": 0.07448789682612392, \"time-step\": 3386}, {\"errors\": 0.0744442522686117, \"time-step\": 3387}, {\"errors\": 0.07440054117892661, \"time-step\": 3388}, {\"errors\": 0.07435676347210102, \"time-step\": 3389}, {\"errors\": 0.07431291906409992, \"time-step\": 3390}, {\"errors\": 0.07426900787182736, \"time-step\": 3391}, {\"errors\": 0.07422502981313293, \"time-step\": 3392}, {\"errors\": 0.07418098480681845, \"time-step\": 3393}, {\"errors\": 0.07413687277264429, \"time-step\": 3394}, {\"errors\": 0.07409269363133592, \"time-step\": 3395}, {\"errors\": 0.07404844730459023, \"time-step\": 3396}, {\"errors\": 0.07400413371508228, \"time-step\": 3397}, {\"errors\": 0.07395975278647118, \"time-step\": 3398}, {\"errors\": 0.07391530444340705, \"time-step\": 3399}, {\"errors\": 0.073870788611537, \"time-step\": 3400}, {\"errors\": 0.07382620521751138, \"time-step\": 3401}, {\"errors\": 0.0737815541889906, \"time-step\": 3402}, {\"errors\": 0.07373683545465085, \"time-step\": 3403}, {\"errors\": 0.07369204894419067, \"time-step\": 3404}, {\"errors\": 0.07364719458833716, \"time-step\": 3405}, {\"errors\": 0.07360227231885214, \"time-step\": 3406}, {\"errors\": 0.07355728206853826, \"time-step\": 3407}, {\"errors\": 0.07351222377124536, \"time-step\": 3408}, {\"errors\": 0.07346709736187629, \"time-step\": 3409}, {\"errors\": 0.07342190277639335, \"time-step\": 3410}, {\"errors\": 0.07337663995182414, \"time-step\": 3411}, {\"errors\": 0.07333130882626769, \"time-step\": 3412}, {\"errors\": 0.07328590933890032, \"time-step\": 3413}, {\"errors\": 0.07324044142998193, \"time-step\": 3414}, {\"errors\": 0.07319490504086146, \"time-step\": 3415}, {\"errors\": 0.07314930011398328, \"time-step\": 3416}, {\"errors\": 0.07310362659289299, \"time-step\": 3417}, {\"errors\": 0.07305788442224287, \"time-step\": 3418}, {\"errors\": 0.0730120735477982, \"time-step\": 3419}, {\"errors\": 0.07296619391644282, \"time-step\": 3420}, {\"errors\": 0.07292024547618475, \"time-step\": 3421}, {\"errors\": 0.07287422817616215, \"time-step\": 3422}, {\"errors\": 0.07282814196664882, \"time-step\": 3423}, {\"errors\": 0.0727819867990599, \"time-step\": 3424}, {\"errors\": 0.07273576262595749, \"time-step\": 3425}, {\"errors\": 0.07268946940105625, \"time-step\": 3426}, {\"errors\": 0.07264310707922875, \"time-step\": 3427}, {\"errors\": 0.07259667561651112, \"time-step\": 3428}, {\"errors\": 0.07255017497010852, \"time-step\": 3429}, {\"errors\": 0.07250360509840048, \"time-step\": 3430}, {\"errors\": 0.07245696596094622, \"time-step\": 3431}, {\"errors\": 0.07241025751849008, \"time-step\": 3432}, {\"errors\": 0.0723634797329667, \"time-step\": 3433}, {\"errors\": 0.07231663256750655, \"time-step\": 3434}, {\"errors\": 0.0722697159864407, \"time-step\": 3435}, {\"errors\": 0.07222272995530635, \"time-step\": 3436}, {\"errors\": 0.07217567444085182, \"time-step\": 3437}, {\"errors\": 0.07212854941104152, \"time-step\": 3438}, {\"errors\": 0.07208135483506117, \"time-step\": 3439}, {\"errors\": 0.07203409068332278, \"time-step\": 3440}, {\"errors\": 0.07198675692746945, \"time-step\": 3441}, {\"errors\": 0.07193935354038028, \"time-step\": 3442}, {\"errors\": 0.07189188049617551, \"time-step\": 3443}, {\"errors\": 0.07184433777022112, \"time-step\": 3444}, {\"errors\": 0.07179672533913332, \"time-step\": 3445}, {\"errors\": 0.07174904318078393, \"time-step\": 3446}, {\"errors\": 0.07170129127430441, \"time-step\": 3447}, {\"errors\": 0.071653469600091, \"time-step\": 3448}, {\"errors\": 0.07160557813980886, \"time-step\": 3449}, {\"errors\": 0.07155761687639683, \"time-step\": 3450}, {\"errors\": 0.07150958579407207, \"time-step\": 3451}, {\"errors\": 0.071461484878334, \"time-step\": 3452}, {\"errors\": 0.07141331411596932, \"time-step\": 3453}, {\"errors\": 0.07136507349505582, \"time-step\": 3454}, {\"errors\": 0.07131676300496691, \"time-step\": 3455}, {\"errors\": 0.07126838263637587, \"time-step\": 3456}, {\"errors\": 0.07121993238125998, \"time-step\": 3457}, {\"errors\": 0.07117141223290452, \"time-step\": 3458}, {\"errors\": 0.07112282218590726, \"time-step\": 3459}, {\"errors\": 0.071074162236182, \"time-step\": 3460}, {\"errors\": 0.07102543238096284, \"time-step\": 3461}, {\"errors\": 0.07097663261880816, \"time-step\": 3462}, {\"errors\": 0.07092776294960423, \"time-step\": 3463}, {\"errors\": 0.07087882337456933, \"time-step\": 3464}, {\"errors\": 0.07082981389625734, \"time-step\": 3465}, {\"errors\": 0.0707807345185615, \"time-step\": 3466}, {\"errors\": 0.07073158524671815, \"time-step\": 3467}, {\"errors\": 0.07068236608731016, \"time-step\": 3468}, {\"errors\": 0.07063307704827085, \"time-step\": 3469}, {\"errors\": 0.07058371813888696, \"time-step\": 3470}, {\"errors\": 0.07053428936980266, \"time-step\": 3471}, {\"errors\": 0.07048479075302255, \"time-step\": 3472}, {\"errors\": 0.0704352223019152, \"time-step\": 3473}, {\"errors\": 0.07038558403121642, \"time-step\": 3474}, {\"errors\": 0.07033587595703235, \"time-step\": 3475}, {\"errors\": 0.07028609809684291, \"time-step\": 3476}, {\"errors\": 0.07023625046950469, \"time-step\": 3477}, {\"errors\": 0.07018633309525404, \"time-step\": 3478}, {\"errors\": 0.07013634599571023, \"time-step\": 3479}, {\"errors\": 0.07008628919387817, \"time-step\": 3480}, {\"errors\": 0.07003616271415172, \"time-step\": 3481}, {\"errors\": 0.06998596658231604, \"time-step\": 3482}, {\"errors\": 0.06993570082555059, \"time-step\": 3483}, {\"errors\": 0.06988536547243215, \"time-step\": 3484}, {\"errors\": 0.06983496055293695, \"time-step\": 3485}, {\"errors\": 0.06978448609844376, \"time-step\": 3486}, {\"errors\": 0.06973394214173613, \"time-step\": 3487}, {\"errors\": 0.06968332871700511, \"time-step\": 3488}, {\"errors\": 0.06963264585985166, \"time-step\": 3489}, {\"errors\": 0.06958189360728884, \"time-step\": 3490}, {\"errors\": 0.06953107199774447, \"time-step\": 3491}, {\"errors\": 0.06948018107106323, \"time-step\": 3492}, {\"errors\": 0.06942922086850888, \"time-step\": 3493}, {\"errors\": 0.06937819143276638, \"time-step\": 3494}, {\"errors\": 0.06932709280794419, \"time-step\": 3495}, {\"errors\": 0.06927592503957615, \"time-step\": 3496}, {\"errors\": 0.06922468817462342, \"time-step\": 3497}, {\"errors\": 0.06917338226147668, \"time-step\": 3498}, {\"errors\": 0.06912200734995769, \"time-step\": 3499}, {\"errors\": 0.0690705634913214, \"time-step\": 3500}, {\"errors\": 0.06901905073825752, \"time-step\": 3501}, {\"errors\": 0.06896746914489223, \"time-step\": 3502}, {\"errors\": 0.06891581876678994, \"time-step\": 3503}, {\"errors\": 0.06886409966095494, \"time-step\": 3504}, {\"errors\": 0.0688123118858325, \"time-step\": 3505}, {\"errors\": 0.0687604555013111, \"time-step\": 3506}, {\"errors\": 0.06870853056872306, \"time-step\": 3507}, {\"errors\": 0.06865653715084641, \"time-step\": 3508}, {\"errors\": 0.06860447531190603, \"time-step\": 3509}, {\"errors\": 0.06855234511757508, \"time-step\": 3510}, {\"errors\": 0.06850014663497565, \"time-step\": 3511}, {\"errors\": 0.06844787993268066, \"time-step\": 3512}, {\"errors\": 0.06839554508071428, \"time-step\": 3513}, {\"errors\": 0.0683431421505534, \"time-step\": 3514}, {\"errors\": 0.0682906712151283, \"time-step\": 3515}, {\"errors\": 0.06823813234882388, \"time-step\": 3516}, {\"errors\": 0.06818552562748002, \"time-step\": 3517}, {\"errors\": 0.06813285112839276, \"time-step\": 3518}, {\"errors\": 0.06808010893031505, \"time-step\": 3519}, {\"errors\": 0.06802729911345727, \"time-step\": 3520}, {\"errors\": 0.06797442175948781, \"time-step\": 3521}, {\"errors\": 0.06792147695153389, \"time-step\": 3522}, {\"errors\": 0.06786846477418175, \"time-step\": 3523}, {\"errors\": 0.06781538531347737, \"time-step\": 3524}, {\"errors\": 0.06776223865692688, \"time-step\": 3525}, {\"errors\": 0.06770902489349657, \"time-step\": 3526}, {\"errors\": 0.06765574411361364, \"time-step\": 3527}, {\"errors\": 0.06760239640916613, \"time-step\": 3528}, {\"errors\": 0.06754898187350307, \"time-step\": 3529}, {\"errors\": 0.06749550060143489, \"time-step\": 3530}, {\"errors\": 0.06744195268923328, \"time-step\": 3531}, {\"errors\": 0.0673883382346312, \"time-step\": 3532}, {\"errors\": 0.06733465733682292, \"time-step\": 3533}, {\"errors\": 0.06728091009646385, \"time-step\": 3534}, {\"errors\": 0.06722709661567053, \"time-step\": 3535}, {\"errors\": 0.06717321699802023, \"time-step\": 3536}, {\"errors\": 0.06711927134855086, \"time-step\": 3537}, {\"errors\": 0.06706525977376063, \"time-step\": 3538}, {\"errors\": 0.06701118238160757, \"time-step\": 3539}, {\"errors\": 0.06695703928150937, \"time-step\": 3540}, {\"errors\": 0.06690283058434246, \"time-step\": 3541}, {\"errors\": 0.06684855640244214, \"time-step\": 3542}, {\"errors\": 0.06679421684960135, \"time-step\": 3543}, {\"errors\": 0.06673981204107046, \"time-step\": 3544}, {\"errors\": 0.06668534209355649, \"time-step\": 3545}, {\"errors\": 0.06663080712522225, \"time-step\": 3546}, {\"errors\": 0.06657620725568571, \"time-step\": 3547}, {\"errors\": 0.06652154260601915, \"time-step\": 3548}, {\"errors\": 0.06646681329874816, \"time-step\": 3549}, {\"errors\": 0.06641201945785083, \"time-step\": 3550}, {\"errors\": 0.06635716120875677, \"time-step\": 3551}, {\"errors\": 0.06630223867834589, \"time-step\": 3552}, {\"errors\": 0.06624725199494741, \"time-step\": 3553}, {\"errors\": 0.0661922012883388, \"time-step\": 3554}, {\"errors\": 0.06613708668974455, \"time-step\": 3555}, {\"errors\": 0.06608190833183489, \"time-step\": 3556}, {\"errors\": 0.06602666634872445, \"time-step\": 3557}, {\"errors\": 0.06597136087597086, \"time-step\": 3558}, {\"errors\": 0.06591599205057369, \"time-step\": 3559}, {\"errors\": 0.06586056001097271, \"time-step\": 3560}, {\"errors\": 0.06580506489704642, \"time-step\": 3561}, {\"errors\": 0.0657495068501106, \"time-step\": 3562}, {\"errors\": 0.06569388601291669, \"time-step\": 3563}, {\"errors\": 0.0656382025296501, \"time-step\": 3564}, {\"errors\": 0.06558245654592865, \"time-step\": 3565}, {\"errors\": 0.06552664820880061, \"time-step\": 3566}, {\"errors\": 0.06547077766674335, \"time-step\": 3567}, {\"errors\": 0.06541484506966094, \"time-step\": 3568}, {\"errors\": 0.06535885056888267, \"time-step\": 3569}, {\"errors\": 0.06530279431716102, \"time-step\": 3570}, {\"errors\": 0.06524667646866969, \"time-step\": 3571}, {\"errors\": 0.06519049717900155, \"time-step\": 3572}, {\"errors\": 0.06513425660516658, \"time-step\": 3573}, {\"errors\": 0.06507795490558979, \"time-step\": 3574}, {\"errors\": 0.06502159224010907, \"time-step\": 3575}, {\"errors\": 0.064965168769973, \"time-step\": 3576}, {\"errors\": 0.06490868465783844, \"time-step\": 3577}, {\"errors\": 0.0648521400677684, \"time-step\": 3578}, {\"errors\": 0.06479553516522973, \"time-step\": 3579}, {\"errors\": 0.06473887011709072, \"time-step\": 3580}, {\"errors\": 0.06468214509161825, \"time-step\": 3581}, {\"errors\": 0.06462536025847607, \"time-step\": 3582}, {\"errors\": 0.06456851578872169, \"time-step\": 3583}, {\"errors\": 0.06451161185480404, \"time-step\": 3584}, {\"errors\": 0.06445464863056077, \"time-step\": 3585}, {\"errors\": 0.06439762629121565, \"time-step\": 3586}, {\"errors\": 0.06434054501337588, \"time-step\": 3587}, {\"errors\": 0.0642834049750294, \"time-step\": 3588}, {\"errors\": 0.06422620635554185, \"time-step\": 3589}, {\"errors\": 0.0641689493356541, \"time-step\": 3590}, {\"errors\": 0.06411163409747912, \"time-step\": 3591}, {\"errors\": 0.06405426082449912, \"time-step\": 3592}, {\"errors\": 0.06399682970156259, \"time-step\": 3593}, {\"errors\": 0.06393934091488147, \"time-step\": 3594}, {\"errors\": 0.06388179465202763, \"time-step\": 3595}, {\"errors\": 0.0638241911019305, \"time-step\": 3596}, {\"errors\": 0.06376653045487307, \"time-step\": 3597}, {\"errors\": 0.06370881290248968, \"time-step\": 3598}, {\"errors\": 0.06365103863776189, \"time-step\": 3599}, {\"errors\": 0.06359320785501592, \"time-step\": 3600}, {\"errors\": 0.0635353207499189, \"time-step\": 3601}, {\"errors\": 0.06347737751947569, \"time-step\": 3602}, {\"errors\": 0.06341937836202564, \"time-step\": 3603}, {\"errors\": 0.06336132347723891, \"time-step\": 3604}, {\"errors\": 0.06330321306611307, \"time-step\": 3605}, {\"errors\": 0.06324504733096982, \"time-step\": 3606}, {\"errors\": 0.06318682647545117, \"time-step\": 3607}, {\"errors\": 0.06312855070451591, \"time-step\": 3608}, {\"errors\": 0.0630702202244359, \"time-step\": 3609}, {\"errors\": 0.06301183524279286, \"time-step\": 3610}, {\"errors\": 0.06295339596847396, \"time-step\": 3611}, {\"errors\": 0.06289490261166855, \"time-step\": 3612}, {\"errors\": 0.06283635538386426, \"time-step\": 3613}, {\"errors\": 0.06277775449784312, \"time-step\": 3614}, {\"errors\": 0.06271910016767769, \"time-step\": 3615}, {\"errors\": 0.06266039260872716, \"time-step\": 3616}, {\"errors\": 0.06260163203763328, \"time-step\": 3617}, {\"errors\": 0.06254281867231683, \"time-step\": 3618}, {\"errors\": 0.062483952731972825, \"time-step\": 3619}, {\"errors\": 0.06242503443706708, \"time-step\": 3620}, {\"errors\": 0.062366064009331895, \"time-step\": 3621}, {\"errors\": 0.06230704167176171, \"time-step\": 3622}, {\"errors\": 0.06224796764860923, \"time-step\": 3623}, {\"errors\": 0.062188842165380995, \"time-step\": 3624}, {\"errors\": 0.06212966544883317, \"time-step\": 3625}, {\"errors\": 0.06207043772696719, \"time-step\": 3626}, {\"errors\": 0.06201115922902539, \"time-step\": 3627}, {\"errors\": 0.061951830185486854, \"time-step\": 3628}, {\"errors\": 0.061892450828062634, \"time-step\": 3629}, {\"errors\": 0.061833021389691385, \"time-step\": 3630}, {\"errors\": 0.061773542104535145, \"time-step\": 3631}, {\"errors\": 0.0617140132079744, \"time-step\": 3632}, {\"errors\": 0.06165443493660358, \"time-step\": 3633}, {\"errors\": 0.061594807528226866, \"time-step\": 3634}, {\"errors\": 0.06153513122185275, \"time-step\": 3635}, {\"errors\": 0.061475406257690005, \"time-step\": 3636}, {\"errors\": 0.06141563287714272, \"time-step\": 3637}, {\"errors\": 0.061355811322805376, \"time-step\": 3638}, {\"errors\": 0.061295941838458295, \"time-step\": 3639}, {\"errors\": 0.061236024669062424, \"time-step\": 3640}, {\"errors\": 0.06117606006075492, \"time-step\": 3641}, {\"errors\": 0.06111604826084377, \"time-step\": 3642}, {\"errors\": 0.06105598951780314, \"time-step\": 3643}, {\"errors\": 0.060995884081268034, \"time-step\": 3644}, {\"errors\": 0.06093573220202972, \"time-step\": 3645}, {\"errors\": 0.06087553413203009, \"time-step\": 3646}, {\"errors\": 0.060815290124356866, \"time-step\": 3647}, {\"errors\": 0.060755000433238615, \"time-step\": 3648}, {\"errors\": 0.060694665314038956, \"time-step\": 3649}, {\"errors\": 0.060634285023251897, \"time-step\": 3650}, {\"errors\": 0.06057385981849624, \"time-step\": 3651}, {\"errors\": 0.06051338995851034, \"time-step\": 3652}, {\"errors\": 0.06045287570314685, \"time-step\": 3653}, {\"errors\": 0.06039231731336702, \"time-step\": 3654}, {\"errors\": 0.060331715051235746, \"time-step\": 3655}, {\"errors\": 0.06027106917991564, \"time-step\": 3656}, {\"errors\": 0.06021037996366174, \"time-step\": 3657}, {\"errors\": 0.06014964766781597, \"time-step\": 3658}, {\"errors\": 0.06008887255880152, \"time-step\": 3659}, {\"errors\": 0.060028054904117126, \"time-step\": 3660}, {\"errors\": 0.059967194972331606, \"time-step\": 3661}, {\"errors\": 0.059906293033077956, \"time-step\": 3662}, {\"errors\": 0.05984534935704779, \"time-step\": 3663}, {\"errors\": 0.05978436421598536, \"time-step\": 3664}, {\"errors\": 0.059723337882681915, \"time-step\": 3665}, {\"errors\": 0.059662270630969884, \"time-step\": 3666}, {\"errors\": 0.059601162735716647, \"time-step\": 3667}, {\"errors\": 0.059540014472819015, \"time-step\": 3668}, {\"errors\": 0.05947882611919706, \"time-step\": 3669}, {\"errors\": 0.059417597952788156, \"time-step\": 3670}, {\"errors\": 0.05935633025254086, \"time-step\": 3671}, {\"errors\": 0.059295023298408925, \"time-step\": 3672}, {\"errors\": 0.059233677371345064, \"time-step\": 3673}, {\"errors\": 0.05917229275329492, \"time-step\": 3674}, {\"errors\": 0.05911086972719091, \"time-step\": 3675}, {\"errors\": 0.059049408576945656, \"time-step\": 3676}, {\"errors\": 0.058987909587446166, \"time-step\": 3677}, {\"errors\": 0.05892637304454713, \"time-step\": 3678}, {\"errors\": 0.05886479923506498, \"time-step\": 3679}, {\"errors\": 0.05880318844677103, \"time-step\": 3680}, {\"errors\": 0.058741540968385325, \"time-step\": 3681}, {\"errors\": 0.058679857089570325, \"time-step\": 3682}, {\"errors\": 0.05861813710092404, \"time-step\": 3683}, {\"errors\": 0.05855638129397369, \"time-step\": 3684}, {\"errors\": 0.058494589961169186, \"time-step\": 3685}, {\"errors\": 0.05843276339587651, \"time-step\": 3686}, {\"errors\": 0.058370901892370694, \"time-step\": 3687}, {\"errors\": 0.0583090057458298, \"time-step\": 3688}, {\"errors\": 0.05824707525232753, \"time-step\": 3689}, {\"errors\": 0.058185110708826995, \"time-step\": 3690}, {\"errors\": 0.05812311241317353, \"time-step\": 3691}, {\"errors\": 0.05806108066408801, \"time-step\": 3692}, {\"errors\": 0.057999015761160094, \"time-step\": 3693}, {\"errors\": 0.057936918004840944, \"time-step\": 3694}, {\"errors\": 0.05787478769643687, \"time-step\": 3695}, {\"errors\": 0.0578126251381015, \"time-step\": 3696}, {\"errors\": 0.05775043063282978, \"time-step\": 3697}, {\"errors\": 0.0576882044844499, \"time-step\": 3698}, {\"errors\": 0.05762594699761694, \"time-step\": 3699}, {\"errors\": 0.05756365847780551, \"time-step\": 3700}, {\"errors\": 0.05750133923130223, \"time-step\": 3701}, {\"errors\": 0.057438989565199175, \"time-step\": 3702}, {\"errors\": 0.057376609787386054, \"time-step\": 3703}, {\"errors\": 0.057314200206543174, \"time-step\": 3704}, {\"errors\": 0.05725176113213415, \"time-step\": 3705}, {\"errors\": 0.05718929287439849, \"time-step\": 3706}, {\"errors\": 0.05712679574434419, \"time-step\": 3707}, {\"errors\": 0.057064270053740374, \"time-step\": 3708}, {\"errors\": 0.05700171611510978, \"time-step\": 3709}, {\"errors\": 0.056939134241721166, \"time-step\": 3710}, {\"errors\": 0.05687652474758204, \"time-step\": 3711}, {\"errors\": 0.056813887947430794, \"time-step\": 3712}, {\"errors\": 0.05675122415672938, \"time-step\": 3713}, {\"errors\": 0.05668853369165536, \"time-step\": 3714}, {\"errors\": 0.05662581686909457, \"time-step\": 3715}, {\"errors\": 0.056563074006633074, \"time-step\": 3716}, {\"errors\": 0.056500305422549704, \"time-step\": 3717}, {\"errors\": 0.056437511435808205, \"time-step\": 3718}, {\"errors\": 0.056374692366049126, \"time-step\": 3719}, {\"errors\": 0.0563118485335825, \"time-step\": 3720}, {\"errors\": 0.05624898025937959, \"time-step\": 3721}, {\"errors\": 0.05618608786506509, \"time-step\": 3722}, {\"errors\": 0.05612317167290902, \"time-step\": 3723}, {\"errors\": 0.0560602320058191, \"time-step\": 3724}, {\"errors\": 0.05599726918733236, \"time-step\": 3725}, {\"errors\": 0.05593428354160729, \"time-step\": 3726}, {\"errors\": 0.05587127539341574, \"time-step\": 3727}, {\"errors\": 0.055808245068134754, \"time-step\": 3728}, {\"errors\": 0.05574519289173844, \"time-step\": 3729}, {\"errors\": 0.05568211919078983, \"time-step\": 3730}, {\"errors\": 0.055619024292432574, \"time-step\": 3731}, {\"errors\": 0.05555590852438288, \"time-step\": 3732}, {\"errors\": 0.055492772214921, \"time-step\": 3733}, {\"errors\": 0.05542961569288317, \"time-step\": 3734}, {\"errors\": 0.05536643928765299, \"time-step\": 3735}, {\"errors\": 0.05530324332915343, \"time-step\": 3736}, {\"errors\": 0.055240028147837975, \"time-step\": 3737}, {\"errors\": 0.055176794074682685, \"time-step\": 3738}, {\"errors\": 0.055113541441177305, \"time-step\": 3739}, {\"errors\": 0.05505027057931708, \"time-step\": 3740}, {\"errors\": 0.05498698182159406, \"time-step\": 3741}, {\"errors\": 0.05492367550098871, \"time-step\": 3742}, {\"errors\": 0.054860351950961186, \"time-step\": 3743}, {\"errors\": 0.05479701150544286, \"time-step\": 3744}, {\"errors\": 0.05473365449882746, \"time-step\": 3745}, {\"errors\": 0.054670281265962725, \"time-step\": 3746}, {\"errors\": 0.054606892142141636, \"time-step\": 3747}, {\"errors\": 0.054543487463093454, \"time-step\": 3748}, {\"errors\": 0.054480067564975226, \"time-step\": 3749}, {\"errors\": 0.054416632784363074, \"time-step\": 3750}, {\"errors\": 0.05435318345824312, \"time-step\": 3751}, {\"errors\": 0.054289719924003006, \"time-step\": 3752}, {\"errors\": 0.05422624251942271, \"time-step\": 3753}, {\"errors\": 0.05416275158266596, \"time-step\": 3754}, {\"errors\": 0.05409924745227127, \"time-step\": 3755}, {\"errors\": 0.054035730467142815, \"time-step\": 3756}, {\"errors\": 0.053972200966541775, \"time-step\": 3757}, {\"errors\": 0.053908659290077335, \"time-step\": 3758}, {\"errors\": 0.053845105777697425, \"time-step\": 3759}, {\"errors\": 0.053781540769680045, \"time-step\": 3760}, {\"errors\": 0.0537179646066241, \"time-step\": 3761}, {\"errors\": 0.05365437762944025, \"time-step\": 3762}, {\"errors\": 0.053590780179341935, \"time-step\": 3763}, {\"errors\": 0.053527172597836264, \"time-step\": 3764}, {\"errors\": 0.0534635552267151, \"time-step\": 3765}, {\"errors\": 0.053399928408045375, \"time-step\": 3766}, {\"errors\": 0.0533362924841605, \"time-step\": 3767}, {\"errors\": 0.053272647797650965, \"time-step\": 3768}, {\"errors\": 0.05320899469135512, \"time-step\": 3769}, {\"errors\": 0.053145333508349935, \"time-step\": 3770}, {\"errors\": 0.053081664591941906, \"time-step\": 3771}, {\"errors\": 0.05301798828565771, \"time-step\": 3772}, {\"errors\": 0.052954304933234886, \"time-step\": 3773}, {\"errors\": 0.0528906148786127, \"time-step\": 3774}, {\"errors\": 0.052826918465922766, \"time-step\": 3775}, {\"errors\": 0.052763216039479616, \"time-step\": 3776}, {\"errors\": 0.0526995079437717, \"time-step\": 3777}, {\"errors\": 0.05263579452345167, \"time-step\": 3778}, {\"errors\": 0.052572076123327205, \"time-step\": 3779}, {\"errors\": 0.05250835308835168, \"time-step\": 3780}, {\"errors\": 0.05244462576361471, \"time-step\": 3781}, {\"errors\": 0.05238089449433264, \"time-step\": 3782}, {\"errors\": 0.05231715962583952, \"time-step\": 3783}, {\"errors\": 0.05225342150357714, \"time-step\": 3784}, {\"errors\": 0.05218968047308617, \"time-step\": 3785}, {\"errors\": 0.05212593687999621, \"time-step\": 3786}, {\"errors\": 0.05206219107001667, \"time-step\": 3787}, {\"errors\": 0.05199844338892711, \"time-step\": 3788}, {\"errors\": 0.05193469418256805, \"time-step\": 3789}, {\"errors\": 0.05187094379683116, \"time-step\": 3790}, {\"errors\": 0.051807192577649916, \"time-step\": 3791}, {\"errors\": 0.05174344087099016, \"time-step\": 3792}, {\"errors\": 0.05167968902284056, \"time-step\": 3793}, {\"errors\": 0.051615937379203156, \"time-step\": 3794}, {\"errors\": 0.05155218628608367, \"time-step\": 3795}, {\"errors\": 0.05148843608948211, \"time-step\": 3796}, {\"errors\": 0.05142468713538343, \"time-step\": 3797}, {\"errors\": 0.051360939769747635, \"time-step\": 3798}, {\"errors\": 0.051297194338500524, \"time-step\": 3799}, {\"errors\": 0.051233451187524134, \"time-step\": 3800}, {\"errors\": 0.051169710662647014, \"time-step\": 3801}, {\"errors\": 0.05110597310963502, \"time-step\": 3802}, {\"errors\": 0.0510422388741815, \"time-step\": 3803}, {\"errors\": 0.05097850830189779, \"time-step\": 3804}, {\"errors\": 0.05091478173830391, \"time-step\": 3805}, {\"errors\": 0.0508510595288187, \"time-step\": 3806}, {\"errors\": 0.050787342018750535, \"time-step\": 3807}, {\"errors\": 0.05072362955328781, \"time-step\": 3808}, {\"errors\": 0.0506599224774891, \"time-step\": 3809}, {\"errors\": 0.05059622113627406, \"time-step\": 3810}, {\"errors\": 0.0505325258744136, \"time-step\": 3811}, {\"errors\": 0.050468837036520484, \"time-step\": 3812}, {\"errors\": 0.050405154967039754, \"time-step\": 3813}, {\"errors\": 0.050341480010239414, \"time-step\": 3814}, {\"errors\": 0.050277812510200665, \"time-step\": 3815}, {\"errors\": 0.05021415281080868, \"time-step\": 3816}, {\"errors\": 0.050150501255742774, \"time-step\": 3817}, {\"errors\": 0.050086858188467365, \"time-step\": 3818}, {\"errors\": 0.050023223952222085, \"time-step\": 3819}, {\"errors\": 0.04995959889001271, \"time-step\": 3820}, {\"errors\": 0.04989598334460135, \"time-step\": 3821}, {\"errors\": 0.04983237765849734, \"time-step\": 3822}, {\"errors\": 0.04976878217394748, \"time-step\": 3823}, {\"errors\": 0.049705197232926976, \"time-step\": 3824}, {\"errors\": 0.04964162317712975, \"time-step\": 3825}, {\"errors\": 0.04957806034795926, \"time-step\": 3826}, {\"errors\": 0.04951450908651889, \"time-step\": 3827}, {\"errors\": 0.049450969733602815, \"time-step\": 3828}, {\"errors\": 0.049387442629686626, \"time-step\": 3829}, {\"errors\": 0.04932392811491784, \"time-step\": 3830}, {\"errors\": 0.04926042652910685, \"time-step\": 3831}, {\"errors\": 0.049196938211717244, \"time-step\": 3832}, {\"errors\": 0.049133463501856975, \"time-step\": 3833}, {\"errors\": 0.04907000273826878, \"time-step\": 3834}, {\"errors\": 0.04900655625932099, \"time-step\": 3835}, {\"errors\": 0.04894312440299839, \"time-step\": 3836}, {\"errors\": 0.04887970750689313, \"time-step\": 3837}, {\"errors\": 0.04881630590819519, \"time-step\": 3838}, {\"errors\": 0.04875291994368347, \"time-step\": 3839}, {\"errors\": 0.0486895499497167, \"time-step\": 3840}, {\"errors\": 0.048626196262224225, \"time-step\": 3841}, {\"errors\": 0.04856285921669673, \"time-step\": 3842}, {\"errors\": 0.04849953914817751, \"time-step\": 3843}, {\"errors\": 0.04843623639125323, \"time-step\": 3844}, {\"errors\": 0.04837295128004513, \"time-step\": 3845}, {\"errors\": 0.04830968414819942, \"time-step\": 3846}, {\"errors\": 0.04824643532887912, \"time-step\": 3847}, {\"errors\": 0.04818320515475455, \"time-step\": 3848}, {\"errors\": 0.048119993957994614, \"time-step\": 3849}, {\"errors\": 0.04805680207025785, \"time-step\": 3850}, {\"errors\": 0.047993629822683744, \"time-step\": 3851}, {\"errors\": 0.04793047754588363, \"time-step\": 3852}, {\"errors\": 0.047867345569932065, \"time-step\": 3853}, {\"errors\": 0.04780423422435809, \"time-step\": 3854}, {\"errors\": 0.047741143838136324, \"time-step\": 3855}, {\"errors\": 0.047678074739678285, \"time-step\": 3856}, {\"errors\": 0.04761502725682399, \"time-step\": 3857}, {\"errors\": 0.0475520017168329, \"time-step\": 3858}, {\"errors\": 0.04748899844637559, \"time-step\": 3859}, {\"errors\": 0.04742601777152507, \"time-step\": 3860}, {\"errors\": 0.047363060017748336, \"time-step\": 3861}, {\"errors\": 0.047300125509897574, \"time-step\": 3862}, {\"errors\": 0.047237214572202126, \"time-step\": 3863}, {\"errors\": 0.04717432752825962, \"time-step\": 3864}, {\"errors\": 0.04711146470102798, \"time-step\": 3865}, {\"errors\": 0.04704862641281665, \"time-step\": 3866}, {\"errors\": 0.046985812985278555, \"time-step\": 3867}, {\"errors\": 0.04692302473940179, \"time-step\": 3868}, {\"errors\": 0.04686026199550118, \"time-step\": 3869}, {\"errors\": 0.0467975250732103, \"time-step\": 3870}, {\"errors\": 0.046734814291473074, \"time-step\": 3871}, {\"errors\": 0.046672129968535904, \"time-step\": 3872}, {\"errors\": 0.04660947242193932, \"time-step\": 3873}, {\"errors\": 0.04654684196851015, \"time-step\": 3874}, {\"errors\": 0.04648423892435333, \"time-step\": 3875}, {\"errors\": 0.04642166360484408, \"time-step\": 3876}, {\"errors\": 0.046359116324619934, \"time-step\": 3877}, {\"errors\": 0.04629659739757272, \"time-step\": 3878}, {\"errors\": 0.04623410713684109, \"time-step\": 3879}, {\"errors\": 0.046171645854802254, \"time-step\": 3880}, {\"errors\": 0.04610921386306457, \"time-step\": 3881}, {\"errors\": 0.04604681147245976, \"time-step\": 3882}, {\"errors\": 0.04598443899303516, \"time-step\": 3883}, {\"errors\": 0.04592209673404632, \"time-step\": 3884}, {\"errors\": 0.04585978500394913, \"time-step\": 3885}, {\"errors\": 0.04579750411039264, \"time-step\": 3886}, {\"errors\": 0.04573525436021128, \"time-step\": 3887}, {\"errors\": 0.04567303605941774, \"time-step\": 3888}, {\"errors\": 0.04561084951319531, \"time-step\": 3889}, {\"errors\": 0.045548695025890686, \"time-step\": 3890}, {\"errors\": 0.04548657290100686, \"time-step\": 3891}, {\"errors\": 0.04542448344119552, \"time-step\": 3892}, {\"errors\": 0.04536242694825025, \"time-step\": 3893}, {\"errors\": 0.0453004037230991, \"time-step\": 3894}, {\"errors\": 0.0452384140657978, \"time-step\": 3895}, {\"errors\": 0.04517645827552248, \"time-step\": 3896}, {\"errors\": 0.04511453665056284, \"time-step\": 3897}, {\"errors\": 0.04505264948831518, \"time-step\": 3898}, {\"errors\": 0.044990797085275654, \"time-step\": 3899}, {\"errors\": 0.04492897973703307, \"time-step\": 3900}, {\"errors\": 0.04486719773826282, \"time-step\": 3901}, {\"errors\": 0.04480545138271941, \"time-step\": 3902}, {\"errors\": 0.04474374096323032, \"time-step\": 3903}, {\"errors\": 0.04468206677168925, \"time-step\": 3904}, {\"errors\": 0.04462042909904951, \"time-step\": 3905}, {\"errors\": 0.04455882823531764, \"time-step\": 3906}, {\"errors\": 0.04449726446954691, \"time-step\": 3907}, {\"errors\": 0.044435738089830895, \"time-step\": 3908}, {\"errors\": 0.044374249383297315, \"time-step\": 3909}, {\"errors\": 0.044312798636101616, \"time-step\": 3910}, {\"errors\": 0.044251386133420806, \"time-step\": 3911}, {\"errors\": 0.04419001215944729, \"time-step\": 3912}, {\"errors\": 0.0441286769973828, \"time-step\": 3913}, {\"errors\": 0.04406738092943246, \"time-step\": 3914}, {\"errors\": 0.04400612423679842, \"time-step\": 3915}, {\"errors\": 0.04394490719967452, \"time-step\": 3916}, {\"errors\": 0.04388373009723985, \"time-step\": 3917}, {\"errors\": 0.0438225932076534, \"time-step\": 3918}, {\"errors\": 0.04376149680804799, \"time-step\": 3919}, {\"errors\": 0.04370044117452467, \"time-step\": 3920}, {\"errors\": 0.043639426582147325, \"time-step\": 3921}, {\"errors\": 0.04357845330493672, \"time-step\": 3922}, {\"errors\": 0.0435175216158652, \"time-step\": 3923}, {\"errors\": 0.04345663178685142, \"time-step\": 3924}, {\"errors\": 0.04339578408875443, \"time-step\": 3925}, {\"errors\": 0.04333497879136886, \"time-step\": 3926}, {\"errors\": 0.04327421616341953, \"time-step\": 3927}, {\"errors\": 0.04321349647255601, \"time-step\": 3928}, {\"errors\": 0.04315281998534779, \"time-step\": 3929}, {\"errors\": 0.04309218696727885, \"time-step\": 3930}, {\"errors\": 0.04303159768274306, \"time-step\": 3931}, {\"errors\": 0.042971052395038845, \"time-step\": 3932}, {\"errors\": 0.04291055136636446, \"time-step\": 3933}, {\"errors\": 0.04285009485781305, \"time-step\": 3934}, {\"errors\": 0.04278968312936811, \"time-step\": 3935}, {\"errors\": 0.04272931643989843, \"time-step\": 3936}, {\"errors\": 0.042668995047153754, \"time-step\": 3937}, {\"errors\": 0.04260871920775991, \"time-step\": 3938}, {\"errors\": 0.04254848917721457, \"time-step\": 3939}, {\"errors\": 0.042488305209882476, \"time-step\": 3940}, {\"errors\": 0.04242816755899138, \"time-step\": 3941}, {\"errors\": 0.04236807647662742, \"time-step\": 3942}, {\"errors\": 0.04230803221373105, \"time-step\": 3943}, {\"errors\": 0.04224803502009257, \"time-step\": 3944}, {\"errors\": 0.04218808514434829, \"time-step\": 3945}, {\"errors\": 0.04212818283397626, \"time-step\": 3946}, {\"errors\": 0.0420683283352922, \"time-step\": 3947}, {\"errors\": 0.04200852189344574, \"time-step\": 3948}, {\"errors\": 0.04194876375241635, \"time-step\": 3949}, {\"errors\": 0.041889054155009535, \"time-step\": 3950}, {\"errors\": 0.04182939334285323, \"time-step\": 3951}, {\"errors\": 0.04176978155639379, \"time-step\": 3952}, {\"errors\": 0.04171021903489261, \"time-step\": 3953}, {\"errors\": 0.04165070601642251, \"time-step\": 3954}, {\"errors\": 0.04159124273786406, \"time-step\": 3955}, {\"errors\": 0.0415318294349024, \"time-step\": 3956}, {\"errors\": 0.041472466342023534, \"time-step\": 3957}, {\"errors\": 0.041413153692511265, \"time-step\": 3958}, {\"errors\": 0.04135389171844388, \"time-step\": 3959}, {\"errors\": 0.04129468065069081, \"time-step\": 3960}, {\"errors\": 0.04123552071890969, \"time-step\": 3961}, {\"errors\": 0.04117641215154332, \"time-step\": 3962}, {\"errors\": 0.04111735517581634, \"time-step\": 3963}, {\"errors\": 0.04105835001773262, \"time-step\": 3964}, {\"errors\": 0.04099939690207233, \"time-step\": 3965}, {\"errors\": 0.04094049605238895, \"time-step\": 3966}, {\"errors\": 0.04088164769100672, \"time-step\": 3967}, {\"errors\": 0.040822852039017865, \"time-step\": 3968}, {\"errors\": 0.04076410931628004, \"time-step\": 3969}, {\"errors\": 0.04070541974141367, \"time-step\": 3970}, {\"errors\": 0.04064678353179948, \"time-step\": 3971}, {\"errors\": 0.04058820090357611, \"time-step\": 3972}, {\"errors\": 0.040529672071637796, \"time-step\": 3973}, {\"errors\": 0.040471197249631934, \"time-step\": 3974}, {\"errors\": 0.04041277664995686, \"time-step\": 3975}, {\"errors\": 0.04035441048375989, \"time-step\": 3976}, {\"errors\": 0.040296098960934834, \"time-step\": 3977}, {\"errors\": 0.0402378422901202, \"time-step\": 3978}, {\"errors\": 0.04017964067869719, \"time-step\": 3979}, {\"errors\": 0.0401214943327877, \"time-step\": 3980}, {\"errors\": 0.04006340345725244, \"time-step\": 3981}, {\"errors\": 0.0400053682556892, \"time-step\": 3982}, {\"errors\": 0.039947388930431066, \"time-step\": 3983}, {\"errors\": 0.0398894656825448, \"time-step\": 3984}, {\"errors\": 0.03983159871182905, \"time-step\": 3985}, {\"errors\": 0.039773788216813016, \"time-step\": 3986}, {\"errors\": 0.03971603439475485, \"time-step\": 3987}, {\"errors\": 0.0396583374416402, \"time-step\": 3988}, {\"errors\": 0.039600697552180854, \"time-step\": 3989}, {\"errors\": 0.03954311491981349, \"time-step\": 3990}, {\"errors\": 0.03948558973669822, \"time-step\": 3991}, {\"errors\": 0.039428122193717885, \"time-step\": 3992}, {\"errors\": 0.039370712480476217, \"time-step\": 3993}, {\"errors\": 0.03931336078529733, \"time-step\": 3994}, {\"errors\": 0.03925606729522453, \"time-step\": 3995}, {\"errors\": 0.03919883219601937, \"time-step\": 3996}, {\"errors\": 0.039141655672160755, \"time-step\": 3997}, {\"errors\": 0.03908453790684395, \"time-step\": 3998}, {\"errors\": 0.039027479081980246, \"time-step\": 3999}, {\"errors\": 0.03897047937819571, \"time-step\": 4000}, {\"errors\": 0.038913538974830957, \"time-step\": 4001}, {\"errors\": 0.03885665804994024, \"time-step\": 4002}, {\"errors\": 0.03879983678029131, \"time-step\": 4003}, {\"errors\": 0.038743075341364376, \"time-step\": 4004}, {\"errors\": 0.03868637390735222, \"time-step\": 4005}, {\"errors\": 0.03862973265115956, \"time-step\": 4006}, {\"errors\": 0.03857315174440268, \"time-step\": 4007}, {\"errors\": 0.03851663135740943, \"time-step\": 4008}, {\"errors\": 0.038460171659218875, \"time-step\": 4009}, {\"errors\": 0.03840377281758112, \"time-step\": 4010}, {\"errors\": 0.03834743499895733, \"time-step\": 4011}, {\"errors\": 0.038291158368519665, \"time-step\": 4012}, {\"errors\": 0.03823494309015138, \"time-step\": 4013}, {\"errors\": 0.0381787893264467, \"time-step\": 4014}, {\"errors\": 0.038122697238711256, \"time-step\": 4015}, {\"errors\": 0.03806666698696205, \"time-step\": 4016}, {\"errors\": 0.038010698729927836, \"time-step\": 4017}, {\"errors\": 0.03795479262504943, \"time-step\": 4018}, {\"errors\": 0.03789894882847989, \"time-step\": 4019}, {\"errors\": 0.03784316749508517, \"time-step\": 4020}, {\"errors\": 0.03778744877844458, \"time-step\": 4021}, {\"errors\": 0.03773179283085101, \"time-step\": 4022}, {\"errors\": 0.037676199803311855, \"time-step\": 4023}, {\"errors\": 0.03762066984554934, \"time-step\": 4024}, {\"errors\": 0.03756520310600169, \"time-step\": 4025}, {\"errors\": 0.03750979973182311, \"time-step\": 4026}, {\"errors\": 0.03745445986888524, \"time-step\": 4027}, {\"errors\": 0.037399183661777705, \"time-step\": 4028}, {\"errors\": 0.03734397125380897, \"time-step\": 4029}, {\"errors\": 0.03728882278700737, \"time-step\": 4030}, {\"errors\": 0.03723373840212204, \"time-step\": 4031}, {\"errors\": 0.03717871823862401, \"time-step\": 4032}, {\"errors\": 0.037123762434707164, \"time-step\": 4033}, {\"errors\": 0.037068871127289627, \"time-step\": 4034}, {\"errors\": 0.03701404445201468, \"time-step\": 4035}, {\"errors\": 0.03695928254325202, \"time-step\": 4036}, {\"errors\": 0.03690458553409927, \"time-step\": 4037}, {\"errors\": 0.036849953556383076, \"time-step\": 4038}, {\"errors\": 0.03679538674066065, \"time-step\": 4039}, {\"errors\": 0.036740885216221, \"time-step\": 4040}, {\"errors\": 0.03668644911108658, \"time-step\": 4041}, {\"errors\": 0.03663207855201474, \"time-step\": 4042}, {\"errors\": 0.036577773664499276, \"time-step\": 4043}, {\"errors\": 0.03652353457277209, \"time-step\": 4044}, {\"errors\": 0.036469361399804646, \"time-step\": 4045}, {\"errors\": 0.0364152542673102, \"time-step\": 4046}, {\"errors\": 0.03636121329574477, \"time-step\": 4047}, {\"errors\": 0.03630723860430964, \"time-step\": 4048}, {\"errors\": 0.0362533303109527, \"time-step\": 4049}, {\"errors\": 0.036199488532370705, \"time-step\": 4050}, {\"errors\": 0.036145713384010736, \"time-step\": 4051}, {\"errors\": 0.03609200498007278, \"time-step\": 4052}, {\"errors\": 0.036038363433511064, \"time-step\": 4053}, {\"errors\": 0.0359847888560367, \"time-step\": 4054}, {\"errors\": 0.03593128135811936, \"time-step\": 4055}, {\"errors\": 0.03587784104898967, \"time-step\": 4056}, {\"errors\": 0.03582446803664115, \"time-step\": 4057}, {\"errors\": 0.035771162427832605, \"time-step\": 4058}, {\"errors\": 0.03571792432809035, \"time-step\": 4059}, {\"errors\": 0.03566475384171058, \"time-step\": 4060}, {\"errors\": 0.035611651071761445, \"time-step\": 4061}, {\"errors\": 0.03555861612008565, \"time-step\": 4062}, {\"errors\": 0.035505649087302846, \"time-step\": 4063}, {\"errors\": 0.035452750072812025, \"time-step\": 4064}, {\"errors\": 0.035399919174794056, \"time-step\": 4065}, {\"errors\": 0.03534715649021417, \"time-step\": 4066}, {\"errors\": 0.03529446211482456, \"time-step\": 4067}, {\"errors\": 0.03524183614316692, \"time-step\": 4068}, {\"errors\": 0.03518927866857516, \"time-step\": 4069}, {\"errors\": 0.03513678978317815, \"time-step\": 4070}, {\"errors\": 0.03508436957790219, \"time-step\": 4071}, {\"errors\": 0.03503201814247394, \"time-step\": 4072}, {\"errors\": 0.03497973556542334, \"time-step\": 4073}, {\"errors\": 0.03492752193408599, \"time-step\": 4074}, {\"errors\": 0.034875377334606425, \"time-step\": 4075}, {\"errors\": 0.03482330185194078, \"time-step\": 4076}, {\"errors\": 0.034771295569859854, \"time-step\": 4077}, {\"errors\": 0.03471935857095189, \"time-step\": 4078}, {\"errors\": 0.03466749093662573, \"time-step\": 4079}, {\"errors\": 0.034615692747113624, \"time-step\": 4080}, {\"errors\": 0.03456396408147453, \"time-step\": 4081}, {\"errors\": 0.03451230501759702, \"time-step\": 4082}, {\"errors\": 0.03446071563220248, \"time-step\": 4083}, {\"errors\": 0.03440919600084814, \"time-step\": 4084}, {\"errors\": 0.034357746197930444, \"time-step\": 4085}, {\"errors\": 0.034306366296688, \"time-step\": 4086}, {\"errors\": 0.034255056369205054, \"time-step\": 4087}, {\"errors\": 0.03420381648641466, \"time-step\": 4088}, {\"errors\": 0.03415264671810184, \"time-step\": 4089}, {\"errors\": 0.03410154713290718, \"time-step\": 4090}, {\"errors\": 0.03405051779832986, \"time-step\": 4091}, {\"errors\": 0.033999558780731354, \"time-step\": 4092}, {\"errors\": 0.03394867014533867, \"time-step\": 4093}, {\"errors\": 0.03389785195624764, \"time-step\": 4094}, {\"errors\": 0.03384710427642669, \"time-step\": 4095}, {\"errors\": 0.03379642716772004, \"time-step\": 4096}, {\"errors\": 0.03374582069085146, \"time-step\": 4097}, {\"errors\": 0.03369528490542756, \"time-step\": 4098}, {\"errors\": 0.033644819869941535, \"time-step\": 4099}, {\"errors\": 0.03359442564177673, \"time-step\": 4100}, {\"errors\": 0.033544102277210205, \"time-step\": 4101}, {\"errors\": 0.03349384983141626, \"time-step\": 4102}, {\"errors\": 0.03344366835847033, \"time-step\": 4103}, {\"errors\": 0.033393557911352525, \"time-step\": 4104}, {\"errors\": 0.03334351854195136, \"time-step\": 4105}, {\"errors\": 0.033293550301067426, \"time-step\": 4106}, {\"errors\": 0.0332436532384173, \"time-step\": 4107}, {\"errors\": 0.03319382740263711, \"time-step\": 4108}, {\"errors\": 0.03314407284128647, \"time-step\": 4109}, {\"errors\": 0.033094389600852286, \"time-step\": 4110}, {\"errors\": 0.03304477772675244, \"time-step\": 4111}, {\"errors\": 0.03299523726333993, \"time-step\": 4112}, {\"errors\": 0.03294576825390649, \"time-step\": 4113}, {\"errors\": 0.03289637074068655, \"time-step\": 4114}, {\"errors\": 0.03284704476486121, \"time-step\": 4115}, {\"errors\": 0.03279779036656213, \"time-step\": 4116}, {\"errors\": 0.032748607584875564, \"time-step\": 4117}, {\"errors\": 0.03269949645784607, \"time-step\": 4118}, {\"errors\": 0.03265045702248087, \"time-step\": 4119}, {\"errors\": 0.03260148931475363, \"time-step\": 4120}, {\"errors\": 0.03255259336960845, \"time-step\": 4121}, {\"errors\": 0.03250376922096404, \"time-step\": 4122}, {\"errors\": 0.03245501690171771, \"time-step\": 4123}, {\"errors\": 0.03240633644374939, \"time-step\": 4124}, {\"errors\": 0.03235772787792586, \"time-step\": 4125}, {\"errors\": 0.032309191234104695, \"time-step\": 4126}, {\"errors\": 0.03226072654113852, \"time-step\": 4127}, {\"errors\": 0.03221233382687899, \"time-step\": 4128}, {\"errors\": 0.03216401311818118, \"time-step\": 4129}, {\"errors\": 0.03211576444090737, \"time-step\": 4130}, {\"errors\": 0.03206758781993167, \"time-step\": 4131}, {\"errors\": 0.03201948327914388, \"time-step\": 4132}, {\"errors\": 0.03197145084145373, \"time-step\": 4133}, {\"errors\": 0.031923490528795354, \"time-step\": 4134}, {\"errors\": 0.031875602362131106, \"time-step\": 4135}, {\"errors\": 0.03182778636145615, \"time-step\": 4136}, {\"errors\": 0.03178004254580255, \"time-step\": 4137}, {\"errors\": 0.03173237093324358, \"time-step\": 4138}, {\"errors\": 0.031684771540897994, \"time-step\": 4139}, {\"errors\": 0.031637244384934204, \"time-step\": 4140}, {\"errors\": 0.03158978948057475, \"time-step\": 4141}, {\"errors\": 0.03154240684210052, \"time-step\": 4142}, {\"errors\": 0.03149509648285501, \"time-step\": 4143}, {\"errors\": 0.03144785841524883, \"time-step\": 4144}, {\"errors\": 0.031400692650763784, \"time-step\": 4145}, {\"errors\": 0.031353599199957366, \"time-step\": 4146}, {\"errors\": 0.03130657807246719, \"time-step\": 4147}, {\"errors\": 0.03125962927701515, \"time-step\": 4148}, {\"errors\": 0.031212752821411928, \"time-step\": 4149}, {\"errors\": 0.03116594871256127, \"time-step\": 4150}, {\"errors\": 0.03111921695646454, \"time-step\": 4151}, {\"errors\": 0.031072557558224904, \"time-step\": 4152}, {\"errors\": 0.03102597052205181, \"time-step\": 4153}, {\"errors\": 0.030979455851265478, \"time-step\": 4154}, {\"errors\": 0.03093301354830118, \"time-step\": 4155}, {\"errors\": 0.030886643614713688, \"time-step\": 4156}, {\"errors\": 0.030840346051181793, \"time-step\": 4157}, {\"errors\": 0.030794120857512576, \"time-step\": 4158}, {\"errors\": 0.030747968032645956, \"time-step\": 4159}, {\"errors\": 0.030701887574659067, \"time-step\": 4160}, {\"errors\": 0.030655879480770712, \"time-step\": 4161}, {\"errors\": 0.03060994374734579, \"time-step\": 4162}, {\"errors\": 0.03056408036989991, \"time-step\": 4163}, {\"errors\": 0.03051828934310348, \"time-step\": 4164}, {\"errors\": 0.030472570660786555, \"time-step\": 4165}, {\"errors\": 0.030426924315943057, \"time-step\": 4166}, {\"errors\": 0.030381350300735355, \"time-step\": 4167}, {\"errors\": 0.030335848606498603, \"time-step\": 4168}, {\"errors\": 0.030290419223745292, \"time-step\": 4169}, {\"errors\": 0.030245062142169758, \"time-step\": 4170}, {\"errors\": 0.03019977735065263, \"time-step\": 4171}, {\"errors\": 0.030154564837265196, \"time-step\": 4172}, {\"errors\": 0.03010942458927395, \"time-step\": 4173}, {\"errors\": 0.03006435659314518, \"time-step\": 4174}, {\"errors\": 0.03001936083454923, \"time-step\": 4175}, {\"errors\": 0.029974437298365186, \"time-step\": 4176}, {\"errors\": 0.02992958596868515, \"time-step\": 4177}, {\"errors\": 0.029884806828818843, \"time-step\": 4178}, {\"errors\": 0.02984009986129807, \"time-step\": 4179}, {\"errors\": 0.02979546504788117, \"time-step\": 4180}, {\"errors\": 0.029750902369557557, \"time-step\": 4181}, {\"errors\": 0.029706411806552, \"time-step\": 4182}, {\"errors\": 0.02966199333832942, \"time-step\": 4183}, {\"errors\": 0.029617646943598933, \"time-step\": 4184}, {\"errors\": 0.029573372600318858, \"time-step\": 4185}, {\"errors\": 0.02952917028570059, \"time-step\": 4186}, {\"errors\": 0.029485039976213587, \"time-step\": 4187}, {\"errors\": 0.029440981647589487, \"time-step\": 4188}, {\"errors\": 0.02939699527482675, \"time-step\": 4189}, {\"errors\": 0.02935308083219508, \"time-step\": 4190}, {\"errors\": 0.02930923829323975, \"time-step\": 4191}, {\"errors\": 0.02926546763078633, \"time-step\": 4192}, {\"errors\": 0.029221768816944875, \"time-step\": 4193}, {\"errors\": 0.029178141823114387, \"time-step\": 4194}, {\"errors\": 0.02913458661998755, \"time-step\": 4195}, {\"errors\": 0.029091103177554756, \"time-step\": 4196}, {\"errors\": 0.02904769146510886, \"time-step\": 4197}, {\"errors\": 0.029004351451249438, \"time-step\": 4198}, {\"errors\": 0.02896108310388728, \"time-step\": 4199}, {\"errors\": 0.02891788639024874, \"time-step\": 4200}, {\"errors\": 0.028874761276880295, \"time-step\": 4201}, {\"errors\": 0.02883170772965278, \"time-step\": 4202}, {\"errors\": 0.02878872571376595, \"time-step\": 4203}, {\"errors\": 0.02874581519375274, \"time-step\": 4204}, {\"errors\": 0.028702976133483778, \"time-step\": 4205}, {\"errors\": 0.028660208496171638, \"time-step\": 4206}, {\"errors\": 0.028617512244375372, \"time-step\": 4207}, {\"errors\": 0.028574887340004858, \"time-step\": 4208}, {\"errors\": 0.028532333744324966, \"time-step\": 4209}, {\"errors\": 0.028489851417960246, \"time-step\": 4210}, {\"errors\": 0.028447440320899027, \"time-step\": 4211}, {\"errors\": 0.028405100412497858, \"time-step\": 4212}, {\"errors\": 0.028362831651485943, \"time-step\": 4213}, {\"errors\": 0.0283206339959692, \"time-step\": 4214}, {\"errors\": 0.02827850740343493, \"time-step\": 4215}, {\"errors\": 0.02823645183075588, \"time-step\": 4216}, {\"errors\": 0.028194467234194727, \"time-step\": 4217}, {\"errors\": 0.028152553569408163, \"time-step\": 4218}, {\"errors\": 0.02811071079145144, \"time-step\": 4219}, {\"errors\": 0.028068938854782573, \"time-step\": 4220}, {\"errors\": 0.028027237713266456, \"time-step\": 4221}, {\"errors\": 0.02798560732017938, \"time-step\": 4222}, {\"errors\": 0.027944047628213148, \"time-step\": 4223}, {\"errors\": 0.02790255858947932, \"time-step\": 4224}, {\"errors\": 0.027861140155513553, \"time-step\": 4225}, {\"errors\": 0.02781979227727973, \"time-step\": 4226}, {\"errors\": 0.02777851490517424, \"time-step\": 4227}, {\"errors\": 0.027737307989030256, \"time-step\": 4228}, {\"errors\": 0.027696171478121718, \"time-step\": 4229}, {\"errors\": 0.02765510532116784, \"time-step\": 4230}, {\"errors\": 0.027614109466337078, \"time-step\": 4231}, {\"errors\": 0.02757318386125126, \"time-step\": 4232}, {\"errors\": 0.027532328452990047, \"time-step\": 4233}, {\"errors\": 0.027491543188094797, \"time-step\": 4234}, {\"errors\": 0.02745082801257282, \"time-step\": 4235}, {\"errors\": 0.027410182871901452, \"time-step\": 4236}, {\"errors\": 0.027369607711032397, \"time-step\": 4237}, {\"errors\": 0.027329102474395524, \"time-step\": 4238}, {\"errors\": 0.027288667105903126, \"time-step\": 4239}, {\"errors\": 0.02724830154895413, \"time-step\": 4240}, {\"errors\": 0.027208005746437964, \"time-step\": 4241}, {\"errors\": 0.027167779640738788, \"time-step\": 4242}, {\"errors\": 0.027127623173739387, \"time-step\": 4243}, {\"errors\": 0.027087536286825427, \"time-step\": 4244}, {\"errors\": 0.027047518920889323, \"time-step\": 4245}, {\"errors\": 0.02700757101633433, \"time-step\": 4246}, {\"errors\": 0.02696769251307856, \"time-step\": 4247}, {\"errors\": 0.026927883350558943, \"time-step\": 4248}, {\"errors\": 0.026888143467735312, \"time-step\": 4249}, {\"errors\": 0.02684847280309426, \"time-step\": 4250}, {\"errors\": 0.026808871294653085, \"time-step\": 4251}, {\"errors\": 0.02676933887996395, \"time-step\": 4252}, {\"errors\": 0.026729875496117675, \"time-step\": 4253}, {\"errors\": 0.02669048107974756, \"time-step\": 4254}, {\"errors\": 0.026651155567033506, \"time-step\": 4255}, {\"errors\": 0.02661189889370583, \"time-step\": 4256}, {\"errors\": 0.026572710995049147, \"time-step\": 4257}, {\"errors\": 0.026533591805906212, \"time-step\": 4258}, {\"errors\": 0.02649454126068189, \"time-step\": 4259}, {\"errors\": 0.026455559293346927, \"time-step\": 4260}, {\"errors\": 0.026416645837441823, \"time-step\": 4261}, {\"errors\": 0.026377800826080586, \"time-step\": 4262}, {\"errors\": 0.026339024191954732, \"time-step\": 4263}, {\"errors\": 0.02630031586733677, \"time-step\": 4264}, {\"errors\": 0.026261675784084292, \"time-step\": 4265}, {\"errors\": 0.02622310387364367, \"time-step\": 4266}, {\"errors\": 0.026184600067053684, \"time-step\": 4267}, {\"errors\": 0.026146164294949363, \"time-step\": 4268}, {\"errors\": 0.026107796487565785, \"time-step\": 4269}, {\"errors\": 0.02606949657474166, \"time-step\": 4270}, {\"errors\": 0.02603126448592314, \"time-step\": 4271}, {\"errors\": 0.02599310015016741, \"time-step\": 4272}, {\"errors\": 0.025955003496146514, \"time-step\": 4273}, {\"errors\": 0.025916974452150875, \"time-step\": 4274}, {\"errors\": 0.025879012946092975, \"time-step\": 4275}, {\"errors\": 0.025841118905511107, \"time-step\": 4276}, {\"errors\": 0.02580329225757287, \"time-step\": 4277}, {\"errors\": 0.025765532929078804, \"time-step\": 4278}, {\"errors\": 0.025727840846465948, \"time-step\": 4279}, {\"errors\": 0.02569021593581161, \"time-step\": 4280}, {\"errors\": 0.02565265812283663, \"time-step\": 4281}, {\"errors\": 0.025615167332909222, \"time-step\": 4282}, {\"errors\": 0.025577743491048327, \"time-step\": 4283}, {\"errors\": 0.02554038652192718, \"time-step\": 4284}, {\"errors\": 0.025503096349876818, \"time-step\": 4285}, {\"errors\": 0.02546587289888968, \"time-step\": 4286}, {\"errors\": 0.025428716092622854, \"time-step\": 4287}, {\"errors\": 0.025391625854401828, \"time-step\": 4288}, {\"errors\": 0.025354602107223685, \"time-step\": 4289}, {\"errors\": 0.0253176447737607, \"time-step\": 4290}, {\"errors\": 0.0252807537763637, \"time-step\": 4291}, {\"errors\": 0.025243929037065425, \"time-step\": 4292}, {\"errors\": 0.025207170477584136, \"time-step\": 4293}, {\"errors\": 0.02517047801932661, \"time-step\": 4294}, {\"errors\": 0.025133851583391913, \"time-step\": 4295}, {\"errors\": 0.025097291090574445, \"time-step\": 4296}, {\"errors\": 0.025060796461367447, \"time-step\": 4297}, {\"errors\": 0.025024367615966228, \"time-step\": 4298}, {\"errors\": 0.024988004474271543, \"time-step\": 4299}, {\"errors\": 0.024951706955892817, \"time-step\": 4300}, {\"errors\": 0.02491547498015139, \"time-step\": 4301}, {\"errors\": 0.02487930846608392, \"time-step\": 4302}, {\"errors\": 0.024843207332445473, \"time-step\": 4303}, {\"errors\": 0.024807171497712804, \"time-step\": 4304}, {\"errors\": 0.02477120088008767, \"time-step\": 4305}, {\"errors\": 0.024735295397499777, \"time-step\": 4306}, {\"errors\": 0.024699454967610307, \"time-step\": 4307}, {\"errors\": 0.02466367950781478, \"time-step\": 4308}, {\"errors\": 0.024627968935246373, \"time-step\": 4309}, {\"errors\": 0.02459232316677901, \"time-step\": 4310}, {\"errors\": 0.024556742119030542, \"time-step\": 4311}, {\"errors\": 0.024521225708365752, \"time-step\": 4312}, {\"errors\": 0.024485773850899534, \"time-step\": 4313}, {\"errors\": 0.024450386462499918, \"time-step\": 4314}, {\"errors\": 0.024415063458791197, \"time-step\": 4315}, {\"errors\": 0.0243798047551569, \"time-step\": 4316}, {\"errors\": 0.0243446102667429, \"time-step\": 4317}, {\"errors\": 0.02430947990846035, \"time-step\": 4318}, {\"errors\": 0.024274413594988796, \"time-step\": 4319}, {\"errors\": 0.02423941124077902, \"time-step\": 4320}, {\"errors\": 0.02420447276005612, \"time-step\": 4321}, {\"errors\": 0.024169598066822468, \"time-step\": 4322}, {\"errors\": 0.024134787074860636, \"time-step\": 4323}, {\"errors\": 0.024100039697736227, \"time-step\": 4324}, {\"errors\": 0.024065355848801047, \"time-step\": 4325}, {\"errors\": 0.02403073544119557, \"time-step\": 4326}, {\"errors\": 0.023996178387852295, \"time-step\": 4327}, {\"errors\": 0.02396168460149833, \"time-step\": 4328}, {\"errors\": 0.023927253994658282, \"time-step\": 4329}, {\"errors\": 0.023892886479657142, \"time-step\": 4330}, {\"errors\": 0.023858581968623116, \"time-step\": 4331}, {\"errors\": 0.023824340373490377, \"time-step\": 4332}, {\"errors\": 0.023790161606001836, \"time-step\": 4333}, {\"errors\": 0.02375604557771205, \"time-step\": 4334}, {\"errors\": 0.02372199219998987, \"time-step\": 4335}, {\"errors\": 0.023688001384021162, \"time-step\": 4336}, {\"errors\": 0.023654073040811747, \"time-step\": 4337}, {\"errors\": 0.02362020708118974, \"time-step\": 4338}, {\"errors\": 0.023586403415808664, \"time-step\": 4339}, {\"errors\": 0.023552661955149823, \"time-step\": 4340}, {\"errors\": 0.023518982609525237, \"time-step\": 4341}, {\"errors\": 0.02348536528908, \"time-step\": 4342}, {\"errors\": 0.023451809903795223, \"time-step\": 4343}, {\"errors\": 0.023418316363490448, \"time-step\": 4344}, {\"errors\": 0.023384884577826302, \"time-step\": 4345}, {\"errors\": 0.02335151445630721, \"time-step\": 4346}, {\"errors\": 0.02331820590828383, \"time-step\": 4347}, {\"errors\": 0.02328495884295575, \"time-step\": 4348}, {\"errors\": 0.023251773169373886, \"time-step\": 4349}, {\"errors\": 0.023218648796443135, \"time-step\": 4350}, {\"errors\": 0.023185585632924954, \"time-step\": 4351}, {\"errors\": 0.023152583587439664, \"time-step\": 4352}, {\"errors\": 0.023119642568469115, \"time-step\": 4353}, {\"errors\": 0.02308676248435914, \"time-step\": 4354}, {\"errors\": 0.02305394324332198, \"time-step\": 4355}, {\"errors\": 0.023021184753438728, \"time-step\": 4356}, {\"errors\": 0.02298848692266177, \"time-step\": 4357}, {\"errors\": 0.02295584965881732, \"time-step\": 4358}, {\"errors\": 0.02292327286960761, \"time-step\": 4359}, {\"errors\": 0.02289075646261343, \"time-step\": 4360}, {\"errors\": 0.02285830034529646, \"time-step\": 4361}, {\"errors\": 0.022825904425001778, \"time-step\": 4362}, {\"errors\": 0.022793568608959855, \"time-step\": 4363}, {\"errors\": 0.02276129280428927, \"time-step\": 4364}, {\"errors\": 0.022729076917998806, \"time-step\": 4365}, {\"errors\": 0.02269692085698987, \"time-step\": 4366}, {\"errors\": 0.022664824528058607, \"time-step\": 4367}, {\"errors\": 0.02263278783789846, \"time-step\": 4368}, {\"errors\": 0.022600810693102123, \"time-step\": 4369}, {\"errors\": 0.022568893000164066, \"time-step\": 4370}, {\"errors\": 0.02253703466548252, \"time-step\": 4371}, {\"errors\": 0.02250523559536194, \"time-step\": 4372}, {\"errors\": 0.022473495696015013, \"time-step\": 4373}, {\"errors\": 0.022441814873564895, \"time-step\": 4374}, {\"errors\": 0.02241019303404749, \"time-step\": 4375}, {\"errors\": 0.022378630083413502, \"time-step\": 4376}, {\"errors\": 0.022347125927530628, \"time-step\": 4377}, {\"errors\": 0.022315680472185687, \"time-step\": 4378}, {\"errors\": 0.022284293623086742, \"time-step\": 4379}, {\"errors\": 0.02225296528586517, \"time-step\": 4380}, {\"errors\": 0.02222169536607787, \"time-step\": 4381}, {\"errors\": 0.02219048376920923, \"time-step\": 4382}, {\"errors\": 0.022159330400673166, \"time-step\": 4383}, {\"errors\": 0.022128235165815364, \"time-step\": 4384}, {\"errors\": 0.02209719796991507, \"time-step\": 4385}, {\"errors\": 0.02206621871818732, \"time-step\": 4386}, {\"errors\": 0.02203529731578483, \"time-step\": 4387}, {\"errors\": 0.02200443366779999, \"time-step\": 4388}, {\"errors\": 0.02197362767926702, \"time-step\": 4389}, {\"errors\": 0.021942879255163764, \"time-step\": 4390}, {\"errors\": 0.021912188300413554, \"time-step\": 4391}, {\"errors\": 0.021881554719887508, \"time-step\": 4392}, {\"errors\": 0.0218509784184061, \"time-step\": 4393}, {\"errors\": 0.021820459300741293, \"time-step\": 4394}, {\"errors\": 0.021789997271618317, \"time-step\": 4395}, {\"errors\": 0.021759592235717752, \"time-step\": 4396}, {\"errors\": 0.02172924409767715, \"time-step\": 4397}, {\"errors\": 0.02169895276209308, \"time-step\": 4398}, {\"errors\": 0.021668718133522863, \"time-step\": 4399}, {\"errors\": 0.02163854011648654, \"time-step\": 4400}, {\"errors\": 0.02160841861546858, \"time-step\": 4401}, {\"errors\": 0.021578353534919804, \"time-step\": 4402}, {\"errors\": 0.02154834477925905, \"time-step\": 4403}, {\"errors\": 0.0215183922528751, \"time-step\": 4404}, {\"errors\": 0.02148849586012836, \"time-step\": 4405}, {\"errors\": 0.021458655505352614, \"time-step\": 4406}, {\"errors\": 0.02142887109285682, \"time-step\": 4407}, {\"errors\": 0.021399142526926866, \"time-step\": 4408}, {\"errors\": 0.02136946971182726, \"time-step\": 4409}, {\"errors\": 0.021339852551802818, \"time-step\": 4410}, {\"errors\": 0.02131029095108036, \"time-step\": 4411}, {\"errors\": 0.02128078481387047, \"time-step\": 4412}, {\"errors\": 0.02125133404436913, \"time-step\": 4413}, {\"errors\": 0.02122193854675931, \"time-step\": 4414}, {\"errors\": 0.02119259822521273, \"time-step\": 4415}, {\"errors\": 0.02116331298389141, \"time-step\": 4416}, {\"errors\": 0.02113408272694932, \"time-step\": 4417}, {\"errors\": 0.021104907358534125, \"time-step\": 4418}, {\"errors\": 0.02107578678278842, \"time-step\": 4419}, {\"errors\": 0.021046720903851783, \"time-step\": 4420}, {\"errors\": 0.02101770962586202, \"time-step\": 4421}, {\"errors\": 0.020988752852956837, \"time-step\": 4422}, {\"errors\": 0.02095985048927539, \"time-step\": 4423}, {\"errors\": 0.020931002438959866, \"time-step\": 4424}, {\"errors\": 0.020902208606156887, \"time-step\": 4425}, {\"errors\": 0.02087346889501917, \"time-step\": 4426}, {\"errors\": 0.020844783209706966, \"time-step\": 4427}, {\"errors\": 0.02081615145438952, \"time-step\": 4428}, {\"errors\": 0.02078757353324657, \"time-step\": 4429}, {\"errors\": 0.020759049350469884, \"time-step\": 4430}, {\"errors\": 0.02073057881026463, \"time-step\": 4431}, {\"errors\": 0.020702161816850903, \"time-step\": 4432}, {\"errors\": 0.02067379827446501, \"time-step\": 4433}, {\"errors\": 0.020645488087361087, \"time-step\": 4434}, {\"errors\": 0.02061723115981238, \"time-step\": 4435}, {\"errors\": 0.02058902739611273, \"time-step\": 4436}, {\"errors\": 0.020560876700577855, \"time-step\": 4437}, {\"errors\": 0.020532778977546833, \"time-step\": 4438}, {\"errors\": 0.020504734131383387, \"time-step\": 4439}, {\"errors\": 0.020476742066477316, \"time-step\": 4440}, {\"errors\": 0.02044880268724583, \"time-step\": 4441}, {\"errors\": 0.02042091589813474, \"time-step\": 4442}, {\"errors\": 0.020393081603620036, \"time-step\": 4443}, {\"errors\": 0.02036529970820891, \"time-step\": 4444}, {\"errors\": 0.02033757011644137, \"time-step\": 4445}, {\"errors\": 0.02030989273289128, \"time-step\": 4446}, {\"errors\": 0.02028226746216769, \"time-step\": 4447}, {\"errors\": 0.020254694208916228, \"time-step\": 4448}, {\"errors\": 0.020227172877820172, \"time-step\": 4449}, {\"errors\": 0.020199703373601868, \"time-step\": 4450}, {\"errors\": 0.02017228560102388, \"time-step\": 4451}, {\"errors\": 0.020144919464890186, \"time-step\": 4452}, {\"errors\": 0.02011760487004749, \"time-step\": 4453}, {\"errors\": 0.02009034172138634, \"time-step\": 4454}, {\"errors\": 0.020063129923842352, \"time-step\": 4455}, {\"errors\": 0.020035969382397427, \"time-step\": 4456}, {\"errors\": 0.020008860002080856, \"time-step\": 4457}, {\"errors\": 0.01998180168797058, \"time-step\": 4458}, {\"errors\": 0.019954794345194263, \"time-step\": 4459}, {\"errors\": 0.019927837878930436, \"time-step\": 4460}, {\"errors\": 0.01990093219440965, \"time-step\": 4461}, {\"errors\": 0.01987407719691567, \"time-step\": 4462}, {\"errors\": 0.01984727279178648, \"time-step\": 4463}, {\"errors\": 0.019820518884415418, \"time-step\": 4464}, {\"errors\": 0.019793815380252273, \"time-step\": 4465}, {\"errors\": 0.019767162184804468, \"time-step\": 4466}, {\"errors\": 0.019740559203637962, \"time-step\": 4467}, {\"errors\": 0.019714006342378344, \"time-step\": 4468}, {\"errors\": 0.019687503506712098, \"time-step\": 4469}, {\"errors\": 0.019661050602387365, \"time-step\": 4470}, {\"errors\": 0.01963464753521514, \"time-step\": 4471}, {\"errors\": 0.01960829421107027, \"time-step\": 4472}, {\"errors\": 0.019581990535892477, \"time-step\": 4473}, {\"errors\": 0.019555736415687322, \"time-step\": 4474}, {\"errors\": 0.019529531756527253, \"time-step\": 4475}, {\"errors\": 0.01950337646455259, \"time-step\": 4476}, {\"errors\": 0.019477270445972396, \"time-step\": 4477}, {\"errors\": 0.019451213607065677, \"time-step\": 4478}, {\"errors\": 0.01942520585418211, \"time-step\": 4479}, {\"errors\": 0.01939924709374312, \"time-step\": 4480}, {\"errors\": 0.01937333723224278, \"time-step\": 4481}, {\"errors\": 0.01934747617624876, \"time-step\": 4482}, {\"errors\": 0.019321663832403264, \"time-step\": 4483}, {\"errors\": 0.01929590010742396, \"time-step\": 4484}, {\"errors\": 0.019270184908104757, \"time-step\": 4485}, {\"errors\": 0.019244518141316933, \"time-step\": 4486}, {\"errors\": 0.01921889971400976, \"time-step\": 4487}, {\"errors\": 0.019193329533211637, \"time-step\": 4488}, {\"errors\": 0.01916780750603079, \"time-step\": 4489}, {\"errors\": 0.01914233353965622, \"time-step\": 4490}, {\"errors\": 0.01911690754135846, \"time-step\": 4491}, {\"errors\": 0.01909152941849059, \"time-step\": 4492}, {\"errors\": 0.01906619907848891, \"time-step\": 4493}, {\"errors\": 0.019040916428873837, \"time-step\": 4494}, {\"errors\": 0.019015681377250727, \"time-step\": 4495}, {\"errors\": 0.018990493831310712, \"time-step\": 4496}, {\"errors\": 0.018965353698831455, \"time-step\": 4497}, {\"errors\": 0.018940260887677945, \"time-step\": 4498}, {\"errors\": 0.01891521530580339, \"time-step\": 4499}, {\"errors\": 0.018890216861249778, \"time-step\": 4500}, {\"errors\": 0.01886526546214887, \"time-step\": 4501}, {\"errors\": 0.01884036101672295, \"time-step\": 4502}, {\"errors\": 0.018815503433285342, \"time-step\": 4503}, {\"errors\": 0.01879069262024142, \"time-step\": 4504}, {\"errors\": 0.01876592848608931, \"time-step\": 4505}, {\"errors\": 0.01874121093942044, \"time-step\": 4506}, {\"errors\": 0.01871653988892047, \"time-step\": 4507}, {\"errors\": 0.018691915243369852, \"time-step\": 4508}, {\"errors\": 0.01866733691164476, \"time-step\": 4509}, {\"errors\": 0.018642804802717464, \"time-step\": 4510}, {\"errors\": 0.01861831882565737, \"time-step\": 4511}, {\"errors\": 0.018593878889631363, \"time-step\": 4512}, {\"errors\": 0.01856948490390481, \"time-step\": 4513}, {\"errors\": 0.01854513677784202, \"time-step\": 4514}, {\"errors\": 0.018520834420907, \"time-step\": 4515}, {\"errors\": 0.018496577742664017, \"time-step\": 4516}, {\"errors\": 0.01847236665277839, \"time-step\": 4517}, {\"errors\": 0.01844820106101701, \"time-step\": 4518}, {\"errors\": 0.018424080877248988, \"time-step\": 4519}, {\"errors\": 0.018400006011446347, \"time-step\": 4520}, {\"errors\": 0.01837597637368461, \"time-step\": 4521}, {\"errors\": 0.01835199187414338, \"time-step\": 4522}, {\"errors\": 0.01832805242310696, \"time-step\": 4523}, {\"errors\": 0.018304157930965043, \"time-step\": 4524}, {\"errors\": 0.018280308308213103, \"time-step\": 4525}, {\"errors\": 0.018256503465453155, \"time-step\": 4526}, {\"errors\": 0.018232743313394313, \"time-step\": 4527}, {\"errors\": 0.018209027762853266, \"time-step\": 4528}, {\"errors\": 0.018185356724754947, \"time-step\": 4529}, {\"errors\": 0.018161730110132966, \"time-step\": 4530}, {\"errors\": 0.01813814783013036, \"time-step\": 4531}, {\"errors\": 0.018114609795999846, \"time-step\": 4532}, {\"errors\": 0.018091115919104696, \"time-step\": 4533}, {\"errors\": 0.01806766611091897, \"time-step\": 4534}, {\"errors\": 0.01804426028302827, \"time-step\": 4535}, {\"errors\": 0.018020898347130058, \"time-step\": 4536}, {\"errors\": 0.01799758021503428, \"time-step\": 4537}, {\"errors\": 0.0179743057986639, \"time-step\": 4538}, {\"errors\": 0.01795107501005534, \"time-step\": 4539}, {\"errors\": 0.017927887761358913, \"time-step\": 4540}, {\"errors\": 0.017904743964839494, \"time-step\": 4541}, {\"errors\": 0.017881643532876752, \"time-step\": 4542}, {\"errors\": 0.017858586377965825, \"time-step\": 4543}, {\"errors\": 0.017835572412717743, \"time-step\": 4544}, {\"errors\": 0.017812601549859773, \"time-step\": 4545}, {\"errors\": 0.017789673702236025, \"time-step\": 4546}, {\"errors\": 0.017766788782807835, \"time-step\": 4547}, {\"errors\": 0.017743946704654148, \"time-step\": 4548}, {\"errors\": 0.017721147380972066, \"time-step\": 4549}, {\"errors\": 0.0176983907250772, \"time-step\": 4550}, {\"errors\": 0.017675676650404145, \"time-step\": 4551}, {\"errors\": 0.017653005070506857, \"time-step\": 4552}, {\"errors\": 0.01763037589905911, \"time-step\": 4553}, {\"errors\": 0.017607789049854827, \"time-step\": 4554}, {\"errors\": 0.017585244436808523, \"time-step\": 4555}, {\"errors\": 0.017562741973955784, \"time-step\": 4556}, {\"errors\": 0.01754028157545348, \"time-step\": 4557}, {\"errors\": 0.01751786315558037, \"time-step\": 4558}, {\"errors\": 0.01749548662873722, \"time-step\": 4559}, {\"errors\": 0.017473151909447444, \"time-step\": 4560}, {\"errors\": 0.017450858912357224, \"time-step\": 4561}, {\"errors\": 0.017428607552236096, \"time-step\": 4562}, {\"errors\": 0.01740639774397714, \"time-step\": 4563}, {\"errors\": 0.01738422940259744, \"time-step\": 4564}, {\"errors\": 0.017362102443238315, \"time-step\": 4565}, {\"errors\": 0.01734001678116579, \"time-step\": 4566}, {\"errors\": 0.017317972331770813, \"time-step\": 4567}, {\"errors\": 0.01729596901056973, \"time-step\": 4568}, {\"errors\": 0.01727400673320446, \"time-step\": 4569}, {\"errors\": 0.017252085415442833, \"time-step\": 4570}, {\"errors\": 0.01723020497317907, \"time-step\": 4571}, {\"errors\": 0.017208365322433847, \"time-step\": 4572}, {\"errors\": 0.017186566379354784, \"time-step\": 4573}, {\"errors\": 0.01716480806021673, \"time-step\": 4574}, {\"errors\": 0.017143090281421886, \"time-step\": 4575}, {\"errors\": 0.017121412959500298, \"time-step\": 4576}, {\"errors\": 0.017099776011110082, \"time-step\": 4577}, {\"errors\": 0.01707817935303764, \"time-step\": 4578}, {\"errors\": 0.01705662290219804, \"time-step\": 4579}, {\"errors\": 0.017035106575635155, \"time-step\": 4580}, {\"errors\": 0.017013630290522004, \"time-step\": 4581}, {\"errors\": 0.016992193964161083, \"time-step\": 4582}, {\"errors\": 0.016970797513984483, \"time-step\": 4583}, {\"errors\": 0.016949440857554225, \"time-step\": 4584}, {\"errors\": 0.016928123912562473, \"time-step\": 4585}, {\"errors\": 0.01690684659683177, \"time-step\": 4586}, {\"errors\": 0.01688560882831537, \"time-step\": 4587}, {\"errors\": 0.01686441052509733, \"time-step\": 4588}, {\"errors\": 0.01684325160539282, \"time-step\": 4589}, {\"errors\": 0.016822131987548315, \"time-step\": 4590}, {\"errors\": 0.016801051590041874, \"time-step\": 4591}, {\"errors\": 0.016780010331483287, \"time-step\": 4592}, {\"errors\": 0.016759008130614327, \"time-step\": 4593}, {\"errors\": 0.016738044906308897, \"time-step\": 4594}, {\"errors\": 0.016717120577573304, \"time-step\": 4595}, {\"errors\": 0.016696235063546457, \"time-step\": 4596}, {\"errors\": 0.016675388283499987, \"time-step\": 4597}, {\"errors\": 0.01665458015683855, \"time-step\": 4598}, {\"errors\": 0.016633810603099826, \"time-step\": 4599}, {\"errors\": 0.016613079541954904, \"time-step\": 4600}, {\"errors\": 0.0165923868932084, \"time-step\": 4601}, {\"errors\": 0.01657173257679853, \"time-step\": 4602}, {\"errors\": 0.01655111651279741, \"time-step\": 4603}, {\"errors\": 0.01653053862141112, \"time-step\": 4604}, {\"errors\": 0.016509998822979967, \"time-step\": 4605}, {\"errors\": 0.016489497037978532, \"time-step\": 4606}, {\"errors\": 0.01646903318701591, \"time-step\": 4607}, {\"errors\": 0.01644860719083577, \"time-step\": 4608}, {\"errors\": 0.01642821897031667, \"time-step\": 4609}, {\"errors\": 0.016407868446471956, \"time-step\": 4610}, {\"errors\": 0.016387555540450086, \"time-step\": 4611}, {\"errors\": 0.016367280173534775, \"time-step\": 4612}, {\"errors\": 0.01634704226714491, \"time-step\": 4613}, {\"errors\": 0.016326841742834945, \"time-step\": 4614}, {\"errors\": 0.016306678522294865, \"time-step\": 4615}, {\"errors\": 0.016286552527350326, \"time-step\": 4616}, {\"errors\": 0.016266463679962862, \"time-step\": 4617}, {\"errors\": 0.016246411902229828, \"time-step\": 4618}, {\"errors\": 0.01622639711638465, \"time-step\": 4619}, {\"errors\": 0.016206419244796873, \"time-step\": 4620}, {\"errors\": 0.01618647820997231, \"time-step\": 4621}, {\"errors\": 0.016166573934553098, \"time-step\": 4622}, {\"errors\": 0.016146706341317717, \"time-step\": 4623}, {\"errors\": 0.016126875353181316, \"time-step\": 4624}, {\"errors\": 0.016107080893195506, \"time-step\": 4625}, {\"errors\": 0.01608732288454866, \"time-step\": 4626}, {\"errors\": 0.016067601250565933, \"time-step\": 4627}, {\"errors\": 0.016047915914709308, \"time-step\": 4628}, {\"errors\": 0.016028266800577676, \"time-step\": 4629}, {\"errors\": 0.016008653831906968, \"time-step\": 4630}, {\"errors\": 0.01598907693257014, \"time-step\": 4631}, {\"errors\": 0.01596953602657728, \"time-step\": 4632}, {\"errors\": 0.015950031038075747, \"time-step\": 4633}, {\"errors\": 0.015930561891349997, \"time-step\": 4634}, {\"errors\": 0.015911128510821968, \"time-step\": 4635}, {\"errors\": 0.015891730821050835, \"time-step\": 4636}, {\"errors\": 0.015872368746733184, \"time-step\": 4637}, {\"errors\": 0.01585304221270315, \"time-step\": 4638}, {\"errors\": 0.015833751143932297, \"time-step\": 4639}, {\"errors\": 0.01581449546552975, \"time-step\": 4640}, {\"errors\": 0.015795275102742194, \"time-step\": 4641}, {\"errors\": 0.01577608998095396, \"time-step\": 4642}, {\"errors\": 0.015756940025686977, \"time-step\": 4643}, {\"errors\": 0.01573782516260089, \"time-step\": 4644}, {\"errors\": 0.015718745317493024, \"time-step\": 4645}, {\"errors\": 0.015699700416298444, \"time-step\": 4646}, {\"errors\": 0.015680690385089922, \"time-step\": 4647}, {\"errors\": 0.01566171515007806, \"time-step\": 4648}, {\"errors\": 0.015642774637611163, \"time-step\": 4649}, {\"errors\": 0.015623868774175344, \"time-step\": 4650}, {\"errors\": 0.01560499748639457, \"time-step\": 4651}, {\"errors\": 0.015586160701030534, \"time-step\": 4652}, {\"errors\": 0.015567358344982785, \"time-step\": 4653}, {\"errors\": 0.015548590345288684, \"time-step\": 4654}, {\"errors\": 0.015529856629123366, \"time-step\": 4655}, {\"errors\": 0.015511157123799862, \"time-step\": 4656}, {\"errors\": 0.015492491756768874, \"time-step\": 4657}, {\"errors\": 0.015473860455618993, \"time-step\": 4658}, {\"errors\": 0.015455263148076548, \"time-step\": 4659}, {\"errors\": 0.015436699762005675, \"time-step\": 4660}, {\"errors\": 0.015418170225408246, \"time-step\": 4661}, {\"errors\": 0.015399674466423803, \"time-step\": 4662}, {\"errors\": 0.015381212413329681, \"time-step\": 4663}, {\"errors\": 0.015362783994540902, \"time-step\": 4664}, {\"errors\": 0.015344389138610049, \"time-step\": 4665}, {\"errors\": 0.01532602777422749, \"time-step\": 4666}, {\"errors\": 0.015307699830221063, \"time-step\": 4667}, {\"errors\": 0.01528940523555625, \"time-step\": 4668}, {\"errors\": 0.015271143919336098, \"time-step\": 4669}, {\"errors\": 0.01525291581080104, \"time-step\": 4670}, {\"errors\": 0.015234720839329075, \"time-step\": 4671}, {\"errors\": 0.015216558934435562, \"time-step\": 4672}, {\"errors\": 0.015198430025773275, \"time-step\": 4673}, {\"errors\": 0.015180334043132234, \"time-step\": 4674}, {\"errors\": 0.015162270916439863, \"time-step\": 4675}, {\"errors\": 0.015144240575760692, \"time-step\": 4676}, {\"errors\": 0.015126242951296531, \"time-step\": 4677}, {\"errors\": 0.015108277973386198, \"time-step\": 4678}, {\"errors\": 0.01509034557250567, \"time-step\": 4679}, {\"errors\": 0.015072445679267878, \"time-step\": 4680}, {\"errors\": 0.01505457822442273, \"time-step\": 4681}, {\"errors\": 0.01503674313885696, \"time-step\": 4682}, {\"errors\": 0.01501894035359421, \"time-step\": 4683}, {\"errors\": 0.015001169799794753, \"time-step\": 4684}, {\"errors\": 0.01498343140875565, \"time-step\": 4685}, {\"errors\": 0.014965725111910497, \"time-step\": 4686}, {\"errors\": 0.014948050840829473, \"time-step\": 4687}, {\"errors\": 0.014930408527219163, \"time-step\": 4688}, {\"errors\": 0.01491279810292261, \"time-step\": 4689}, {\"errors\": 0.014895219499919092, \"time-step\": 4690}, {\"errors\": 0.014877672650324181, \"time-step\": 4691}, {\"errors\": 0.014860157486389533, \"time-step\": 4692}, {\"errors\": 0.014842673940502885, \"time-step\": 4693}, {\"errors\": 0.014825221945187966, \"time-step\": 4694}, {\"errors\": 0.014807801433104385, \"time-step\": 4695}, {\"errors\": 0.014790412337047473, \"time-step\": 4696}, {\"errors\": 0.014773054589948396, \"time-step\": 4697}, {\"errors\": 0.01475572812487385, \"time-step\": 4698}, {\"errors\": 0.014738432875026072, \"time-step\": 4699}, {\"errors\": 0.014721168773742683, \"time-step\": 4700}, {\"errors\": 0.014703935754496706, \"time-step\": 4701}, {\"errors\": 0.014686733750896342, \"time-step\": 4702}, {\"errors\": 0.014669562696684877, \"time-step\": 4703}, {\"errors\": 0.014652422525740703, \"time-step\": 4704}, {\"errors\": 0.014635313172077065, \"time-step\": 4705}, {\"errors\": 0.014618234569842035, \"time-step\": 4706}, {\"errors\": 0.014601186653318388, \"time-step\": 4707}, {\"errors\": 0.014584169356923509, \"time-step\": 4708}, {\"errors\": 0.014567182615209225, \"time-step\": 4709}, {\"errors\": 0.014550226362861794, \"time-step\": 4710}, {\"errors\": 0.014533300534701688, \"time-step\": 4711}, {\"errors\": 0.014516405065683516, \"time-step\": 4712}, {\"errors\": 0.014499539890895953, \"time-step\": 4713}, {\"errors\": 0.014482704945561545, \"time-step\": 4714}, {\"errors\": 0.014465900165036644, \"time-step\": 4715}, {\"errors\": 0.01444912548481125, \"time-step\": 4716}, {\"errors\": 0.014432380840508888, \"time-step\": 4717}, {\"errors\": 0.014415666167886611, \"time-step\": 4718}, {\"errors\": 0.014398981402834644, \"time-step\": 4719}, {\"errors\": 0.014382326481376426, \"time-step\": 4720}, {\"errors\": 0.014365701339668462, \"time-step\": 4721}, {\"errors\": 0.01434910591400013, \"time-step\": 4722}, {\"errors\": 0.014332540140793607, \"time-step\": 4723}, {\"errors\": 0.014316003956603747, \"time-step\": 4724}, {\"errors\": 0.014299497298117858, \"time-step\": 4725}, {\"errors\": 0.014283020102155684, \"time-step\": 4726}, {\"errors\": 0.014266572305669217, \"time-step\": 4727}, {\"errors\": 0.014250153845742481, \"time-step\": 4728}, {\"errors\": 0.014233764659591606, \"time-step\": 4729}, {\"errors\": 0.014217404684564451, \"time-step\": 4730}, {\"errors\": 0.014201073858140565, \"time-step\": 4731}, {\"errors\": 0.014184772117931111, \"time-step\": 4732}, {\"errors\": 0.014168499401678617, \"time-step\": 4733}, {\"errors\": 0.0141522556472569, \"time-step\": 4734}, {\"errors\": 0.014136040792670872, \"time-step\": 4735}, {\"errors\": 0.014119854776056394, \"time-step\": 4736}, {\"errors\": 0.014103697535680224, \"time-step\": 4737}, {\"errors\": 0.01408756900993974, \"time-step\": 4738}, {\"errors\": 0.01407146913736285, \"time-step\": 4739}, {\"errors\": 0.01405539785660788, \"time-step\": 4740}, {\"errors\": 0.014039355106463319, \"time-step\": 4741}, {\"errors\": 0.01402334082584776, \"time-step\": 4742}, {\"errors\": 0.01400735495380974, \"time-step\": 4743}, {\"errors\": 0.013991397429527517, \"time-step\": 4744}, {\"errors\": 0.01397546819230893, \"time-step\": 4745}, {\"errors\": 0.01395956718159137, \"time-step\": 4746}, {\"errors\": 0.013943694336941424, \"time-step\": 4747}, {\"errors\": 0.013927849598054796, \"time-step\": 4748}, {\"errors\": 0.0139120329047563, \"time-step\": 4749}, {\"errors\": 0.013896244196999424, \"time-step\": 4750}, {\"errors\": 0.013880483414866385, \"time-step\": 4751}, {\"errors\": 0.013864750498567831, \"time-step\": 4752}, {\"errors\": 0.013849045388442748, \"time-step\": 4753}, {\"errors\": 0.01383336802495837, \"time-step\": 4754}, {\"errors\": 0.013817718348709748, \"time-step\": 4755}, {\"errors\": 0.013802096300419973, \"time-step\": 4756}, {\"errors\": 0.013786501820939625, \"time-step\": 4757}, {\"errors\": 0.01377093485124689, \"time-step\": 4758}, {\"errors\": 0.013755395332447178, \"time-step\": 4759}, {\"errors\": 0.013739883205773146, \"time-step\": 4760}, {\"errors\": 0.013724398412584389, \"time-step\": 4761}, {\"errors\": 0.01370894089436733, \"time-step\": 4762}, {\"errors\": 0.013693510592735032, \"time-step\": 4763}, {\"errors\": 0.01367810744942703, \"time-step\": 4764}, {\"errors\": 0.013662731406309095, \"time-step\": 4765}, {\"errors\": 0.013647382405373235, \"time-step\": 4766}, {\"errors\": 0.013632060388737304, \"time-step\": 4767}, {\"errors\": 0.013616765298644987, \"time-step\": 4768}, {\"errors\": 0.013601497077465493, \"time-step\": 4769}, {\"errors\": 0.013586255667693517, \"time-step\": 4770}, {\"errors\": 0.013571041011948975, \"time-step\": 4771}, {\"errors\": 0.013555853052976803, \"time-step\": 4772}, {\"errors\": 0.01354069173364686, \"time-step\": 4773}, {\"errors\": 0.01352555699695368, \"time-step\": 4774}, {\"errors\": 0.013510448786016326, \"time-step\": 4775}, {\"errors\": 0.013495367044078194, \"time-step\": 4776}, {\"errors\": 0.013480311714506824, \"time-step\": 4777}, {\"errors\": 0.013465282740793748, \"time-step\": 4778}, {\"errors\": 0.013450280066554262, \"time-step\": 4779}, {\"errors\": 0.01343530363552732, \"time-step\": 4780}, {\"errors\": 0.013420353391575206, \"time-step\": 4781}, {\"errors\": 0.01340542927868352, \"time-step\": 4782}, {\"errors\": 0.013390531240960898, \"time-step\": 4783}, {\"errors\": 0.013375659222638786, \"time-step\": 4784}, {\"errors\": 0.013360813168071358, \"time-step\": 4785}, {\"errors\": 0.01334599302173526, \"time-step\": 4786}, {\"errors\": 0.013331198728229412, \"time-step\": 4787}, {\"errors\": 0.013316430232274887, \"time-step\": 4788}, {\"errors\": 0.013301687478714647, \"time-step\": 4789}, {\"errors\": 0.013286970412513435, \"time-step\": 4790}, {\"errors\": 0.013272278978757452, \"time-step\": 4791}, {\"errors\": 0.013257613122654322, \"time-step\": 4792}, {\"errors\": 0.01324297278953283, \"time-step\": 4793}, {\"errors\": 0.013228357924842667, \"time-step\": 4794}, {\"errors\": 0.013213768474154345, \"time-step\": 4795}, {\"errors\": 0.013199204383158936, \"time-step\": 4796}, {\"errors\": 0.013184665597667943, \"time-step\": 4797}, {\"errors\": 0.013170152063613036, \"time-step\": 4798}, {\"errors\": 0.013155663727045873, \"time-step\": 4799}, {\"errors\": 0.013141200534137951, \"time-step\": 4800}, {\"errors\": 0.013126762431180335, \"time-step\": 4801}, {\"errors\": 0.01311234936458358, \"time-step\": 4802}, {\"errors\": 0.013097961280877373, \"time-step\": 4803}, {\"errors\": 0.013083598126710484, \"time-step\": 4804}, {\"errors\": 0.01306925984885051, \"time-step\": 4805}, {\"errors\": 0.013054946394183668, \"time-step\": 4806}, {\"errors\": 0.013040657709714572, \"time-step\": 4807}, {\"errors\": 0.013026393742566148, \"time-step\": 4808}, {\"errors\": 0.013012154439979272, \"time-step\": 4809}, {\"errors\": 0.012997939749312768, \"time-step\": 4810}, {\"errors\": 0.012983749618042998, \"time-step\": 4811}, {\"errors\": 0.012969583993763797, \"time-step\": 4812}, {\"errors\": 0.012955442824186258, \"time-step\": 4813}, {\"errors\": 0.012941326057138505, \"time-step\": 4814}, {\"errors\": 0.012927233640565514, \"time-step\": 4815}, {\"errors\": 0.012913165522528865, \"time-step\": 4816}, {\"errors\": 0.012899121651206647, \"time-step\": 4817}, {\"errors\": 0.012885101974893095, \"time-step\": 4818}, {\"errors\": 0.012871106441998563, \"time-step\": 4819}, {\"errors\": 0.012857135001049201, \"time-step\": 4820}, {\"errors\": 0.012843187600686794, \"time-step\": 4821}, {\"errors\": 0.012829264189668552, \"time-step\": 4822}, {\"errors\": 0.012815364716866937, \"time-step\": 4823}, {\"errors\": 0.01280148913126939, \"time-step\": 4824}, {\"errors\": 0.012787637381978245, \"time-step\": 4825}, {\"errors\": 0.01277380941821041, \"time-step\": 4826}, {\"errors\": 0.012760005189297197, \"time-step\": 4827}, {\"errors\": 0.012746224644684133, \"time-step\": 4828}, {\"errors\": 0.012732467733930785, \"time-step\": 4829}, {\"errors\": 0.012718734406710494, \"time-step\": 4830}, {\"errors\": 0.012705024612810194, \"time-step\": 4831}, {\"errors\": 0.01269133830213023, \"time-step\": 4832}, {\"errors\": 0.01267767542468415, \"time-step\": 4833}, {\"errors\": 0.012664035930598415, \"time-step\": 4834}, {\"errors\": 0.012650419770112373, \"time-step\": 4835}, {\"errors\": 0.012636826893577851, \"time-step\": 4836}, {\"errors\": 0.012623257251459056, \"time-step\": 4837}, {\"errors\": 0.01260971079433238, \"time-step\": 4838}, {\"errors\": 0.01259618747288618, \"time-step\": 4839}, {\"errors\": 0.012582687237920553, \"time-step\": 4840}, {\"errors\": 0.012569210040347105, \"time-step\": 4841}, {\"errors\": 0.012555755831188804, \"time-step\": 4842}, {\"errors\": 0.012542324561579736, \"time-step\": 4843}, {\"errors\": 0.012528916182764928, \"time-step\": 4844}, {\"errors\": 0.012515530646100104, \"time-step\": 4845}, {\"errors\": 0.012502167903051493, \"time-step\": 4846}, {\"errors\": 0.012488827905195626, \"time-step\": 4847}, {\"errors\": 0.012475510604219139, \"time-step\": 4848}, {\"errors\": 0.012462215951918546, \"time-step\": 4849}, {\"errors\": 0.012448943900200037, \"time-step\": 4850}, {\"errors\": 0.012435694401079275, \"time-step\": 4851}, {\"errors\": 0.012422467406681171, \"time-step\": 4852}, {\"errors\": 0.012409262869239695, \"time-step\": 4853}, {\"errors\": 0.012396080741097677, \"time-step\": 4854}, {\"errors\": 0.012382920974706613, \"time-step\": 4855}, {\"errors\": 0.01236978352262635, \"time-step\": 4856}, {\"errors\": 0.012356668337525013, \"time-step\": 4857}, {\"errors\": 0.012343575372178714, \"time-step\": 4858}, {\"errors\": 0.012330504579471404, \"time-step\": 4859}, {\"errors\": 0.012317455912394599, \"time-step\": 4860}, {\"errors\": 0.012304429324047243, \"time-step\": 4861}, {\"errors\": 0.012291424767635402, \"time-step\": 4862}, {\"errors\": 0.012278442196472145, \"time-step\": 4863}, {\"errors\": 0.012265481563977308, \"time-step\": 4864}, {\"errors\": 0.012252542823677298, \"time-step\": 4865}, {\"errors\": 0.012239625929204832, \"time-step\": 4866}, {\"errors\": 0.012226730834298753, \"time-step\": 4867}, {\"errors\": 0.012213857492803896, \"time-step\": 4868}, {\"errors\": 0.012201005858670743, \"time-step\": 4869}, {\"errors\": 0.012188175885955319, \"time-step\": 4870}, {\"errors\": 0.01217536752881898, \"time-step\": 4871}, {\"errors\": 0.012162580741528145, \"time-step\": 4872}, {\"errors\": 0.012149815478454097, \"time-step\": 4873}, {\"errors\": 0.012137071694072845, \"time-step\": 4874}, {\"errors\": 0.012124349342964812, \"time-step\": 4875}, {\"errors\": 0.012111648379814745, \"time-step\": 4876}, {\"errors\": 0.012098968759411355, \"time-step\": 4877}, {\"errors\": 0.012086310436647282, \"time-step\": 4878}, {\"errors\": 0.012073673366518736, \"time-step\": 4879}, {\"errors\": 0.012061057504125373, \"time-step\": 4880}, {\"errors\": 0.012048462804670087, \"time-step\": 4881}, {\"errors\": 0.012035889223458746, \"time-step\": 4882}, {\"errors\": 0.012023336715900022, \"time-step\": 4883}, {\"errors\": 0.012010805237505178, \"time-step\": 4884}, {\"errors\": 0.0119982947438879, \"time-step\": 4885}, {\"errors\": 0.011985805190763966, \"time-step\": 4886}, {\"errors\": 0.011973336533951202, \"time-step\": 4887}, {\"errors\": 0.01196088872936912, \"time-step\": 4888}, {\"errors\": 0.011948461733038877, \"time-step\": 4889}, {\"errors\": 0.011936055501082857, \"time-step\": 4890}, {\"errors\": 0.011923669989724644, \"time-step\": 4891}, {\"errors\": 0.011911305155288737, \"time-step\": 4892}, {\"errors\": 0.011898960954200339, \"time-step\": 4893}, {\"errors\": 0.011886637342985194, \"time-step\": 4894}, {\"errors\": 0.011874334278269321, \"time-step\": 4895}, {\"errors\": 0.011862051716778808, \"time-step\": 4896}, {\"errors\": 0.011849789615339695, \"time-step\": 4897}, {\"errors\": 0.011837547930877663, \"time-step\": 4898}, {\"errors\": 0.011825326620417864, \"time-step\": 4899}, {\"errors\": 0.01181312564108473, \"time-step\": 4900}, {\"errors\": 0.011800944950101722, \"time-step\": 4901}, {\"errors\": 0.011788784504791178, \"time-step\": 4902}, {\"errors\": 0.011776644262574104, \"time-step\": 4903}, {\"errors\": 0.01176452418096988, \"time-step\": 4904}, {\"errors\": 0.011752424217596159, \"time-step\": 4905}, {\"errors\": 0.011740344330168627, \"time-step\": 4906}, {\"errors\": 0.011728284476500745, \"time-step\": 4907}, {\"errors\": 0.01171624461450364, \"time-step\": 4908}, {\"errors\": 0.011704224702185791, \"time-step\": 4909}, {\"errors\": 0.011692224697652926, \"time-step\": 4910}, {\"errors\": 0.011680244559107739, \"time-step\": 4911}, {\"errors\": 0.011668284244849749, \"time-step\": 4912}, {\"errors\": 0.011656343713274949, \"time-step\": 4913}, {\"errors\": 0.011644422922875867, \"time-step\": 4914}, {\"errors\": 0.01163252183224109, \"time-step\": 4915}, {\"errors\": 0.011620640400055185, \"time-step\": 4916}, {\"errors\": 0.011608778585098541, \"time-step\": 4917}, {\"errors\": 0.011596936346247057, \"time-step\": 4918}, {\"errors\": 0.011585113642471983, \"time-step\": 4919}, {\"errors\": 0.011573310432839734, \"time-step\": 4920}, {\"errors\": 0.01156152667651168, \"time-step\": 4921}, {\"errors\": 0.011549762332743884, \"time-step\": 4922}, {\"errors\": 0.011538017360887004, \"time-step\": 4923}, {\"errors\": 0.011526291720386012, \"time-step\": 4924}, {\"errors\": 0.011514585370779961, \"time-step\": 4925}, {\"errors\": 0.011502898271701858, \"time-step\": 4926}, {\"errors\": 0.011491230382878501, \"time-step\": 4927}, {\"errors\": 0.011479581664130123, \"time-step\": 4928}, {\"errors\": 0.01146795207537029, \"time-step\": 4929}, {\"errors\": 0.011456341576605689, \"time-step\": 4930}, {\"errors\": 0.01144475012793592, \"time-step\": 4931}, {\"errors\": 0.011433177689553303, \"time-step\": 4932}, {\"errors\": 0.011421624221742645, \"time-step\": 4933}, {\"errors\": 0.011410089684881053, \"time-step\": 4934}, {\"errors\": 0.011398574039437743, \"time-step\": 4935}, {\"errors\": 0.011387077245973888, \"time-step\": 4936}, {\"errors\": 0.011375599265142275, \"time-step\": 4937}, {\"errors\": 0.011364140057687235, \"time-step\": 4938}, {\"errors\": 0.011352699584444358, \"time-step\": 4939}, {\"errors\": 0.011341277806340413, \"time-step\": 4940}, {\"errors\": 0.01132987468439298, \"time-step\": 4941}, {\"errors\": 0.01131849017971039, \"time-step\": 4942}, {\"errors\": 0.011307124253491455, \"time-step\": 4943}, {\"errors\": 0.011295776867025261, \"time-step\": 4944}, {\"errors\": 0.011284447981691028, \"time-step\": 4945}, {\"errors\": 0.011273137558957856, \"time-step\": 4946}, {\"errors\": 0.011261845560384552, \"time-step\": 4947}, {\"errors\": 0.01125057194761942, \"time-step\": 4948}, {\"errors\": 0.011239316682400032, \"time-step\": 4949}, {\"errors\": 0.01122807972655311, \"time-step\": 4950}, {\"errors\": 0.01121686104199429, \"time-step\": 4951}, {\"errors\": 0.011205660590727817, \"time-step\": 4952}, {\"errors\": 0.011194478334846594, \"time-step\": 4953}, {\"errors\": 0.011183314236531705, \"time-step\": 4954}, {\"errors\": 0.011172168258052432, \"time-step\": 4955}, {\"errors\": 0.011161040361765927, \"time-step\": 4956}, {\"errors\": 0.011149930510117072, \"time-step\": 4957}, {\"errors\": 0.011138838665638275, \"time-step\": 4958}, {\"errors\": 0.01112776479094928, \"time-step\": 4959}, {\"errors\": 0.011116708848756962, \"time-step\": 4960}, {\"errors\": 0.011105670801855113, \"time-step\": 4961}, {\"errors\": 0.011094650613124259, \"time-step\": 4962}, {\"errors\": 0.01108364824553154, \"time-step\": 4963}, {\"errors\": 0.011072663662130335, \"time-step\": 4964}, {\"errors\": 0.011061696826060265, \"time-step\": 4965}, {\"errors\": 0.011050747700546855, \"time-step\": 4966}, {\"errors\": 0.011039816248901466, \"time-step\": 4967}, {\"errors\": 0.01102890243452093, \"time-step\": 4968}, {\"errors\": 0.011018006220887559, \"time-step\": 4969}, {\"errors\": 0.011007127571568786, \"time-step\": 4970}, {\"errors\": 0.010996266450217016, \"time-step\": 4971}, {\"errors\": 0.010985422820569565, \"time-step\": 4972}, {\"errors\": 0.010974596646448183, \"time-step\": 4973}, {\"errors\": 0.010963787891759195, \"time-step\": 4974}, {\"errors\": 0.01095299652049303, \"time-step\": 4975}, {\"errors\": 0.010942222496724224, \"time-step\": 4976}, {\"errors\": 0.010931465784611115, \"time-step\": 4977}, {\"errors\": 0.010920726348395702, \"time-step\": 4978}, {\"errors\": 0.010910004152403362, \"time-step\": 4979}, {\"errors\": 0.010899299161042882, \"time-step\": 4980}, {\"errors\": 0.01088861133880599, \"time-step\": 4981}, {\"errors\": 0.010877940650267358, \"time-step\": 4982}, {\"errors\": 0.01086728706008433, \"time-step\": 4983}, {\"errors\": 0.01085665053299678, \"time-step\": 4984}, {\"errors\": 0.010846031033826867, \"time-step\": 4985}, {\"errors\": 0.010835428527478892, \"time-step\": 4986}, {\"errors\": 0.010824842978939087, \"time-step\": 4987}, {\"errors\": 0.01081427435327541, \"time-step\": 4988}, {\"errors\": 0.010803722615637392, \"time-step\": 4989}, {\"errors\": 0.010793187731255973, \"time-step\": 4990}, {\"errors\": 0.010782669665443199, \"time-step\": 4991}, {\"errors\": 0.010772168383592181, \"time-step\": 4992}, {\"errors\": 0.010761683851176804, \"time-step\": 4993}, {\"errors\": 0.010751216033751588, \"time-step\": 4994}, {\"errors\": 0.010740764896951471, \"time-step\": 4995}, {\"errors\": 0.010730330406491618, \"time-step\": 4996}, {\"errors\": 0.010719912528167366, \"time-step\": 4997}, {\"errors\": 0.010709511227853777, \"time-step\": 4998}, {\"errors\": 0.010699126471505706, \"time-step\": 4999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"errors\":errors, \"time-step\": np.arange(0, len(errors))})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(x=\"time-step\", y=\"errors\").properties(title='Chart 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error curve is revealing. After the first few iterations the error dropped fast to around 0.13, and from there went down more gradually. If you are wondering how the accuracy is 100% although the error is not zero, remember that the binary predictions have no business in the error computation and that many different sets of weights may generate the correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: multilayer perceptron with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we implemented our own multilayer perceptron was for **pedagogical purposes**. Richard Feynman once famously said: \"**What I cannot create I do not understand**\", which is probably an exaggeration but I personally agree with the principle of \"learning by creating\". Learning to build neural networks is similar to learn math (maybe because they are *literally* math): yes, you'll end up using a calculator to compute almost everything, yet, we still do the exercise of computing systems of equations by hand when learning algebra. There is a deeper level of understanding that is unlocked when you actually get to build something from scratch.\n",
    "\n",
    "Nonetheless, there is no need to go through this process every time. Nowadays, we have access to very good libraries to build neural networks. [Keras](https://keras.io/) is a popular Python library for this. Keras main strength is the simplicity and elegance of its interface (sometimes people call it \"API\"). Keras hides most of the computations to the users and provides a way to define neural networks that match with what you would normally do when drawing a diagram. There are many other libraries you may hear about (Tensorflow, PyTorch, MXNet, Caffe, etc.) but I'll use this one because is the best for beginners in my opinion.\n",
    "\n",
    "Next, we will build another multi-layer perceptron to solve the same XOR Problem and to illustrate how simple is the process with Keras. \n",
    "\n",
    "This time, I'll put together a network with the following characteristics:\n",
    "\n",
    "- **Input layer** with 2 neurons (i.e., the two features).\n",
    "- **One hidden** layer with 16 neurons with sigmoid activation functions.\n",
    "- **Output layer** with 1 neuron with a sigmoid activation (i.e., a target value of 0 or 1).\n",
    "- **Mean squared error** as the cost (or loss) function.\n",
    "- **\"Adam\" optimizer**. This a variation of gradient descent that (sometimes) speed up the process by adapting the learning rate for each parameter in the network. It has the advantage that we don't need to manually search for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected values\n",
    "y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "# features\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the model definition:\n",
    "- `Sequential()` specifies that the network is a linear stack of layers\n",
    "- `model.add()` adds the hidden layer.\n",
    "- `Dense` means that neurons between layers are fully connected\n",
    "- `input_dim` defines the number of features in the training dataset\n",
    "- `activation` defines the activation function\n",
    "- `loss` selects the cost function\n",
    "- `optimizer` selects the learning algorithm\n",
    "- `metrics` selects the performance metrics to be saved for further analysis\n",
    "- `model.fit()` initialize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mean_squared_error'])\n",
    "\n",
    "history = model.fit(X, y, epochs=3000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-5a49cb839eee4a98b3193b60ef11f4bf\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-5a49cb839eee4a98b3193b60ef11f4bf\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6bfc0a5d97678e1be6f97ee0918be17a\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"time-step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"errors\"}}, \"title\": \"Chart 3\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-6bfc0a5d97678e1be6f97ee0918be17a\": [{\"errors\": 0.3597352206707001, \"time-step\": 0}, {\"errors\": 0.3589778542518616, \"time-step\": 1}, {\"errors\": 0.3581027090549469, \"time-step\": 2}, {\"errors\": 0.35708147287368774, \"time-step\": 3}, {\"errors\": 0.3560582399368286, \"time-step\": 4}, {\"errors\": 0.35503315925598145, \"time-step\": 5}, {\"errors\": 0.3540063202381134, \"time-step\": 6}, {\"errors\": 0.35297778248786926, \"time-step\": 7}, {\"errors\": 0.351947546005249, \"time-step\": 8}, {\"errors\": 0.3509158194065094, \"time-step\": 9}, {\"errors\": 0.34988269209861755, \"time-step\": 10}, {\"errors\": 0.3488481044769287, \"time-step\": 11}, {\"errors\": 0.34781235456466675, \"time-step\": 12}, {\"errors\": 0.3467753529548645, \"time-step\": 13}, {\"errors\": 0.3457373380661011, \"time-step\": 14}, {\"errors\": 0.34469836950302124, \"time-step\": 15}, {\"errors\": 0.34365859627723694, \"time-step\": 16}, {\"errors\": 0.34261804819107056, \"time-step\": 17}, {\"errors\": 0.3415769338607788, \"time-step\": 18}, {\"errors\": 0.34053534269332886, \"time-step\": 19}, {\"errors\": 0.3394935131072998, \"time-step\": 20}, {\"errors\": 0.3384513854980469, \"time-step\": 21}, {\"errors\": 0.33739760518074036, \"time-step\": 22}, {\"errors\": 0.3363555371761322, \"time-step\": 23}, {\"errors\": 0.33531373739242554, \"time-step\": 24}, {\"errors\": 0.3342723250389099, \"time-step\": 25}, {\"errors\": 0.33323144912719727, \"time-step\": 26}, {\"errors\": 0.33219125866889954, \"time-step\": 27}, {\"errors\": 0.33115196228027344, \"time-step\": 28}, {\"errors\": 0.33011364936828613, \"time-step\": 29}, {\"errors\": 0.32907652854919434, \"time-step\": 30}, {\"errors\": 0.3280407190322876, \"time-step\": 31}, {\"errors\": 0.3270064890384674, \"time-step\": 32}, {\"errors\": 0.32597389817237854, \"time-step\": 33}, {\"errors\": 0.32494330406188965, \"time-step\": 34}, {\"errors\": 0.3239145278930664, \"time-step\": 35}, {\"errors\": 0.32288825511932373, \"time-step\": 36}, {\"errors\": 0.32186415791511536, \"time-step\": 37}, {\"errors\": 0.3208426833152771, \"time-step\": 38}, {\"errors\": 0.31982406973838806, \"time-step\": 39}, {\"errors\": 0.3188084363937378, \"time-step\": 40}, {\"errors\": 0.31779584288597107, \"time-step\": 41}, {\"errors\": 0.31678664684295654, \"time-step\": 42}, {\"errors\": 0.31578096747398376, \"time-step\": 43}, {\"errors\": 0.3147689700126648, \"time-step\": 44}, {\"errors\": 0.31377094984054565, \"time-step\": 45}, {\"errors\": 0.3127771019935608, \"time-step\": 46}, {\"errors\": 0.31178751587867737, \"time-step\": 47}, {\"errors\": 0.3108024597167969, \"time-step\": 48}, {\"errors\": 0.3098221719264984, \"time-step\": 49}, {\"errors\": 0.30884671211242676, \"time-step\": 50}, {\"errors\": 0.3078763484954834, \"time-step\": 51}, {\"errors\": 0.30691128969192505, \"time-step\": 52}, {\"errors\": 0.3059517741203308, \"time-step\": 53}, {\"errors\": 0.3049979507923126, \"time-step\": 54}, {\"errors\": 0.30404990911483765, \"time-step\": 55}, {\"errors\": 0.3031080365180969, \"time-step\": 56}, {\"errors\": 0.30217236280441284, \"time-step\": 57}, {\"errors\": 0.3012431561946869, \"time-step\": 58}, {\"errors\": 0.300320565700531, \"time-step\": 59}, {\"errors\": 0.2994048595428467, \"time-step\": 60}, {\"errors\": 0.2984960079193115, \"time-step\": 61}, {\"errors\": 0.29759442806243896, \"time-step\": 62}, {\"errors\": 0.2967001497745514, \"time-step\": 63}, {\"errors\": 0.2958133816719055, \"time-step\": 64}, {\"errors\": 0.29493433237075806, \"time-step\": 65}, {\"errors\": 0.29406309127807617, \"time-step\": 66}, {\"errors\": 0.2931998372077942, \"time-step\": 67}, {\"errors\": 0.29234474897384644, \"time-step\": 68}, {\"errors\": 0.29149800539016724, \"time-step\": 69}, {\"errors\": 0.29065966606140137, \"time-step\": 70}, {\"errors\": 0.28982993960380554, \"time-step\": 71}, {\"errors\": 0.2890089750289917, \"time-step\": 72}, {\"errors\": 0.2881968319416046, \"time-step\": 73}, {\"errors\": 0.287393718957901, \"time-step\": 74}, {\"errors\": 0.28659969568252563, \"time-step\": 75}, {\"errors\": 0.28581491112709045, \"time-step\": 76}, {\"errors\": 0.285034716129303, \"time-step\": 77}, {\"errors\": 0.28426870703697205, \"time-step\": 78}, {\"errors\": 0.2835123538970947, \"time-step\": 79}, {\"errors\": 0.28276553750038147, \"time-step\": 80}, {\"errors\": 0.28202855587005615, \"time-step\": 81}, {\"errors\": 0.281301349401474, \"time-step\": 82}, {\"errors\": 0.28058406710624695, \"time-step\": 83}, {\"errors\": 0.279876708984375, \"time-step\": 84}, {\"errors\": 0.2791794240474701, \"time-step\": 85}, {\"errors\": 0.2784922420978546, \"time-step\": 86}, {\"errors\": 0.27781519293785095, \"time-step\": 87}, {\"errors\": 0.2771483063697815, \"time-step\": 88}, {\"errors\": 0.2764917016029358, \"time-step\": 89}, {\"errors\": 0.27584534883499146, \"time-step\": 90}, {\"errors\": 0.27520933747291565, \"time-step\": 91}, {\"errors\": 0.274583637714386, \"time-step\": 92}, {\"errors\": 0.27396824955940247, \"time-step\": 93}, {\"errors\": 0.27336329221725464, \"time-step\": 94}, {\"errors\": 0.27276861667633057, \"time-step\": 95}, {\"errors\": 0.2721843719482422, \"time-step\": 96}, {\"errors\": 0.2716104984283447, \"time-step\": 97}, {\"errors\": 0.27104416489601135, \"time-step\": 98}, {\"errors\": 0.27048835158348083, \"time-step\": 99}, {\"errors\": 0.269942969083786, \"time-step\": 100}, {\"errors\": 0.2694079577922821, \"time-step\": 101}, {\"errors\": 0.26888328790664673, \"time-step\": 102}, {\"errors\": 0.2683689594268799, \"time-step\": 103}, {\"errors\": 0.26786714792251587, \"time-step\": 104}, {\"errors\": 0.26737549901008606, \"time-step\": 105}, {\"errors\": 0.26689383387565613, \"time-step\": 106}, {\"errors\": 0.2664222717285156, \"time-step\": 107}, {\"errors\": 0.26596057415008545, \"time-step\": 108}, {\"errors\": 0.265508770942688, \"time-step\": 109}, {\"errors\": 0.26506686210632324, \"time-step\": 110}, {\"errors\": 0.26463449001312256, \"time-step\": 111}, {\"errors\": 0.26421189308166504, \"time-step\": 112}, {\"errors\": 0.2637988030910492, \"time-step\": 113}, {\"errors\": 0.26339513063430786, \"time-step\": 114}, {\"errors\": 0.26300084590911865, \"time-step\": 115}, {\"errors\": 0.2626158893108368, \"time-step\": 116}, {\"errors\": 0.26224005222320557, \"time-step\": 117}, {\"errors\": 0.2618733048439026, \"time-step\": 118}, {\"errors\": 0.26151540875434875, \"time-step\": 119}, {\"errors\": 0.2611664831638336, \"time-step\": 120}, {\"errors\": 0.2608262300491333, \"time-step\": 121}, {\"errors\": 0.260494589805603, \"time-step\": 122}, {\"errors\": 0.26017144322395325, \"time-step\": 123}, {\"errors\": 0.2598566710948944, \"time-step\": 124}, {\"errors\": 0.2595501244068146, \"time-step\": 125}, {\"errors\": 0.25925174355506897, \"time-step\": 126}, {\"errors\": 0.25896134972572327, \"time-step\": 127}, {\"errors\": 0.2586788535118103, \"time-step\": 128}, {\"errors\": 0.25840407609939575, \"time-step\": 129}, {\"errors\": 0.2581368386745453, \"time-step\": 130}, {\"errors\": 0.2578771710395813, \"time-step\": 131}, {\"errors\": 0.2576248347759247, \"time-step\": 132}, {\"errors\": 0.2573796808719635, \"time-step\": 133}, {\"errors\": 0.2571415901184082, \"time-step\": 134}, {\"errors\": 0.2569104731082916, \"time-step\": 135}, {\"errors\": 0.25668615102767944, \"time-step\": 136}, {\"errors\": 0.2564685046672821, \"time-step\": 137}, {\"errors\": 0.25625738501548767, \"time-step\": 138}, {\"errors\": 0.2560526132583618, \"time-step\": 139}, {\"errors\": 0.25585418939590454, \"time-step\": 140}, {\"errors\": 0.25566181540489197, \"time-step\": 141}, {\"errors\": 0.2554754912853241, \"time-step\": 142}, {\"errors\": 0.2552949786186218, \"time-step\": 143}, {\"errors\": 0.255120187997818, \"time-step\": 144}, {\"errors\": 0.25495100021362305, \"time-step\": 145}, {\"errors\": 0.25478726625442505, \"time-step\": 146}, {\"errors\": 0.25462883710861206, \"time-step\": 147}, {\"errors\": 0.2544756233692169, \"time-step\": 148}, {\"errors\": 0.2543274760246277, \"time-step\": 149}, {\"errors\": 0.2541842460632324, \"time-step\": 150}, {\"errors\": 0.2540458142757416, \"time-step\": 151}, {\"errors\": 0.2539120316505432, \"time-step\": 152}, {\"errors\": 0.25378286838531494, \"time-step\": 153}, {\"errors\": 0.25365811586380005, \"time-step\": 154}, {\"errors\": 0.253537654876709, \"time-step\": 155}, {\"errors\": 0.253421425819397, \"time-step\": 156}, {\"errors\": 0.2533092200756073, \"time-step\": 157}, {\"errors\": 0.25320103764533997, \"time-step\": 158}, {\"errors\": 0.25309664011001587, \"time-step\": 159}, {\"errors\": 0.2529959976673126, \"time-step\": 160}, {\"errors\": 0.2528989911079407, \"time-step\": 161}, {\"errors\": 0.2528054714202881, \"time-step\": 162}, {\"errors\": 0.25271540880203247, \"time-step\": 163}, {\"errors\": 0.2526286244392395, \"time-step\": 164}, {\"errors\": 0.2525450587272644, \"time-step\": 165}, {\"errors\": 0.25246456265449524, \"time-step\": 166}, {\"errors\": 0.25238707661628723, \"time-step\": 167}, {\"errors\": 0.25231248140335083, \"time-step\": 168}, {\"errors\": 0.25224074721336365, \"time-step\": 169}, {\"errors\": 0.25217169523239136, \"time-step\": 170}, {\"errors\": 0.2521052658557892, \"time-step\": 171}, {\"errors\": 0.25204142928123474, \"time-step\": 172}, {\"errors\": 0.2519800066947937, \"time-step\": 173}, {\"errors\": 0.2519209682941437, \"time-step\": 174}, {\"errors\": 0.2518641948699951, \"time-step\": 175}, {\"errors\": 0.2518097162246704, \"time-step\": 176}, {\"errors\": 0.25175729393959045, \"time-step\": 177}, {\"errors\": 0.25170695781707764, \"time-step\": 178}, {\"errors\": 0.2516586184501648, \"time-step\": 179}, {\"errors\": 0.2516121566295624, \"time-step\": 180}, {\"errors\": 0.251567542552948, \"time-step\": 181}, {\"errors\": 0.25152477622032166, \"time-step\": 182}, {\"errors\": 0.25148364901542664, \"time-step\": 183}, {\"errors\": 0.25144416093826294, \"time-step\": 184}, {\"errors\": 0.25140631198883057, \"time-step\": 185}, {\"errors\": 0.25137001276016235, \"time-step\": 186}, {\"errors\": 0.251335084438324, \"time-step\": 187}, {\"errors\": 0.2513016164302826, \"time-step\": 188}, {\"errors\": 0.25126951932907104, \"time-step\": 189}, {\"errors\": 0.25123873353004456, \"time-step\": 190}, {\"errors\": 0.25120916962623596, \"time-step\": 191}, {\"errors\": 0.25118082761764526, \"time-step\": 192}, {\"errors\": 0.2511536478996277, \"time-step\": 193}, {\"errors\": 0.25112754106521606, \"time-step\": 194}, {\"errors\": 0.2511025369167328, \"time-step\": 195}, {\"errors\": 0.2510785460472107, \"time-step\": 196}, {\"errors\": 0.2510555386543274, \"time-step\": 197}, {\"errors\": 0.2510334551334381, \"time-step\": 198}, {\"errors\": 0.25101226568222046, \"time-step\": 199}, {\"errors\": 0.25099194049835205, \"time-step\": 200}, {\"errors\": 0.2509724795818329, \"time-step\": 201}, {\"errors\": 0.2509537637233734, \"time-step\": 202}, {\"errors\": 0.25093579292297363, \"time-step\": 203}, {\"errors\": 0.2509186267852783, \"time-step\": 204}, {\"errors\": 0.25090205669403076, \"time-step\": 205}, {\"errors\": 0.2508862316608429, \"time-step\": 206}, {\"errors\": 0.2508710026741028, \"time-step\": 207}, {\"errors\": 0.25085633993148804, \"time-step\": 208}, {\"errors\": 0.2508423328399658, \"time-step\": 209}, {\"errors\": 0.2508288621902466, \"time-step\": 210}, {\"errors\": 0.25081586837768555, \"time-step\": 211}, {\"errors\": 0.2508034110069275, \"time-step\": 212}, {\"errors\": 0.2507914900779724, \"time-step\": 213}, {\"errors\": 0.25077998638153076, \"time-step\": 214}, {\"errors\": 0.2507689297199249, \"time-step\": 215}, {\"errors\": 0.25075826048851013, \"time-step\": 216}, {\"errors\": 0.25074803829193115, \"time-step\": 217}, {\"errors\": 0.2507381737232208, \"time-step\": 218}, {\"errors\": 0.25072866678237915, \"time-step\": 219}, {\"errors\": 0.2507195472717285, \"time-step\": 220}, {\"errors\": 0.25071072578430176, \"time-step\": 221}, {\"errors\": 0.25070223212242126, \"time-step\": 222}, {\"errors\": 0.25069403648376465, \"time-step\": 223}, {\"errors\": 0.2506861090660095, \"time-step\": 224}, {\"errors\": 0.25067847967147827, \"time-step\": 225}, {\"errors\": 0.2506710886955261, \"time-step\": 226}, {\"errors\": 0.2506639361381531, \"time-step\": 227}, {\"errors\": 0.2506570816040039, \"time-step\": 228}, {\"errors\": 0.25065040588378906, \"time-step\": 229}, {\"errors\": 0.25064393877983093, \"time-step\": 230}, {\"errors\": 0.2506376802921295, \"time-step\": 231}, {\"errors\": 0.2506316304206848, \"time-step\": 232}, {\"errors\": 0.25062572956085205, \"time-step\": 233}, {\"errors\": 0.2506200671195984, \"time-step\": 234}, {\"errors\": 0.2506144940853119, \"time-step\": 235}, {\"errors\": 0.2506091594696045, \"time-step\": 236}, {\"errors\": 0.25060391426086426, \"time-step\": 237}, {\"errors\": 0.2505987882614136, \"time-step\": 238}, {\"errors\": 0.2505938708782196, \"time-step\": 239}, {\"errors\": 0.2505890130996704, \"time-step\": 240}, {\"errors\": 0.25058433413505554, \"time-step\": 241}, {\"errors\": 0.25057974457740784, \"time-step\": 242}, {\"errors\": 0.2505752742290497, \"time-step\": 243}, {\"errors\": 0.2505709230899811, \"time-step\": 244}, {\"errors\": 0.25056663155555725, \"time-step\": 245}, {\"errors\": 0.2505624294281006, \"time-step\": 246}, {\"errors\": 0.25055834650993347, \"time-step\": 247}, {\"errors\": 0.2505543529987335, \"time-step\": 248}, {\"errors\": 0.25055041909217834, \"time-step\": 249}, {\"errors\": 0.25054657459259033, \"time-step\": 250}, {\"errors\": 0.2505427896976471, \"time-step\": 251}, {\"errors\": 0.250539094209671, \"time-step\": 252}, {\"errors\": 0.2505354583263397, \"time-step\": 253}, {\"errors\": 0.2505318522453308, \"time-step\": 254}, {\"errors\": 0.25052833557128906, \"time-step\": 255}, {\"errors\": 0.2505248785018921, \"time-step\": 256}, {\"errors\": 0.2505214512348175, \"time-step\": 257}, {\"errors\": 0.2505181133747101, \"time-step\": 258}, {\"errors\": 0.25051477551460266, \"time-step\": 259}, {\"errors\": 0.2505115270614624, \"time-step\": 260}, {\"errors\": 0.25050827860832214, \"time-step\": 261}, {\"errors\": 0.25050508975982666, \"time-step\": 262}, {\"errors\": 0.25050193071365356, \"time-step\": 263}, {\"errors\": 0.25049886107444763, \"time-step\": 264}, {\"errors\": 0.2504957318305969, \"time-step\": 265}, {\"errors\": 0.25049272179603577, \"time-step\": 266}, {\"errors\": 0.2504896819591522, \"time-step\": 267}, {\"errors\": 0.25048673152923584, \"time-step\": 268}, {\"errors\": 0.25048378109931946, \"time-step\": 269}, {\"errors\": 0.2504808306694031, \"time-step\": 270}, {\"errors\": 0.2504779100418091, \"time-step\": 271}, {\"errors\": 0.25047504901885986, \"time-step\": 272}, {\"errors\": 0.25047218799591064, \"time-step\": 273}, {\"errors\": 0.2504693865776062, \"time-step\": 274}, {\"errors\": 0.25046655535697937, \"time-step\": 275}, {\"errors\": 0.2504637539386749, \"time-step\": 276}, {\"errors\": 0.2504609525203705, \"time-step\": 277}, {\"errors\": 0.2504582405090332, \"time-step\": 278}, {\"errors\": 0.25045549869537354, \"time-step\": 279}, {\"errors\": 0.25045281648635864, \"time-step\": 280}, {\"errors\": 0.25045010447502136, \"time-step\": 281}, {\"errors\": 0.25044742226600647, \"time-step\": 282}, {\"errors\": 0.25044476985931396, \"time-step\": 283}, {\"errors\": 0.2504420876502991, \"time-step\": 284}, {\"errors\": 0.25043943524360657, \"time-step\": 285}, {\"errors\": 0.25043681263923645, \"time-step\": 286}, {\"errors\": 0.25043419003486633, \"time-step\": 287}, {\"errors\": 0.2504315674304962, \"time-step\": 288}, {\"errors\": 0.2504289746284485, \"time-step\": 289}, {\"errors\": 0.25042638182640076, \"time-step\": 290}, {\"errors\": 0.2504238188266754, \"time-step\": 291}, {\"errors\": 0.2504212558269501, \"time-step\": 292}, {\"errors\": 0.25041869282722473, \"time-step\": 293}, {\"errors\": 0.2504161596298218, \"time-step\": 294}, {\"errors\": 0.2504136264324188, \"time-step\": 295}, {\"errors\": 0.25041109323501587, \"time-step\": 296}, {\"errors\": 0.2504085600376129, \"time-step\": 297}, {\"errors\": 0.25040602684020996, \"time-step\": 298}, {\"errors\": 0.2504035532474518, \"time-step\": 299}, {\"errors\": 0.2504010498523712, \"time-step\": 300}, {\"errors\": 0.25039854645729065, \"time-step\": 301}, {\"errors\": 0.2503960430622101, \"time-step\": 302}, {\"errors\": 0.2503935992717743, \"time-step\": 303}, {\"errors\": 0.2503910958766937, \"time-step\": 304}, {\"errors\": 0.25038865208625793, \"time-step\": 305}, {\"errors\": 0.25038617849349976, \"time-step\": 306}, {\"errors\": 0.25038376450538635, \"time-step\": 307}, {\"errors\": 0.2503812909126282, \"time-step\": 308}, {\"errors\": 0.2503788471221924, \"time-step\": 309}, {\"errors\": 0.2503764033317566, \"time-step\": 310}, {\"errors\": 0.2503739595413208, \"time-step\": 311}, {\"errors\": 0.2503715753555298, \"time-step\": 312}, {\"errors\": 0.2503691613674164, \"time-step\": 313}, {\"errors\": 0.250366747379303, \"time-step\": 314}, {\"errors\": 0.25036436319351196, \"time-step\": 315}, {\"errors\": 0.25036191940307617, \"time-step\": 316}, {\"errors\": 0.2503594756126404, \"time-step\": 317}, {\"errors\": 0.25035709142684937, \"time-step\": 318}, {\"errors\": 0.25035473704338074, \"time-step\": 319}, {\"errors\": 0.2503523528575897, \"time-step\": 320}, {\"errors\": 0.2503499686717987, \"time-step\": 321}, {\"errors\": 0.2503475844860077, \"time-step\": 322}, {\"errors\": 0.2503452003002167, \"time-step\": 323}, {\"errors\": 0.25034284591674805, \"time-step\": 324}, {\"errors\": 0.2503404915332794, \"time-step\": 325}, {\"errors\": 0.2503381371498108, \"time-step\": 326}, {\"errors\": 0.2503357529640198, \"time-step\": 327}, {\"errors\": 0.25033342838287354, \"time-step\": 328}, {\"errors\": 0.2503310441970825, \"time-step\": 329}, {\"errors\": 0.2503287196159363, \"time-step\": 330}, {\"errors\": 0.25032639503479004, \"time-step\": 331}, {\"errors\": 0.2503240406513214, \"time-step\": 332}, {\"errors\": 0.25032171607017517, \"time-step\": 333}, {\"errors\": 0.25031936168670654, \"time-step\": 334}, {\"errors\": 0.2503170371055603, \"time-step\": 335}, {\"errors\": 0.25031477212905884, \"time-step\": 336}, {\"errors\": 0.2503124475479126, \"time-step\": 337}, {\"errors\": 0.25031009316444397, \"time-step\": 338}, {\"errors\": 0.25030776858329773, \"time-step\": 339}, {\"errors\": 0.2503054738044739, \"time-step\": 340}, {\"errors\": 0.25030317902565, \"time-step\": 341}, {\"errors\": 0.25030088424682617, \"time-step\": 342}, {\"errors\": 0.2502985894680023, \"time-step\": 343}, {\"errors\": 0.2502962648868561, \"time-step\": 344}, {\"errors\": 0.2502939999103546, \"time-step\": 345}, {\"errors\": 0.2502916753292084, \"time-step\": 346}, {\"errors\": 0.2502893805503845, \"time-step\": 347}, {\"errors\": 0.25028711557388306, \"time-step\": 348}, {\"errors\": 0.2502848505973816, \"time-step\": 349}, {\"errors\": 0.2502825856208801, \"time-step\": 350}, {\"errors\": 0.2502802908420563, \"time-step\": 351}, {\"errors\": 0.2502780258655548, \"time-step\": 352}, {\"errors\": 0.25027576088905334, \"time-step\": 353}, {\"errors\": 0.2502734661102295, \"time-step\": 354}, {\"errors\": 0.250271201133728, \"time-step\": 355}, {\"errors\": 0.25026896595954895, \"time-step\": 356}, {\"errors\": 0.2502667009830475, \"time-step\": 357}, {\"errors\": 0.250264436006546, \"time-step\": 358}, {\"errors\": 0.25026220083236694, \"time-step\": 359}, {\"errors\": 0.2502599358558655, \"time-step\": 360}, {\"errors\": 0.2502577006816864, \"time-step\": 361}, {\"errors\": 0.2502554655075073, \"time-step\": 362}, {\"errors\": 0.25025320053100586, \"time-step\": 363}, {\"errors\": 0.25025099515914917, \"time-step\": 364}, {\"errors\": 0.2502487599849701, \"time-step\": 365}, {\"errors\": 0.250246524810791, \"time-step\": 366}, {\"errors\": 0.25024425983428955, \"time-step\": 367}, {\"errors\": 0.25024205446243286, \"time-step\": 368}, {\"errors\": 0.25023984909057617, \"time-step\": 369}, {\"errors\": 0.2502375841140747, \"time-step\": 370}, {\"errors\": 0.25023531913757324, \"time-step\": 371}, {\"errors\": 0.25023314356803894, \"time-step\": 372}, {\"errors\": 0.25023093819618225, \"time-step\": 373}, {\"errors\": 0.2502287030220032, \"time-step\": 374}, {\"errors\": 0.2502264976501465, \"time-step\": 375}, {\"errors\": 0.2502242624759674, \"time-step\": 376}, {\"errors\": 0.2502220869064331, \"time-step\": 377}, {\"errors\": 0.2502198815345764, \"time-step\": 378}, {\"errors\": 0.25021764636039734, \"time-step\": 379}, {\"errors\": 0.25021547079086304, \"time-step\": 380}, {\"errors\": 0.25021326541900635, \"time-step\": 381}, {\"errors\": 0.25021106004714966, \"time-step\": 382}, {\"errors\": 0.25020888447761536, \"time-step\": 383}, {\"errors\": 0.25020667910575867, \"time-step\": 384}, {\"errors\": 0.25020450353622437, \"time-step\": 385}, {\"errors\": 0.2502022683620453, \"time-step\": 386}, {\"errors\": 0.2502001225948334, \"time-step\": 387}, {\"errors\": 0.2501978874206543, \"time-step\": 388}, {\"errors\": 0.2501957416534424, \"time-step\": 389}, {\"errors\": 0.2501935362815857, \"time-step\": 390}, {\"errors\": 0.2501913905143738, \"time-step\": 391}, {\"errors\": 0.2501892149448395, \"time-step\": 392}, {\"errors\": 0.2501870393753052, \"time-step\": 393}, {\"errors\": 0.2501848340034485, \"time-step\": 394}, {\"errors\": 0.2501826584339142, \"time-step\": 395}, {\"errors\": 0.25018051266670227, \"time-step\": 396}, {\"errors\": 0.2501783072948456, \"time-step\": 397}, {\"errors\": 0.25017616152763367, \"time-step\": 398}, {\"errors\": 0.25017401576042175, \"time-step\": 399}, {\"errors\": 0.25017181038856506, \"time-step\": 400}, {\"errors\": 0.25016969442367554, \"time-step\": 401}, {\"errors\": 0.2501675486564636, \"time-step\": 402}, {\"errors\": 0.25016534328460693, \"time-step\": 403}, {\"errors\": 0.250163197517395, \"time-step\": 404}, {\"errors\": 0.2501610517501831, \"time-step\": 405}, {\"errors\": 0.2501589059829712, \"time-step\": 406}, {\"errors\": 0.2501567602157593, \"time-step\": 407}, {\"errors\": 0.25015461444854736, \"time-step\": 408}, {\"errors\": 0.25015246868133545, \"time-step\": 409}, {\"errors\": 0.25015032291412354, \"time-step\": 410}, {\"errors\": 0.25014814734458923, \"time-step\": 411}, {\"errors\": 0.2501460313796997, \"time-step\": 412}, {\"errors\": 0.2501438856124878, \"time-step\": 413}, {\"errors\": 0.2501417398452759, \"time-step\": 414}, {\"errors\": 0.25013959407806396, \"time-step\": 415}, {\"errors\": 0.25013744831085205, \"time-step\": 416}, {\"errors\": 0.25013530254364014, \"time-step\": 417}, {\"errors\": 0.2501331567764282, \"time-step\": 418}, {\"errors\": 0.2501310408115387, \"time-step\": 419}, {\"errors\": 0.25012892484664917, \"time-step\": 420}, {\"errors\": 0.25012677907943726, \"time-step\": 421}, {\"errors\": 0.25012463331222534, \"time-step\": 422}, {\"errors\": 0.2501225471496582, \"time-step\": 423}, {\"errors\": 0.2501203715801239, \"time-step\": 424}, {\"errors\": 0.25011831521987915, \"time-step\": 425}, {\"errors\": 0.25011613965034485, \"time-step\": 426}, {\"errors\": 0.2501140236854553, \"time-step\": 427}, {\"errors\": 0.2501119077205658, \"time-step\": 428}, {\"errors\": 0.2501097619533539, \"time-step\": 429}, {\"errors\": 0.25010764598846436, \"time-step\": 430}, {\"errors\": 0.25010550022125244, \"time-step\": 431}, {\"errors\": 0.2501034140586853, \"time-step\": 432}, {\"errors\": 0.2501012980937958, \"time-step\": 433}, {\"errors\": 0.25009921193122864, \"time-step\": 434}, {\"errors\": 0.25009703636169434, \"time-step\": 435}, {\"errors\": 0.2500949501991272, \"time-step\": 436}, {\"errors\": 0.25009286403656006, \"time-step\": 437}, {\"errors\": 0.2500907778739929, \"time-step\": 438}, {\"errors\": 0.250088632106781, \"time-step\": 439}, {\"errors\": 0.2500864863395691, \"time-step\": 440}, {\"errors\": 0.25008440017700195, \"time-step\": 441}, {\"errors\": 0.2500823140144348, \"time-step\": 442}, {\"errors\": 0.2500801980495453, \"time-step\": 443}, {\"errors\": 0.25007808208465576, \"time-step\": 444}, {\"errors\": 0.25007596611976624, \"time-step\": 445}, {\"errors\": 0.2500738501548767, \"time-step\": 446}, {\"errors\": 0.2500717341899872, \"time-step\": 447}, {\"errors\": 0.25006964802742004, \"time-step\": 448}, {\"errors\": 0.2500675320625305, \"time-step\": 449}, {\"errors\": 0.2500654458999634, \"time-step\": 450}, {\"errors\": 0.25006335973739624, \"time-step\": 451}, {\"errors\": 0.2500612437725067, \"time-step\": 452}, {\"errors\": 0.2500591576099396, \"time-step\": 453}, {\"errors\": 0.25005704164505005, \"time-step\": 454}, {\"errors\": 0.2500549554824829, \"time-step\": 455}, {\"errors\": 0.25005286931991577, \"time-step\": 456}, {\"errors\": 0.25005075335502625, \"time-step\": 457}, {\"errors\": 0.2500486671924591, \"time-step\": 458}, {\"errors\": 0.2500465512275696, \"time-step\": 459}, {\"errors\": 0.25004446506500244, \"time-step\": 460}, {\"errors\": 0.2500423789024353, \"time-step\": 461}, {\"errors\": 0.2500402629375458, \"time-step\": 462}, {\"errors\": 0.25003814697265625, \"time-step\": 463}, {\"errors\": 0.2500360608100891, \"time-step\": 464}, {\"errors\": 0.2500339448451996, \"time-step\": 465}, {\"errors\": 0.25003188848495483, \"time-step\": 466}, {\"errors\": 0.2500298023223877, \"time-step\": 467}, {\"errors\": 0.25002768635749817, \"time-step\": 468}, {\"errors\": 0.25002560019493103, \"time-step\": 469}, {\"errors\": 0.2500235140323639, \"time-step\": 470}, {\"errors\": 0.25002145767211914, \"time-step\": 471}, {\"errors\": 0.2500193417072296, \"time-step\": 472}, {\"errors\": 0.2500172555446625, \"time-step\": 473}, {\"errors\": 0.25001513957977295, \"time-step\": 474}, {\"errors\": 0.2500130534172058, \"time-step\": 475}, {\"errors\": 0.25001096725463867, \"time-step\": 476}, {\"errors\": 0.25000888109207153, \"time-step\": 477}, {\"errors\": 0.2500067353248596, \"time-step\": 478}, {\"errors\": 0.25000470876693726, \"time-step\": 479}, {\"errors\": 0.25000256299972534, \"time-step\": 480}, {\"errors\": 0.2500005066394806, \"time-step\": 481}, {\"errors\": 0.24999840557575226, \"time-step\": 482}, {\"errors\": 0.24999630451202393, \"time-step\": 483}, {\"errors\": 0.2499942034482956, \"time-step\": 484}, {\"errors\": 0.24999213218688965, \"time-step\": 485}, {\"errors\": 0.2499900460243225, \"time-step\": 486}, {\"errors\": 0.24998795986175537, \"time-step\": 487}, {\"errors\": 0.24998584389686584, \"time-step\": 488}, {\"errors\": 0.2499837577342987, \"time-step\": 489}, {\"errors\": 0.24998165667057037, \"time-step\": 490}, {\"errors\": 0.24997958540916443, \"time-step\": 491}, {\"errors\": 0.24997752904891968, \"time-step\": 492}, {\"errors\": 0.24997538328170776, \"time-step\": 493}, {\"errors\": 0.24997329711914062, \"time-step\": 494}, {\"errors\": 0.24997122585773468, \"time-step\": 495}, {\"errors\": 0.24996912479400635, \"time-step\": 496}, {\"errors\": 0.24996700882911682, \"time-step\": 497}, {\"errors\": 0.24996493756771088, \"time-step\": 498}, {\"errors\": 0.24996282160282135, \"time-step\": 499}, {\"errors\": 0.24996072053909302, \"time-step\": 500}, {\"errors\": 0.24995863437652588, \"time-step\": 501}, {\"errors\": 0.24995654821395874, \"time-step\": 502}, {\"errors\": 0.2499544471502304, \"time-step\": 503}, {\"errors\": 0.24995234608650208, \"time-step\": 504}, {\"errors\": 0.24995025992393494, \"time-step\": 505}, {\"errors\": 0.2499481588602066, \"time-step\": 506}, {\"errors\": 0.24994607269763947, \"time-step\": 507}, {\"errors\": 0.24994395673274994, \"time-step\": 508}, {\"errors\": 0.2499418556690216, \"time-step\": 509}, {\"errors\": 0.24993973970413208, \"time-step\": 510}, {\"errors\": 0.24993765354156494, \"time-step\": 511}, {\"errors\": 0.24993553757667542, \"time-step\": 512}, {\"errors\": 0.24993345141410828, \"time-step\": 513}, {\"errors\": 0.24993132054805756, \"time-step\": 514}, {\"errors\": 0.2499292641878128, \"time-step\": 515}, {\"errors\": 0.24992713332176208, \"time-step\": 516}, {\"errors\": 0.24992501735687256, \"time-step\": 517}, {\"errors\": 0.24992293119430542, \"time-step\": 518}, {\"errors\": 0.2499208152294159, \"time-step\": 519}, {\"errors\": 0.24991872906684875, \"time-step\": 520}, {\"errors\": 0.24991658329963684, \"time-step\": 521}, {\"errors\": 0.24991443753242493, \"time-step\": 522}, {\"errors\": 0.24991238117218018, \"time-step\": 523}, {\"errors\": 0.24991026520729065, \"time-step\": 524}, {\"errors\": 0.24990814924240112, \"time-step\": 525}, {\"errors\": 0.2499060034751892, \"time-step\": 526}, {\"errors\": 0.24990388751029968, \"time-step\": 527}, {\"errors\": 0.24990178644657135, \"time-step\": 528}, {\"errors\": 0.24989967048168182, \"time-step\": 529}, {\"errors\": 0.2498975396156311, \"time-step\": 530}, {\"errors\": 0.2498953938484192, \"time-step\": 531}, {\"errors\": 0.24989330768585205, \"time-step\": 532}, {\"errors\": 0.24989116191864014, \"time-step\": 533}, {\"errors\": 0.24988903105258942, \"time-step\": 534}, {\"errors\": 0.2498869150876999, \"time-step\": 535}, {\"errors\": 0.24988479912281036, \"time-step\": 536}, {\"errors\": 0.24988266825675964, \"time-step\": 537}, {\"errors\": 0.24988052248954773, \"time-step\": 538}, {\"errors\": 0.2498784065246582, \"time-step\": 539}, {\"errors\": 0.2498762458562851, \"time-step\": 540}, {\"errors\": 0.24987414479255676, \"time-step\": 541}, {\"errors\": 0.24987199902534485, \"time-step\": 542}, {\"errors\": 0.24986985325813293, \"time-step\": 543}, {\"errors\": 0.24986770749092102, \"time-step\": 544}, {\"errors\": 0.2498655617237091, \"time-step\": 545}, {\"errors\": 0.249863401055336, \"time-step\": 546}, {\"errors\": 0.24986127018928528, \"time-step\": 547}, {\"errors\": 0.24985912442207336, \"time-step\": 548}, {\"errors\": 0.24985696375370026, \"time-step\": 549}, {\"errors\": 0.24985483288764954, \"time-step\": 550}, {\"errors\": 0.24985262751579285, \"time-step\": 551}, {\"errors\": 0.24985051155090332, \"time-step\": 552}, {\"errors\": 0.2498483508825302, \"time-step\": 553}, {\"errors\": 0.2498461902141571, \"time-step\": 554}, {\"errors\": 0.249844029545784, \"time-step\": 555}, {\"errors\": 0.24984189867973328, \"time-step\": 556}, {\"errors\": 0.2498396933078766, \"time-step\": 557}, {\"errors\": 0.24983754754066467, \"time-step\": 558}, {\"errors\": 0.24983538687229156, \"time-step\": 559}, {\"errors\": 0.24983322620391846, \"time-step\": 560}, {\"errors\": 0.24983105063438416, \"time-step\": 561}, {\"errors\": 0.24982884526252747, \"time-step\": 562}, {\"errors\": 0.24982669949531555, \"time-step\": 563}, {\"errors\": 0.24982447922229767, \"time-step\": 564}, {\"errors\": 0.24982230365276337, \"time-step\": 565}, {\"errors\": 0.24982011318206787, \"time-step\": 566}, {\"errors\": 0.24981793761253357, \"time-step\": 567}, {\"errors\": 0.24981576204299927, \"time-step\": 568}, {\"errors\": 0.24981357157230377, \"time-step\": 569}, {\"errors\": 0.2498113512992859, \"time-step\": 570}, {\"errors\": 0.2498091757297516, \"time-step\": 571}, {\"errors\": 0.2498069703578949, \"time-step\": 572}, {\"errors\": 0.24980475008487701, \"time-step\": 573}, {\"errors\": 0.2498025745153427, \"time-step\": 574}, {\"errors\": 0.24980035424232483, \"time-step\": 575}, {\"errors\": 0.24979813396930695, \"time-step\": 576}, {\"errors\": 0.24979591369628906, \"time-step\": 577}, {\"errors\": 0.24979370832443237, \"time-step\": 578}, {\"errors\": 0.24979150295257568, \"time-step\": 579}, {\"errors\": 0.24978932738304138, \"time-step\": 580}, {\"errors\": 0.24978704750537872, \"time-step\": 581}, {\"errors\": 0.24978482723236084, \"time-step\": 582}, {\"errors\": 0.24978257715702057, \"time-step\": 583}, {\"errors\": 0.24978035688400269, \"time-step\": 584}, {\"errors\": 0.2497781217098236, \"time-step\": 585}, {\"errors\": 0.24977585673332214, \"time-step\": 586}, {\"errors\": 0.24977363646030426, \"time-step\": 587}, {\"errors\": 0.24977141618728638, \"time-step\": 588}, {\"errors\": 0.2497691512107849, \"time-step\": 589}, {\"errors\": 0.24976690113544464, \"time-step\": 590}, {\"errors\": 0.24976462125778198, \"time-step\": 591}, {\"errors\": 0.2497624009847641, \"time-step\": 592}, {\"errors\": 0.24976012110710144, \"time-step\": 593}, {\"errors\": 0.24975785613059998, \"time-step\": 594}, {\"errors\": 0.24975557625293732, \"time-step\": 595}, {\"errors\": 0.24975329637527466, \"time-step\": 596}, {\"errors\": 0.2497510313987732, \"time-step\": 597}, {\"errors\": 0.24974876642227173, \"time-step\": 598}, {\"errors\": 0.24974647164344788, \"time-step\": 599}, {\"errors\": 0.24974416196346283, \"time-step\": 600}, {\"errors\": 0.24974188208580017, \"time-step\": 601}, {\"errors\": 0.2497396022081375, \"time-step\": 602}, {\"errors\": 0.24973729252815247, \"time-step\": 603}, {\"errors\": 0.2497350126504898, \"time-step\": 604}, {\"errors\": 0.24973271787166595, \"time-step\": 605}, {\"errors\": 0.24973037838935852, \"time-step\": 606}, {\"errors\": 0.24972809851169586, \"time-step\": 607}, {\"errors\": 0.24972578883171082, \"time-step\": 608}, {\"errors\": 0.2497234344482422, \"time-step\": 609}, {\"errors\": 0.24972113966941833, \"time-step\": 610}, {\"errors\": 0.2497187852859497, \"time-step\": 611}, {\"errors\": 0.24971644580364227, \"time-step\": 612}, {\"errors\": 0.24971413612365723, \"time-step\": 613}, {\"errors\": 0.2497117966413498, \"time-step\": 614}, {\"errors\": 0.24970944225788116, \"time-step\": 615}, {\"errors\": 0.24970711767673492, \"time-step\": 616}, {\"errors\": 0.24970471858978271, \"time-step\": 617}, {\"errors\": 0.2497023642063141, \"time-step\": 618}, {\"errors\": 0.24969999492168427, \"time-step\": 619}, {\"errors\": 0.24969764053821564, \"time-step\": 620}, {\"errors\": 0.24969527125358582, \"time-step\": 621}, {\"errors\": 0.2496929168701172, \"time-step\": 622}, {\"errors\": 0.24969050288200378, \"time-step\": 623}, {\"errors\": 0.24968814849853516, \"time-step\": 624}, {\"errors\": 0.24968573451042175, \"time-step\": 625}, {\"errors\": 0.24968333542346954, \"time-step\": 626}, {\"errors\": 0.24968093633651733, \"time-step\": 627}, {\"errors\": 0.24967852234840393, \"time-step\": 628}, {\"errors\": 0.24967613816261292, \"time-step\": 629}, {\"errors\": 0.24967369437217712, \"time-step\": 630}, {\"errors\": 0.24967128038406372, \"time-step\": 631}, {\"errors\": 0.2496688812971115, \"time-step\": 632}, {\"errors\": 0.24966643750667572, \"time-step\": 633}, {\"errors\": 0.24966400861740112, \"time-step\": 634}, {\"errors\": 0.24966156482696533, \"time-step\": 635}, {\"errors\": 0.24965910613536835, \"time-step\": 636}, {\"errors\": 0.24965664744377136, \"time-step\": 637}, {\"errors\": 0.24965423345565796, \"time-step\": 638}, {\"errors\": 0.2496517151594162, \"time-step\": 639}, {\"errors\": 0.2496492564678192, \"time-step\": 640}, {\"errors\": 0.24964678287506104, \"time-step\": 641}, {\"errors\": 0.24964432418346405, \"time-step\": 642}, {\"errors\": 0.24964183568954468, \"time-step\": 643}, {\"errors\": 0.2496393620967865, \"time-step\": 644}, {\"errors\": 0.24963685870170593, \"time-step\": 645}, {\"errors\": 0.24963434040546417, \"time-step\": 646}, {\"errors\": 0.2496318221092224, \"time-step\": 647}, {\"errors\": 0.24962933361530304, \"time-step\": 648}, {\"errors\": 0.24962680041790009, \"time-step\": 649}, {\"errors\": 0.24962428212165833, \"time-step\": 650}, {\"errors\": 0.24962174892425537, \"time-step\": 651}, {\"errors\": 0.24961921572685242, \"time-step\": 652}, {\"errors\": 0.24961668252944946, \"time-step\": 653}, {\"errors\": 0.24961411952972412, \"time-step\": 654}, {\"errors\": 0.24961155652999878, \"time-step\": 655}, {\"errors\": 0.24960899353027344, \"time-step\": 656}, {\"errors\": 0.2496064305305481, \"time-step\": 657}, {\"errors\": 0.24960388243198395, \"time-step\": 658}, {\"errors\": 0.24960128962993622, \"time-step\": 659}, {\"errors\": 0.2495986968278885, \"time-step\": 660}, {\"errors\": 0.24959608912467957, \"time-step\": 661}, {\"errors\": 0.24959349632263184, \"time-step\": 662}, {\"errors\": 0.24959087371826172, \"time-step\": 663}, {\"errors\": 0.249588280916214, \"time-step\": 664}, {\"errors\": 0.24958565831184387, \"time-step\": 665}, {\"errors\": 0.24958303570747375, \"time-step\": 666}, {\"errors\": 0.24958038330078125, \"time-step\": 667}, {\"errors\": 0.24957773089408875, \"time-step\": 668}, {\"errors\": 0.24957510828971863, \"time-step\": 669}, {\"errors\": 0.24957245588302612, \"time-step\": 670}, {\"errors\": 0.24956975877285004, \"time-step\": 671}, {\"errors\": 0.24956709146499634, \"time-step\": 672}, {\"errors\": 0.24956437945365906, \"time-step\": 673}, {\"errors\": 0.24956174194812775, \"time-step\": 674}, {\"errors\": 0.24955904483795166, \"time-step\": 675}, {\"errors\": 0.24955633282661438, \"time-step\": 676}, {\"errors\": 0.2495535910129547, \"time-step\": 677}, {\"errors\": 0.24955090880393982, \"time-step\": 678}, {\"errors\": 0.24954819679260254, \"time-step\": 679}, {\"errors\": 0.24954545497894287, \"time-step\": 680}, {\"errors\": 0.2495427131652832, \"time-step\": 681}, {\"errors\": 0.24953997135162354, \"time-step\": 682}, {\"errors\": 0.24953719973564148, \"time-step\": 683}, {\"errors\": 0.24953442811965942, \"time-step\": 684}, {\"errors\": 0.24953162670135498, \"time-step\": 685}, {\"errors\": 0.2495288997888565, \"time-step\": 686}, {\"errors\": 0.24952606856822968, \"time-step\": 687}, {\"errors\": 0.24952328205108643, \"time-step\": 688}, {\"errors\": 0.24952048063278198, \"time-step\": 689}, {\"errors\": 0.24951766431331635, \"time-step\": 690}, {\"errors\": 0.24951481819152832, \"time-step\": 691}, {\"errors\": 0.24951200187206268, \"time-step\": 692}, {\"errors\": 0.24950915575027466, \"time-step\": 693}, {\"errors\": 0.24950629472732544, \"time-step\": 694}, {\"errors\": 0.2495034635066986, \"time-step\": 695}, {\"errors\": 0.24950061738491058, \"time-step\": 696}, {\"errors\": 0.24949771165847778, \"time-step\": 697}, {\"errors\": 0.24949485063552856, \"time-step\": 698}, {\"errors\": 0.24949195981025696, \"time-step\": 699}, {\"errors\": 0.24948900938034058, \"time-step\": 700}, {\"errors\": 0.24948614835739136, \"time-step\": 701}, {\"errors\": 0.2494831681251526, \"time-step\": 702}, {\"errors\": 0.2494802474975586, \"time-step\": 703}, {\"errors\": 0.2494773119688034, \"time-step\": 704}, {\"errors\": 0.24947437644004822, \"time-step\": 705}, {\"errors\": 0.24947142601013184, \"time-step\": 706}, {\"errors\": 0.24946844577789307, \"time-step\": 707}, {\"errors\": 0.2494654506444931, \"time-step\": 708}, {\"errors\": 0.24946242570877075, \"time-step\": 709}, {\"errors\": 0.24945944547653198, \"time-step\": 710}, {\"errors\": 0.24945645034313202, \"time-step\": 711}, {\"errors\": 0.24945339560508728, \"time-step\": 712}, {\"errors\": 0.24945038557052612, \"time-step\": 713}, {\"errors\": 0.24944734573364258, \"time-step\": 714}, {\"errors\": 0.24944427609443665, \"time-step\": 715}, {\"errors\": 0.2494412511587143, \"time-step\": 716}, {\"errors\": 0.24943816661834717, \"time-step\": 717}, {\"errors\": 0.24943503737449646, \"time-step\": 718}, {\"errors\": 0.24943196773529053, \"time-step\": 719}, {\"errors\": 0.24942883849143982, \"time-step\": 720}, {\"errors\": 0.2494257688522339, \"time-step\": 721}, {\"errors\": 0.2494226098060608, \"time-step\": 722}, {\"errors\": 0.24941948056221008, \"time-step\": 723}, {\"errors\": 0.249416321516037, \"time-step\": 724}, {\"errors\": 0.2494131624698639, \"time-step\": 725}, {\"errors\": 0.2494100034236908, \"time-step\": 726}, {\"errors\": 0.2494068145751953, \"time-step\": 727}, {\"errors\": 0.24940362572669983, \"time-step\": 728}, {\"errors\": 0.24940040707588196, \"time-step\": 729}, {\"errors\": 0.2493971884250641, \"time-step\": 730}, {\"errors\": 0.24939393997192383, \"time-step\": 731}, {\"errors\": 0.24939069151878357, \"time-step\": 732}, {\"errors\": 0.2493874728679657, \"time-step\": 733}, {\"errors\": 0.24938414990901947, \"time-step\": 734}, {\"errors\": 0.24938088655471802, \"time-step\": 735}, {\"errors\": 0.24937760829925537, \"time-step\": 736}, {\"errors\": 0.24937430024147034, \"time-step\": 737}, {\"errors\": 0.24937096238136292, \"time-step\": 738}, {\"errors\": 0.24936765432357788, \"time-step\": 739}, {\"errors\": 0.24936430156230927, \"time-step\": 740}, {\"errors\": 0.24936093389987946, \"time-step\": 741}, {\"errors\": 0.24935756623744965, \"time-step\": 742}, {\"errors\": 0.24935418367385864, \"time-step\": 743}, {\"errors\": 0.24935080111026764, \"time-step\": 744}, {\"errors\": 0.24934738874435425, \"time-step\": 745}, {\"errors\": 0.24934397637844086, \"time-step\": 746}, {\"errors\": 0.24934053421020508, \"time-step\": 747}, {\"errors\": 0.2493370622396469, \"time-step\": 748}, {\"errors\": 0.24933362007141113, \"time-step\": 749}, {\"errors\": 0.24933016300201416, \"time-step\": 750}, {\"errors\": 0.2493266463279724, \"time-step\": 751}, {\"errors\": 0.24932312965393066, \"time-step\": 752}, {\"errors\": 0.24931961297988892, \"time-step\": 753}, {\"errors\": 0.24931609630584717, \"time-step\": 754}, {\"errors\": 0.24931253492832184, \"time-step\": 755}, {\"errors\": 0.2493089884519577, \"time-step\": 756}, {\"errors\": 0.24930541217327118, \"time-step\": 757}, {\"errors\": 0.24930180609226227, \"time-step\": 758}, {\"errors\": 0.24929822981357574, \"time-step\": 759}, {\"errors\": 0.24929456412792206, \"time-step\": 760}, {\"errors\": 0.24929094314575195, \"time-step\": 761}, {\"errors\": 0.24928730726242065, \"time-step\": 762}, {\"errors\": 0.24928361177444458, \"time-step\": 763}, {\"errors\": 0.2492799609899521, \"time-step\": 764}, {\"errors\": 0.2492762804031372, \"time-step\": 765}, {\"errors\": 0.24927255511283875, \"time-step\": 766}, {\"errors\": 0.24926882982254028, \"time-step\": 767}, {\"errors\": 0.24926507472991943, \"time-step\": 768}, {\"errors\": 0.24926131963729858, \"time-step\": 769}, {\"errors\": 0.24925756454467773, \"time-step\": 770}, {\"errors\": 0.2492537498474121, \"time-step\": 771}, {\"errors\": 0.24924993515014648, \"time-step\": 772}, {\"errors\": 0.24924612045288086, \"time-step\": 773}, {\"errors\": 0.24924229085445404, \"time-step\": 774}, {\"errors\": 0.24923840165138245, \"time-step\": 775}, {\"errors\": 0.24923452734947205, \"time-step\": 776}, {\"errors\": 0.24923068284988403, \"time-step\": 777}, {\"errors\": 0.24922676384449005, \"time-step\": 778}, {\"errors\": 0.24922284483909607, \"time-step\": 779}, {\"errors\": 0.2492188811302185, \"time-step\": 780}, {\"errors\": 0.24921491742134094, \"time-step\": 781}, {\"errors\": 0.249210923910141, \"time-step\": 782}, {\"errors\": 0.24920694530010223, \"time-step\": 783}, {\"errors\": 0.2492029368877411, \"time-step\": 784}, {\"errors\": 0.24919889867305756, \"time-step\": 785}, {\"errors\": 0.24919486045837402, \"time-step\": 786}, {\"errors\": 0.2491908073425293, \"time-step\": 787}, {\"errors\": 0.24918672442436218, \"time-step\": 788}, {\"errors\": 0.24918261170387268, \"time-step\": 789}, {\"errors\": 0.2491784691810608, \"time-step\": 790}, {\"errors\": 0.2491743564605713, \"time-step\": 791}, {\"errors\": 0.2491702139377594, \"time-step\": 792}, {\"errors\": 0.24916604161262512, \"time-step\": 793}, {\"errors\": 0.24916180968284607, \"time-step\": 794}, {\"errors\": 0.2491575926542282, \"time-step\": 795}, {\"errors\": 0.24915337562561035, \"time-step\": 796}, {\"errors\": 0.2491491138935089, \"time-step\": 797}, {\"errors\": 0.24914482235908508, \"time-step\": 798}, {\"errors\": 0.24914056062698364, \"time-step\": 799}, {\"errors\": 0.24913623929023743, \"time-step\": 800}, {\"errors\": 0.24913187325000763, \"time-step\": 801}, {\"errors\": 0.24912753701210022, \"time-step\": 802}, {\"errors\": 0.24912315607070923, \"time-step\": 803}, {\"errors\": 0.24911876022815704, \"time-step\": 804}, {\"errors\": 0.24911433458328247, \"time-step\": 805}, {\"errors\": 0.2491099238395691, \"time-step\": 806}, {\"errors\": 0.24910546839237213, \"time-step\": 807}, {\"errors\": 0.24910098314285278, \"time-step\": 808}, {\"errors\": 0.24909648299217224, \"time-step\": 809}, {\"errors\": 0.2490919530391693, \"time-step\": 810}, {\"errors\": 0.24908742308616638, \"time-step\": 811}, {\"errors\": 0.24908286333084106, \"time-step\": 812}, {\"errors\": 0.24907825887203217, \"time-step\": 813}, {\"errors\": 0.24907363951206207, \"time-step\": 814}, {\"errors\": 0.24906903505325317, \"time-step\": 815}, {\"errors\": 0.2490643560886383, \"time-step\": 816}, {\"errors\": 0.24905972182750702, \"time-step\": 817}, {\"errors\": 0.24905499815940857, \"time-step\": 818}, {\"errors\": 0.24905025959014893, \"time-step\": 819}, {\"errors\": 0.2490454912185669, \"time-step\": 820}, {\"errors\": 0.24904072284698486, \"time-step\": 821}, {\"errors\": 0.24903595447540283, \"time-step\": 822}, {\"errors\": 0.24903114140033722, \"time-step\": 823}, {\"errors\": 0.2490263283252716, \"time-step\": 824}, {\"errors\": 0.24902141094207764, \"time-step\": 825}, {\"errors\": 0.24901658296585083, \"time-step\": 826}, {\"errors\": 0.24901165068149567, \"time-step\": 827}, {\"errors\": 0.2490067034959793, \"time-step\": 828}, {\"errors\": 0.24900174140930176, \"time-step\": 829}, {\"errors\": 0.248996764421463, \"time-step\": 830}, {\"errors\": 0.2489917278289795, \"time-step\": 831}, {\"errors\": 0.24898675084114075, \"time-step\": 832}, {\"errors\": 0.24898168444633484, \"time-step\": 833}, {\"errors\": 0.24897657334804535, \"time-step\": 834}, {\"errors\": 0.24897149205207825, \"time-step\": 835}, {\"errors\": 0.24896636605262756, \"time-step\": 836}, {\"errors\": 0.24896115064620972, \"time-step\": 837}, {\"errors\": 0.24895596504211426, \"time-step\": 838}, {\"errors\": 0.24895079433918, \"time-step\": 839}, {\"errors\": 0.2489454746246338, \"time-step\": 840}, {\"errors\": 0.24894025921821594, \"time-step\": 841}, {\"errors\": 0.24893493950366974, \"time-step\": 842}, {\"errors\": 0.24892961978912354, \"time-step\": 843}, {\"errors\": 0.24892428517341614, \"time-step\": 844}, {\"errors\": 0.24891889095306396, \"time-step\": 845}, {\"errors\": 0.2489134967327118, \"time-step\": 846}, {\"errors\": 0.24890802800655365, \"time-step\": 847}, {\"errors\": 0.24890261888504028, \"time-step\": 848}, {\"errors\": 0.24889713525772095, \"time-step\": 849}, {\"errors\": 0.24889157712459564, \"time-step\": 850}, {\"errors\": 0.24888604879379272, \"time-step\": 851}, {\"errors\": 0.24888047575950623, \"time-step\": 852}, {\"errors\": 0.24887485802173615, \"time-step\": 853}, {\"errors\": 0.24886924028396606, \"time-step\": 854}, {\"errors\": 0.2488635778427124, \"time-step\": 855}, {\"errors\": 0.24885788559913635, \"time-step\": 856}, {\"errors\": 0.24885214865207672, \"time-step\": 857}, {\"errors\": 0.2488463968038559, \"time-step\": 858}, {\"errors\": 0.2488406002521515, \"time-step\": 859}, {\"errors\": 0.24883480370044708, \"time-step\": 860}, {\"errors\": 0.2488289475440979, \"time-step\": 861}, {\"errors\": 0.24882309138774872, \"time-step\": 862}, {\"errors\": 0.24881717562675476, \"time-step\": 863}, {\"errors\": 0.24881121516227722, \"time-step\": 864}, {\"errors\": 0.24880526959896088, \"time-step\": 865}, {\"errors\": 0.24879926443099976, \"time-step\": 866}, {\"errors\": 0.24879321455955505, \"time-step\": 867}, {\"errors\": 0.24878714978694916, \"time-step\": 868}, {\"errors\": 0.24878104031085968, \"time-step\": 869}, {\"errors\": 0.2487749457359314, \"time-step\": 870}, {\"errors\": 0.24876874685287476, \"time-step\": 871}, {\"errors\": 0.24876254796981812, \"time-step\": 872}, {\"errors\": 0.2487563192844391, \"time-step\": 873}, {\"errors\": 0.24875007569789886, \"time-step\": 874}, {\"errors\": 0.24874375760555267, \"time-step\": 875}, {\"errors\": 0.24873745441436768, \"time-step\": 876}, {\"errors\": 0.2487310767173767, \"time-step\": 877}, {\"errors\": 0.24872466921806335, \"time-step\": 878}, {\"errors\": 0.2487182319164276, \"time-step\": 879}, {\"errors\": 0.24871176481246948, \"time-step\": 880}, {\"errors\": 0.24870526790618896, \"time-step\": 881}, {\"errors\": 0.24869871139526367, \"time-step\": 882}, {\"errors\": 0.24869213998317719, \"time-step\": 883}, {\"errors\": 0.24868552386760712, \"time-step\": 884}, {\"errors\": 0.24867889285087585, \"time-step\": 885}, {\"errors\": 0.24867217242717743, \"time-step\": 886}, {\"errors\": 0.24866542220115662, \"time-step\": 887}, {\"errors\": 0.248658686876297, \"time-step\": 888}, {\"errors\": 0.2486519068479538, \"time-step\": 889}, {\"errors\": 0.24864503741264343, \"time-step\": 890}, {\"errors\": 0.24863819777965546, \"time-step\": 891}, {\"errors\": 0.24863125383853912, \"time-step\": 892}, {\"errors\": 0.24862432479858398, \"time-step\": 893}, {\"errors\": 0.24861735105514526, \"time-step\": 894}, {\"errors\": 0.24861031770706177, \"time-step\": 895}, {\"errors\": 0.2486032098531723, \"time-step\": 896}, {\"errors\": 0.24859611690044403, \"time-step\": 897}, {\"errors\": 0.24858897924423218, \"time-step\": 898}, {\"errors\": 0.24858178198337555, \"time-step\": 899}, {\"errors\": 0.24857455492019653, \"time-step\": 900}, {\"errors\": 0.24856728315353394, \"time-step\": 901}, {\"errors\": 0.24855995178222656, \"time-step\": 902}, {\"errors\": 0.24855265021324158, \"time-step\": 903}, {\"errors\": 0.24854522943496704, \"time-step\": 904}, {\"errors\": 0.2485378086566925, \"time-step\": 905}, {\"errors\": 0.2485303431749344, \"time-step\": 906}, {\"errors\": 0.2485228180885315, \"time-step\": 907}, {\"errors\": 0.2485153079032898, \"time-step\": 908}, {\"errors\": 0.24850764870643616, \"time-step\": 909}, {\"errors\": 0.2485000491142273, \"time-step\": 910}, {\"errors\": 0.24849236011505127, \"time-step\": 911}, {\"errors\": 0.24848461151123047, \"time-step\": 912}, {\"errors\": 0.2484768182039261, \"time-step\": 913}, {\"errors\": 0.2484690099954605, \"time-step\": 914}, {\"errors\": 0.24846117198467255, \"time-step\": 915}, {\"errors\": 0.24845324456691742, \"time-step\": 916}, {\"errors\": 0.2484452724456787, \"time-step\": 917}, {\"errors\": 0.24843725562095642, \"time-step\": 918}, {\"errors\": 0.24842923879623413, \"time-step\": 919}, {\"errors\": 0.24842113256454468, \"time-step\": 920}, {\"errors\": 0.24841301143169403, \"time-step\": 921}, {\"errors\": 0.2484048455953598, \"time-step\": 922}, {\"errors\": 0.2483965903520584, \"time-step\": 923}, {\"errors\": 0.2483883500099182, \"time-step\": 924}, {\"errors\": 0.24837994575500488, \"time-step\": 925}, {\"errors\": 0.24837160110473633, \"time-step\": 926}, {\"errors\": 0.2483631670475006, \"time-step\": 927}, {\"errors\": 0.2483547329902649, \"time-step\": 928}, {\"errors\": 0.24834617972373962, \"time-step\": 929}, {\"errors\": 0.24833764135837555, \"time-step\": 930}, {\"errors\": 0.24832899868488312, \"time-step\": 931}, {\"errors\": 0.2483203262090683, \"time-step\": 932}, {\"errors\": 0.24831163883209229, \"time-step\": 933}, {\"errors\": 0.24830284714698792, \"time-step\": 934}, {\"errors\": 0.24829401075839996, \"time-step\": 935}, {\"errors\": 0.24828511476516724, \"time-step\": 936}, {\"errors\": 0.2482762187719345, \"time-step\": 937}, {\"errors\": 0.2482672482728958, \"time-step\": 938}, {\"errors\": 0.24825820326805115, \"time-step\": 939}, {\"errors\": 0.2482491433620453, \"time-step\": 940}, {\"errors\": 0.24823999404907227, \"time-step\": 941}, {\"errors\": 0.24823081493377686, \"time-step\": 942}, {\"errors\": 0.24822157621383667, \"time-step\": 943}, {\"errors\": 0.24821226298809052, \"time-step\": 944}, {\"errors\": 0.24820289015769958, \"time-step\": 945}, {\"errors\": 0.24819353222846985, \"time-step\": 946}, {\"errors\": 0.24818405508995056, \"time-step\": 947}, {\"errors\": 0.2481745481491089, \"time-step\": 948}, {\"errors\": 0.24816498160362244, \"time-step\": 949}, {\"errors\": 0.24815532565116882, \"time-step\": 950}, {\"errors\": 0.2481456995010376, \"time-step\": 951}, {\"errors\": 0.24813593924045563, \"time-step\": 952}, {\"errors\": 0.24812613427639008, \"time-step\": 953}, {\"errors\": 0.24811625480651855, \"time-step\": 954}, {\"errors\": 0.24810634553432465, \"time-step\": 955}, {\"errors\": 0.24809636175632477, \"time-step\": 956}, {\"errors\": 0.24808631837368011, \"time-step\": 957}, {\"errors\": 0.24807626008987427, \"time-step\": 958}, {\"errors\": 0.24806606769561768, \"time-step\": 959}, {\"errors\": 0.2480558454990387, \"time-step\": 960}, {\"errors\": 0.24804560840129852, \"time-step\": 961}, {\"errors\": 0.2480352520942688, \"time-step\": 962}, {\"errors\": 0.2480248510837555, \"time-step\": 963}, {\"errors\": 0.2480143904685974, \"time-step\": 964}, {\"errors\": 0.24800390005111694, \"time-step\": 965}, {\"errors\": 0.24799329042434692, \"time-step\": 966}, {\"errors\": 0.24798265099525452, \"time-step\": 967}, {\"errors\": 0.24797195196151733, \"time-step\": 968}, {\"errors\": 0.24796119332313538, \"time-step\": 969}, {\"errors\": 0.24795034527778625, \"time-step\": 970}, {\"errors\": 0.24793943762779236, \"time-step\": 971}, {\"errors\": 0.2479284703731537, \"time-step\": 972}, {\"errors\": 0.24791741371154785, \"time-step\": 973}, {\"errors\": 0.24790632724761963, \"time-step\": 974}, {\"errors\": 0.24789516627788544, \"time-step\": 975}, {\"errors\": 0.24788391590118408, \"time-step\": 976}, {\"errors\": 0.24787262082099915, \"time-step\": 977}, {\"errors\": 0.24786126613616943, \"time-step\": 978}, {\"errors\": 0.24784982204437256, \"time-step\": 979}, {\"errors\": 0.2478383183479309, \"time-step\": 980}, {\"errors\": 0.2478267401456833, \"time-step\": 981}, {\"errors\": 0.2478151023387909, \"time-step\": 982}, {\"errors\": 0.24780340492725372, \"time-step\": 983}, {\"errors\": 0.24779163300991058, \"time-step\": 984}, {\"errors\": 0.2477797567844391, \"time-step\": 985}, {\"errors\": 0.24776782095432281, \"time-step\": 986}, {\"errors\": 0.24775584042072296, \"time-step\": 987}, {\"errors\": 0.24774375557899475, \"time-step\": 988}, {\"errors\": 0.24773159623146057, \"time-step\": 989}, {\"errors\": 0.24771936237812042, \"time-step\": 990}, {\"errors\": 0.24770712852478027, \"time-step\": 991}, {\"errors\": 0.24769476056098938, \"time-step\": 992}, {\"errors\": 0.24768228828907013, \"time-step\": 993}, {\"errors\": 0.2476697862148285, \"time-step\": 994}, {\"errors\": 0.2476571798324585, \"time-step\": 995}, {\"errors\": 0.24764452874660492, \"time-step\": 996}, {\"errors\": 0.24763178825378418, \"time-step\": 997}, {\"errors\": 0.24761895835399628, \"time-step\": 998}, {\"errors\": 0.2476060688495636, \"time-step\": 999}, {\"errors\": 0.24759310483932495, \"time-step\": 1000}, {\"errors\": 0.24758000671863556, \"time-step\": 1001}, {\"errors\": 0.24756687879562378, \"time-step\": 1002}, {\"errors\": 0.24755364656448364, \"time-step\": 1003}, {\"errors\": 0.24754035472869873, \"time-step\": 1004}, {\"errors\": 0.24752700328826904, \"time-step\": 1005}, {\"errors\": 0.2475135326385498, \"time-step\": 1006}, {\"errors\": 0.24750003218650818, \"time-step\": 1007}, {\"errors\": 0.2474863976240158, \"time-step\": 1008}, {\"errors\": 0.24747267365455627, \"time-step\": 1009}, {\"errors\": 0.24745890498161316, \"time-step\": 1010}, {\"errors\": 0.2474450021982193, \"time-step\": 1011}, {\"errors\": 0.24743105471134186, \"time-step\": 1012}, {\"errors\": 0.24741701781749725, \"time-step\": 1013}, {\"errors\": 0.24740290641784668, \"time-step\": 1014}, {\"errors\": 0.24738870561122894, \"time-step\": 1015}, {\"errors\": 0.24737438559532166, \"time-step\": 1016}, {\"errors\": 0.247359961271286, \"time-step\": 1017}, {\"errors\": 0.24734550714492798, \"time-step\": 1018}, {\"errors\": 0.2473309487104416, \"time-step\": 1019}, {\"errors\": 0.24731628596782684, \"time-step\": 1020}, {\"errors\": 0.24730157852172852, \"time-step\": 1021}, {\"errors\": 0.24728675186634064, \"time-step\": 1022}, {\"errors\": 0.2472718060016632, \"time-step\": 1023}, {\"errors\": 0.2472568154335022, \"time-step\": 1024}, {\"errors\": 0.24724167585372925, \"time-step\": 1025}, {\"errors\": 0.24722647666931152, \"time-step\": 1026}, {\"errors\": 0.24721118807792664, \"time-step\": 1027}, {\"errors\": 0.24719582498073578, \"time-step\": 1028}, {\"errors\": 0.24718035757541656, \"time-step\": 1029}, {\"errors\": 0.24716481566429138, \"time-step\": 1030}, {\"errors\": 0.24714909493923187, \"time-step\": 1031}, {\"errors\": 0.24713334441184998, \"time-step\": 1032}, {\"errors\": 0.24711748957633972, \"time-step\": 1033}, {\"errors\": 0.24710150063037872, \"time-step\": 1034}, {\"errors\": 0.24708545207977295, \"time-step\": 1035}, {\"errors\": 0.2470693290233612, \"time-step\": 1036}, {\"errors\": 0.24705305695533752, \"time-step\": 1037}, {\"errors\": 0.24703672528266907, \"time-step\": 1038}, {\"errors\": 0.24702025949954987, \"time-step\": 1039}, {\"errors\": 0.2470037341117859, \"time-step\": 1040}, {\"errors\": 0.24698705971240997, \"time-step\": 1041}, {\"errors\": 0.2469703108072281, \"time-step\": 1042}, {\"errors\": 0.24695345759391785, \"time-step\": 1043}, {\"errors\": 0.24693650007247925, \"time-step\": 1044}, {\"errors\": 0.2469193935394287, \"time-step\": 1045}, {\"errors\": 0.2469022572040558, \"time-step\": 1046}, {\"errors\": 0.2468850016593933, \"time-step\": 1047}, {\"errors\": 0.24686762690544128, \"time-step\": 1048}, {\"errors\": 0.2468501180410385, \"time-step\": 1049}, {\"errors\": 0.24683253467082977, \"time-step\": 1050}, {\"errors\": 0.24681486189365387, \"time-step\": 1051}, {\"errors\": 0.24679704010486603, \"time-step\": 1052}, {\"errors\": 0.24677912890911102, \"time-step\": 1053}, {\"errors\": 0.24676108360290527, \"time-step\": 1054}, {\"errors\": 0.24674299359321594, \"time-step\": 1055}, {\"errors\": 0.2467247098684311, \"time-step\": 1056}, {\"errors\": 0.24670638144016266, \"time-step\": 1057}, {\"errors\": 0.2466878890991211, \"time-step\": 1058}, {\"errors\": 0.24666933715343475, \"time-step\": 1059}, {\"errors\": 0.24665062129497528, \"time-step\": 1060}, {\"errors\": 0.24663180112838745, \"time-step\": 1061}, {\"errors\": 0.24661284685134888, \"time-step\": 1062}, {\"errors\": 0.24659383296966553, \"time-step\": 1063}, {\"errors\": 0.24657468497753143, \"time-step\": 1064}, {\"errors\": 0.2465553730726242, \"time-step\": 1065}, {\"errors\": 0.246535986661911, \"time-step\": 1066}, {\"errors\": 0.24651649594306946, \"time-step\": 1067}, {\"errors\": 0.24649685621261597, \"time-step\": 1068}, {\"errors\": 0.2464771270751953, \"time-step\": 1069}, {\"errors\": 0.24645720422267914, \"time-step\": 1070}, {\"errors\": 0.24643723666667938, \"time-step\": 1071}, {\"errors\": 0.2464171051979065, \"time-step\": 1072}, {\"errors\": 0.24639688432216644, \"time-step\": 1073}, {\"errors\": 0.24637657403945923, \"time-step\": 1074}, {\"errors\": 0.2463560402393341, \"time-step\": 1075}, {\"errors\": 0.2463354468345642, \"time-step\": 1076}, {\"errors\": 0.24631470441818237, \"time-step\": 1077}, {\"errors\": 0.24629387259483337, \"time-step\": 1078}, {\"errors\": 0.24627286195755005, \"time-step\": 1079}, {\"errors\": 0.24625174701213837, \"time-step\": 1080}, {\"errors\": 0.24623048305511475, \"time-step\": 1081}, {\"errors\": 0.24620917439460754, \"time-step\": 1082}, {\"errors\": 0.24618761241436005, \"time-step\": 1083}, {\"errors\": 0.24616603553295135, \"time-step\": 1084}, {\"errors\": 0.24614423513412476, \"time-step\": 1085}, {\"errors\": 0.246122345328331, \"time-step\": 1086}, {\"errors\": 0.24610033631324768, \"time-step\": 1087}, {\"errors\": 0.24607819318771362, \"time-step\": 1088}, {\"errors\": 0.24605587124824524, \"time-step\": 1089}, {\"errors\": 0.2460334599018097, \"time-step\": 1090}, {\"errors\": 0.2460108995437622, \"time-step\": 1091}, {\"errors\": 0.2459881752729416, \"time-step\": 1092}, {\"errors\": 0.24596531689167023, \"time-step\": 1093}, {\"errors\": 0.2459423840045929, \"time-step\": 1094}, {\"errors\": 0.24591925740242004, \"time-step\": 1095}, {\"errors\": 0.24589599668979645, \"time-step\": 1096}, {\"errors\": 0.2458726167678833, \"time-step\": 1097}, {\"errors\": 0.24584908783435822, \"time-step\": 1098}, {\"errors\": 0.2458254098892212, \"time-step\": 1099}, {\"errors\": 0.24580159783363342, \"time-step\": 1100}, {\"errors\": 0.24577762186527252, \"time-step\": 1101}, {\"errors\": 0.24575352668762207, \"time-step\": 1102}, {\"errors\": 0.2457292526960373, \"time-step\": 1103}, {\"errors\": 0.24570485949516296, \"time-step\": 1104}, {\"errors\": 0.2456803172826767, \"time-step\": 1105}, {\"errors\": 0.2456556260585785, \"time-step\": 1106}, {\"errors\": 0.24563080072402954, \"time-step\": 1107}, {\"errors\": 0.24560579657554626, \"time-step\": 1108}, {\"errors\": 0.24558065831661224, \"time-step\": 1109}, {\"errors\": 0.24555537104606628, \"time-step\": 1110}, {\"errors\": 0.24552994966506958, \"time-step\": 1111}, {\"errors\": 0.24550434947013855, \"time-step\": 1112}, {\"errors\": 0.2454785853624344, \"time-step\": 1113}, {\"errors\": 0.24545274674892426, \"time-step\": 1114}, {\"errors\": 0.24542666971683502, \"time-step\": 1115}, {\"errors\": 0.24540044367313385, \"time-step\": 1116}, {\"errors\": 0.24537406861782074, \"time-step\": 1117}, {\"errors\": 0.24534755945205688, \"time-step\": 1118}, {\"errors\": 0.24532093107700348, \"time-step\": 1119}, {\"errors\": 0.24529406428337097, \"time-step\": 1120}, {\"errors\": 0.2452670931816101, \"time-step\": 1121}, {\"errors\": 0.24523992836475372, \"time-step\": 1122}, {\"errors\": 0.2452126145362854, \"time-step\": 1123}, {\"errors\": 0.24518516659736633, \"time-step\": 1124}, {\"errors\": 0.24515751004219055, \"time-step\": 1125}, {\"errors\": 0.24512968957424164, \"time-step\": 1126}, {\"errors\": 0.24510174989700317, \"time-step\": 1127}, {\"errors\": 0.24507364630699158, \"time-step\": 1128}, {\"errors\": 0.24504531919956207, \"time-step\": 1129}, {\"errors\": 0.24501684308052063, \"time-step\": 1130}, {\"errors\": 0.24498823285102844, \"time-step\": 1131}, {\"errors\": 0.24495945870876312, \"time-step\": 1132}, {\"errors\": 0.2449304610490799, \"time-step\": 1133}, {\"errors\": 0.24490132927894592, \"time-step\": 1134}, {\"errors\": 0.24487203359603882, \"time-step\": 1135}, {\"errors\": 0.2448425143957138, \"time-step\": 1136}, {\"errors\": 0.24481293559074402, \"time-step\": 1137}, {\"errors\": 0.24478305876255035, \"time-step\": 1138}, {\"errors\": 0.24475306272506714, \"time-step\": 1139}, {\"errors\": 0.24472293257713318, \"time-step\": 1140}, {\"errors\": 0.24469256401062012, \"time-step\": 1141}, {\"errors\": 0.24466204643249512, \"time-step\": 1142}, {\"errors\": 0.2446313500404358, \"time-step\": 1143}, {\"errors\": 0.24460045993328094, \"time-step\": 1144}, {\"errors\": 0.24456945061683655, \"time-step\": 1145}, {\"errors\": 0.24453818798065186, \"time-step\": 1146}, {\"errors\": 0.24450679123401642, \"time-step\": 1147}, {\"errors\": 0.24447515606880188, \"time-step\": 1148}, {\"errors\": 0.2444434016942978, \"time-step\": 1149}, {\"errors\": 0.2444114089012146, \"time-step\": 1150}, {\"errors\": 0.24437928199768066, \"time-step\": 1151}, {\"errors\": 0.2443469613790512, \"time-step\": 1152}, {\"errors\": 0.24431441724300385, \"time-step\": 1153}, {\"errors\": 0.24428170919418335, \"time-step\": 1154}, {\"errors\": 0.24424883723258972, \"time-step\": 1155}, {\"errors\": 0.24421575665473938, \"time-step\": 1156}, {\"errors\": 0.24418248236179352, \"time-step\": 1157}, {\"errors\": 0.24414904415607452, \"time-step\": 1158}, {\"errors\": 0.24411538243293762, \"time-step\": 1159}, {\"errors\": 0.2440815567970276, \"time-step\": 1160}, {\"errors\": 0.24404750764369965, \"time-step\": 1161}, {\"errors\": 0.24401327967643738, \"time-step\": 1162}, {\"errors\": 0.24397888779640198, \"time-step\": 1163}, {\"errors\": 0.24394425749778748, \"time-step\": 1164}, {\"errors\": 0.24390944838523865, \"time-step\": 1165}, {\"errors\": 0.2438744455575943, \"time-step\": 1166}, {\"errors\": 0.24383924901485443, \"time-step\": 1167}, {\"errors\": 0.24380382895469666, \"time-step\": 1168}, {\"errors\": 0.24376824498176575, \"time-step\": 1169}, {\"errors\": 0.24373242259025574, \"time-step\": 1170}, {\"errors\": 0.2436964213848114, \"time-step\": 1171}, {\"errors\": 0.24366021156311035, \"time-step\": 1172}, {\"errors\": 0.2436237931251526, \"time-step\": 1173}, {\"errors\": 0.2435871958732605, \"time-step\": 1174}, {\"errors\": 0.2435503900051117, \"time-step\": 1175}, {\"errors\": 0.24351337552070618, \"time-step\": 1176}, {\"errors\": 0.24347616732120514, \"time-step\": 1177}, {\"errors\": 0.2434387356042862, \"time-step\": 1178}, {\"errors\": 0.24340111017227173, \"time-step\": 1179}, {\"errors\": 0.24336323142051697, \"time-step\": 1180}, {\"errors\": 0.24332518875598907, \"time-step\": 1181}, {\"errors\": 0.24328690767288208, \"time-step\": 1182}, {\"errors\": 0.24324844777584076, \"time-step\": 1183}, {\"errors\": 0.24320976436138153, \"time-step\": 1184}, {\"errors\": 0.243170827627182, \"time-step\": 1185}, {\"errors\": 0.24313169717788696, \"time-step\": 1186}, {\"errors\": 0.2430923581123352, \"time-step\": 1187}, {\"errors\": 0.24305281043052673, \"time-step\": 1188}, {\"errors\": 0.24301305413246155, \"time-step\": 1189}, {\"errors\": 0.24297305941581726, \"time-step\": 1190}, {\"errors\": 0.24293287098407745, \"time-step\": 1191}, {\"errors\": 0.24289244413375854, \"time-step\": 1192}, {\"errors\": 0.24285182356834412, \"time-step\": 1193}, {\"errors\": 0.24281097948551178, \"time-step\": 1194}, {\"errors\": 0.24276988208293915, \"time-step\": 1195}, {\"errors\": 0.242728590965271, \"time-step\": 1196}, {\"errors\": 0.24268706142902374, \"time-step\": 1197}, {\"errors\": 0.24264532327651978, \"time-step\": 1198}, {\"errors\": 0.2426033318042755, \"time-step\": 1199}, {\"errors\": 0.24256113171577454, \"time-step\": 1200}, {\"errors\": 0.24251872301101685, \"time-step\": 1201}, {\"errors\": 0.24247607588768005, \"time-step\": 1202}, {\"errors\": 0.24243316054344177, \"time-step\": 1203}, {\"errors\": 0.24239006638526917, \"time-step\": 1204}, {\"errors\": 0.24234670400619507, \"time-step\": 1205}, {\"errors\": 0.24230313301086426, \"time-step\": 1206}, {\"errors\": 0.24225932359695435, \"time-step\": 1207}, {\"errors\": 0.24221530556678772, \"time-step\": 1208}, {\"errors\": 0.24217106401920319, \"time-step\": 1209}, {\"errors\": 0.24212650954723358, \"time-step\": 1210}, {\"errors\": 0.24208182096481323, \"time-step\": 1211}, {\"errors\": 0.24203680455684662, \"time-step\": 1212}, {\"errors\": 0.24199160933494568, \"time-step\": 1213}, {\"errors\": 0.24194616079330444, \"time-step\": 1214}, {\"errors\": 0.2419004589319229, \"time-step\": 1215}, {\"errors\": 0.24185451865196228, \"time-step\": 1216}, {\"errors\": 0.24180835485458374, \"time-step\": 1217}, {\"errors\": 0.2417619377374649, \"time-step\": 1218}, {\"errors\": 0.24171529710292816, \"time-step\": 1219}, {\"errors\": 0.24166841804981232, \"time-step\": 1220}, {\"errors\": 0.2416212558746338, \"time-step\": 1221}, {\"errors\": 0.24157385528087616, \"time-step\": 1222}, {\"errors\": 0.24152624607086182, \"time-step\": 1223}, {\"errors\": 0.24147836863994598, \"time-step\": 1224}, {\"errors\": 0.24143026769161224, \"time-step\": 1225}, {\"errors\": 0.24138188362121582, \"time-step\": 1226}, {\"errors\": 0.2413332462310791, \"time-step\": 1227}, {\"errors\": 0.24128440022468567, \"time-step\": 1228}, {\"errors\": 0.24123527109622955, \"time-step\": 1229}, {\"errors\": 0.24118593335151672, \"time-step\": 1230}, {\"errors\": 0.24113628268241882, \"time-step\": 1231}, {\"errors\": 0.24108639359474182, \"time-step\": 1232}, {\"errors\": 0.2410362958908081, \"time-step\": 1233}, {\"errors\": 0.24098588526248932, \"time-step\": 1234}, {\"errors\": 0.24093522131443024, \"time-step\": 1235}, {\"errors\": 0.24088434875011444, \"time-step\": 1236}, {\"errors\": 0.24083319306373596, \"time-step\": 1237}, {\"errors\": 0.240781769156456, \"time-step\": 1238}, {\"errors\": 0.24073012173175812, \"time-step\": 1239}, {\"errors\": 0.24067819118499756, \"time-step\": 1240}, {\"errors\": 0.2406259924173355, \"time-step\": 1241}, {\"errors\": 0.24057354032993317, \"time-step\": 1242}, {\"errors\": 0.24052080512046814, \"time-step\": 1243}, {\"errors\": 0.2404678463935852, \"time-step\": 1244}, {\"errors\": 0.240414559841156, \"time-step\": 1245}, {\"errors\": 0.2403610646724701, \"time-step\": 1246}, {\"errors\": 0.2403073012828827, \"time-step\": 1247}, {\"errors\": 0.2402532696723938, \"time-step\": 1248}, {\"errors\": 0.24019895493984222, \"time-step\": 1249}, {\"errors\": 0.24014437198638916, \"time-step\": 1250}, {\"errors\": 0.2400895208120346, \"time-step\": 1251}, {\"errors\": 0.24003440141677856, \"time-step\": 1252}, {\"errors\": 0.23997902870178223, \"time-step\": 1253}, {\"errors\": 0.2399234026670456, \"time-step\": 1254}, {\"errors\": 0.2398674190044403, \"time-step\": 1255}, {\"errors\": 0.23981121182441711, \"time-step\": 1256}, {\"errors\": 0.23975473642349243, \"time-step\": 1257}, {\"errors\": 0.23969800770282745, \"time-step\": 1258}, {\"errors\": 0.2396409809589386, \"time-step\": 1259}, {\"errors\": 0.23958364129066467, \"time-step\": 1260}, {\"errors\": 0.23952606320381165, \"time-step\": 1261}, {\"errors\": 0.23946821689605713, \"time-step\": 1262}, {\"errors\": 0.23941007256507874, \"time-step\": 1263}, {\"errors\": 0.23935166001319885, \"time-step\": 1264}, {\"errors\": 0.2392929494380951, \"time-step\": 1265}, {\"errors\": 0.23923397064208984, \"time-step\": 1266}, {\"errors\": 0.23917466402053833, \"time-step\": 1267}, {\"errors\": 0.2391151487827301, \"time-step\": 1268}, {\"errors\": 0.2390553057193756, \"time-step\": 1269}, {\"errors\": 0.23899520933628082, \"time-step\": 1270}, {\"errors\": 0.23893477022647858, \"time-step\": 1271}, {\"errors\": 0.23887406289577484, \"time-step\": 1272}, {\"errors\": 0.2388131022453308, \"time-step\": 1273}, {\"errors\": 0.2387518435716629, \"time-step\": 1274}, {\"errors\": 0.23869025707244873, \"time-step\": 1275}, {\"errors\": 0.23862841725349426, \"time-step\": 1276}, {\"errors\": 0.2385662943124771, \"time-step\": 1277}, {\"errors\": 0.23850387334823608, \"time-step\": 1278}, {\"errors\": 0.23844113945960999, \"time-step\": 1279}, {\"errors\": 0.2383781373500824, \"time-step\": 1280}, {\"errors\": 0.23831482231616974, \"time-step\": 1281}, {\"errors\": 0.2382512092590332, \"time-step\": 1282}, {\"errors\": 0.23818731307983398, \"time-step\": 1283}, {\"errors\": 0.2381231188774109, \"time-step\": 1284}, {\"errors\": 0.23805861175060272, \"time-step\": 1285}, {\"errors\": 0.23799383640289307, \"time-step\": 1286}, {\"errors\": 0.23792873322963715, \"time-step\": 1287}, {\"errors\": 0.23786333203315735, \"time-step\": 1288}, {\"errors\": 0.23779764771461487, \"time-step\": 1289}, {\"errors\": 0.2377316653728485, \"time-step\": 1290}, {\"errors\": 0.2376653552055359, \"time-step\": 1291}, {\"errors\": 0.2375987470149994, \"time-step\": 1292}, {\"errors\": 0.2375318557024002, \"time-step\": 1293}, {\"errors\": 0.23746465146541595, \"time-step\": 1294}, {\"errors\": 0.23739713430404663, \"time-step\": 1295}, {\"errors\": 0.23732930421829224, \"time-step\": 1296}, {\"errors\": 0.23726116120815277, \"time-step\": 1297}, {\"errors\": 0.23719273507595062, \"time-step\": 1298}, {\"errors\": 0.2371239960193634, \"time-step\": 1299}, {\"errors\": 0.2370549440383911, \"time-step\": 1300}, {\"errors\": 0.23698556423187256, \"time-step\": 1301}, {\"errors\": 0.23691591620445251, \"time-step\": 1302}, {\"errors\": 0.236845925450325, \"time-step\": 1303}, {\"errors\": 0.23677562177181244, \"time-step\": 1304}, {\"errors\": 0.2367049902677536, \"time-step\": 1305}, {\"errors\": 0.23663409054279327, \"time-step\": 1306}, {\"errors\": 0.2365628182888031, \"time-step\": 1307}, {\"errors\": 0.23649129271507263, \"time-step\": 1308}, {\"errors\": 0.23641939461231232, \"time-step\": 1309}, {\"errors\": 0.23634721338748932, \"time-step\": 1310}, {\"errors\": 0.23627468943595886, \"time-step\": 1311}, {\"errors\": 0.23620185256004333, \"time-step\": 1312}, {\"errors\": 0.23612870275974274, \"time-step\": 1313}, {\"errors\": 0.23605524003505707, \"time-step\": 1314}, {\"errors\": 0.23598144948482513, \"time-step\": 1315}, {\"errors\": 0.23590734601020813, \"time-step\": 1316}, {\"errors\": 0.2358328402042389, \"time-step\": 1317}, {\"errors\": 0.23575809597969055, \"time-step\": 1318}, {\"errors\": 0.23568303883075714, \"time-step\": 1319}, {\"errors\": 0.23560762405395508, \"time-step\": 1320}, {\"errors\": 0.23553188145160675, \"time-step\": 1321}, {\"errors\": 0.23545582592487335, \"time-step\": 1322}, {\"errors\": 0.2353794127702713, \"time-step\": 1323}, {\"errors\": 0.23530268669128418, \"time-step\": 1324}, {\"errors\": 0.235225647687912, \"time-step\": 1325}, {\"errors\": 0.23514828085899353, \"time-step\": 1326}, {\"errors\": 0.23507052659988403, \"time-step\": 1327}, {\"errors\": 0.23499250411987305, \"time-step\": 1328}, {\"errors\": 0.23491410911083221, \"time-step\": 1329}, {\"errors\": 0.2348354458808899, \"time-step\": 1330}, {\"errors\": 0.23475638031959534, \"time-step\": 1331}, {\"errors\": 0.2346770018339157, \"time-step\": 1332}, {\"errors\": 0.23459729552268982, \"time-step\": 1333}, {\"errors\": 0.23451724648475647, \"time-step\": 1334}, {\"errors\": 0.23443686962127686, \"time-step\": 1335}, {\"errors\": 0.2343561351299286, \"time-step\": 1336}, {\"errors\": 0.23427508771419525, \"time-step\": 1337}, {\"errors\": 0.23419366776943207, \"time-step\": 1338}, {\"errors\": 0.2341119349002838, \"time-step\": 1339}, {\"errors\": 0.2340298742055893, \"time-step\": 1340}, {\"errors\": 0.23394744098186493, \"time-step\": 1341}, {\"errors\": 0.2338646799325943, \"time-step\": 1342}, {\"errors\": 0.23378154635429382, \"time-step\": 1343}, {\"errors\": 0.23369809985160828, \"time-step\": 1344}, {\"errors\": 0.23361429572105408, \"time-step\": 1345}, {\"errors\": 0.233530193567276, \"time-step\": 1346}, {\"errors\": 0.23344570398330688, \"time-step\": 1347}, {\"errors\": 0.2333608716726303, \"time-step\": 1348}, {\"errors\": 0.23327571153640747, \"time-step\": 1349}, {\"errors\": 0.23319017887115479, \"time-step\": 1350}, {\"errors\": 0.23310430347919464, \"time-step\": 1351}, {\"errors\": 0.23301810026168823, \"time-step\": 1352}, {\"errors\": 0.23293150961399078, \"time-step\": 1353}, {\"errors\": 0.23284459114074707, \"time-step\": 1354}, {\"errors\": 0.23275728523731232, \"time-step\": 1355}, {\"errors\": 0.2326696664094925, \"time-step\": 1356}, {\"errors\": 0.2325817197561264, \"time-step\": 1357}, {\"errors\": 0.23249338567256927, \"time-step\": 1358}, {\"errors\": 0.2324046939611435, \"time-step\": 1359}, {\"errors\": 0.23231567442417145, \"time-step\": 1360}, {\"errors\": 0.23222626745700836, \"time-step\": 1361}, {\"errors\": 0.23213651776313782, \"time-step\": 1362}, {\"errors\": 0.23204641044139862, \"time-step\": 1363}, {\"errors\": 0.23195596039295197, \"time-step\": 1364}, {\"errors\": 0.23186513781547546, \"time-step\": 1365}, {\"errors\": 0.2317739725112915, \"time-step\": 1366}, {\"errors\": 0.23168238997459412, \"time-step\": 1367}, {\"errors\": 0.23159050941467285, \"time-step\": 1368}, {\"errors\": 0.23149825632572174, \"time-step\": 1369}, {\"errors\": 0.23140566051006317, \"time-step\": 1370}, {\"errors\": 0.23131267726421356, \"time-step\": 1371}, {\"errors\": 0.2312193214893341, \"time-step\": 1372}, {\"errors\": 0.231125608086586, \"time-step\": 1373}, {\"errors\": 0.23103155195713043, \"time-step\": 1374}, {\"errors\": 0.23093712329864502, \"time-step\": 1375}, {\"errors\": 0.23084232211112976, \"time-step\": 1376}, {\"errors\": 0.23074716329574585, \"time-step\": 1377}, {\"errors\": 0.2306516468524933, \"time-step\": 1378}, {\"errors\": 0.2305557280778885, \"time-step\": 1379}, {\"errors\": 0.23045946657657623, \"time-step\": 1380}, {\"errors\": 0.23036286234855652, \"time-step\": 1381}, {\"errors\": 0.23026582598686218, \"time-step\": 1382}, {\"errors\": 0.23016849160194397, \"time-step\": 1383}, {\"errors\": 0.23007075488567352, \"time-step\": 1384}, {\"errors\": 0.22997267544269562, \"time-step\": 1385}, {\"errors\": 0.22987417876720428, \"time-step\": 1386}, {\"errors\": 0.2297753244638443, \"time-step\": 1387}, {\"errors\": 0.22967611253261566, \"time-step\": 1388}, {\"errors\": 0.22957652807235718, \"time-step\": 1389}, {\"errors\": 0.22947655618190765, \"time-step\": 1390}, {\"errors\": 0.2293761968612671, \"time-step\": 1391}, {\"errors\": 0.22927550971508026, \"time-step\": 1392}, {\"errors\": 0.2291744351387024, \"time-step\": 1393}, {\"errors\": 0.22907298803329468, \"time-step\": 1394}, {\"errors\": 0.22897115349769592, \"time-step\": 1395}, {\"errors\": 0.22886893153190613, \"time-step\": 1396}, {\"errors\": 0.22876635193824768, \"time-step\": 1397}, {\"errors\": 0.2286633551120758, \"time-step\": 1398}, {\"errors\": 0.22856006026268005, \"time-step\": 1399}, {\"errors\": 0.22845634818077087, \"time-step\": 1400}, {\"errors\": 0.22835221886634827, \"time-step\": 1401}, {\"errors\": 0.2282477617263794, \"time-step\": 1402}, {\"errors\": 0.22814291715621948, \"time-step\": 1403}, {\"errors\": 0.22803767025470734, \"time-step\": 1404}, {\"errors\": 0.22793208062648773, \"time-step\": 1405}, {\"errors\": 0.2278260886669159, \"time-step\": 1406}, {\"errors\": 0.2277197241783142, \"time-step\": 1407}, {\"errors\": 0.22761297225952148, \"time-step\": 1408}, {\"errors\": 0.22750583291053772, \"time-step\": 1409}, {\"errors\": 0.22739830613136292, \"time-step\": 1410}, {\"errors\": 0.22729040682315826, \"time-step\": 1411}, {\"errors\": 0.22718209028244019, \"time-step\": 1412}, {\"errors\": 0.22707343101501465, \"time-step\": 1413}, {\"errors\": 0.22696441411972046, \"time-step\": 1414}, {\"errors\": 0.22685495018959045, \"time-step\": 1415}, {\"errors\": 0.2267451286315918, \"time-step\": 1416}, {\"errors\": 0.2266349196434021, \"time-step\": 1417}, {\"errors\": 0.22652432322502136, \"time-step\": 1418}, {\"errors\": 0.22641333937644958, \"time-step\": 1419}, {\"errors\": 0.22630199790000916, \"time-step\": 1420}, {\"errors\": 0.2261902540922165, \"time-step\": 1421}, {\"errors\": 0.22607813775539398, \"time-step\": 1422}, {\"errors\": 0.22596555948257446, \"time-step\": 1423}, {\"errors\": 0.22585265338420868, \"time-step\": 1424}, {\"errors\": 0.22573935985565186, \"time-step\": 1425}, {\"errors\": 0.22562569379806519, \"time-step\": 1426}, {\"errors\": 0.2255115807056427, \"time-step\": 1427}, {\"errors\": 0.22539713978767395, \"time-step\": 1428}, {\"errors\": 0.22528226673603058, \"time-step\": 1429}, {\"errors\": 0.22516702115535736, \"time-step\": 1430}, {\"errors\": 0.2250514030456543, \"time-step\": 1431}, {\"errors\": 0.224935382604599, \"time-step\": 1432}, {\"errors\": 0.22481897473335266, \"time-step\": 1433}, {\"errors\": 0.2247021496295929, \"time-step\": 1434}, {\"errors\": 0.2245849221944809, \"time-step\": 1435}, {\"errors\": 0.22446735203266144, \"time-step\": 1436}, {\"errors\": 0.22434936463832855, \"time-step\": 1437}, {\"errors\": 0.22423101961612701, \"time-step\": 1438}, {\"errors\": 0.22411222755908966, \"time-step\": 1439}, {\"errors\": 0.22399309277534485, \"time-step\": 1440}, {\"errors\": 0.2238735407590866, \"time-step\": 1441}, {\"errors\": 0.22375358641147614, \"time-step\": 1442}, {\"errors\": 0.22363325953483582, \"time-step\": 1443}, {\"errors\": 0.22351253032684326, \"time-step\": 1444}, {\"errors\": 0.22339139878749847, \"time-step\": 1445}, {\"errors\": 0.22326987981796265, \"time-step\": 1446}, {\"errors\": 0.22314797341823578, \"time-step\": 1447}, {\"errors\": 0.22302567958831787, \"time-step\": 1448}, {\"errors\": 0.22290296852588654, \"time-step\": 1449}, {\"errors\": 0.22277989983558655, \"time-step\": 1450}, {\"errors\": 0.22265639901161194, \"time-step\": 1451}, {\"errors\": 0.2225324809551239, \"time-step\": 1452}, {\"errors\": 0.2224082350730896, \"time-step\": 1453}, {\"errors\": 0.2222835272550583, \"time-step\": 1454}, {\"errors\": 0.2221584916114807, \"time-step\": 1455}, {\"errors\": 0.22203302383422852, \"time-step\": 1456}, {\"errors\": 0.22190716862678528, \"time-step\": 1457}, {\"errors\": 0.221780925989151, \"time-step\": 1458}, {\"errors\": 0.2216542810201645, \"time-step\": 1459}, {\"errors\": 0.22152720391750336, \"time-step\": 1460}, {\"errors\": 0.22139978408813477, \"time-step\": 1461}, {\"errors\": 0.22127193212509155, \"time-step\": 1462}, {\"errors\": 0.2211436927318573, \"time-step\": 1463}, {\"errors\": 0.221015065908432, \"time-step\": 1464}, {\"errors\": 0.2208860218524933, \"time-step\": 1465}, {\"errors\": 0.22075659036636353, \"time-step\": 1466}, {\"errors\": 0.2206268012523651, \"time-step\": 1467}, {\"errors\": 0.22049656510353088, \"time-step\": 1468}, {\"errors\": 0.22036594152450562, \"time-step\": 1469}, {\"errors\": 0.2202349454164505, \"time-step\": 1470}, {\"errors\": 0.22010354697704315, \"time-step\": 1471}, {\"errors\": 0.21997173130512238, \"time-step\": 1472}, {\"errors\": 0.21983951330184937, \"time-step\": 1473}, {\"errors\": 0.2197069227695465, \"time-step\": 1474}, {\"errors\": 0.21957391500473022, \"time-step\": 1475}, {\"errors\": 0.2194405198097229, \"time-step\": 1476}, {\"errors\": 0.21930669248104095, \"time-step\": 1477}, {\"errors\": 0.21917253732681274, \"time-step\": 1478}, {\"errors\": 0.2190379649400711, \"time-step\": 1479}, {\"errors\": 0.21890297532081604, \"time-step\": 1480}, {\"errors\": 0.21876758337020874, \"time-step\": 1481}, {\"errors\": 0.2186318188905716, \"time-step\": 1482}, {\"errors\": 0.21849563717842102, \"time-step\": 1483}, {\"errors\": 0.2183590680360794, \"time-step\": 1484}, {\"errors\": 0.21822208166122437, \"time-step\": 1485}, {\"errors\": 0.21808476746082306, \"time-step\": 1486}, {\"errors\": 0.21794697642326355, \"time-step\": 1487}, {\"errors\": 0.2178088128566742, \"time-step\": 1488}, {\"errors\": 0.2176702469587326, \"time-step\": 1489}, {\"errors\": 0.21753130853176117, \"time-step\": 1490}, {\"errors\": 0.2173919677734375, \"time-step\": 1491}, {\"errors\": 0.2172521948814392, \"time-step\": 1492}, {\"errors\": 0.21711207926273346, \"time-step\": 1493}, {\"errors\": 0.2169715166091919, \"time-step\": 1494}, {\"errors\": 0.21683059632778168, \"time-step\": 1495}, {\"errors\": 0.21668925881385803, \"time-step\": 1496}, {\"errors\": 0.21654754877090454, \"time-step\": 1497}, {\"errors\": 0.21640539169311523, \"time-step\": 1498}, {\"errors\": 0.21626287698745728, \"time-step\": 1499}, {\"errors\": 0.21611995995044708, \"time-step\": 1500}, {\"errors\": 0.21597665548324585, \"time-step\": 1501}, {\"errors\": 0.21583294868469238, \"time-step\": 1502}, {\"errors\": 0.21568885445594788, \"time-step\": 1503}, {\"errors\": 0.21554434299468994, \"time-step\": 1504}, {\"errors\": 0.21539945900440216, \"time-step\": 1505}, {\"errors\": 0.21525415778160095, \"time-step\": 1506}, {\"errors\": 0.2151084840297699, \"time-step\": 1507}, {\"errors\": 0.21496239304542542, \"time-step\": 1508}, {\"errors\": 0.2148159146308899, \"time-step\": 1509}, {\"errors\": 0.21466907858848572, \"time-step\": 1510}, {\"errors\": 0.21452181041240692, \"time-step\": 1511}, {\"errors\": 0.21437418460845947, \"time-step\": 1512}, {\"errors\": 0.2142261117696762, \"time-step\": 1513}, {\"errors\": 0.2140776515007019, \"time-step\": 1514}, {\"errors\": 0.21392884850502014, \"time-step\": 1515}, {\"errors\": 0.21377962827682495, \"time-step\": 1516}, {\"errors\": 0.21362997591495514, \"time-step\": 1517}, {\"errors\": 0.21347999572753906, \"time-step\": 1518}, {\"errors\": 0.21332958340644836, \"time-step\": 1519}, {\"errors\": 0.21317876875400543, \"time-step\": 1520}, {\"errors\": 0.21302761137485504, \"time-step\": 1521}, {\"errors\": 0.21287602186203003, \"time-step\": 1522}, {\"errors\": 0.21272404491901398, \"time-step\": 1523}, {\"errors\": 0.21257168054580688, \"time-step\": 1524}, {\"errors\": 0.21241892874240875, \"time-step\": 1525}, {\"errors\": 0.2122657746076584, \"time-step\": 1526}, {\"errors\": 0.21211223304271698, \"time-step\": 1527}, {\"errors\": 0.21195831894874573, \"time-step\": 1528}, {\"errors\": 0.21180401742458344, \"time-step\": 1529}, {\"errors\": 0.2116493135690689, \"time-step\": 1530}, {\"errors\": 0.21149423718452454, \"time-step\": 1531}, {\"errors\": 0.21133874356746674, \"time-step\": 1532}, {\"errors\": 0.21118289232254028, \"time-step\": 1533}, {\"errors\": 0.2110266387462616, \"time-step\": 1534}, {\"errors\": 0.21086999773979187, \"time-step\": 1535}, {\"errors\": 0.21071293950080872, \"time-step\": 1536}, {\"errors\": 0.2105555236339569, \"time-step\": 1537}, {\"errors\": 0.21039772033691406, \"time-step\": 1538}, {\"errors\": 0.2102394998073578, \"time-step\": 1539}, {\"errors\": 0.21008095145225525, \"time-step\": 1540}, {\"errors\": 0.2099219709634781, \"time-step\": 1541}, {\"errors\": 0.2097626030445099, \"time-step\": 1542}, {\"errors\": 0.20960287749767303, \"time-step\": 1543}, {\"errors\": 0.20944279432296753, \"time-step\": 1544}, {\"errors\": 0.2092822790145874, \"time-step\": 1545}, {\"errors\": 0.20912140607833862, \"time-step\": 1546}, {\"errors\": 0.20896011590957642, \"time-step\": 1547}, {\"errors\": 0.20879848301410675, \"time-step\": 1548}, {\"errors\": 0.20863643288612366, \"time-step\": 1549}, {\"errors\": 0.2084740251302719, \"time-step\": 1550}, {\"errors\": 0.20831120014190674, \"time-step\": 1551}, {\"errors\": 0.2081480175256729, \"time-step\": 1552}, {\"errors\": 0.20798447728157043, \"time-step\": 1553}, {\"errors\": 0.20782054960727692, \"time-step\": 1554}, {\"errors\": 0.20765617489814758, \"time-step\": 1555}, {\"errors\": 0.20749151706695557, \"time-step\": 1556}, {\"errors\": 0.2073264718055725, \"time-step\": 1557}, {\"errors\": 0.20716096460819244, \"time-step\": 1558}, {\"errors\": 0.20699509978294373, \"time-step\": 1559}, {\"errors\": 0.20682890713214874, \"time-step\": 1560}, {\"errors\": 0.2066623419523239, \"time-step\": 1561}, {\"errors\": 0.20649534463882446, \"time-step\": 1562}, {\"errors\": 0.20632798969745636, \"time-step\": 1563}, {\"errors\": 0.2061602622270584, \"time-step\": 1564}, {\"errors\": 0.20599216222763062, \"time-step\": 1565}, {\"errors\": 0.20582370460033417, \"time-step\": 1566}, {\"errors\": 0.20565484464168549, \"time-step\": 1567}, {\"errors\": 0.20548564195632935, \"time-step\": 1568}, {\"errors\": 0.20531606674194336, \"time-step\": 1569}, {\"errors\": 0.20514607429504395, \"time-step\": 1570}, {\"errors\": 0.20497570931911469, \"time-step\": 1571}, {\"errors\": 0.20480501651763916, \"time-step\": 1572}, {\"errors\": 0.2046339213848114, \"time-step\": 1573}, {\"errors\": 0.2044624537229538, \"time-step\": 1574}, {\"errors\": 0.20429064333438873, \"time-step\": 1575}, {\"errors\": 0.20411844551563263, \"time-step\": 1576}, {\"errors\": 0.20394589006900787, \"time-step\": 1577}, {\"errors\": 0.20377294719219208, \"time-step\": 1578}, {\"errors\": 0.20359966158866882, \"time-step\": 1579}, {\"errors\": 0.20342598855495453, \"time-step\": 1580}, {\"errors\": 0.2032519280910492, \"time-step\": 1581}, {\"errors\": 0.2030775547027588, \"time-step\": 1582}, {\"errors\": 0.20290279388427734, \"time-step\": 1583}, {\"errors\": 0.20272764563560486, \"time-step\": 1584}, {\"errors\": 0.2025521844625473, \"time-step\": 1585}, {\"errors\": 0.20237627625465393, \"time-step\": 1586}, {\"errors\": 0.20220008492469788, \"time-step\": 1587}, {\"errors\": 0.2020234912633896, \"time-step\": 1588}, {\"errors\": 0.20184653997421265, \"time-step\": 1589}, {\"errors\": 0.20166921615600586, \"time-step\": 1590}, {\"errors\": 0.2014915496110916, \"time-step\": 1591}, {\"errors\": 0.20131352543830872, \"time-step\": 1592}, {\"errors\": 0.20113509893417358, \"time-step\": 1593}, {\"errors\": 0.20095638930797577, \"time-step\": 1594}, {\"errors\": 0.20077727735042572, \"time-step\": 1595}, {\"errors\": 0.20059777796268463, \"time-step\": 1596}, {\"errors\": 0.20041798055171967, \"time-step\": 1597}, {\"errors\": 0.20023779571056366, \"time-step\": 1598}, {\"errors\": 0.200057253241539, \"time-step\": 1599}, {\"errors\": 0.19987636804580688, \"time-step\": 1600}, {\"errors\": 0.19969509541988373, \"time-step\": 1601}, {\"errors\": 0.1995135247707367, \"time-step\": 1602}, {\"errors\": 0.19933158159255981, \"time-step\": 1603}, {\"errors\": 0.19914928078651428, \"time-step\": 1604}, {\"errors\": 0.1989666372537613, \"time-step\": 1605}, {\"errors\": 0.19878360629081726, \"time-step\": 1606}, {\"errors\": 0.19860026240348816, \"time-step\": 1607}, {\"errors\": 0.1984165608882904, \"time-step\": 1608}, {\"errors\": 0.1982324868440628, \"time-step\": 1609}, {\"errors\": 0.19804809987545013, \"time-step\": 1610}, {\"errors\": 0.19786337018013, \"time-step\": 1611}, {\"errors\": 0.19767823815345764, \"time-step\": 1612}, {\"errors\": 0.1974928081035614, \"time-step\": 1613}, {\"errors\": 0.1973070502281189, \"time-step\": 1614}, {\"errors\": 0.19712091982364655, \"time-step\": 1615}, {\"errors\": 0.19693441689014435, \"time-step\": 1616}, {\"errors\": 0.19674760103225708, \"time-step\": 1617}, {\"errors\": 0.19656047224998474, \"time-step\": 1618}, {\"errors\": 0.19637292623519897, \"time-step\": 1619}, {\"errors\": 0.1961851269006729, \"time-step\": 1620}, {\"errors\": 0.1959969401359558, \"time-step\": 1621}, {\"errors\": 0.19580842554569244, \"time-step\": 1622}, {\"errors\": 0.1956195831298828, \"time-step\": 1623}, {\"errors\": 0.19543036818504333, \"time-step\": 1624}, {\"errors\": 0.19524088501930237, \"time-step\": 1625}, {\"errors\": 0.19505098462104797, \"time-step\": 1626}, {\"errors\": 0.1948608160018921, \"time-step\": 1627}, {\"errors\": 0.19467027485370636, \"time-step\": 1628}, {\"errors\": 0.19447939097881317, \"time-step\": 1629}, {\"errors\": 0.1942882239818573, \"time-step\": 1630}, {\"errors\": 0.1940966546535492, \"time-step\": 1631}, {\"errors\": 0.1939048171043396, \"time-step\": 1632}, {\"errors\": 0.19371262192726135, \"time-step\": 1633}, {\"errors\": 0.19352008402347565, \"time-step\": 1634}, {\"errors\": 0.19332721829414368, \"time-step\": 1635}, {\"errors\": 0.19313408434391022, \"time-step\": 1636}, {\"errors\": 0.19294054806232452, \"time-step\": 1637}, {\"errors\": 0.19274675846099854, \"time-step\": 1638}, {\"errors\": 0.1925526261329651, \"time-step\": 1639}, {\"errors\": 0.192358136177063, \"time-step\": 1640}, {\"errors\": 0.192163348197937, \"time-step\": 1641}, {\"errors\": 0.19196823239326477, \"time-step\": 1642}, {\"errors\": 0.19177275896072388, \"time-step\": 1643}, {\"errors\": 0.1915770173072815, \"time-step\": 1644}, {\"errors\": 0.19138093292713165, \"time-step\": 1645}, {\"errors\": 0.19118456542491913, \"time-step\": 1646}, {\"errors\": 0.19098784029483795, \"time-step\": 1647}, {\"errors\": 0.19079084694385529, \"time-step\": 1648}, {\"errors\": 0.19059348106384277, \"time-step\": 1649}, {\"errors\": 0.19039581716060638, \"time-step\": 1650}, {\"errors\": 0.19019785523414612, \"time-step\": 1651}, {\"errors\": 0.1899995505809784, \"time-step\": 1652}, {\"errors\": 0.18980096280574799, \"time-step\": 1653}, {\"errors\": 0.1896020472049713, \"time-step\": 1654}, {\"errors\": 0.18940284848213196, \"time-step\": 1655}, {\"errors\": 0.18920330703258514, \"time-step\": 1656}, {\"errors\": 0.18900349736213684, \"time-step\": 1657}, {\"errors\": 0.18880334496498108, \"time-step\": 1658}, {\"errors\": 0.18860292434692383, \"time-step\": 1659}, {\"errors\": 0.18840214610099792, \"time-step\": 1660}, {\"errors\": 0.18820111453533173, \"time-step\": 1661}, {\"errors\": 0.18799978494644165, \"time-step\": 1662}, {\"errors\": 0.18779809772968292, \"time-step\": 1663}, {\"errors\": 0.1875961571931839, \"time-step\": 1664}, {\"errors\": 0.1873939037322998, \"time-step\": 1665}, {\"errors\": 0.18719133734703064, \"time-step\": 1666}, {\"errors\": 0.1869884878396988, \"time-step\": 1667}, {\"errors\": 0.18678534030914307, \"time-step\": 1668}, {\"errors\": 0.18658192455768585, \"time-step\": 1669}, {\"errors\": 0.18637819588184357, \"time-step\": 1670}, {\"errors\": 0.18617413938045502, \"time-step\": 1671}, {\"errors\": 0.18596982955932617, \"time-step\": 1672}, {\"errors\": 0.18576525151729584, \"time-step\": 1673}, {\"errors\": 0.18556034564971924, \"time-step\": 1674}, {\"errors\": 0.18535512685775757, \"time-step\": 1675}, {\"errors\": 0.1851496398448944, \"time-step\": 1676}, {\"errors\": 0.18494389951229095, \"time-step\": 1677}, {\"errors\": 0.18473786115646362, \"time-step\": 1678}, {\"errors\": 0.1845315396785736, \"time-step\": 1679}, {\"errors\": 0.18432490527629852, \"time-step\": 1680}, {\"errors\": 0.18411800265312195, \"time-step\": 1681}, {\"errors\": 0.18391083180904388, \"time-step\": 1682}, {\"errors\": 0.18370337784290314, \"time-step\": 1683}, {\"errors\": 0.1834956258535385, \"time-step\": 1684}, {\"errors\": 0.1832876205444336, \"time-step\": 1685}, {\"errors\": 0.18307934701442719, \"time-step\": 1686}, {\"errors\": 0.1828707754611969, \"time-step\": 1687}, {\"errors\": 0.18266192078590393, \"time-step\": 1688}, {\"errors\": 0.18245284259319305, \"time-step\": 1689}, {\"errors\": 0.1822434514760971, \"time-step\": 1690}, {\"errors\": 0.18203380703926086, \"time-step\": 1691}, {\"errors\": 0.18182389438152313, \"time-step\": 1692}, {\"errors\": 0.18161368370056152, \"time-step\": 1693}, {\"errors\": 0.1814032346010208, \"time-step\": 1694}, {\"errors\": 0.1811925172805786, \"time-step\": 1695}, {\"errors\": 0.18098151683807373, \"time-step\": 1696}, {\"errors\": 0.18077024817466736, \"time-step\": 1697}, {\"errors\": 0.18055877089500427, \"time-step\": 1698}, {\"errors\": 0.18034698069095612, \"time-step\": 1699}, {\"errors\": 0.18013493716716766, \"time-step\": 1700}, {\"errors\": 0.1799226552248001, \"time-step\": 1701}, {\"errors\": 0.17971011996269226, \"time-step\": 1702}, {\"errors\": 0.17949733138084412, \"time-step\": 1703}, {\"errors\": 0.17928427457809448, \"time-step\": 1704}, {\"errors\": 0.17907097935676575, \"time-step\": 1705}, {\"errors\": 0.17885738611221313, \"time-step\": 1706}, {\"errors\": 0.17864356935024261, \"time-step\": 1707}, {\"errors\": 0.178429514169693, \"time-step\": 1708}, {\"errors\": 0.17821523547172546, \"time-step\": 1709}, {\"errors\": 0.17800064384937286, \"time-step\": 1710}, {\"errors\": 0.17778584361076355, \"time-step\": 1711}, {\"errors\": 0.17757081985473633, \"time-step\": 1712}, {\"errors\": 0.17735552787780762, \"time-step\": 1713}, {\"errors\": 0.1771399825811386, \"time-step\": 1714}, {\"errors\": 0.1769242286682129, \"time-step\": 1715}, {\"errors\": 0.17670822143554688, \"time-step\": 1716}, {\"errors\": 0.17649197578430176, \"time-step\": 1717}, {\"errors\": 0.17627552151679993, \"time-step\": 1718}, {\"errors\": 0.1760587841272354, \"time-step\": 1719}, {\"errors\": 0.17584183812141418, \"time-step\": 1720}, {\"errors\": 0.17562465369701385, \"time-step\": 1721}, {\"errors\": 0.1754072904586792, \"time-step\": 1722}, {\"errors\": 0.17518959939479828, \"time-step\": 1723}, {\"errors\": 0.17497174441814423, \"time-step\": 1724}, {\"errors\": 0.1747536063194275, \"time-step\": 1725}, {\"errors\": 0.1745353639125824, \"time-step\": 1726}, {\"errors\": 0.17431680858135223, \"time-step\": 1727}, {\"errors\": 0.17409804463386536, \"time-step\": 1728}, {\"errors\": 0.17387902736663818, \"time-step\": 1729}, {\"errors\": 0.17365983128547668, \"time-step\": 1730}, {\"errors\": 0.17344044148921967, \"time-step\": 1731}, {\"errors\": 0.17322079837322235, \"time-step\": 1732}, {\"errors\": 0.17300094664096832, \"time-step\": 1733}, {\"errors\": 0.172780841588974, \"time-step\": 1734}, {\"errors\": 0.17256061732769012, \"time-step\": 1735}, {\"errors\": 0.17234013974666595, \"time-step\": 1736}, {\"errors\": 0.17211943864822388, \"time-step\": 1737}, {\"errors\": 0.17189854383468628, \"time-step\": 1738}, {\"errors\": 0.17167741060256958, \"time-step\": 1739}, {\"errors\": 0.17145609855651855, \"time-step\": 1740}, {\"errors\": 0.171234592795372, \"time-step\": 1741}, {\"errors\": 0.17101289331912994, \"time-step\": 1742}, {\"errors\": 0.17079094052314758, \"time-step\": 1743}, {\"errors\": 0.17056885361671448, \"time-step\": 1744}, {\"errors\": 0.17034654319286346, \"time-step\": 1745}, {\"errors\": 0.17012402415275574, \"time-step\": 1746}, {\"errors\": 0.1699013113975525, \"time-step\": 1747}, {\"errors\": 0.1696784645318985, \"time-step\": 1748}, {\"errors\": 0.16945533454418182, \"time-step\": 1749}, {\"errors\": 0.1692320704460144, \"time-step\": 1750}, {\"errors\": 0.16900861263275146, \"time-step\": 1751}, {\"errors\": 0.16878493130207062, \"time-step\": 1752}, {\"errors\": 0.16856111586093903, \"time-step\": 1753}, {\"errors\": 0.1683371216058731, \"time-step\": 1754}, {\"errors\": 0.16811291873455048, \"time-step\": 1755}, {\"errors\": 0.16788853704929352, \"time-step\": 1756}, {\"errors\": 0.16766397655010223, \"time-step\": 1757}, {\"errors\": 0.16743923723697662, \"time-step\": 1758}, {\"errors\": 0.1672143191099167, \"time-step\": 1759}, {\"errors\": 0.16698923707008362, \"time-step\": 1760}, {\"errors\": 0.1667640209197998, \"time-step\": 1761}, {\"errors\": 0.1665385663509369, \"time-step\": 1762}, {\"errors\": 0.16631296277046204, \"time-step\": 1763}, {\"errors\": 0.16608721017837524, \"time-step\": 1764}, {\"errors\": 0.16586127877235413, \"time-step\": 1765}, {\"errors\": 0.16563516855239868, \"time-step\": 1766}, {\"errors\": 0.16540895402431488, \"time-step\": 1767}, {\"errors\": 0.16518253087997437, \"time-step\": 1768}, {\"errors\": 0.1649559587240219, \"time-step\": 1769}, {\"errors\": 0.16472920775413513, \"time-step\": 1770}, {\"errors\": 0.1645023226737976, \"time-step\": 1771}, {\"errors\": 0.16427525877952576, \"time-step\": 1772}, {\"errors\": 0.16404809057712555, \"time-step\": 1773}, {\"errors\": 0.16382072865962982, \"time-step\": 1774}, {\"errors\": 0.16359326243400574, \"time-step\": 1775}, {\"errors\": 0.16336563229560852, \"time-step\": 1776}, {\"errors\": 0.16313783824443817, \"time-step\": 1777}, {\"errors\": 0.1629098653793335, \"time-step\": 1778}, {\"errors\": 0.16268180310726166, \"time-step\": 1779}, {\"errors\": 0.16245362162590027, \"time-step\": 1780}, {\"errors\": 0.16222524642944336, \"time-step\": 1781}, {\"errors\": 0.1619967818260193, \"time-step\": 1782}, {\"errors\": 0.1617681086063385, \"time-step\": 1783}, {\"errors\": 0.16153933107852936, \"time-step\": 1784}, {\"errors\": 0.16131044924259186, \"time-step\": 1785}, {\"errors\": 0.161081463098526, \"time-step\": 1786}, {\"errors\": 0.16085228323936462, \"time-step\": 1787}, {\"errors\": 0.16062301397323608, \"time-step\": 1788}, {\"errors\": 0.16039356589317322, \"time-step\": 1789}, {\"errors\": 0.16016405820846558, \"time-step\": 1790}, {\"errors\": 0.1599343866109848, \"time-step\": 1791}, {\"errors\": 0.15970459580421448, \"time-step\": 1792}, {\"errors\": 0.15947476029396057, \"time-step\": 1793}, {\"errors\": 0.15924474596977234, \"time-step\": 1794}, {\"errors\": 0.15901459753513336, \"time-step\": 1795}, {\"errors\": 0.1587843894958496, \"time-step\": 1796}, {\"errors\": 0.15855401754379272, \"time-step\": 1797}, {\"errors\": 0.15832357108592987, \"time-step\": 1798}, {\"errors\": 0.15809299051761627, \"time-step\": 1799}, {\"errors\": 0.15786230564117432, \"time-step\": 1800}, {\"errors\": 0.15763156116008759, \"time-step\": 1801}, {\"errors\": 0.15740065276622772, \"time-step\": 1802}, {\"errors\": 0.15716969966888428, \"time-step\": 1803}, {\"errors\": 0.1569385826587677, \"time-step\": 1804}, {\"errors\": 0.15670739114284515, \"time-step\": 1805}, {\"errors\": 0.15647614002227783, \"time-step\": 1806}, {\"errors\": 0.15624476969242096, \"time-step\": 1807}, {\"errors\": 0.15601330995559692, \"time-step\": 1808}, {\"errors\": 0.15578176081180573, \"time-step\": 1809}, {\"errors\": 0.15555009245872498, \"time-step\": 1810}, {\"errors\": 0.15531834959983826, \"time-step\": 1811}, {\"errors\": 0.15508653223514557, \"time-step\": 1812}, {\"errors\": 0.1548546701669693, \"time-step\": 1813}, {\"errors\": 0.15462270379066467, \"time-step\": 1814}, {\"errors\": 0.1543906331062317, \"time-step\": 1815}, {\"errors\": 0.15415847301483154, \"time-step\": 1816}, {\"errors\": 0.15392625331878662, \"time-step\": 1817}, {\"errors\": 0.15369397401809692, \"time-step\": 1818}, {\"errors\": 0.15346162021160126, \"time-step\": 1819}, {\"errors\": 0.15322914719581604, \"time-step\": 1820}, {\"errors\": 0.15299665927886963, \"time-step\": 1821}, {\"errors\": 0.15276408195495605, \"time-step\": 1822}, {\"errors\": 0.1525314748287201, \"time-step\": 1823}, {\"errors\": 0.15229874849319458, \"time-step\": 1824}, {\"errors\": 0.15206597745418549, \"time-step\": 1825}, {\"errors\": 0.151833176612854, \"time-step\": 1826}, {\"errors\": 0.15160027146339417, \"time-step\": 1827}, {\"errors\": 0.15136735141277313, \"time-step\": 1828}, {\"errors\": 0.15113435685634613, \"time-step\": 1829}, {\"errors\": 0.15090131759643555, \"time-step\": 1830}, {\"errors\": 0.1506682187318802, \"time-step\": 1831}, {\"errors\": 0.15043509006500244, \"time-step\": 1832}, {\"errors\": 0.15020188689231873, \"time-step\": 1833}, {\"errors\": 0.14996863901615143, \"time-step\": 1834}, {\"errors\": 0.14973533153533936, \"time-step\": 1835}, {\"errors\": 0.14950202405452728, \"time-step\": 1836}, {\"errors\": 0.14926865696907043, \"time-step\": 1837}, {\"errors\": 0.1490352302789688, \"time-step\": 1838}, {\"errors\": 0.148801788687706, \"time-step\": 1839}, {\"errors\": 0.14856833219528198, \"time-step\": 1840}, {\"errors\": 0.1483348309993744, \"time-step\": 1841}, {\"errors\": 0.14810128509998322, \"time-step\": 1842}, {\"errors\": 0.14786770939826965, \"time-step\": 1843}, {\"errors\": 0.1476341187953949, \"time-step\": 1844}, {\"errors\": 0.14740049839019775, \"time-step\": 1845}, {\"errors\": 0.14716683328151703, \"time-step\": 1846}, {\"errors\": 0.14693313837051392, \"time-step\": 1847}, {\"errors\": 0.1466994434595108, \"time-step\": 1848}, {\"errors\": 0.1464657485485077, \"time-step\": 1849}, {\"errors\": 0.146232008934021, \"time-step\": 1850}, {\"errors\": 0.14599823951721191, \"time-step\": 1851}, {\"errors\": 0.14576449990272522, \"time-step\": 1852}, {\"errors\": 0.14553071558475494, \"time-step\": 1853}, {\"errors\": 0.14529696106910706, \"time-step\": 1854}, {\"errors\": 0.14506316184997559, \"time-step\": 1855}, {\"errors\": 0.14482936263084412, \"time-step\": 1856}, {\"errors\": 0.14459557831287384, \"time-step\": 1857}, {\"errors\": 0.14436177909374237, \"time-step\": 1858}, {\"errors\": 0.1441279798746109, \"time-step\": 1859}, {\"errors\": 0.14389415085315704, \"time-step\": 1860}, {\"errors\": 0.14366035163402557, \"time-step\": 1861}, {\"errors\": 0.1434265524148941, \"time-step\": 1862}, {\"errors\": 0.14319276809692383, \"time-step\": 1863}, {\"errors\": 0.14295896887779236, \"time-step\": 1864}, {\"errors\": 0.14272521436214447, \"time-step\": 1865}, {\"errors\": 0.14249145984649658, \"time-step\": 1866}, {\"errors\": 0.1422576904296875, \"time-step\": 1867}, {\"errors\": 0.1420239508152008, \"time-step\": 1868}, {\"errors\": 0.1417902559041977, \"time-step\": 1869}, {\"errors\": 0.1415565460920334, \"time-step\": 1870}, {\"errors\": 0.14132286608219147, \"time-step\": 1871}, {\"errors\": 0.14108920097351074, \"time-step\": 1872}, {\"errors\": 0.1408555954694748, \"time-step\": 1873}, {\"errors\": 0.14062198996543884, \"time-step\": 1874}, {\"errors\": 0.1403883993625641, \"time-step\": 1875}, {\"errors\": 0.14015483856201172, \"time-step\": 1876}, {\"errors\": 0.13992132246494293, \"time-step\": 1877}, {\"errors\": 0.13968786597251892, \"time-step\": 1878}, {\"errors\": 0.1394544094800949, \"time-step\": 1879}, {\"errors\": 0.1392209678888321, \"time-step\": 1880}, {\"errors\": 0.13898761570453644, \"time-step\": 1881}, {\"errors\": 0.13875427842140198, \"time-step\": 1882}, {\"errors\": 0.1385209709405899, \"time-step\": 1883}, {\"errors\": 0.1382877230644226, \"time-step\": 1884}, {\"errors\": 0.1380545198917389, \"time-step\": 1885}, {\"errors\": 0.13782134652137756, \"time-step\": 1886}, {\"errors\": 0.1375882476568222, \"time-step\": 1887}, {\"errors\": 0.13735516369342804, \"time-step\": 1888}, {\"errors\": 0.13712219893932343, \"time-step\": 1889}, {\"errors\": 0.13688921928405762, \"time-step\": 1890}, {\"errors\": 0.13665632903575897, \"time-step\": 1891}, {\"errors\": 0.13642346858978271, \"time-step\": 1892}, {\"errors\": 0.13619065284729004, \"time-step\": 1893}, {\"errors\": 0.13595795631408691, \"time-step\": 1894}, {\"errors\": 0.13572528958320618, \"time-step\": 1895}, {\"errors\": 0.1354926973581314, \"time-step\": 1896}, {\"errors\": 0.13526016473770142, \"time-step\": 1897}, {\"errors\": 0.135027676820755, \"time-step\": 1898}, {\"errors\": 0.13479524850845337, \"time-step\": 1899}, {\"errors\": 0.13456293940544128, \"time-step\": 1900}, {\"errors\": 0.13433067500591278, \"time-step\": 1901}, {\"errors\": 0.13409845530986786, \"time-step\": 1902}, {\"errors\": 0.1338663548231125, \"time-step\": 1903}, {\"errors\": 0.13363434374332428, \"time-step\": 1904}, {\"errors\": 0.13340237736701965, \"time-step\": 1905}, {\"errors\": 0.13317051529884338, \"time-step\": 1906}, {\"errors\": 0.1329387128353119, \"time-step\": 1907}, {\"errors\": 0.13270701467990875, \"time-step\": 1908}, {\"errors\": 0.1324753612279892, \"time-step\": 1909}, {\"errors\": 0.1322438269853592, \"time-step\": 1910}, {\"errors\": 0.13201236724853516, \"time-step\": 1911}, {\"errors\": 0.13178105652332306, \"time-step\": 1912}, {\"errors\": 0.13154976069927216, \"time-step\": 1913}, {\"errors\": 0.131318598985672, \"time-step\": 1914}, {\"errors\": 0.1310874968767166, \"time-step\": 1915}, {\"errors\": 0.13085652887821198, \"time-step\": 1916}, {\"errors\": 0.1306256353855133, \"time-step\": 1917}, {\"errors\": 0.13039487600326538, \"time-step\": 1918}, {\"errors\": 0.13016417622566223, \"time-step\": 1919}, {\"errors\": 0.12993358075618744, \"time-step\": 1920}, {\"errors\": 0.1297031044960022, \"time-step\": 1921}, {\"errors\": 0.1294727623462677, \"time-step\": 1922}, {\"errors\": 0.12924247980117798, \"time-step\": 1923}, {\"errors\": 0.129012331366539, \"time-step\": 1924}, {\"errors\": 0.1287822723388672, \"time-step\": 1925}, {\"errors\": 0.12855231761932373, \"time-step\": 1926}, {\"errors\": 0.1283225417137146, \"time-step\": 1927}, {\"errors\": 0.12809282541275024, \"time-step\": 1928}, {\"errors\": 0.12786321341991425, \"time-step\": 1929}, {\"errors\": 0.12763378024101257, \"time-step\": 1930}, {\"errors\": 0.12740442156791687, \"time-step\": 1931}, {\"errors\": 0.1271751970052719, \"time-step\": 1932}, {\"errors\": 0.1269461065530777, \"time-step\": 1933}, {\"errors\": 0.12671709060668945, \"time-step\": 1934}, {\"errors\": 0.12648825347423553, \"time-step\": 1935}, {\"errors\": 0.12625953555107117, \"time-step\": 1936}, {\"errors\": 0.12603093683719635, \"time-step\": 1937}, {\"errors\": 0.12580248713493347, \"time-step\": 1938}, {\"errors\": 0.12557415664196014, \"time-step\": 1939}, {\"errors\": 0.12534596025943756, \"time-step\": 1940}, {\"errors\": 0.12511788308620453, \"time-step\": 1941}, {\"errors\": 0.12488994747400284, \"time-step\": 1942}, {\"errors\": 0.12466216087341309, \"time-step\": 1943}, {\"errors\": 0.1244344711303711, \"time-step\": 1944}, {\"errors\": 0.1242070123553276, \"time-step\": 1945}, {\"errors\": 0.12397964298725128, \"time-step\": 1946}, {\"errors\": 0.12375238537788391, \"time-step\": 1947}, {\"errors\": 0.12352532148361206, \"time-step\": 1948}, {\"errors\": 0.12329838424921036, \"time-step\": 1949}, {\"errors\": 0.12307158857584, \"time-step\": 1950}, {\"errors\": 0.12284496426582336, \"time-step\": 1951}, {\"errors\": 0.12261846661567688, \"time-step\": 1952}, {\"errors\": 0.12239213287830353, \"time-step\": 1953}, {\"errors\": 0.12216596305370331, \"time-step\": 1954}, {\"errors\": 0.12193992733955383, \"time-step\": 1955}, {\"errors\": 0.1217140406370163, \"time-step\": 1956}, {\"errors\": 0.12148837745189667, \"time-step\": 1957}, {\"errors\": 0.12126277387142181, \"time-step\": 1958}, {\"errors\": 0.12103740870952606, \"time-step\": 1959}, {\"errors\": 0.12081217765808105, \"time-step\": 1960}, {\"errors\": 0.12058711051940918, \"time-step\": 1961}, {\"errors\": 0.12036220729351044, \"time-step\": 1962}, {\"errors\": 0.12013748288154602, \"time-step\": 1963}, {\"errors\": 0.11991290748119354, \"time-step\": 1964}, {\"errors\": 0.1196884959936142, \"time-step\": 1965}, {\"errors\": 0.11946427077054977, \"time-step\": 1966}, {\"errors\": 0.11924022436141968, \"time-step\": 1967}, {\"errors\": 0.11901630461215973, \"time-step\": 1968}, {\"errors\": 0.11879262328147888, \"time-step\": 1969}, {\"errors\": 0.11856907606124878, \"time-step\": 1970}, {\"errors\": 0.1183457002043724, \"time-step\": 1971}, {\"errors\": 0.11812251061201096, \"time-step\": 1972}, {\"errors\": 0.11789948493242264, \"time-step\": 1973}, {\"errors\": 0.11767666786909103, \"time-step\": 1974}, {\"errors\": 0.11745402961969376, \"time-step\": 1975}, {\"errors\": 0.11723160743713379, \"time-step\": 1976}, {\"errors\": 0.11700929701328278, \"time-step\": 1977}, {\"errors\": 0.11678722500801086, \"time-step\": 1978}, {\"errors\": 0.1165652945637703, \"time-step\": 1979}, {\"errors\": 0.11634358763694763, \"time-step\": 1980}, {\"errors\": 0.1161220520734787, \"time-step\": 1981}, {\"errors\": 0.11590072512626648, \"time-step\": 1982}, {\"errors\": 0.1156795546412468, \"time-step\": 1983}, {\"errors\": 0.11545860767364502, \"time-step\": 1984}, {\"errors\": 0.11523783951997757, \"time-step\": 1985}, {\"errors\": 0.11501727998256683, \"time-step\": 1986}, {\"errors\": 0.11479690670967102, \"time-step\": 1987}, {\"errors\": 0.11457672715187073, \"time-step\": 1988}, {\"errors\": 0.11435678601264954, \"time-step\": 1989}, {\"errors\": 0.11413699388504028, \"time-step\": 1990}, {\"errors\": 0.11391744017601013, \"time-step\": 1991}, {\"errors\": 0.11369803547859192, \"time-step\": 1992}, {\"errors\": 0.113478884100914, \"time-step\": 1993}, {\"errors\": 0.11325988918542862, \"time-step\": 1994}, {\"errors\": 0.11304113268852234, \"time-step\": 1995}, {\"errors\": 0.11282260715961456, \"time-step\": 1996}, {\"errors\": 0.11260424554347992, \"time-step\": 1997}, {\"errors\": 0.11238610744476318, \"time-step\": 1998}, {\"errors\": 0.11216818541288376, \"time-step\": 1999}, {\"errors\": 0.11195047944784164, \"time-step\": 2000}, {\"errors\": 0.11173294484615326, \"time-step\": 2001}, {\"errors\": 0.11151567101478577, \"time-step\": 2002}, {\"errors\": 0.1112985908985138, \"time-step\": 2003}, {\"errors\": 0.11108171939849854, \"time-step\": 2004}, {\"errors\": 0.11086509376764297, \"time-step\": 2005}, {\"errors\": 0.11064866185188293, \"time-step\": 2006}, {\"errors\": 0.1104324460029602, \"time-step\": 2007}, {\"errors\": 0.11021646112203598, \"time-step\": 2008}, {\"errors\": 0.11000066995620728, \"time-step\": 2009}, {\"errors\": 0.10978513956069946, \"time-step\": 2010}, {\"errors\": 0.10956982523202896, \"time-step\": 2011}, {\"errors\": 0.10935470461845398, \"time-step\": 2012}, {\"errors\": 0.1091398373246193, \"time-step\": 2013}, {\"errors\": 0.10892520844936371, \"time-step\": 2014}, {\"errors\": 0.10871076583862305, \"time-step\": 2015}, {\"errors\": 0.10849656909704208, \"time-step\": 2016}, {\"errors\": 0.10828261822462082, \"time-step\": 2017}, {\"errors\": 0.10806883871555328, \"time-step\": 2018}, {\"errors\": 0.10785537213087082, \"time-step\": 2019}, {\"errors\": 0.10764209181070328, \"time-step\": 2020}, {\"errors\": 0.10742902755737305, \"time-step\": 2021}, {\"errors\": 0.10721622407436371, \"time-step\": 2022}, {\"errors\": 0.10700365900993347, \"time-step\": 2023}, {\"errors\": 0.10679131746292114, \"time-step\": 2024}, {\"errors\": 0.10657922178506851, \"time-step\": 2025}, {\"errors\": 0.10636735707521439, \"time-step\": 2026}, {\"errors\": 0.10615570843219757, \"time-step\": 2027}, {\"errors\": 0.10594432055950165, \"time-step\": 2028}, {\"errors\": 0.10573316365480423, \"time-step\": 2029}, {\"errors\": 0.10552230477333069, \"time-step\": 2030}, {\"errors\": 0.10531161725521088, \"time-step\": 2031}, {\"errors\": 0.10510119795799255, \"time-step\": 2032}, {\"errors\": 0.10489100962877274, \"time-step\": 2033}, {\"errors\": 0.10468106716871262, \"time-step\": 2034}, {\"errors\": 0.10447138547897339, \"time-step\": 2035}, {\"errors\": 0.10426194220781326, \"time-step\": 2036}, {\"errors\": 0.10405274480581284, \"time-step\": 2037}, {\"errors\": 0.10384377837181091, \"time-step\": 2038}, {\"errors\": 0.10363508015871048, \"time-step\": 2039}, {\"errors\": 0.10342665016651154, \"time-step\": 2040}, {\"errors\": 0.1032184436917305, \"time-step\": 2041}, {\"errors\": 0.10301048308610916, \"time-step\": 2042}, {\"errors\": 0.10280279070138931, \"time-step\": 2043}, {\"errors\": 0.10259536653757095, \"time-step\": 2044}, {\"errors\": 0.1023881733417511, \"time-step\": 2045}, {\"errors\": 0.10218122601509094, \"time-step\": 2046}, {\"errors\": 0.10197456181049347, \"time-step\": 2047}, {\"errors\": 0.1017681360244751, \"time-step\": 2048}, {\"errors\": 0.10156197100877762, \"time-step\": 2049}, {\"errors\": 0.10135606676340103, \"time-step\": 2050}, {\"errors\": 0.10115037858486176, \"time-step\": 2051}, {\"errors\": 0.10094501078128815, \"time-step\": 2052}, {\"errors\": 0.10073989629745483, \"time-step\": 2053}, {\"errors\": 0.10053502023220062, \"time-step\": 2054}, {\"errors\": 0.1003304272890091, \"time-step\": 2055}, {\"errors\": 0.10012608021497726, \"time-step\": 2056}, {\"errors\": 0.09992196410894394, \"time-step\": 2057}, {\"errors\": 0.09971817582845688, \"time-step\": 2058}, {\"errors\": 0.09951458871364594, \"time-step\": 2059}, {\"errors\": 0.09931132942438126, \"time-step\": 2060}, {\"errors\": 0.09910828620195389, \"time-step\": 2061}, {\"errors\": 0.0989055186510086, \"time-step\": 2062}, {\"errors\": 0.09870303422212601, \"time-step\": 2063}, {\"errors\": 0.0985008254647255, \"time-step\": 2064}, {\"errors\": 0.09829886257648468, \"time-step\": 2065}, {\"errors\": 0.09809716045856476, \"time-step\": 2066}, {\"errors\": 0.09789576381444931, \"time-step\": 2067}, {\"errors\": 0.09769464284181595, \"time-step\": 2068}, {\"errors\": 0.0974937304854393, \"time-step\": 2069}, {\"errors\": 0.09729315340518951, \"time-step\": 2070}, {\"errors\": 0.09709281474351883, \"time-step\": 2071}, {\"errors\": 0.09689273685216904, \"time-step\": 2072}, {\"errors\": 0.09669297933578491, \"time-step\": 2073}, {\"errors\": 0.09649346768856049, \"time-step\": 2074}, {\"errors\": 0.09629422426223755, \"time-step\": 2075}, {\"errors\": 0.09609527140855789, \"time-step\": 2076}, {\"errors\": 0.09589659422636032, \"time-step\": 2077}, {\"errors\": 0.09569819271564484, \"time-step\": 2078}, {\"errors\": 0.09550005942583084, \"time-step\": 2079}, {\"errors\": 0.09530220180749893, \"time-step\": 2080}, {\"errors\": 0.0951046347618103, \"time-step\": 2081}, {\"errors\": 0.09490734338760376, \"time-step\": 2082}, {\"errors\": 0.09471036493778229, \"time-step\": 2083}, {\"errors\": 0.09451359510421753, \"time-step\": 2084}, {\"errors\": 0.09431716799736023, \"time-step\": 2085}, {\"errors\": 0.09412097185850143, \"time-step\": 2086}, {\"errors\": 0.09392508864402771, \"time-step\": 2087}, {\"errors\": 0.09372948110103607, \"time-step\": 2088}, {\"errors\": 0.09353415668010712, \"time-step\": 2089}, {\"errors\": 0.09333913028240204, \"time-step\": 2090}, {\"errors\": 0.09314437210559845, \"time-step\": 2091}, {\"errors\": 0.09294994175434113, \"time-step\": 2092}, {\"errors\": 0.09275570511817932, \"time-step\": 2093}, {\"errors\": 0.09256181120872498, \"time-step\": 2094}, {\"errors\": 0.09236817061901093, \"time-step\": 2095}, {\"errors\": 0.09217486530542374, \"time-step\": 2096}, {\"errors\": 0.09198185056447983, \"time-step\": 2097}, {\"errors\": 0.091789111495018, \"time-step\": 2098}, {\"errors\": 0.0915965810418129, \"time-step\": 2099}, {\"errors\": 0.09140443801879883, \"time-step\": 2100}, {\"errors\": 0.09121255576610565, \"time-step\": 2101}, {\"errors\": 0.09102091938257217, \"time-step\": 2102}, {\"errors\": 0.09082963317632675, \"time-step\": 2103}, {\"errors\": 0.09063860774040222, \"time-step\": 2104}, {\"errors\": 0.09044790267944336, \"time-step\": 2105}, {\"errors\": 0.09025748074054718, \"time-step\": 2106}, {\"errors\": 0.0900672972202301, \"time-step\": 2107}, {\"errors\": 0.08987745642662048, \"time-step\": 2108}, {\"errors\": 0.08968791365623474, \"time-step\": 2109}, {\"errors\": 0.0894986242055893, \"time-step\": 2110}, {\"errors\": 0.08930965512990952, \"time-step\": 2111}, {\"errors\": 0.08912099897861481, \"time-step\": 2112}, {\"errors\": 0.0889325886964798, \"time-step\": 2113}, {\"errors\": 0.08874447643756866, \"time-step\": 2114}, {\"errors\": 0.0885566994547844, \"time-step\": 2115}, {\"errors\": 0.08836919069290161, \"time-step\": 2116}, {\"errors\": 0.0881819874048233, \"time-step\": 2117}, {\"errors\": 0.08799508959054947, \"time-step\": 2118}, {\"errors\": 0.08780848234891891, \"time-step\": 2119}, {\"errors\": 0.08762214332818985, \"time-step\": 2120}, {\"errors\": 0.08743615448474884, \"time-step\": 2121}, {\"errors\": 0.08725041896104813, \"time-step\": 2122}, {\"errors\": 0.08706500381231308, \"time-step\": 2123}, {\"errors\": 0.08687985688447952, \"time-step\": 2124}, {\"errors\": 0.08669501543045044, \"time-step\": 2125}, {\"errors\": 0.08651050180196762, \"time-step\": 2126}, {\"errors\": 0.08632627874612808, \"time-step\": 2127}, {\"errors\": 0.08614233136177063, \"time-step\": 2128}, {\"errors\": 0.08595868945121765, \"time-step\": 2129}, {\"errors\": 0.08577535301446915, \"time-step\": 2130}, {\"errors\": 0.08559231460094452, \"time-step\": 2131}, {\"errors\": 0.08540961146354675, \"time-step\": 2132}, {\"errors\": 0.08522716164588928, \"time-step\": 2133}, {\"errors\": 0.08504501730203629, \"time-step\": 2134}, {\"errors\": 0.08486319333314896, \"time-step\": 2135}, {\"errors\": 0.08468165993690491, \"time-step\": 2136}, {\"errors\": 0.08450044691562653, \"time-step\": 2137}, {\"errors\": 0.08431949466466904, \"time-step\": 2138}, {\"errors\": 0.08413886278867722, \"time-step\": 2139}, {\"errors\": 0.08395857363939285, \"time-step\": 2140}, {\"errors\": 0.08377856016159058, \"time-step\": 2141}, {\"errors\": 0.08359885215759277, \"time-step\": 2142}, {\"errors\": 0.08341942727565765, \"time-step\": 2143}, {\"errors\": 0.0832403302192688, \"time-step\": 2144}, {\"errors\": 0.08306150883436203, \"time-step\": 2145}, {\"errors\": 0.08288301527500153, \"time-step\": 2146}, {\"errors\": 0.08270479738712311, \"time-step\": 2147}, {\"errors\": 0.08252690732479095, \"time-step\": 2148}, {\"errors\": 0.08234934508800507, \"time-step\": 2149}, {\"errors\": 0.08217205107212067, \"time-step\": 2150}, {\"errors\": 0.08199506998062134, \"time-step\": 2151}, {\"errors\": 0.08181837946176529, \"time-step\": 2152}, {\"errors\": 0.0816420465707779, \"time-step\": 2153}, {\"errors\": 0.0814659520983696, \"time-step\": 2154}, {\"errors\": 0.08129020780324936, \"time-step\": 2155}, {\"errors\": 0.0811147689819336, \"time-step\": 2156}, {\"errors\": 0.08093961328268051, \"time-step\": 2157}, {\"errors\": 0.0807647854089737, \"time-step\": 2158}, {\"errors\": 0.08059023320674896, \"time-step\": 2159}, {\"errors\": 0.0804159939289093, \"time-step\": 2160}, {\"errors\": 0.0802420973777771, \"time-step\": 2161}, {\"errors\": 0.08006848394870758, \"time-step\": 2162}, {\"errors\": 0.07989516854286194, \"time-step\": 2163}, {\"errors\": 0.07972218096256256, \"time-step\": 2164}, {\"errors\": 0.07954947650432587, \"time-step\": 2165}, {\"errors\": 0.07937711477279663, \"time-step\": 2166}, {\"errors\": 0.07920504361391068, \"time-step\": 2167}, {\"errors\": 0.0790332481265068, \"time-step\": 2168}, {\"errors\": 0.0788617879152298, \"time-step\": 2169}, {\"errors\": 0.07869064062833786, \"time-step\": 2170}, {\"errors\": 0.0785197764635086, \"time-step\": 2171}, {\"errors\": 0.07834924012422562, \"time-step\": 2172}, {\"errors\": 0.0781790167093277, \"time-step\": 2173}, {\"errors\": 0.07800909876823425, \"time-step\": 2174}, {\"errors\": 0.07783948630094528, \"time-step\": 2175}, {\"errors\": 0.077670156955719, \"time-step\": 2176}, {\"errors\": 0.07750117033720016, \"time-step\": 2177}, {\"errors\": 0.07733248919248581, \"time-step\": 2178}, {\"errors\": 0.07716409862041473, \"time-step\": 2179}, {\"errors\": 0.07699602842330933, \"time-step\": 2180}, {\"errors\": 0.0768282562494278, \"time-step\": 2181}, {\"errors\": 0.07666079699993134, \"time-step\": 2182}, {\"errors\": 0.07649365067481995, \"time-step\": 2183}, {\"errors\": 0.07632680237293243, \"time-step\": 2184}, {\"errors\": 0.07616028934717178, \"time-step\": 2185}, {\"errors\": 0.07599405944347382, \"time-step\": 2186}, {\"errors\": 0.07582813501358032, \"time-step\": 2187}, {\"errors\": 0.0756625384092331, \"time-step\": 2188}, {\"errors\": 0.07549723237752914, \"time-step\": 2189}, {\"errors\": 0.07533224672079086, \"time-step\": 2190}, {\"errors\": 0.07516756653785706, \"time-step\": 2191}, {\"errors\": 0.07500320672988892, \"time-step\": 2192}, {\"errors\": 0.07483913004398346, \"time-step\": 2193}, {\"errors\": 0.07467538863420486, \"time-step\": 2194}, {\"errors\": 0.07451193034648895, \"time-step\": 2195}, {\"errors\": 0.0743487998843193, \"time-step\": 2196}, {\"errors\": 0.07418598234653473, \"time-step\": 2197}, {\"errors\": 0.07402347028255463, \"time-step\": 2198}, {\"errors\": 0.0738612487912178, \"time-step\": 2199}, {\"errors\": 0.07369936257600784, \"time-step\": 2200}, {\"errors\": 0.07353775948286057, \"time-step\": 2201}, {\"errors\": 0.07337649166584015, \"time-step\": 2202}, {\"errors\": 0.07321550697088242, \"time-step\": 2203}, {\"errors\": 0.07305484265089035, \"time-step\": 2204}, {\"errors\": 0.07289446890354156, \"time-step\": 2205}, {\"errors\": 0.07273440808057785, \"time-step\": 2206}, {\"errors\": 0.072574682533741, \"time-step\": 2207}, {\"errors\": 0.07241526991128922, \"time-step\": 2208}, {\"errors\": 0.07225612550973892, \"time-step\": 2209}, {\"errors\": 0.0720973089337349, \"time-step\": 2210}, {\"errors\": 0.07193880528211594, \"time-step\": 2211}, {\"errors\": 0.07178058475255966, \"time-step\": 2212}, {\"errors\": 0.07162270694971085, \"time-step\": 2213}, {\"errors\": 0.07146512717008591, \"time-step\": 2214}, {\"errors\": 0.07130783796310425, \"time-step\": 2215}, {\"errors\": 0.07115086913108826, \"time-step\": 2216}, {\"errors\": 0.07099422812461853, \"time-step\": 2217}, {\"errors\": 0.07083787024021149, \"time-step\": 2218}, {\"errors\": 0.07068182528018951, \"time-step\": 2219}, {\"errors\": 0.07052607089281082, \"time-step\": 2220}, {\"errors\": 0.0703706443309784, \"time-step\": 2221}, {\"errors\": 0.07021550089120865, \"time-step\": 2222}, {\"errors\": 0.07006069272756577, \"time-step\": 2223}, {\"errors\": 0.06990617513656616, \"time-step\": 2224}, {\"errors\": 0.06975196301937103, \"time-step\": 2225}, {\"errors\": 0.06959807872772217, \"time-step\": 2226}, {\"errors\": 0.06944449990987778, \"time-step\": 2227}, {\"errors\": 0.06929120421409607, \"time-step\": 2228}, {\"errors\": 0.06913822889328003, \"time-step\": 2229}, {\"errors\": 0.06898555159568787, \"time-step\": 2230}, {\"errors\": 0.06883318722248077, \"time-step\": 2231}, {\"errors\": 0.06868110597133636, \"time-step\": 2232}, {\"errors\": 0.06852935999631882, \"time-step\": 2233}, {\"errors\": 0.06837791949510574, \"time-step\": 2234}, {\"errors\": 0.06822677701711655, \"time-step\": 2235}, {\"errors\": 0.06807593256235123, \"time-step\": 2236}, {\"errors\": 0.06792537868022919, \"time-step\": 2237}, {\"errors\": 0.06777515262365341, \"time-step\": 2238}, {\"errors\": 0.0676252543926239, \"time-step\": 2239}, {\"errors\": 0.06747560203075409, \"time-step\": 2240}, {\"errors\": 0.06732630729675293, \"time-step\": 2241}, {\"errors\": 0.06717727333307266, \"time-step\": 2242}, {\"errors\": 0.06702855974435806, \"time-step\": 2243}, {\"errors\": 0.06688015908002853, \"time-step\": 2244}, {\"errors\": 0.06673206388950348, \"time-step\": 2245}, {\"errors\": 0.06658423691987991, \"time-step\": 2246}, {\"errors\": 0.066436767578125, \"time-step\": 2247}, {\"errors\": 0.06628959625959396, \"time-step\": 2248}, {\"errors\": 0.06614265590906143, \"time-step\": 2249}, {\"errors\": 0.06599611788988113, \"time-step\": 2250}, {\"errors\": 0.06584982573986053, \"time-step\": 2251}, {\"errors\": 0.0657038539648056, \"time-step\": 2252}, {\"errors\": 0.06555813550949097, \"time-step\": 2253}, {\"errors\": 0.06541275233030319, \"time-step\": 2254}, {\"errors\": 0.06526768952608109, \"time-step\": 2255}, {\"errors\": 0.06512291729450226, \"time-step\": 2256}, {\"errors\": 0.06497843563556671, \"time-step\": 2257}, {\"errors\": 0.06483427435159683, \"time-step\": 2258}, {\"errors\": 0.06469037383794785, \"time-step\": 2259}, {\"errors\": 0.06454681605100632, \"time-step\": 2260}, {\"errors\": 0.06440355628728867, \"time-step\": 2261}, {\"errors\": 0.0642605796456337, \"time-step\": 2262}, {\"errors\": 0.06411789357662201, \"time-step\": 2263}, {\"errors\": 0.06397553533315659, \"time-step\": 2264}, {\"errors\": 0.06383346021175385, \"time-step\": 2265}, {\"errors\": 0.06369167566299438, \"time-step\": 2266}, {\"errors\": 0.0635501816868782, \"time-step\": 2267}, {\"errors\": 0.06340903043746948, \"time-step\": 2268}, {\"errors\": 0.06326813250780106, \"time-step\": 2269}, {\"errors\": 0.06312756985425949, \"time-step\": 2270}, {\"errors\": 0.06298727542161942, \"time-step\": 2271}, {\"errors\": 0.06284727156162262, \"time-step\": 2272}, {\"errors\": 0.06270758807659149, \"time-step\": 2273}, {\"errors\": 0.06256821006536484, \"time-step\": 2274}, {\"errors\": 0.06242910027503967, \"time-step\": 2275}, {\"errors\": 0.06229030713438988, \"time-step\": 2276}, {\"errors\": 0.06215181574225426, \"time-step\": 2277}, {\"errors\": 0.06201360374689102, \"time-step\": 2278}, {\"errors\": 0.061875686049461365, \"time-step\": 2279}, {\"errors\": 0.06173808127641678, \"time-step\": 2280}, {\"errors\": 0.06160072982311249, \"time-step\": 2281}, {\"errors\": 0.06146373227238655, \"time-step\": 2282}, {\"errors\": 0.06132698431611061, \"time-step\": 2283}, {\"errors\": 0.06119054928421974, \"time-step\": 2284}, {\"errors\": 0.061054401099681854, \"time-step\": 2285}, {\"errors\": 0.060918569564819336, \"time-step\": 2286}, {\"errors\": 0.0607830174267292, \"time-step\": 2287}, {\"errors\": 0.06064772605895996, \"time-step\": 2288}, {\"errors\": 0.06051274389028549, \"time-step\": 2289}, {\"errors\": 0.06037807837128639, \"time-step\": 2290}, {\"errors\": 0.06024370342493057, \"time-step\": 2291}, {\"errors\": 0.06010960787534714, \"time-step\": 2292}, {\"errors\": 0.05997578799724579, \"time-step\": 2293}, {\"errors\": 0.05984225869178772, \"time-step\": 2294}, {\"errors\": 0.059709057211875916, \"time-step\": 2295}, {\"errors\": 0.0595761239528656, \"time-step\": 2296}, {\"errors\": 0.05944349244236946, \"time-step\": 2297}, {\"errors\": 0.05931110680103302, \"time-step\": 2298}, {\"errors\": 0.05917905271053314, \"time-step\": 2299}, {\"errors\": 0.05904727801680565, \"time-step\": 2300}, {\"errors\": 0.05891577899456024, \"time-step\": 2301}, {\"errors\": 0.058784596621990204, \"time-step\": 2302}, {\"errors\": 0.05865369737148285, \"time-step\": 2303}, {\"errors\": 0.05852307751774788, \"time-step\": 2304}, {\"errors\": 0.05839274078607559, \"time-step\": 2305}, {\"errors\": 0.058262694627046585, \"time-step\": 2306}, {\"errors\": 0.05813293159008026, \"time-step\": 2307}, {\"errors\": 0.05800343677401543, \"time-step\": 2308}, {\"errors\": 0.05787426605820656, \"time-step\": 2309}, {\"errors\": 0.05774536728858948, \"time-step\": 2310}, {\"errors\": 0.057616740465164185, \"time-step\": 2311}, {\"errors\": 0.05748843029141426, \"time-step\": 2312}, {\"errors\": 0.057360369712114334, \"time-step\": 2313}, {\"errors\": 0.05723261833190918, \"time-step\": 2314}, {\"errors\": 0.057105131447315216, \"time-step\": 2315}, {\"errors\": 0.05697793513536453, \"time-step\": 2316}, {\"errors\": 0.05685102194547653, \"time-step\": 2317}, {\"errors\": 0.056724414229393005, \"time-step\": 2318}, {\"errors\": 0.05659804120659828, \"time-step\": 2319}, {\"errors\": 0.05647200345993042, \"time-step\": 2320}, {\"errors\": 0.05634620785713196, \"time-step\": 2321}, {\"errors\": 0.05622069537639618, \"time-step\": 2322}, {\"errors\": 0.056095484644174576, \"time-step\": 2323}, {\"errors\": 0.055970557034015656, \"time-step\": 2324}, {\"errors\": 0.055845897644758224, \"time-step\": 2325}, {\"errors\": 0.05572152137756348, \"time-step\": 2326}, {\"errors\": 0.05559743568301201, \"time-step\": 2327}, {\"errors\": 0.055473603308200836, \"time-step\": 2328}, {\"errors\": 0.055350080132484436, \"time-step\": 2329}, {\"errors\": 0.05522681400179863, \"time-step\": 2330}, {\"errors\": 0.0551038458943367, \"time-step\": 2331}, {\"errors\": 0.054981134831905365, \"time-step\": 2332}, {\"errors\": 0.05485871061682701, \"time-step\": 2333}, {\"errors\": 0.05473654344677925, \"time-step\": 2334}, {\"errors\": 0.05461467057466507, \"time-step\": 2335}, {\"errors\": 0.054493095725774765, \"time-step\": 2336}, {\"errors\": 0.054371755570173264, \"time-step\": 2337}, {\"errors\": 0.05425069481134415, \"time-step\": 2338}, {\"errors\": 0.054129939526319504, \"time-step\": 2339}, {\"errors\": 0.05400943383574486, \"time-step\": 2340}, {\"errors\": 0.05388922989368439, \"time-step\": 2341}, {\"errors\": 0.05376926437020302, \"time-step\": 2342}, {\"errors\": 0.05364958196878433, \"time-step\": 2343}, {\"errors\": 0.05353020131587982, \"time-step\": 2344}, {\"errors\": 0.05341107398271561, \"time-step\": 2345}, {\"errors\": 0.053292207419872284, \"time-step\": 2346}, {\"errors\": 0.05317363142967224, \"time-step\": 2347}, {\"errors\": 0.0530553013086319, \"time-step\": 2348}, {\"errors\": 0.05293726176023483, \"time-step\": 2349}, {\"errors\": 0.052819494158029556, \"time-step\": 2350}, {\"errors\": 0.05270199850201607, \"time-step\": 2351}, {\"errors\": 0.052584756165742874, \"time-step\": 2352}, {\"errors\": 0.05246780440211296, \"time-step\": 2353}, {\"errors\": 0.05235110595822334, \"time-step\": 2354}, {\"errors\": 0.05223468318581581, \"time-step\": 2355}, {\"errors\": 0.05211852490901947, \"time-step\": 2356}, {\"errors\": 0.05200263112783432, \"time-step\": 2357}, {\"errors\": 0.051887013018131256, \"time-step\": 2358}, {\"errors\": 0.05177165940403938, \"time-step\": 2359}, {\"errors\": 0.051656574010849, \"time-step\": 2360}, {\"errors\": 0.051541734486818314, \"time-step\": 2361}, {\"errors\": 0.051427192986011505, \"time-step\": 2362}, {\"errors\": 0.051312901079654694, \"time-step\": 2363}, {\"errors\": 0.05119886249303818, \"time-step\": 2364}, {\"errors\": 0.051085107028484344, \"time-step\": 2365}, {\"errors\": 0.0509716160595417, \"time-step\": 2366}, {\"errors\": 0.050858382135629654, \"time-step\": 2367}, {\"errors\": 0.050745416432619095, \"time-step\": 2368}, {\"errors\": 0.05063271522521973, \"time-step\": 2369}, {\"errors\": 0.05052027851343155, \"time-step\": 2370}, {\"errors\": 0.05040806531906128, \"time-step\": 2371}, {\"errors\": 0.05029613897204399, \"time-step\": 2372}, {\"errors\": 0.050184495747089386, \"time-step\": 2373}, {\"errors\": 0.05007307231426239, \"time-step\": 2374}, {\"errors\": 0.04996193200349808, \"time-step\": 2375}, {\"errors\": 0.049851059913635254, \"time-step\": 2376}, {\"errors\": 0.049740418791770935, \"time-step\": 2377}, {\"errors\": 0.049630071967840195, \"time-step\": 2378}, {\"errors\": 0.04951995983719826, \"time-step\": 2379}, {\"errors\": 0.04941011220216751, \"time-step\": 2380}, {\"errors\": 0.04930055886507034, \"time-step\": 2381}, {\"errors\": 0.04919121414422989, \"time-step\": 2382}, {\"errors\": 0.049082107841968536, \"time-step\": 2383}, {\"errors\": 0.04897329956293106, \"time-step\": 2384}, {\"errors\": 0.04886474460363388, \"time-step\": 2385}, {\"errors\": 0.0487564280629158, \"time-step\": 2386}, {\"errors\": 0.04864838719367981, \"time-step\": 2387}, {\"errors\": 0.04854058474302292, \"time-step\": 2388}, {\"errors\": 0.048433031886816025, \"time-step\": 2389}, {\"errors\": 0.04832573980093002, \"time-step\": 2390}, {\"errors\": 0.04821871593594551, \"time-step\": 2391}, {\"errors\": 0.048111915588378906, \"time-step\": 2392}, {\"errors\": 0.04800537973642349, \"time-step\": 2393}, {\"errors\": 0.04789910092949867, \"time-step\": 2394}, {\"errors\": 0.04779306799173355, \"time-step\": 2395}, {\"errors\": 0.047687284648418427, \"time-step\": 2396}, {\"errors\": 0.047581747174263, \"time-step\": 2397}, {\"errors\": 0.04747648537158966, \"time-step\": 2398}, {\"errors\": 0.047371454536914825, \"time-step\": 2399}, {\"errors\": 0.047266677021980286, \"time-step\": 2400}, {\"errors\": 0.04716213047504425, \"time-step\": 2401}, {\"errors\": 0.04705784469842911, \"time-step\": 2402}, {\"errors\": 0.046953827142715454, \"time-step\": 2403}, {\"errors\": 0.04685003310441971, \"time-step\": 2404}, {\"errors\": 0.046746496111154556, \"time-step\": 2405}, {\"errors\": 0.0466432124376297, \"time-step\": 2406}, {\"errors\": 0.046540144830942154, \"time-step\": 2407}, {\"errors\": 0.0464373342692852, \"time-step\": 2408}, {\"errors\": 0.04633479192852974, \"time-step\": 2409}, {\"errors\": 0.04623245447874069, \"time-step\": 2410}, {\"errors\": 0.04613039642572403, \"time-step\": 2411}, {\"errors\": 0.04602857679128647, \"time-step\": 2412}, {\"errors\": 0.04592697694897652, \"time-step\": 2413}, {\"errors\": 0.04582562297582626, \"time-step\": 2414}, {\"errors\": 0.045724548399448395, \"time-step\": 2415}, {\"errors\": 0.04562368616461754, \"time-step\": 2416}, {\"errors\": 0.045523062348365784, \"time-step\": 2417}, {\"errors\": 0.04542271047830582, \"time-step\": 2418}, {\"errors\": 0.045322567224502563, \"time-step\": 2419}, {\"errors\": 0.04522266238927841, \"time-step\": 2420}, {\"errors\": 0.04512302950024605, \"time-step\": 2421}, {\"errors\": 0.045023612678050995, \"time-step\": 2422}, {\"errors\": 0.044924430549144745, \"time-step\": 2423}, {\"errors\": 0.04482549428939819, \"time-step\": 2424}, {\"errors\": 0.04472678154706955, \"time-step\": 2425}, {\"errors\": 0.0446283221244812, \"time-step\": 2426}, {\"errors\": 0.04453009366989136, \"time-step\": 2427}, {\"errors\": 0.04443208873271942, \"time-step\": 2428}, {\"errors\": 0.04433433711528778, \"time-step\": 2429}, {\"errors\": 0.044236816465854645, \"time-step\": 2430}, {\"errors\": 0.04413953423500061, \"time-step\": 2431}, {\"errors\": 0.044042497873306274, \"time-step\": 2432}, {\"errors\": 0.043945662677288055, \"time-step\": 2433}, {\"errors\": 0.04384910315275192, \"time-step\": 2434}, {\"errors\": 0.04375274479389191, \"time-step\": 2435}, {\"errors\": 0.043656617403030396, \"time-step\": 2436}, {\"errors\": 0.043560732156038284, \"time-step\": 2437}, {\"errors\": 0.04346508905291557, \"time-step\": 2438}, {\"errors\": 0.04336967691779137, \"time-step\": 2439}, {\"errors\": 0.04327448084950447, \"time-step\": 2440}, {\"errors\": 0.043179530650377274, \"time-step\": 2441}, {\"errors\": 0.043084803968667984, \"time-step\": 2442}, {\"errors\": 0.042990297079086304, \"time-step\": 2443}, {\"errors\": 0.04289602115750313, \"time-step\": 2444}, {\"errors\": 0.04280197247862816, \"time-step\": 2445}, {\"errors\": 0.0427081435918808, \"time-step\": 2446}, {\"errors\": 0.04261458292603493, \"time-step\": 2447}, {\"errors\": 0.042521219700574875, \"time-step\": 2448}, {\"errors\": 0.042428094893693924, \"time-step\": 2449}, {\"errors\": 0.042335182428359985, \"time-step\": 2450}, {\"errors\": 0.042242493480443954, \"time-step\": 2451}, {\"errors\": 0.04215003550052643, \"time-step\": 2452}, {\"errors\": 0.04205780103802681, \"time-step\": 2453}, {\"errors\": 0.0419657863676548, \"time-step\": 2454}, {\"errors\": 0.041874002665281296, \"time-step\": 2455}, {\"errors\": 0.04178246483206749, \"time-step\": 2456}, {\"errors\": 0.04169110581278801, \"time-step\": 2457}, {\"errors\": 0.041600000113248825, \"time-step\": 2458}, {\"errors\": 0.041509099304676056, \"time-step\": 2459}, {\"errors\": 0.041418448090553284, \"time-step\": 2460}, {\"errors\": 0.041327979415655136, \"time-step\": 2461}, {\"errors\": 0.04123775288462639, \"time-step\": 2462}, {\"errors\": 0.041147734969854355, \"time-step\": 2463}, {\"errors\": 0.04105796664953232, \"time-step\": 2464}, {\"errors\": 0.040968380868434906, \"time-step\": 2465}, {\"errors\": 0.0408790297806263, \"time-step\": 2466}, {\"errors\": 0.040789902210235596, \"time-step\": 2467}, {\"errors\": 0.04070097953081131, \"time-step\": 2468}, {\"errors\": 0.04061229154467583, \"time-step\": 2469}, {\"errors\": 0.04052380472421646, \"time-step\": 2470}, {\"errors\": 0.0404355525970459, \"time-step\": 2471}, {\"errors\": 0.04034748300909996, \"time-step\": 2472}, {\"errors\": 0.04025966674089432, \"time-step\": 2473}, {\"errors\": 0.040172040462493896, \"time-step\": 2474}, {\"errors\": 0.040084630250930786, \"time-step\": 2475}, {\"errors\": 0.03999745100736618, \"time-step\": 2476}, {\"errors\": 0.03991047292947769, \"time-step\": 2477}, {\"errors\": 0.03982369974255562, \"time-step\": 2478}, {\"errors\": 0.03973715379834175, \"time-step\": 2479}, {\"errors\": 0.039650801569223404, \"time-step\": 2480}, {\"errors\": 0.039564669132232666, \"time-step\": 2481}, {\"errors\": 0.039478760212659836, \"time-step\": 2482}, {\"errors\": 0.03939305990934372, \"time-step\": 2483}, {\"errors\": 0.03930756449699402, \"time-step\": 2484}, {\"errors\": 0.03922228887677193, \"time-step\": 2485}, {\"errors\": 0.03913720324635506, \"time-step\": 2486}, {\"errors\": 0.03905235603451729, \"time-step\": 2487}, {\"errors\": 0.03896770626306534, \"time-step\": 2488}, {\"errors\": 0.038883231580257416, \"time-step\": 2489}, {\"errors\": 0.03879900649189949, \"time-step\": 2490}, {\"errors\": 0.038714971393346786, \"time-step\": 2491}, {\"errors\": 0.0386311300098896, \"time-step\": 2492}, {\"errors\": 0.03854752704501152, \"time-step\": 2493}, {\"errors\": 0.03846411779522896, \"time-step\": 2494}, {\"errors\": 0.03838091716170311, \"time-step\": 2495}, {\"errors\": 0.03829789534211159, \"time-step\": 2496}, {\"errors\": 0.038215115666389465, \"time-step\": 2497}, {\"errors\": 0.03813249617815018, \"time-step\": 2498}, {\"errors\": 0.038050100207328796, \"time-step\": 2499}, {\"errors\": 0.03796791285276413, \"time-step\": 2500}, {\"errors\": 0.03788593411445618, \"time-step\": 2501}, {\"errors\": 0.037804145365953445, \"time-step\": 2502}, {\"errors\": 0.037722572684288025, \"time-step\": 2503}, {\"errors\": 0.03764118254184723, \"time-step\": 2504}, {\"errors\": 0.03755999729037285, \"time-step\": 2505}, {\"errors\": 0.03747903183102608, \"time-step\": 2506}, {\"errors\": 0.03739825263619423, \"time-step\": 2507}, {\"errors\": 0.037317659705877304, \"time-step\": 2508}, {\"errors\": 0.03723728656768799, \"time-step\": 2509}, {\"errors\": 0.0371570959687233, \"time-step\": 2510}, {\"errors\": 0.03707712143659592, \"time-step\": 2511}, {\"errors\": 0.03699732944369316, \"time-step\": 2512}, {\"errors\": 0.03691774234175682, \"time-step\": 2513}, {\"errors\": 0.0368383452296257, \"time-step\": 2514}, {\"errors\": 0.0367591567337513, \"time-step\": 2515}, {\"errors\": 0.03668016567826271, \"time-step\": 2516}, {\"errors\": 0.03660134598612785, \"time-step\": 2517}, {\"errors\": 0.03652273118495941, \"time-step\": 2518}, {\"errors\": 0.03644431382417679, \"time-step\": 2519}, {\"errors\": 0.03636608645319939, \"time-step\": 2520}, {\"errors\": 0.036288052797317505, \"time-step\": 2521}, {\"errors\": 0.03621021658182144, \"time-step\": 2522}, {\"errors\": 0.036132581532001495, \"time-step\": 2523}, {\"errors\": 0.036055125296115875, \"time-step\": 2524}, {\"errors\": 0.03597788140177727, \"time-step\": 2525}, {\"errors\": 0.035900793969631195, \"time-step\": 2526}, {\"errors\": 0.03582392632961273, \"time-step\": 2527}, {\"errors\": 0.035747237503528595, \"time-step\": 2528}, {\"errors\": 0.03567075356841087, \"time-step\": 2529}, {\"errors\": 0.035594452172517776, \"time-step\": 2530}, {\"errors\": 0.035518333315849304, \"time-step\": 2531}, {\"errors\": 0.03544239699840546, \"time-step\": 2532}, {\"errors\": 0.03536665812134743, \"time-step\": 2533}, {\"errors\": 0.03529110178351402, \"time-step\": 2534}, {\"errors\": 0.03521574288606644, \"time-step\": 2535}, {\"errors\": 0.03514057770371437, \"time-step\": 2536}, {\"errors\": 0.03506557643413544, \"time-step\": 2537}, {\"errors\": 0.03499075770378113, \"time-step\": 2538}, {\"errors\": 0.03491615504026413, \"time-step\": 2539}, {\"errors\": 0.03484172746539116, \"time-step\": 2540}, {\"errors\": 0.03476746380329132, \"time-step\": 2541}, {\"errors\": 0.0346934013068676, \"time-step\": 2542}, {\"errors\": 0.034619517624378204, \"time-step\": 2543}, {\"errors\": 0.03454583138227463, \"time-step\": 2544}, {\"errors\": 0.03447230905294418, \"time-step\": 2545}, {\"errors\": 0.03439897298812866, \"time-step\": 2546}, {\"errors\": 0.034325823187828064, \"time-step\": 2547}, {\"errors\": 0.03425287455320358, \"time-step\": 2548}, {\"errors\": 0.03418007493019104, \"time-step\": 2549}, {\"errors\": 0.034107450395822525, \"time-step\": 2550}, {\"errors\": 0.03403502330183983, \"time-step\": 2551}, {\"errors\": 0.033962786197662354, \"time-step\": 2552}, {\"errors\": 0.0338907316327095, \"time-step\": 2553}, {\"errors\": 0.03381883725523949, \"time-step\": 2554}, {\"errors\": 0.03374712914228439, \"time-step\": 2555}, {\"errors\": 0.033675599843263626, \"time-step\": 2556}, {\"errors\": 0.03360426053404808, \"time-step\": 2557}, {\"errors\": 0.03353308141231537, \"time-step\": 2558}, {\"errors\": 0.03346209228038788, \"time-step\": 2559}, {\"errors\": 0.033391259610652924, \"time-step\": 2560}, {\"errors\": 0.033320631831884384, \"time-step\": 2561}, {\"errors\": 0.033250145614147186, \"time-step\": 2562}, {\"errors\": 0.03317985683679581, \"time-step\": 2563}, {\"errors\": 0.03310973197221756, \"time-step\": 2564}, {\"errors\": 0.03303977847099304, \"time-step\": 2565}, {\"errors\": 0.032970014959573746, \"time-step\": 2566}, {\"errors\": 0.03290041536092758, \"time-step\": 2567}, {\"errors\": 0.032830994576215744, \"time-step\": 2568}, {\"errors\": 0.03276173770427704, \"time-step\": 2569}, {\"errors\": 0.03269265592098236, \"time-step\": 2570}, {\"errors\": 0.032623738050460815, \"time-step\": 2571}, {\"errors\": 0.03255501389503479, \"time-step\": 2572}, {\"errors\": 0.032486461102962494, \"time-step\": 2573}, {\"errors\": 0.032418061047792435, \"time-step\": 2574}, {\"errors\": 0.0323498398065567, \"time-step\": 2575}, {\"errors\": 0.0322817787528038, \"time-step\": 2576}, {\"errors\": 0.03221388906240463, \"time-step\": 2577}, {\"errors\": 0.03214618191123009, \"time-step\": 2578}, {\"errors\": 0.03207862749695778, \"time-step\": 2579}, {\"errors\": 0.0320112444460392, \"time-step\": 2580}, {\"errors\": 0.03194403648376465, \"time-step\": 2581}, {\"errors\": 0.03187698498368263, \"time-step\": 2582}, {\"errors\": 0.03181011602282524, \"time-step\": 2583}, {\"errors\": 0.03174339234828949, \"time-step\": 2584}, {\"errors\": 0.03167685121297836, \"time-step\": 2585}, {\"errors\": 0.03161046653985977, \"time-step\": 2586}, {\"errors\": 0.03154425323009491, \"time-step\": 2587}, {\"errors\": 0.031478215008974075, \"time-step\": 2588}, {\"errors\": 0.031412336975336075, \"time-step\": 2589}, {\"errors\": 0.03134661540389061, \"time-step\": 2590}, {\"errors\": 0.03128105029463768, \"time-step\": 2591}, {\"errors\": 0.03121565654873848, \"time-step\": 2592}, {\"errors\": 0.03115043416619301, \"time-step\": 2593}, {\"errors\": 0.031085360795259476, \"time-step\": 2594}, {\"errors\": 0.031020451337099075, \"time-step\": 2595}, {\"errors\": 0.030955694615840912, \"time-step\": 2596}, {\"errors\": 0.03089112415909767, \"time-step\": 2597}, {\"errors\": 0.030826689675450325, \"time-step\": 2598}, {\"errors\": 0.03076242096722126, \"time-step\": 2599}, {\"errors\": 0.030698323622345924, \"time-step\": 2600}, {\"errors\": 0.030634388327598572, \"time-step\": 2601}, {\"errors\": 0.03057059645652771, \"time-step\": 2602}, {\"errors\": 0.030506979674100876, \"time-step\": 2603}, {\"errors\": 0.030443506315350533, \"time-step\": 2604}, {\"errors\": 0.03038019686937332, \"time-step\": 2605}, {\"errors\": 0.030317053198814392, \"time-step\": 2606}, {\"errors\": 0.030254041776061058, \"time-step\": 2607}, {\"errors\": 0.0301912073045969, \"time-step\": 2608}, {\"errors\": 0.030128546059131622, \"time-step\": 2609}, {\"errors\": 0.03006599470973015, \"time-step\": 2610}, {\"errors\": 0.030003633350133896, \"time-step\": 2611}, {\"errors\": 0.02994142845273018, \"time-step\": 2612}, {\"errors\": 0.029879357665777206, \"time-step\": 2613}, {\"errors\": 0.02981743961572647, \"time-step\": 2614}, {\"errors\": 0.029755696654319763, \"time-step\": 2615}, {\"errors\": 0.029694100841879845, \"time-step\": 2616}, {\"errors\": 0.02963264472782612, \"time-step\": 2617}, {\"errors\": 0.029571358114480972, \"time-step\": 2618}, {\"errors\": 0.029510220512747765, \"time-step\": 2619}, {\"errors\": 0.02944924496114254, \"time-step\": 2620}, {\"errors\": 0.029388396069407463, \"time-step\": 2621}, {\"errors\": 0.02932770922780037, \"time-step\": 2622}, {\"errors\": 0.029267191886901855, \"time-step\": 2623}, {\"errors\": 0.029206791892647743, \"time-step\": 2624}, {\"errors\": 0.02914656698703766, \"time-step\": 2625}, {\"errors\": 0.02908647060394287, \"time-step\": 2626}, {\"errors\": 0.029026532545685768, \"time-step\": 2627}, {\"errors\": 0.0289667546749115, \"time-step\": 2628}, {\"errors\": 0.028907129541039467, \"time-step\": 2629}, {\"errors\": 0.02884763292968273, \"time-step\": 2630}, {\"errors\": 0.028788287192583084, \"time-step\": 2631}, {\"errors\": 0.02872910164296627, \"time-step\": 2632}, {\"errors\": 0.0286700539290905, \"time-step\": 2633}, {\"errors\": 0.028611164540052414, \"time-step\": 2634}, {\"errors\": 0.028552409261465073, \"time-step\": 2635}, {\"errors\": 0.028493793681263924, \"time-step\": 2636}, {\"errors\": 0.02843533642590046, \"time-step\": 2637}, {\"errors\": 0.02837701328098774, \"time-step\": 2638}, {\"errors\": 0.028318848460912704, \"time-step\": 2639}, {\"errors\": 0.02826082333922386, \"time-step\": 2640}, {\"errors\": 0.02820293791592121, \"time-step\": 2641}, {\"errors\": 0.02814520336687565, \"time-step\": 2642}, {\"errors\": 0.02808760106563568, \"time-step\": 2643}, {\"errors\": 0.02803015522658825, \"time-step\": 2644}, {\"errors\": 0.027972836047410965, \"time-step\": 2645}, {\"errors\": 0.027915677055716515, \"time-step\": 2646}, {\"errors\": 0.02785865031182766, \"time-step\": 2647}, {\"errors\": 0.027801770716905594, \"time-step\": 2648}, {\"errors\": 0.027745017781853676, \"time-step\": 2649}, {\"errors\": 0.02768842503428459, \"time-step\": 2650}, {\"errors\": 0.027631955221295357, \"time-step\": 2651}, {\"errors\": 0.027575630694627762, \"time-step\": 2652}, {\"errors\": 0.027519460767507553, \"time-step\": 2653}, {\"errors\": 0.0274633951485157, \"time-step\": 2654}, {\"errors\": 0.027407506480813026, \"time-step\": 2655}, {\"errors\": 0.027351731434464455, \"time-step\": 2656}, {\"errors\": 0.02729610539972782, \"time-step\": 2657}, {\"errors\": 0.027240626513957977, \"time-step\": 2658}, {\"errors\": 0.027185264974832535, \"time-step\": 2659}, {\"errors\": 0.027130046859383583, \"time-step\": 2660}, {\"errors\": 0.02707497775554657, \"time-step\": 2661}, {\"errors\": 0.027020029723644257, \"time-step\": 2662}, {\"errors\": 0.026965215802192688, \"time-step\": 2663}, {\"errors\": 0.02691054716706276, \"time-step\": 2664}, {\"errors\": 0.026856012642383575, \"time-step\": 2665}, {\"errors\": 0.026801608502864838, \"time-step\": 2666}, {\"errors\": 0.02674735337495804, \"time-step\": 2667}, {\"errors\": 0.02669323794543743, \"time-step\": 2668}, {\"errors\": 0.02663922868669033, \"time-step\": 2669}, {\"errors\": 0.02658536657691002, \"time-step\": 2670}, {\"errors\": 0.026531629264354706, \"time-step\": 2671}, {\"errors\": 0.026478048413991928, \"time-step\": 2672}, {\"errors\": 0.026424581184983253, \"time-step\": 2673}, {\"errors\": 0.026371244341135025, \"time-step\": 2674}, {\"errors\": 0.026318049058318138, \"time-step\": 2675}, {\"errors\": 0.026264989748597145, \"time-step\": 2676}, {\"errors\": 0.026212044060230255, \"time-step\": 2677}, {\"errors\": 0.026159245520830154, \"time-step\": 2678}, {\"errors\": 0.026106566190719604, \"time-step\": 2679}, {\"errors\": 0.026054006069898605, \"time-step\": 2680}, {\"errors\": 0.02600160241127014, \"time-step\": 2681}, {\"errors\": 0.02594931796193123, \"time-step\": 2682}, {\"errors\": 0.025897163897752762, \"time-step\": 2683}, {\"errors\": 0.025845123454928398, \"time-step\": 2684}, {\"errors\": 0.025793222710490227, \"time-step\": 2685}, {\"errors\": 0.02574145421385765, \"time-step\": 2686}, {\"errors\": 0.025689810514450073, \"time-step\": 2687}, {\"errors\": 0.02563830278813839, \"time-step\": 2688}, {\"errors\": 0.02558690495789051, \"time-step\": 2689}, {\"errors\": 0.02553563192486763, \"time-step\": 2690}, {\"errors\": 0.02548450604081154, \"time-step\": 2691}, {\"errors\": 0.025433504953980446, \"time-step\": 2692}, {\"errors\": 0.02538260817527771, \"time-step\": 2693}, {\"errors\": 0.025331858545541763, \"time-step\": 2694}, {\"errors\": 0.025281213223934174, \"time-step\": 2695}, {\"errors\": 0.02523070201277733, \"time-step\": 2696}, {\"errors\": 0.02518032304942608, \"time-step\": 2697}, {\"errors\": 0.02513006143271923, \"time-step\": 2698}, {\"errors\": 0.02507992833852768, \"time-step\": 2699}, {\"errors\": 0.025029907003045082, \"time-step\": 2700}, {\"errors\": 0.02498001977801323, \"time-step\": 2701}, {\"errors\": 0.024930257350206375, \"time-step\": 2702}, {\"errors\": 0.02488061785697937, \"time-step\": 2703}, {\"errors\": 0.02483109012246132, \"time-step\": 2704}, {\"errors\": 0.02478167973458767, \"time-step\": 2705}, {\"errors\": 0.024732399731874466, \"time-step\": 2706}, {\"errors\": 0.024683259427547455, \"time-step\": 2707}, {\"errors\": 0.024634215980768204, \"time-step\": 2708}, {\"errors\": 0.024585289880633354, \"time-step\": 2709}, {\"errors\": 0.02453649789094925, \"time-step\": 2710}, {\"errors\": 0.0244878139346838, \"time-step\": 2711}, {\"errors\": 0.024439264088869095, \"time-step\": 2712}, {\"errors\": 0.024390826001763344, \"time-step\": 2713}, {\"errors\": 0.024342505261301994, \"time-step\": 2714}, {\"errors\": 0.024294303730130196, \"time-step\": 2715}, {\"errors\": 0.0242462195456028, \"time-step\": 2716}, {\"errors\": 0.0241982564330101, \"time-step\": 2717}, {\"errors\": 0.024150414392352104, \"time-step\": 2718}, {\"errors\": 0.024102680385112762, \"time-step\": 2719}, {\"errors\": 0.024055078625679016, \"time-step\": 2720}, {\"errors\": 0.02400757186114788, \"time-step\": 2721}, {\"errors\": 0.023960193619132042, \"time-step\": 2722}, {\"errors\": 0.023912928998470306, \"time-step\": 2723}, {\"errors\": 0.02386578731238842, \"time-step\": 2724}, {\"errors\": 0.023818746209144592, \"time-step\": 2725}, {\"errors\": 0.023771846666932106, \"time-step\": 2726}, {\"errors\": 0.02372504025697708, \"time-step\": 2727}, {\"errors\": 0.02367834560573101, \"time-step\": 2728}, {\"errors\": 0.023631788790225983, \"time-step\": 2729}, {\"errors\": 0.02358531579375267, \"time-step\": 2730}, {\"errors\": 0.0235389843583107, \"time-step\": 2731}, {\"errors\": 0.02349274605512619, \"time-step\": 2732}, {\"errors\": 0.023446639999747276, \"time-step\": 2733}, {\"errors\": 0.023400625213980675, \"time-step\": 2734}, {\"errors\": 0.023354725912213326, \"time-step\": 2735}, {\"errors\": 0.023308943957090378, \"time-step\": 2736}, {\"errors\": 0.02326328121125698, \"time-step\": 2737}, {\"errors\": 0.02321772836148739, \"time-step\": 2738}, {\"errors\": 0.023172281682491302, \"time-step\": 2739}, {\"errors\": 0.023126937448978424, \"time-step\": 2740}, {\"errors\": 0.023081721737980843, \"time-step\": 2741}, {\"errors\": 0.023036599159240723, \"time-step\": 2742}, {\"errors\": 0.022991590201854706, \"time-step\": 2743}, {\"errors\": 0.022946707904338837, \"time-step\": 2744}, {\"errors\": 0.02290191873908043, \"time-step\": 2745}, {\"errors\": 0.022857246920466423, \"time-step\": 2746}, {\"errors\": 0.022812673822045326, \"time-step\": 2747}, {\"errors\": 0.02276821807026863, \"time-step\": 2748}, {\"errors\": 0.02272387593984604, \"time-step\": 2749}, {\"errors\": 0.02267962507903576, \"time-step\": 2750}, {\"errors\": 0.022635482251644135, \"time-step\": 2751}, {\"errors\": 0.022591466084122658, \"time-step\": 2752}, {\"errors\": 0.02254754677414894, \"time-step\": 2753}, {\"errors\": 0.02250373363494873, \"time-step\": 2754}, {\"errors\": 0.022460028529167175, \"time-step\": 2755}, {\"errors\": 0.022416431456804276, \"time-step\": 2756}, {\"errors\": 0.022372925654053688, \"time-step\": 2757}, {\"errors\": 0.022329533472657204, \"time-step\": 2758}, {\"errors\": 0.022286267951130867, \"time-step\": 2759}, {\"errors\": 0.022243088111281395, \"time-step\": 2760}, {\"errors\": 0.02220001257956028, \"time-step\": 2761}, {\"errors\": 0.022157050669193268, \"time-step\": 2762}, {\"errors\": 0.022114183753728867, \"time-step\": 2763}, {\"errors\": 0.022071421146392822, \"time-step\": 2764}, {\"errors\": 0.022028764709830284, \"time-step\": 2765}, {\"errors\": 0.021986225619912148, \"time-step\": 2766}, {\"errors\": 0.021943772211670876, \"time-step\": 2767}, {\"errors\": 0.02190142683684826, \"time-step\": 2768}, {\"errors\": 0.021859178319573402, \"time-step\": 2769}, {\"errors\": 0.02181703969836235, \"time-step\": 2770}, {\"errors\": 0.021775005385279655, \"time-step\": 2771}, {\"errors\": 0.021733073517680168, \"time-step\": 2772}, {\"errors\": 0.02169123664498329, \"time-step\": 2773}, {\"errors\": 0.021649498492479324, \"time-step\": 2774}, {\"errors\": 0.02160787396132946, \"time-step\": 2775}, {\"errors\": 0.021566325798630714, \"time-step\": 2776}, {\"errors\": 0.02152489498257637, \"time-step\": 2777}, {\"errors\": 0.021483559161424637, \"time-step\": 2778}, {\"errors\": 0.02144233137369156, \"time-step\": 2779}, {\"errors\": 0.02140120416879654, \"time-step\": 2780}, {\"errors\": 0.021360158920288086, \"time-step\": 2781}, {\"errors\": 0.02131923846900463, \"time-step\": 2782}, {\"errors\": 0.021278396248817444, \"time-step\": 2783}, {\"errors\": 0.021237647160887718, \"time-step\": 2784}, {\"errors\": 0.021197019144892693, \"time-step\": 2785}, {\"errors\": 0.021156474947929382, \"time-step\": 2786}, {\"errors\": 0.021116036921739578, \"time-step\": 2787}, {\"errors\": 0.021075688302516937, \"time-step\": 2788}, {\"errors\": 0.021035445854067802, \"time-step\": 2789}, {\"errors\": 0.020995289087295532, \"time-step\": 2790}, {\"errors\": 0.020955244079232216, \"time-step\": 2791}, {\"errors\": 0.020915281027555466, \"time-step\": 2792}, {\"errors\": 0.02087542600929737, \"time-step\": 2793}, {\"errors\": 0.020835649222135544, \"time-step\": 2794}, {\"errors\": 0.02079598791897297, \"time-step\": 2795}, {\"errors\": 0.020756404846906662, \"time-step\": 2796}, {\"errors\": 0.020716939121484756, \"time-step\": 2797}, {\"errors\": 0.02067754417657852, \"time-step\": 2798}, {\"errors\": 0.020638253539800644, \"time-step\": 2799}, {\"errors\": 0.02059905230998993, \"time-step\": 2800}, {\"errors\": 0.02055995725095272, \"time-step\": 2801}, {\"errors\": 0.020520959049463272, \"time-step\": 2802}, {\"errors\": 0.02048204094171524, \"time-step\": 2803}, {\"errors\": 0.02044321782886982, \"time-step\": 2804}, {\"errors\": 0.020404493436217308, \"time-step\": 2805}, {\"errors\": 0.02036586031317711, \"time-step\": 2806}, {\"errors\": 0.020327316597104073, \"time-step\": 2807}, {\"errors\": 0.02028886415064335, \"time-step\": 2808}, {\"errors\": 0.02025051787495613, \"time-step\": 2809}, {\"errors\": 0.02021225169301033, \"time-step\": 2810}, {\"errors\": 0.020174071192741394, \"time-step\": 2811}, {\"errors\": 0.020135998725891113, \"time-step\": 2812}, {\"errors\": 0.0200980082154274, \"time-step\": 2813}, {\"errors\": 0.020060105249285698, \"time-step\": 2814}, {\"errors\": 0.02002228982746601, \"time-step\": 2815}, {\"errors\": 0.019984565675258636, \"time-step\": 2816}, {\"errors\": 0.01994694396853447, \"time-step\": 2817}, {\"errors\": 0.01990940235555172, \"time-step\": 2818}, {\"errors\": 0.01987195387482643, \"time-step\": 2819}, {\"errors\": 0.019834598526358604, \"time-step\": 2820}, {\"errors\": 0.019797321408987045, \"time-step\": 2821}, {\"errors\": 0.019760143011808395, \"time-step\": 2822}, {\"errors\": 0.019723044708371162, \"time-step\": 2823}, {\"errors\": 0.019686050713062286, \"time-step\": 2824}, {\"errors\": 0.01964912749826908, \"time-step\": 2825}, {\"errors\": 0.019612299278378487, \"time-step\": 2826}, {\"errors\": 0.01957555115222931, \"time-step\": 2827}, {\"errors\": 0.019538894295692444, \"time-step\": 2828}, {\"errors\": 0.01950233057141304, \"time-step\": 2829}, {\"errors\": 0.01946585439145565, \"time-step\": 2830}, {\"errors\": 0.019429465755820274, \"time-step\": 2831}, {\"errors\": 0.019393155351281166, \"time-step\": 2832}, {\"errors\": 0.01935693435370922, \"time-step\": 2833}, {\"errors\": 0.019320812076330185, \"time-step\": 2834}, {\"errors\": 0.01928476057946682, \"time-step\": 2835}, {\"errors\": 0.019248798489570618, \"time-step\": 2836}, {\"errors\": 0.01921292394399643, \"time-step\": 2837}, {\"errors\": 0.019177144393324852, \"time-step\": 2838}, {\"errors\": 0.01914142817258835, \"time-step\": 2839}, {\"errors\": 0.01910579577088356, \"time-step\": 2840}, {\"errors\": 0.01907026208937168, \"time-step\": 2841}, {\"errors\": 0.01903481036424637, \"time-step\": 2842}, {\"errors\": 0.01899944618344307, \"time-step\": 2843}, {\"errors\": 0.018964162096381187, \"time-step\": 2844}, {\"errors\": 0.01892896182835102, \"time-step\": 2845}, {\"errors\": 0.018893837928771973, \"time-step\": 2846}, {\"errors\": 0.01885879784822464, \"time-step\": 2847}, {\"errors\": 0.018823860213160515, \"time-step\": 2848}, {\"errors\": 0.018788987770676613, \"time-step\": 2849}, {\"errors\": 0.018754204735159874, \"time-step\": 2850}, {\"errors\": 0.018719492480158806, \"time-step\": 2851}, {\"errors\": 0.018684878945350647, \"time-step\": 2852}, {\"errors\": 0.01865033619105816, \"time-step\": 2853}, {\"errors\": 0.018615873530507088, \"time-step\": 2854}, {\"errors\": 0.01858150027692318, \"time-step\": 2855}, {\"errors\": 0.018547195941209793, \"time-step\": 2856}, {\"errors\": 0.01851298101246357, \"time-step\": 2857}, {\"errors\": 0.018478848040103912, \"time-step\": 2858}, {\"errors\": 0.018444795161485672, \"time-step\": 2859}, {\"errors\": 0.0184108205139637, \"time-step\": 2860}, {\"errors\": 0.018376918509602547, \"time-step\": 2861}, {\"errors\": 0.018343109637498856, \"time-step\": 2862}, {\"errors\": 0.018309377133846283, \"time-step\": 2863}, {\"errors\": 0.01827572099864483, \"time-step\": 2864}, {\"errors\": 0.01824214495718479, \"time-step\": 2865}, {\"errors\": 0.018208637833595276, \"time-step\": 2866}, {\"errors\": 0.01817522756755352, \"time-step\": 2867}, {\"errors\": 0.018141895532608032, \"time-step\": 2868}, {\"errors\": 0.018108628690242767, \"time-step\": 2869}, {\"errors\": 0.018075432628393173, \"time-step\": 2870}, {\"errors\": 0.01804233528673649, \"time-step\": 2871}, {\"errors\": 0.018009310588240623, \"time-step\": 2872}, {\"errors\": 0.01797635853290558, \"time-step\": 2873}, {\"errors\": 0.01794348657131195, \"time-step\": 2874}, {\"errors\": 0.017910681664943695, \"time-step\": 2875}, {\"errors\": 0.017877962440252304, \"time-step\": 2876}, {\"errors\": 0.017845315858721733, \"time-step\": 2877}, {\"errors\": 0.017812754958868027, \"time-step\": 2878}, {\"errors\": 0.01778027042746544, \"time-step\": 2879}, {\"errors\": 0.017747849225997925, \"time-step\": 2880}, {\"errors\": 0.017715509980916977, \"time-step\": 2881}, {\"errors\": 0.017683252692222595, \"time-step\": 2882}, {\"errors\": 0.017651058733463287, \"time-step\": 2883}, {\"errors\": 0.017618954181671143, \"time-step\": 2884}, {\"errors\": 0.01758691295981407, \"time-step\": 2885}, {\"errors\": 0.01755494251847267, \"time-step\": 2886}, {\"errors\": 0.017523063346743584, \"time-step\": 2887}, {\"errors\": 0.017491251230239868, \"time-step\": 2888}, {\"errors\": 0.017459502443671227, \"time-step\": 2889}, {\"errors\": 0.017427846789360046, \"time-step\": 2890}, {\"errors\": 0.01739625632762909, \"time-step\": 2891}, {\"errors\": 0.017364734783768654, \"time-step\": 2892}, {\"errors\": 0.017333289608359337, \"time-step\": 2893}, {\"errors\": 0.01730192080140114, \"time-step\": 2894}, {\"errors\": 0.01727062463760376, \"time-step\": 2895}, {\"errors\": 0.01723940297961235, \"time-step\": 2896}, {\"errors\": 0.017208237200975418, \"time-step\": 2897}, {\"errors\": 0.01717715710401535, \"time-step\": 2898}, {\"errors\": 0.017146160826086998, \"time-step\": 2899}, {\"errors\": 0.017115214839577675, \"time-step\": 2900}, {\"errors\": 0.017084352672100067, \"time-step\": 2901}, {\"errors\": 0.017053555697202682, \"time-step\": 2902}, {\"errors\": 0.017022836953401566, \"time-step\": 2903}, {\"errors\": 0.016992192715406418, \"time-step\": 2904}, {\"errors\": 0.016961615532636642, \"time-step\": 2905}, {\"errors\": 0.016931109130382538, \"time-step\": 2906}, {\"errors\": 0.016900675371289253, \"time-step\": 2907}, {\"errors\": 0.01687031053006649, \"time-step\": 2908}, {\"errors\": 0.016840005293488503, \"time-step\": 2909}, {\"errors\": 0.016809780150651932, \"time-step\": 2910}, {\"errors\": 0.016779622063040733, \"time-step\": 2911}, {\"errors\": 0.016749532893300056, \"time-step\": 2912}, {\"errors\": 0.0167195163667202, \"time-step\": 2913}, {\"errors\": 0.016689566895365715, \"time-step\": 2914}, {\"errors\": 0.0166596919298172, \"time-step\": 2915}, {\"errors\": 0.016629891470074654, \"time-step\": 2916}, {\"errors\": 0.01660013571381569, \"time-step\": 2917}, {\"errors\": 0.01657046005129814, \"time-step\": 2918}, {\"errors\": 0.016540858894586563, \"time-step\": 2919}, {\"errors\": 0.016511332243680954, \"time-step\": 2920}, {\"errors\": 0.016481855884194374, \"time-step\": 2921}, {\"errors\": 0.016452452167868614, \"time-step\": 2922}, {\"errors\": 0.016423126682639122, \"time-step\": 2923}, {\"errors\": 0.016393858939409256, \"time-step\": 2924}, {\"errors\": 0.016364671289920807, \"time-step\": 2925}, {\"errors\": 0.016335537657141685, \"time-step\": 2926}, {\"errors\": 0.01630646176636219, \"time-step\": 2927}, {\"errors\": 0.016277477145195007, \"time-step\": 2928}, {\"errors\": 0.0162485521286726, \"time-step\": 2929}, {\"errors\": 0.016219694167375565, \"time-step\": 2930}, {\"errors\": 0.01619088649749756, \"time-step\": 2931}, {\"errors\": 0.01616216078400612, \"time-step\": 2932}, {\"errors\": 0.016133489087224007, \"time-step\": 2933}, {\"errors\": 0.016104893758893013, \"time-step\": 2934}, {\"errors\": 0.016076361760497093, \"time-step\": 2935}, {\"errors\": 0.016047898679971695, \"time-step\": 2936}, {\"errors\": 0.016019489616155624, \"time-step\": 2937}, {\"errors\": 0.015991151332855225, \"time-step\": 2938}, {\"errors\": 0.0159628763794899, \"time-step\": 2939}, {\"errors\": 0.015934664756059647, \"time-step\": 2940}, {\"errors\": 0.015906525775790215, \"time-step\": 2941}, {\"errors\": 0.015878448262810707, \"time-step\": 2942}, {\"errors\": 0.015850428491830826, \"time-step\": 2943}, {\"errors\": 0.015822485089302063, \"time-step\": 2944}, {\"errors\": 0.01579459384083748, \"time-step\": 2945}, {\"errors\": 0.015766765922307968, \"time-step\": 2946}, {\"errors\": 0.01573900133371353, \"time-step\": 2947}, {\"errors\": 0.015711301937699318, \"time-step\": 2948}, {\"errors\": 0.015683665871620178, \"time-step\": 2949}, {\"errors\": 0.015656104311347008, \"time-step\": 2950}, {\"errors\": 0.015628596767783165, \"time-step\": 2951}, {\"errors\": 0.015601150691509247, \"time-step\": 2952}, {\"errors\": 0.015573762357234955, \"time-step\": 2953}, {\"errors\": 0.015546441078186035, \"time-step\": 2954}, {\"errors\": 0.015519186854362488, \"time-step\": 2955}, {\"errors\": 0.01549199316650629, \"time-step\": 2956}, {\"errors\": 0.015464847907423973, \"time-step\": 2957}, {\"errors\": 0.015437774360179901, \"time-step\": 2958}, {\"errors\": 0.015410767868161201, \"time-step\": 2959}, {\"errors\": 0.015383820980787277, \"time-step\": 2960}, {\"errors\": 0.015356937423348427, \"time-step\": 2961}, {\"errors\": 0.015330101363360882, \"time-step\": 2962}, {\"errors\": 0.015303331427276134, \"time-step\": 2963}, {\"errors\": 0.015276624821126461, \"time-step\": 2964}, {\"errors\": 0.015249969437718391, \"time-step\": 2965}, {\"errors\": 0.015223383903503418, \"time-step\": 2966}, {\"errors\": 0.015196858905255795, \"time-step\": 2967}, {\"errors\": 0.015170400962233543, \"time-step\": 2968}, {\"errors\": 0.015143991447985172, \"time-step\": 2969}, {\"errors\": 0.015117642469704151, \"time-step\": 2970}, {\"errors\": 0.015091358684003353, \"time-step\": 2971}, {\"errors\": 0.015065126121044159, \"time-step\": 2972}, {\"errors\": 0.015038957819342613, \"time-step\": 2973}, {\"errors\": 0.015012847259640694, \"time-step\": 2974}, {\"errors\": 0.014986797235906124, \"time-step\": 2975}, {\"errors\": 0.014960814267396927, \"time-step\": 2976}, {\"errors\": 0.014934869483113289, \"time-step\": 2977}, {\"errors\": 0.014908991754055023, \"time-step\": 2978}, {\"errors\": 0.014883177354931831, \"time-step\": 2979}, {\"errors\": 0.01485742162913084, \"time-step\": 2980}, {\"errors\": 0.014831719920039177, \"time-step\": 2981}, {\"errors\": 0.014806082472205162, \"time-step\": 2982}, {\"errors\": 0.014780489727854729, \"time-step\": 2983}, {\"errors\": 0.014754961244761944, \"time-step\": 2984}, {\"errors\": 0.014729497954249382, \"time-step\": 2985}, {\"errors\": 0.014704076573252678, \"time-step\": 2986}, {\"errors\": 0.014678722247481346, \"time-step\": 2987}, {\"errors\": 0.014653431251645088, \"time-step\": 2988}, {\"errors\": 0.01462819054722786, \"time-step\": 2989}, {\"errors\": 0.01460299827158451, \"time-step\": 2990}, {\"errors\": 0.014577865600585938, \"time-step\": 2991}, {\"errors\": 0.014552796259522438, \"time-step\": 2992}, {\"errors\": 0.01452777348458767, \"time-step\": 2993}, {\"errors\": 0.014502815902233124, \"time-step\": 2994}, {\"errors\": 0.014477904886007309, \"time-step\": 2995}, {\"errors\": 0.014453059062361717, \"time-step\": 2996}, {\"errors\": 0.014428270980715752, \"time-step\": 2997}, {\"errors\": 0.014403535053133965, \"time-step\": 2998}, {\"errors\": 0.014378848485648632, \"time-step\": 2999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = history.history['loss']\n",
    "\n",
    "df2 = pd.DataFrame({\"errors\":errors, \"time-step\": np.arange(0, len(errors))})\n",
    "\n",
    "alt.Chart(df2).mark_line().encode(x=\"time-step\", y=\"errors\").properties(title='Chart 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the error curve for our own implementation (**Chart 2**) and the Keras version is the speed at which the error declines. This is mostly accounted for the selection of the Adam optimizer instead of \"plain\" backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X).round()\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     )\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/projects/nn-mod-cog/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise OSError(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we reached 100% of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer perceptrons (and multilayer neural networks more) generally have many limitations worth mentioning. I will focus on a few that are more evident at this point and I'll introduce more complex issues in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and more obvious limitation of the multilayer perceptron is **training time**. It takes an awful lot of iterations for the algorithm to learn to solve a very simple logic problem like the XOR. **This is not an exception but the norm**. Most neural networks you'd encounter in the wild nowadays need from hundreds up to thousands of iterations to reach their top-level accuracy. This has been a common point of criticism, particularly because human learning seems to be way more sample efficient. \n",
    "\n",
    "There are multiple answers to the training time problem. A first argument has to do with raw **processing capacity**. It is seemingly obvious that a neural network with 1 hidden layer and 3 units does not get even close to the massive computational capacity of the human brain. Even if you consider a small subsection of the brain, and design a very large neural network with dozens of layers and units, the brain still has the advantage in most cases. Of course, this alone probably does not account for the entire gap between humans and neural networks but is a point to consider. A second argument refers to the massive **past training experience** accumulated by humans. Neural networks start from scratch every single time. Humans do not reset their storage memories and skills before attempting to learn something new. On the contrary, humans learn and reuse past learning experience across domains continuously. A third argument is related to the **richness of the training data** experienced by humans. Humans not only rely on past learning experiences but also on more *complex and multidimensional training data*. Humans integrate signals from all senses (visual, auditory, tactile, etc.) when learning which most likely speeds up the process. In any case, this is still a major issue and a hot topic of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptrons are \"fragile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second notorious limitation is how **brittle** multilayer perceptrons are to **architectural decisions**. An extra layer, a +0.001 in the learning rate, random uniform weight instead for random normal weights, and or even a different random seed can turn perfectly a functional neural network into a useless one. This is partially related to the fact we are trying to solve a nonconvex optimization problem. Gradient descent has no way to find the actual global minima in the error surface. You just can hope it will find a good enough local minima for your problem. All of this force neural network researchers to **search over enormous combinatorial spaces of \"hyperparameters\"** (i.e., like the learning rate, number layers, etc. Anything but the network weights and biases). In a way, you have to embrace the fact that perfect solutions are rarely found unless you are dealing with simple problems with known solutions like the XOR. Surprisingly, it is often the case that well designed neural networks are able to learn \"good enough\" solutions for a wide variety of problems. Creating more robust neural networks architectures is another present challenge and hot research topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The biological plasubility of backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last issue I'll mention is the elephant in the room: **it is not clear that the brain learns via backpropagation**. Rumelhart, Hinton, and Williams presented no evidence in favor of this assumption. You may think that it does not matter because neural networks do not pretend to be exact replicas of the brain anyways. Yet, it is a highly critical issue coming from the perspective of creating \"biologically plausible\" models of cognition, which is the PDP group perspective. Remember that one of the main problems for Rumelhart was to find a learning mechanism for networks with non-linear units. If the learning mechanism is not plausible, Does the model have any credibility at all? Fortunately, in the last 35 years we have learned quite a lot about the brain, and [several researchers have proposed how the brain could implement \"something like\" backpropagation](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30012-9). Still, keep in mind that this is a highly debated topic and it may pass some time before we reach a resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of multilayer perceptrons trained with backpropagation was a major breakthrough in cognitive science and artificial intelligence in the '80s. It brought back to life a line of research that many thought dead for a while. The key for its success was its ability to overcome one of the major criticism from the previous decade: **its inability to solve problems that required non-linear solutions**. \n",
    "\n",
    "From a cognitive science perspective, the real question is whether such advance says something meaningful about the **plausibility of neural networks as models of cognition**. That is a tough question. If you are in the \"neural network team\" of course you'd think it does. If you are more skeptic you'd rapidly point out to the many weaknesses and unrealistic assumptions on which neural networks depend on.\n",
    "\n",
    "Maybe the best way of thinking about this type of advances in neural networks models of cognition is as another piece of a very complicated puzzle. The \"puzzle\" here is a **working hypothesis**: you are committed to the idea that the puzzle of cognition looks like a neural network when assembled, and your mission is to figure out all the pieces and putting them together. You may be wrong, maybe the puzzle at the end looks like something different, and you'll be proven wrong. Yet, at least in this sense, multilayer perceptrons were a crucial step forward in the neural network research agenda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Feedforward Networks. In Deep Learning. MIT Press. https://www.deeplearningbook.org/contents/mlp.html\n",
    "\n",
    "Kelley, H. J. (1960). Gradient theory of optimal flight paths. Ars Journal, 30(10), 947954.\n",
    "\n",
    "Bryson, A. E. (1961). A gradient method for optimizing multi-stage allocation processes. Proc. Harvard Univ. Symposium on Digital Computers and Their Applications, 72.\n",
    "\n",
    "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning Internal Representations by Error Propagation. In Parallel Distributed Processing: Explorations in the Microestructure of Cognition (Vol. 1). MIT Press.\n",
    "\n",
    "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533536.\n",
    "\n",
    "Werbos, P. J. (1994). The roots of backpropagation: From ordered derivatives to neural networks and political forecasting (Vol. 1). John Wiley & Sons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful on-line resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internet is flooded with learning resourced about neural networks. Here a selection of my personal favorites for this topic:\n",
    "\n",
    "- [3Blue1Brown: Neural Networks Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "- [Welch Labs: Neural Networks Demystified](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU)\n",
    "- [Michael Nielsen's Neural Networks and Deep Learning Book: How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
