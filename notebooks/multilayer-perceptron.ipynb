{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Understand the principles behind the creation of the multilayer perceptron\n",
    "2. Identify how the multilayer perceptron overcame many of the limitations of previous models\n",
    "3. Expand understanding of learning via gradient descent methods\n",
    "4. Develop a basic code implementation of the multilayer perceptron in Python\n",
    "5. Be aware of the main limitations of multilayer perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical and theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The origin of the backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks research came close to become an anecdote in the history of cognitive science during the '70s. The majority of researchers in cognitive science and artificial intelligence thought that neural nets were a silly idea, they could not possibly work. Minsky and Papert even provided formal proofs about it 1969. Yet, as any person that has been around science long enough knows, there are plenty of stubborn researchers that will continue paddling against the current in pursue of their own ideas. \n",
    "\n",
    "David Rumelhart first heard about perceptrons and neural nets in 1963 while in graduate school at Stanford. At the time, he was doing research in mathematical psychology, which although it has lots of equations, is a different field, so he did not pay too much attention to neural nets. It wasn't until the early '70s that Rumelhart took neural nets more seriously. He was in pursuit of a more general framework to understand cognition. Mathematical psychology looked too much like a disconnected mosaic of ad-doc formulas for him. By the late '70s, Rumelhart was working at UC San Diego. He and some colleagues formed a study group about neural networks in cognitive science, that eventually evolved into what is known as the **\"Parallel Distributed Processing\" (PDP) research group**. Among the members of that group were Geoffrey Hinton, Terrence Sejnowski, Michael I. Jordan, Jeffrey L. Elman, and others that eventually became prominent researchers in the neural networks and artificial intelligence fields. \n",
    "\n",
    "The original intention of the PDP group was to create a compendium of the most important research on neural networks. Their enterprise eventually evolved into something larger, producing the famous two volumes book where the so-called **\"backpropagation\" algorithm was introduced**, along with other important models and ideas. Although most people today associate the invention of the gradient descent algorithm with Hinton, the person that came up the idea was David Rumelhart, and as in most things in science, it was just a small change to a previous idea. Rumelhart and James McClelland (another young professor at UC San Diego at the time) wanted to train a neural network with multiple layers and **sigmoidal units** instead of threshold units (as in the perceptron) or linear units (as in the ADALINE), but they did not how to train such a model. Rumelhart knew that you could use gradient descent to train networks with linear units, as Widrow and Hoff did, so he thought that he might as well **pretend that sigmoids units were linear units and see what happens**. It worked, but he realized that training the model took too many iterations, so the got discouraged and let the idea aside for a while.\n",
    "\n",
    "Backpropagation remained dormant for a couple of years until Hinton picked it up again. Rumelhart introduced the idea to Hinton, and **Hinton thought it was a terrible idea**. I could not work. He knew that backpropagation could not break the symmetry between weights and it will get stuck in local minima. He was passionate about energy-based systems known as [Boltzmann machines](https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf), which seemed to have nicer mathematical properties. Yet, as he failed to solve more and more problems with Boltzmann machines he decided to try out backpropagation, mostly out of frustration. It worked amazingly well, way better than Boltzmann machines. He got in touch with Rumelhart about their results and both decided to include a backpropagation chapter in the PDP book and published *Nature* paper along with Ronald Williams. The *Nature* paper became highly visible and **the interest in neural networks got reignited for at least the next decade**. And that is how backpropagation was introduced: by a mathematical psychologist with no training in neural nets modeling and a neural net researcher that thought it was a terrible idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcoming limitations and creating advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truth be told, \"multilayer perceptron\" is a terrible name for what Rumelhart, Hinton, and Williams introduced in the mid-'80s. It is a bad name because its most fundamental piece, the *training algorithm*, is completely different from [the one in the perceptron](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Learning-procedure). Therefore, a multilayer perceptron it is not simply \"a perceptron with multiple layers\" as the name suggests. True, it is a network composed of multiple neuron-like processing units but not every neuron-like processing unit is a perceptron. If you were to put together a bunch of Rossenblat's perceptron in sequence, you would obtain something very different from what most people today would call a multilayer perceptron. If anything, the multi-layer perceptron is more similar to the Widrow and Hoff ADALINE, and in fact, Widrow and Hoff did try multi-layer ADALINEs, known as MADALINEs (i.e., many ADALINEs), but they did not incorporate non-linear functions.\n",
    "\n",
    "\n",
    "Now, the main reason for the resurgence of interest in neural networks was that finally someone designed an architecture that could overcome the perceptron and ADALINE limitations: **to solve problems requiring non-linear solutions**. Problems like the famous [XOR (exclusive or)](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) function (to learn more about it, see the \"Limitations\" section in the [\"The Perceptron\"](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) and [\"The ADALINE\"](https://com-cog-book.github.io/com-cog-book/features/adaline.html#ADALINE-limitations) chapters). \n",
    "\n",
    "Further, a side effect of the capacity to use multiple layers of non-linear units is that neural networks can form **complex internal representations of entities**. The perceptron and ADALINE did not have this capacity. They both are linear models, therefore, it doesn't matter how many layers of processing units you concatenate together, the representation learned by the network will be a linear model. You may as well dropped all the extra layers and the network eventually would learn the same solution that with multiple layers (see [Why adding multiple layers of processing units does not work](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Why-adding-multiple-layers-of-processing-units-does-not-work) for an explanation). This capacity is important in so far **complex multi-level representation of phenomena** is -probably- what the human mind does when solving problems in language, perception, learning, etc. \n",
    "\n",
    "Finally, the backpropagation algorithm effectively **automates the so-called \"feature engineering\" process**. If you have ever done data analysis of any kind, you may have come across variables or features that were not in the original data but was **created by transforming or combining other variables**. For instance, you may have variables for income and education, and combine those to create a socio-economic status variable. That variable may have a predictive capacity above and beyond income and education in isolation. With a multilayer neural network with non-linear units trained with backpropagatio such a *transformation process happens automatically* in the intermediate or **\"hidden\" layers of the network**. Those intermediate representations often are hard or impossible to interpret for humans. They may make no sense whatsoever for us but somehow help to solve the pattern recognition problem at hand, so the network will learn that representation. Does this mean that neural nets learn different representations from the human brain? Maybe, maybe not. The problem is that we don't have direct access to the kind of representations learned by the brain either, and a neural net will seldom be trained with the same data that a human brain is trained in real life.\n",
    "\n",
    "The application of the backpropagation algorithm in multilayer neural network architectures was a major breakthrough in the artificial intelligence and cognitive science community, that catalyzed a new generation of research in cognitive science. Nonetheless, it took several decades of advance on computing and data availability before artificial neural networks became the dominant paradigm in the research landscape as it is today. Next, we will explore its mathematical formalization and application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical multilayer perceptron as introduced by Rumelhart, Hinton, and Williams, can be described by:\n",
    "\n",
    "- a *linear function* that aggregates the input values\n",
    "- a *sigmoid function*, also called *activation function*\n",
    "- a *threshold function* for classification process, and an *identity function* for regression problems\n",
    "- a *loss or cost* function that computes the overall error of the network\n",
    "- a *learning procedure* to adjust the weights of the network, i.e., the so-called *backpropagation* algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear aggregation function is the same as in the perceptron and the ADALINE. But, with a couple of differences that change the notation: now we are dealing multiple layers and processing units. The conventional way to represent this is with **linear algebra notation**. This is not a course of linear algebra, reason I won't cover the mathematics in detail. However, I'll introduce enough concepts and notation to understand the fundamental operations involved in the neural network calculation. The most important aspect is to understand what is a *matrix*, a *vector*, and how to *multiply* them together.\n",
    "\n",
    "A **vector** is a collection of *ordered numbers* or *scalars*. If you are familiar with data analysis, a vector is like a column or row in a dataframe. If you are familiar with programming, a vector is like an array or a list. A generic Vector $\\bf{x}$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/vector.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **matrix** is a *collection of vectors* or *lists of numbers*. In data analysis, this is equivalent to a 2-dimensional dataframe. In programming is equivalent to a multidimensional array or a list of lists. A generic matrix $W$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/matrix.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notation, let's look at a simplified example of a network with:\n",
    "- 3 inputs units\n",
    "- 1 hidden layer with 2 units\n",
    "\n",
    "Like the one in **Figure 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/simple-net.svg\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector for our first training example would look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\bf{x=}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 3 input units connecting to hidden 2 units we have 3x2 weights. This is represented with a matrix as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W=\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *output of the linear function equals to the multiplication of the vector $\\bf{x}$ and the matrix $W$*. To perform the multiplication in this case we need to transpose the matrix $W$ to match the number of columns in $W$ with the number of rows in $\\bf{x}$. Transposing means to \"flip\" the columns of $W$ such that the first column becomes the first row, the second column becomes the second row, and so forth. The matrix-vector multiplication equals to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\bf z=} \n",
    "W^T\\times {\\bf x=}\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\bf z=} \n",
    "W^T\\times {\\bf x=}\n",
    "\\begin{bmatrix}\n",
    "x_1w_{11} + x_2w_{12} + x_3w_{13}\\\\\n",
    "x_1w_{21} + x_2w_{22} + x_3w_{23}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_1 \\\\\n",
    "z_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous matrix operation in summation notation equals to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/linear-function-multi-perceptron.svg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $f$ is a function of each element of the vector $\\bf{x}$ and each element of the matrix $W$. The $m$ index identifies the rows in $W^T$ and the rows in $\\bf{z}$. The $n$ index indicates the columns in $W^T$ and the rows in $\\bf{x}$. Notice that we add a $b$ bias term, that has the role to simplify learning a proper threshold for the function. If you are curious about that [read this](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Linear-aggregation-function). In sum, the **linear function is a weighted sum of the inputs plus a bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the $\\bf{z}$ vector becomes an input for the sigmoid function $\\sigma$():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/sigmoid-function-multi-perceptron.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of $\\sigma(z_m)$ is another $m$ dimensional vector $a$, one entry for each unit in the hidden layer like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bf{a}=\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "a_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $a$ stands for \"activation\", which is a common way to refer to the output of hidden units. This sigmoid function \"wrapping\" the outcome of the linear function is commonly called **activation function**. The idea is that a unit gets \"activated\" in more or less the same manner that a neuron gets activated when a sufficiently strong input is received. The selection of a sigmoid is arbitrary. Many different non-linear functions could be selected at this stage in the network, like a [Tanh](https://mathworld.wolfram.com/HyperbolicTangent.html) or a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). Unfortunately, there is no principled way to chose activation functions for hidden layers. It is mostly a matter of trial and error.\n",
    "\n",
    "A nice property of sigmoid functions is they are \"mostly linear\" but they saturate as they approach 1 and 0 in the extremes. **Chart 1** shows the shape of a sigmoid function (blue line) and the point where the gradient is at its maximum (the red line connecting the blue line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b9fb383871504aeb977bd3450b21ec9c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-b9fb383871504aeb977bd3450b21ec9c\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z1\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a1\"}}}], \"data\": {\"name\": \"data-4ce8df9580f59e633b8d399e9190ac6d\"}, \"title\": \"Chart 1\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-4ce8df9580f59e633b8d399e9190ac6d\": [{\"a\": 0.0066928509242848554, \"z\": -5.0, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.007391541344281971, \"z\": -4.9, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.00816257115315989, \"z\": -4.800000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009013298652847815, \"z\": -4.700000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009951801866904308, \"z\": -4.600000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.010986942630593162, \"z\": -4.500000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.012128434984274213, \"z\": -4.400000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.013386917827664744, \"z\": -4.3000000000000025, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.014774031693273017, \"z\": -4.200000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01630249937144089, \"z\": -4.100000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.017986209962091496, \"z\": -4.0000000000000036, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01984030573407743, \"z\": -3.900000000000004, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.021881270936130383, \"z\": -3.8000000000000043, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.024127021417669092, \"z\": -3.7000000000000046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.026596993576865725, \"z\": -3.600000000000005, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.02931223075135617, \"z\": -3.5000000000000053, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03229546469845033, \"z\": -3.4000000000000057, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.035571189272635965, \"z\": -3.300000000000006, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03916572279676412, \"z\": -3.2000000000000064, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.043107254941085846, \"z\": -3.1000000000000068, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.04742587317756646, \"z\": -3.000000000000007, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05215356307841737, \"z\": -2.9000000000000075, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05732417589886832, \"z\": -2.800000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06297335605699601, \"z\": -2.700000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06913842034334627, \"z\": -2.6000000000000085, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.07585818002124294, \"z\": -2.500000000000009, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.08317269649392166, \"z\": -2.4000000000000092, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09112296101485534, \"z\": -2.3000000000000096, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09975048911968425, \"z\": -2.20000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.10909682119561194, \"z\": -2.1000000000000103, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.11920292202211644, \"z\": -2.0000000000000107, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1301084743629966, \"z\": -1.900000000000011, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1418510649004864, \"z\": -1.8000000000000114, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.15446526508353317, \"z\": -1.7000000000000117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.16798161486607383, \"z\": -1.600000000000012, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1824255238063545, \"z\": -1.5000000000000124, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.19781611144141623, \"z\": -1.4000000000000128, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.21416501695743917, \"z\": -1.3000000000000131, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.23147521650098, \"z\": -1.2000000000000135, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.24973989440487981, \"z\": -1.1000000000000139, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.26894142136999233, \"z\": -1.0000000000000142, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.28905049737499305, \"z\": -0.9000000000000146, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3100255188723844, \"z\": -0.8000000000000149, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3318122278318305, \"z\": -0.7000000000000153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.35434369377420094, \"z\": -0.6000000000000156, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3775406687981417, \"z\": -0.500000000000016, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.40131233988754406, \"z\": -0.40000000000001634, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.4255574831883369, \"z\": -0.3000000000000167, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.45016600268751783, \"z\": -0.20000000000001705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.47502081252105566, \"z\": -0.10000000000001741, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.49999999999999556, \"z\": -1.7763568394002505e-14, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5249791874789355, \"z\": 0.09999999999998188, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5498339973124733, \"z\": 0.19999999999998153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5744425168116544, \"z\": 0.29999999999998117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5986876601124473, \"z\": 0.3999999999999808, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.62245933120185, \"z\": 0.49999999999998046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6456563062257908, \"z\": 0.5999999999999801, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6681877721681616, \"z\": 0.6999999999999797, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6899744811276081, \"z\": 0.7999999999999794, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7109495026249997, \"z\": 0.899999999999979, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7310585786300007, \"z\": 0.9999999999999787, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7502601055951135, \"z\": 1.0999999999999783, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7685247834990137, \"z\": 1.199999999999978, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7858349830425548, \"z\": 1.2999999999999776, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8021838885585781, \"z\": 1.3999999999999773, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8175744761936402, \"z\": 1.499999999999977, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8320183851339212, \"z\": 1.5999999999999766, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8455347349164622, \"z\": 1.6999999999999762, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8581489350995093, \"z\": 1.7999999999999758, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8698915256369995, \"z\": 1.8999999999999755, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8807970779778798, \"z\": 1.9999999999999751, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8909031788043846, \"z\": 2.0999999999999748, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9002495108803125, \"z\": 2.1999999999999744, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9088770389851418, \"z\": 2.299999999999974, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9168273035060757, \"z\": 2.3999999999999737, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9241418199787546, \"z\": 2.4999999999999734, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9308615796566515, \"z\": 2.599999999999973, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.937026643943002, \"z\": 2.6999999999999726, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9426758241011297, \"z\": 2.7999999999999723, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.947846436921581, \"z\": 2.899999999999972, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9525741268224319, \"z\": 2.9999999999999716, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9568927450589126, \"z\": 3.0999999999999712, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9608342772032344, \"z\": 3.199999999999971, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9644288107273629, \"z\": 3.2999999999999705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9677045353015485, \"z\": 3.39999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9706877692486428, \"z\": 3.49999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9734030064231335, \"z\": 3.5999999999999694, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.97587297858233, \"z\": 3.699999999999969, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9781187290638689, \"z\": 3.7999999999999687, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9801596942659219, \"z\": 3.8999999999999684, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.982013790037908, \"z\": 3.999999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9836975006285584, \"z\": 4.099999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9852259683067265, \"z\": 4.199999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9866130821723347, \"z\": 4.299999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9878715650157253, \"z\": 4.399999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9890130573694065, \"z\": 4.499999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9900481981330953, \"z\": 4.599999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9909867013471519, \"z\": 4.6999999999999655, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9918374288468399, \"z\": 4.799999999999965, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9926084586557179, \"z\": 4.899999999999965, \"z1\": 0, \"a1\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "z = np.arange(-5.0,5.0, 0.1)\n",
    "a = expit(z)\n",
    "df = pd.DataFrame({\"a\":a, \"z\":z})\n",
    "df[\"z1\"] = 0\n",
    "df[\"a1\"] = 0.5\n",
    "sigmoid = alt.Chart(df).mark_line().encode(x=\"z\", y=\"a\")\n",
    "threshold = alt.Chart(df).mark_rule(color=\"red\").encode(x=\"z1\", y=\"a1\")\n",
    "(sigmoid + threshold).properties(title='Chart 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **binary classification problems** each output unit implements a **threshold function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} =\n",
    "f(a_m)\n",
    "\\begin{cases}\n",
    "+1, & \\text{if } a \\text{ > 0.5} \\\\\n",
    "-1, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **regression problems** (problems that require a real-valued output value like predicting income or test-scores) each output unit implements an **identity function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y}=f(a_m)=a_m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, an identity function returns the same value as the input. It does nothing. The point is that the $a$ is already the output of a linear function, therefore, it is the value that we need for this kind of problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **multiclass classification problems**, we can use a **softmax function** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\sigma(a)_i = \\frac{e^{\\beta a_i}}{\\sum_{j=1}^{k}e^{\\beta z_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the **measure of \"goodness\" or \"badness\"** (depending on how you like to see things) of the network performance. This can be a confusing term. People sometimes call it *objective function*, *loss function*, or *error function*. Conventionally, *loss function* usually refers to the measure of error for a *single* training case, *cost function* to the aggregate error for the *entire* dataset, and *objective function* is a more generic term referring to any measure of the overall error in a network. For instance, \"mean squared error\", \"sum of squared error\", and \"binary cross-entropy\" are all *objective functions*. For our purposes, I'll use all those terms interchangeably: they all refer to the measure of performance of the network. \n",
    "\n",
    "Nowadays, you would probably want to use different cost functions for different types of problems. In their original work, Rumelhart, Hinton, and Williams used the **sum of squared errors** defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/cost-function.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All neural networks can be divided into two parts: a **forward propagation phase**, where the information \"flows\" forward to compute predictions and the error; and the **backward propagation phase**, where the *backpropagation algorithm* computes the error derivatives and update the network weights. **Figure 2** illustrate a network with 2 input units, 3 hidden units, and 1 output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 2 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/forward-pass.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *forward propagation* phase involves \"chaining\" all the steps we defined so far: the *linear function*, the *sigmoid function*, and the *threshold function*. Consider the network in **Figure 2**. Let's label the linear function as $\\lambda()$, the sigmoid function as $\\sigma()$, and the threshold function as $\\tau()$. Now, the network in **Figure 2** can be represented as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))\n",
    "$$\n",
    "\n",
    "All neural networks can be represented as a **composition of functions** where each step is nested in the next step. For instance, we can add an extra hidden layer to the network in **Figure 2** by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(3)}(\\lambda^{(3)}(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [ADALINE chapter](https://com-cog-book.github.io/com-cog-book/features/adaline.html#The-ADALINE-error-surface) I introduced the ideas of **searching for a set of weights that minimize the error via gradient descent**, and the difference between **convex and non-convex optimization**. If you have not read that section, I'll encourage you to read that first. Otherwise, the important part is to remember that since we are introducing nonlinearities in the network the error surface of the multilayer perceptron is [non-convex](https://arxiv.org/pdf/1712.07897.pdf). This means that there are multiple \"valleys\" with \"local minima\", along with the \"global minima\", and that backpropagation **is not guaranteed to find the global minima**. Remember that the \"global minima\" is the point where the error (i.e., the value of the cost function) is at its minimum, whereas the \"local minima\" is the point of minimum error for a sub-section of the error surface. **Figure 3** illustrates these concepts on a 3D surface. The vertical axis represents the error of the surface, and the other two axes represent different combinations of weights for the network. In the figure, you can observe how different combinations of weights produce different values of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 3 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/sse-nonconvex.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to **introduce the almighty backpropagation algorithm**. Remember that our goal is to learn **how the error changes as we change the weights of the network by tiny amount** and that the cost function was defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = \\frac{1}{2}\\sum_k(a_k - y_k)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one piece of notation I'll introduce to clarify where in the network are we at each step of the computation. I'll use the superscript $L$ to index the outermost function in the network. For example, $a^{(L)}$ index the last sigmoid activation function at the output layer, $a^{(L-1)}$ index the previous sigmoid activation function at the hidden layer, and $x^{(L-2)}$ index the features in the input layer (which are the only thing in that layer). Think about this as moving from the right at $(L)$ to the left at $(L-2)$ in the computational graph of the network in **Figure 4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for single unit multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, tracing the indices in backpropagation is the most confusing part, so I'll ignore the summation symbol and drop the subscript $k$ to make the math as clear as possible. You can think of this as having a network with a single input unit, a single hidden unit, and a single output unit, as in **Figure 4**. We will first work out backpropagation for this simplified network and then expand for the multi-neuron case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 4 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/single-unit.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole purpose of backpropagation is to answer the following question: **\"How does the error change when we change the weights by a tiny amount?\"** (be aware that I'll use the words \"derivatives\" and \"gradients\" interchangeably).\n",
    "\n",
    "To accomplish this you have to realize the following:\n",
    "\n",
    "1. The error $E$ depends on the value of the sigmoid activation function $a$. \n",
    "2. The value of the sigmoid function activation function $a$ depends on the value of the linear function $z$.\n",
    "3. The value of the linear function $z$ depends on the value of the weights $w$  \n",
    "\n",
    "Therefore, we can trace a change of dependence on the weights. This means we have to answer these three questions in a chain:\n",
    "\n",
    "1. How does the error $E$ change when we change the activation $a$ by a tiny amount  \n",
    "2. How does the activation $a$ change when we change the activation $z$ by a tiny amount  \n",
    "3. How does $z$ change when we change the weights $w$ by a tiny amount\n",
    "\n",
    "Such sequence can be mathematically expressed with the **chain-rule of calculus** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/chain-rule.svg\"  width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No deep knowledge of calculus is needed to understand the chain-rule. In essence, indicates **how to differentiate [composite functions](https://en.wikipedia.org/wiki/Function_composition)**, i.e.,  functions nested inside other functions. If you remember the section above this one, we showed that a multi-layer perceptron can be expressed as a composite function. Very convenient. The rule says that we take the derivative of the outermost function, and multiple by the derivative of the inside function, recursively. That's it.\n",
    "\n",
    "Good. Now, let's differentiate each part of $\\frac{\\partial E}{\\partial w^(L)}$. Let's begin from the outermost part. \n",
    "\n",
    "The derivative of the error with respect to (w.r.t) the sigmoid activation function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial a^{(L)}} = a^{(L)} - y \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the derivative of the sigmoid activation function w.r.t the linear function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} = a^{(L)}(1-a^{(L)}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the derivative of the linear function w.r.t the weights is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial z^{(L)}}{\\partial w^{(L)}} = a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put all the pieces together and replace we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have figured out how the error changes as we change the weight connecting the **hidden layer and the output layer $w^{(L)}$**. Amazing progress. We still need to know how the error changes as we adjust the weight connecting the **input layer and the hidden layer $w^{(L-1)}$**. Fortunately, this is pretty straightforward: we apply the chain-rule again, and again until we get there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}} \\times \\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}  \\times \\frac{\\partial z^{(L-1)}}{\\partial w^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, replacing with the actual derivatives this becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times w^{(L)} \\times a^{(L-1)}(1-a^{(L-1)}) \\times x^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic. There is one tiny piece we haven't mentioned: **the derivative of the error with respect to the bias term $b$**. There are two ways to approach this. One way is to treat the bias as another feature (usually with value 1) and add the corresponding weight to the matrix $W$. In such a case, the derivative of the weight for the bias is calculated along with the weights for the other features in the exact same manner. The other option is to compute the derivative separately as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial b^{(L)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know the values for the first two derivatives. We just need to figure out the derivative for $\\frac{\\partial z^{(L)}}{\\partial b^{(L)}}$. Now, remember that the *slope of $z$ does not depend at all from $b$*, because $b$ is just a constant value added at the end. Therefore, the derivative of the error w.r.t the bias reduces to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very convenient because it means we can reutilize part of the calculation for the derivative of the weights to compute the derivative of the biases.\n",
    "\n",
    "The last missing part is the derivative of the error w.r.t. the bias $b$ in the $(L-1)$ layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial a^{(L-1)}} \\times \\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}  \\times \\frac{\\partial z^{(L-1)}}{\\partial b^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives for each expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}}  = a^{(L)} - y \\times a^{(L)}(1-a^{(L)}) \\times w^{(L)} \\times a^{(L-1)}(1-a^{(L-1)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we can reuse part of the calculation for the derivative of $w^{(L-1)}$ to solve this. Every time we train a neural net wit backpropagation we will need to **compute the derivatives for all the weight and biases as showed before**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for multiple unit multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all neural networks you'll find have more than one neuron. Until now, we have assumed a network with a single neuron per layer. The only difference between the expressions we have used so far and added more units is a couple of **extra indices**. For example, we can use the letter $j$ to index the units in the output layer, the letter $k$ to index the units in the hidden layer, and the letter $i$ to index the units in the input layer. We also need indices for the weights. For any network with multiple units, we will have more weights than units, which means we will need two subscripts to indicate each weight. This is visible in the weight matrix in **Figure 2**. We will index the weights as $w_{\\text{destination-units} \\text{, } \\text{origin-units}}$. For instance, weights in $(L)$ become $w_{jk}$.\n",
    "\n",
    "With all this notation in mind, our original equation for the derivative of the error w.r.t the weights in $(L)$ layer becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}_{jk}} = \\frac{\\partial E_i}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial w^{(L)}_{jk}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}_{jk}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times a^{(L-1)}_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second thing to consider. This time we have to take into account that each **sigmoid activation $a$ from  $(L-1)$ layers impacts the error via multiple pathways** (assuming a network with *multiple output units*). In **Figure 5** this is illustrated by blue and red connections to the output layer. To reflect this, we add a summation symbol and the expression for the derivative of the error w.r.t the sigmoid activation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial a^{(L-1)}_k} = \\sum_{j} \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, considering both the new subscripts and summation for $\\frac{\\partial E}{\\partial a^{(L-1)}_k}$, we can apply the chain-rule one more time to compute the error derivatives for $w$ in $(L-1)$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}_{ki}} = \\left(\\sum_{j} \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\\right)  \\times \\frac{\\partial a^{(L-1)}_k}{\\partial z^{(L-1)}_k} \\times \\frac{\\partial z^{(L-1)}_k}{\\partial w^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives for each expression we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}_{ki}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times w^{(L)}_{jk} \\times a^{(L-1)}_k(1-a^{(L-1)}_k) \\times x^{(L-1)}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the new indices, the derivative for the error w.r.t the bias $b$ becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b_j^{(L)}} = \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial b^{(L)}_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L)}_j}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, the expression for the bias $b$ at layer $(L-1)$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k} \\times \\frac{\\partial a^{(L-1)}_k}{\\partial z^{(L-1)}_k}  \\times \\frac{\\partial z^{(L-1)}_k}{\\partial b^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with the actual derivatives we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial b^{(L-1)}}  = a^{(L)}_j - y \\times a^{(L)}_j(1-a^{(L)}_j) \\times w^{(L)}_{jk} \\times a^{(L-1)}_k(1-a^{(L-1)}_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! **Those are all the pieces for the backpropagation algorithm**. Probably, the hardest part is to track all the indices. To further clarify the notation you can look at the diagram in **Figure 5** that exemplifies where each piece of the equation is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 5 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/backprop.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation weight update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned how to compute the gradients for all the weights and biases. Now we just need to **use the computed gradients to update the weights and biases values**. This is actually when the **learning** happens. We do this by taking a portion of the gradient and substracting that to the current weight and bias value.\n",
    "\n",
    "For the wegiths $w_{jk}$ in the $(L)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{jk}^{L} = w_{jk}^{L} - \\eta \\times \\frac{\\partial E}{\\partial w_{jk}^{L}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the wegiths $w_{ki}$ in the $(L-1)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{ki}^{L-1} = w_{ki}^{L-1} - \\eta \\times \\frac{\\partial E}{\\partial w_{ki}^{L-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bias $b$ in the $(L)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b^{(L)} = b^{(L)} - \\eta \\times \\frac{\\partial E}{\\partial b^{(L)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bias $b$ in the $(L-1)$ layer we update by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b^{(L-1)} = b^{(L-1)} - \\eta \\times \\frac{\\partial E}{\\partial b^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\eta$ is the *step size* or *learning rate*. \n",
    "\n",
    "If you are not familiar with the idea of a learning rate, you can review the ADALINE chapter where I briefly explain the concept [here](https://com-cog-book.github.io/com-cog-book/features/adaline.html#Learning-procedure). In brief, a learning rate controls **how fast we descend over the error surface given the computed gradient**. This is important because we want to give steps just large enough to reach the minima of the surface at any point we may be when searching for the weights. You can see a more deep explanation [here](https://en.wikipedia.org/wiki/Learning_rate).\n",
    "\n",
    "I don't know about you but I have to go over several rounds of carefully studying the equations behind backpropagation to finally understand them fully. This may or not be true for you, but I believe the effort pays off as **backpropagation is the engine of every neural network model today**. Regardless, the good news is the modern numerical computation libraries like `NumPy`, `Tensorflow`, and `Pytorch` provide all the necessary methods and abstractions to make the implementation of neural networks and backpropagation relatively easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will **implement a multilayer-perceptron with one hidden layer by translating all our equations into code**. One important thing to consider is that we won't implement all the loops that the summation notation implies. Loops are known for being highly inefficient computationally, so we want to avoid them. Fortunately, we can use **matrix operations to achieve the exact same result**. This means that all the computations will be \"vectorized\". If you are not familiar with [vectorization](https://www.geeksforgeeks.org/vectorization-in-python/) you just need to know that instead of looping over each row in our training dataset we compute the outcome for each row all at once using linear algebra operations. This makes computation in neural networks highly efficient compared to using loops. To do this, I'll only use `NumPy` which is the most popular library for matrix operations and linear algebra in Python.\n",
    "\n",
    "Remember that we need to computer the following operations in order:\n",
    "\n",
    "1. linear function aggregation $z$\n",
    "2. sigmoid function activation $a$\n",
    "3. cost function (error) calculation $E$\n",
    "4. derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L)$ layer\n",
    "5. derivative of the error w.r.t. the weights $w$ and bias $b$ in the $(L-1)$ layer\n",
    "6. weight and bias update for the $(L)$ layer\n",
    "7. weight and bias update for the $(L-1)$ layer\n",
    "\n",
    "Those operations over the entire dataset comprise a single \"iteration\" or \"epoch\". Generally, we need to perform multiple repetitions of that sequence to train the weights. That loop can't be avoided unfortunately and will be part of the \"fit\" function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n_features, n_neurons, n_output):\n",
    "    \"\"\"generate initial parameters sampled from an uniform distribution\n",
    "    \n",
    "    Args:\n",
    "        n_features (int): number of feature vectors \n",
    "        n_neurons (int): number of neurons in hidden layer\n",
    "        n_output (int): number of output neurons\n",
    "    \n",
    "    Returns:\n",
    "        parameters dictionary:\n",
    "            W1: weight matrix, shape = [n_features, n_neurons]\n",
    "            b1: bias vector, shape = [1, n_neurons]\n",
    "            W2: weight matrix, shape = [n_neurons, n_output]\n",
    "            b2: bias vector, shape = [1, n_output]\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(100) # for reproducibility\n",
    "    W1 = np.random.uniform(size=(n_features,n_neurons))\n",
    "    b1 = np.random.uniform(size=(1,n_neurons))\n",
    "    W2 = np.random.uniform(size=(n_neurons,n_output))\n",
    "    b2 = np.random.uniform(size=(1,n_output))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation is very sensitive to the initialization of parameters**. For instance, in the process of writing this tutorial I learned that this particular network has a hard time finding a solution if I sample the weights from a normal distribution with mean = 0 and standard deviation = 0.01, but it does much better sampling from a uniform distribution. In any case, it is common practice to initialize the values for the weights and biases to some small values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $z$: linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(W, X, b):\n",
    "    \"\"\"computes net input as dot product\n",
    "    \n",
    "    Args:\n",
    "        W (ndarray): weight matrix\n",
    "        X (ndarray): matrix of features\n",
    "        b (ndarray): vector of biases\n",
    "        \n",
    "    Returns:\n",
    "        Z (ndarray): weighted sum of features\n",
    "        \"\"\"\n",
    "    \n",
    "    return (X @ W)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $a$: sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(Z):\n",
    "    \"\"\"computes sigmoid activation element wise\n",
    "    \n",
    "    Args:\n",
    "        Z (ndarray): weighted sum of features\n",
    "    \n",
    "    Returns: \n",
    "        S (ndarray): neuron activation\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1/(1+np.exp(-Z)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cost (error) function $E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(A, y):\n",
    "    \"\"\"computes squared error\n",
    "    \n",
    "    Args:\n",
    "        A (ndarray): neuron activation\n",
    "        y (ndarray): vector of expected values\n",
    "    \n",
    "    Returns:\n",
    "        E (float): total squared error\"\"\"\n",
    "    \n",
    "    return (np.mean(np.power(A - y,2)))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions $\\hat{y}$ with learned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, W2, b1, b2):\n",
    "    \"\"\"computes predictions with learned parameters\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): matrix of features\n",
    "        W1 (ndarray): weight matrix for the first layer\n",
    "        W2 (ndarray): weight matrix for the second layer\n",
    "        b1 (ndarray): bias vector for the first layer\n",
    "        b2 (ndarray): bias vector for the second layer\n",
    "        \n",
    "    Returns:\n",
    "        d (ndarray): vector of predicted values\n",
    "    \"\"\"\n",
    "    \n",
    "    Z1 = linear_function(W1, X, b1)\n",
    "    S1 = sigmoid_function(Z1)\n",
    "    Z2 = linear_function(W2, S1, b2)\n",
    "    S2 = sigmoid_function(Z2)\n",
    "    return np.where(S2 >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I plan to solve a binary classification problem, we define a threshold function that takes the output of the last sigmoid activation function and returns a 0 or a 1 for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_features=2, n_neurons=3, n_output=1, iterations=10, eta=0.001):\n",
    "    \"\"\"Multi-layer perceptron trained with backpropagation\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): matrix of features\n",
    "        y (ndarray): vector of expected values\n",
    "        n_features (int): number of feature vectors \n",
    "        n_neurons (int): number of neurons in hidden layer\n",
    "        n_output (int): number of output neurons\n",
    "        iterations (int): number of iterations over the training set\n",
    "        eta (float): learning rate\n",
    "        \n",
    "    Returns: \n",
    "        errors (list): list of errors over iterations\n",
    "        param (dic): dictionary of learned parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    ## ~~ Initialize parameters ~~##\n",
    "    param = init_parameters(n_features=n_features, \n",
    "                            n_neurons=n_neurons, \n",
    "                            n_output=n_output)\n",
    "\n",
    "    ## ~~ storage errors after each iteration ~~##\n",
    "    errors = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        \n",
    "        ##~~ Forward-propagation ~~##\n",
    "        \n",
    "        Z1 = linear_function(param['W1'], X, param['b1'])\n",
    "        S1 = sigmoid_function(Z1)\n",
    "        Z2 = linear_function(param['W2'], S1, param['b2'])\n",
    "        S2 = sigmoid_function(Z2)\n",
    "        \n",
    "        ##~~ Error computation ~~##\n",
    "        error = cost_function(S2, y)\n",
    "        errors.append(error)\n",
    "        \n",
    "        ##~~ Backpropagation ~~##\n",
    "        \n",
    "        # update output weights\n",
    "        delta2 = (S2 - y)* S2*(1-S2)\n",
    "        W2_gradients = S1.T @ delta2\n",
    "        param[\"W2\"] = param[\"W2\"] - W2_gradients * eta\n",
    "\n",
    "        # update output bias\n",
    "        param[\"b2\"] = param[\"b2\"] - np.sum(delta2, axis=0, keepdims=True) * eta\n",
    "\n",
    "        # update hidden weights\n",
    "        delta1 = (delta2 @ param[\"W2\"].T )* S1*(1-S1)\n",
    "        W1_gradients = X.T @ delta1 \n",
    "        param[\"W1\"] = param[\"W1\"] - W1_gradients * eta\n",
    "\n",
    "        # update hidden bias\n",
    "        param[\"b1\"] = param[\"b1\"] - np.sum(delta1, axis=0, keepdims=True) * eta\n",
    "        \n",
    "    return errors, param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we put everything together to train the network. The first part of the function initializes the parameters by calling the `init_parameters` function. The loop (`for _ in range(iterations)`) in the second part of the function is where all the action happens:\n",
    "\n",
    "1. the **Forward-propagation** section chains the linear and sigmoid functions to compute the network output.\n",
    "2. the **Error computation** section computes the cost function value after each iteration.\n",
    "3. the **Backpropagation** section does two things:\n",
    "    - computes the gradients for the weights and biases in the $(L)$ and $(L-1)$ layers\n",
    "    - update the weights and biases in the $(L)$ and $(L-1)$ layers\n",
    "4. the `fit` function returns a list of the errors after each iteration and an updated dictionary with the learned weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: solving the XOR problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have read this and previous chapters, you should know by now that one of the problems that brought about the \"demise\" of the interest in neural network models was the infamous XOR (exclusive or) problem. This was just one example of a large class of problems that can't be solved with linear models as the perceptron and ADALINE. As an act of redemption for neural networks from this criticism, we will solve the XOR problem using our implementation of the multilayer-perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first is to generate the targets and features for the XOR problem. **Table 1** shows the matrix of values we need to generate, where $x_1$ and $x_2$ are the features and $y$ the expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1**: Truth Table For XOR Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $x_1$ | $x_2$ | $y$ |\n",
    "|---|---|--------|\n",
    "| 0 | 0 | 0      |\n",
    "| 0 | 1 | 1      |\n",
    "| 1 | 0 | 1      |\n",
    "| 1 | 1 | 0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected values\n",
    "y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "# features\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the network by running 5,000 iterations with a learning rate of $\\eta = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, param = fit(X, y, iterations=5000, eta=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron predictions and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X, param[\"W1\"], param[\"W2\"], param[\"b1\"], param[\"b2\"])\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dea24de9aed24921993768ecd5e20f9e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-dea24de9aed24921993768ecd5e20f9e\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bf9f27abf3b922139836e40e6f41caa1\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"time-step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"errors\"}}, \"title\": \"Chart 2\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-bf9f27abf3b922139836e40e6f41caa1\": [{\"errors\": 0.17037699424952266, \"time-step\": 0}, {\"errors\": 0.16804892560495124, \"time-step\": 1}, {\"errors\": 0.16571393112397487, \"time-step\": 2}, {\"errors\": 0.16338264704264036, \"time-step\": 3}, {\"errors\": 0.1610662579543201, \"time-step\": 4}, {\"errors\": 0.15877627259708382, \"time-step\": 5}, {\"errors\": 0.1565242673859441, \"time-step\": 6}, {\"errors\": 0.1543216087576396, \"time-step\": 7}, {\"errors\": 0.15217916819896438, \"time-step\": 8}, {\"errors\": 0.15010704555098447, \"time-step\": 9}, {\"errors\": 0.14811431648219273, \"time-step\": 10}, {\"errors\": 0.14620881875104452, \"time-step\": 11}, {\"errors\": 0.14439698911305815, \"time-step\": 12}, {\"errors\": 0.1426837587838099, \"time-step\": 13}, {\"errors\": 0.14107251074295576, \"time-step\": 14}, {\"errors\": 0.13956509744306175, \"time-step\": 15}, {\"errors\": 0.13816191324024166, \"time-step\": 16}, {\"errors\": 0.13686201254529293, \"time-step\": 17}, {\"errors\": 0.135663262576654, \"time-step\": 18}, {\"errors\": 0.13456251874975783, \"time-step\": 19}, {\"errors\": 0.13355581104925907, \"time-step\": 20}, {\"errors\": 0.13263853095890948, \"time-step\": 21}, {\"errors\": 0.13180561036029864, \"time-step\": 22}, {\"errors\": 0.131051685942878, \"time-step\": 23}, {\"errors\": 0.13037124482129453, \"time-step\": 24}, {\"errors\": 0.12975874902740797, \"time-step\": 25}, {\"errors\": 0.12920873820454393, \"time-step\": 26}, {\"errors\": 0.1287159111213709, \"time-step\": 27}, {\"errors\": 0.1282751875384727, \"time-step\": 28}, {\"errors\": 0.12788175253641715, \"time-step\": 29}, {\"errors\": 0.12753108570555177, \"time-step\": 30}, {\"errors\": 0.12721897766859502, \"time-step\": 31}, {\"errors\": 0.12694153631952754, \"time-step\": 32}, {\"errors\": 0.12669518497121812, \"time-step\": 33}, {\"errors\": 0.12647665435446334, \"time-step\": 34}, {\"errors\": 0.12628297013687137, \"time-step\": 35}, {\"errors\": 0.12611143735561572, \"time-step\": 36}, {\"errors\": 0.12595962289952356, \"time-step\": 37}, {\"errors\": 0.1258253369426388, \"time-step\": 38}, {\"errors\": 0.12570661402779357, \"time-step\": 39}, {\"errors\": 0.125601694325875, \"time-step\": 40}, {\"errors\": 0.1255090054531816, \"time-step\": 41}, {\"errors\": 0.1254271451129971, \"time-step\": 42}, {\"errors\": 0.12535486473506974, \"time-step\": 43}, {\"errors\": 0.12529105421466827, \"time-step\": 44}, {\"errors\": 0.12523472779797296, \"time-step\": 45}, {\"errors\": 0.12518501111968122, \"time-step\": 46}, {\"errors\": 0.12514112936915028, \"time-step\": 47}, {\"errors\": 0.12510239654081265, \"time-step\": 48}, {\"errors\": 0.12506820571101648, \"time-step\": 49}, {\"errors\": 0.12503802027522573, \"time-step\": 50}, {\"errors\": 0.12501136607533925, \"time-step\": 51}, {\"errors\": 0.12498782434569705, \"time-step\": 52}, {\"errors\": 0.12496702540728763, \"time-step\": 53}, {\"errors\": 0.12494864304210929, \"time-step\": 54}, {\"errors\": 0.1249323894830601, \"time-step\": 55}, {\"errors\": 0.12491801095875943, \"time-step\": 56}, {\"errors\": 0.12490528373705131, \"time-step\": 57}, {\"errors\": 0.12489401061540381, \"time-step\": 58}, {\"errors\": 0.12488401781084196, \"time-step\": 59}, {\"errors\": 0.1248751522063403, \"time-step\": 60}, {\"errors\": 0.12486727891468291, \"time-step\": 61}, {\"errors\": 0.12486027912462828, \"time-step\": 62}, {\"errors\": 0.12485404819777907, \"time-step\": 63}, {\"errors\": 0.12484849398783454, \"time-step\": 64}, {\"errors\": 0.12484353535690637, \"time-step\": 65}, {\"errors\": 0.12483910086630588, \"time-step\": 66}, {\"errors\": 0.12483512762168453, \"time-step\": 67}, {\"errors\": 0.1248315602546366, \"time-step\": 68}, {\"errors\": 0.12482835002487688, \"time-step\": 69}, {\"errors\": 0.12482545402890177, \"time-step\": 70}, {\"errors\": 0.12482283450264597, \"time-step\": 71}, {\"errors\": 0.12482045820708018, \"time-step\": 72}, {\"errors\": 0.1248182958869694, \"time-step\": 73}, {\"errors\": 0.12481632179414603, \"time-step\": 74}, {\"errors\": 0.12481451326765822, \"time-step\": 75}, {\"errors\": 0.12481285036404699, \"time-step\": 76}, {\"errors\": 0.12481131553179806, \"time-step\": 77}, {\"errors\": 0.12480989332471248, \"time-step\": 78}, {\"errors\": 0.12480857014956259, \"time-step\": 79}, {\"errors\": 0.12480733404394578, \"time-step\": 80}, {\"errors\": 0.12480617448073301, \"time-step\": 81}, {\"errors\": 0.12480508219593676, \"time-step\": 82}, {\"errors\": 0.12480404903720019, \"time-step\": 83}, {\"errors\": 0.12480306783044212, \"time-step\": 84}, {\"errors\": 0.12480213226248582, \"time-step\": 85}, {\"errors\": 0.12480123677775917, \"time-step\": 86}, {\"errors\": 0.12480037648738115, \"time-step\": 87}, {\"errors\": 0.12479954708915163, \"time-step\": 88}, {\"errors\": 0.12479874479713798, \"time-step\": 89}, {\"errors\": 0.12479796627970868, \"time-step\": 90}, {\"errors\": 0.12479720860500113, \"time-step\": 91}, {\"errors\": 0.12479646919293283, \"time-step\": 92}, {\"errors\": 0.12479574577297092, \"time-step\": 93}, {\"errors\": 0.12479503634697006, \"time-step\": 94}, {\"errors\": 0.12479433915646981, \"time-step\": 95}, {\"errors\": 0.12479365265391765, \"time-step\": 96}, {\"errors\": 0.12479297547734565, \"time-step\": 97}, {\"errors\": 0.12479230642808714, \"time-step\": 98}, {\"errors\": 0.12479164445116839, \"time-step\": 99}, {\"errors\": 0.12479098861805385, \"time-step\": 100}, {\"errors\": 0.12479033811146312, \"time-step\": 101}, {\"errors\": 0.12478969221201064, \"time-step\": 102}, {\"errors\": 0.12478905028644971, \"time-step\": 103}, {\"errors\": 0.12478841177732727, \"time-step\": 104}, {\"errors\": 0.1247877761938817, \"time-step\": 105}, {\"errors\": 0.12478714310403269, \"time-step\": 106}, {\"errors\": 0.12478651212733347, \"time-step\": 107}, {\"errors\": 0.12478588292876899, \"time-step\": 108}, {\"errors\": 0.12478525521329914, \"time-step\": 109}, {\"errors\": 0.12478462872105672, \"time-step\": 110}, {\"errors\": 0.1247840032231226, \"time-step\": 111}, {\"errors\": 0.12478337851780788, \"time-step\": 112}, {\"errors\": 0.12478275442738253, \"time-step\": 113}, {\"errors\": 0.12478213079519716, \"time-step\": 114}, {\"errors\": 0.12478150748315013, \"time-step\": 115}, {\"errors\": 0.12478088436945906, \"time-step\": 116}, {\"errors\": 0.12478026134669988, \"time-step\": 117}, {\"errors\": 0.12477963832008138, \"time-step\": 118}, {\"errors\": 0.12477901520592714, \"time-step\": 119}, {\"errors\": 0.12477839193033967, \"time-step\": 120}, {\"errors\": 0.12477776842802496, \"time-step\": 121}, {\"errors\": 0.1247771446412583, \"time-step\": 122}, {\"errors\": 0.12477652051897434, \"time-step\": 123}, {\"errors\": 0.1247758960159664, \"time-step\": 124}, {\"errors\": 0.12477527109218191, \"time-step\": 125}, {\"errors\": 0.12477464571210263, \"time-step\": 126}, {\"errors\": 0.12477401984419925, \"time-step\": 127}, {\"errors\": 0.12477339346045138, \"time-step\": 128}, {\"errors\": 0.12477276653592548, \"time-step\": 129}, {\"errors\": 0.1247721390484033, \"time-step\": 130}, {\"errors\": 0.12477151097805492, \"time-step\": 131}, {\"errors\": 0.1247708823071513, \"time-step\": 132}, {\"errors\": 0.12477025301981115, \"time-step\": 133}, {\"errors\": 0.12476962310177833, \"time-step\": 134}, {\"errors\": 0.12476899254022594, \"time-step\": 135}, {\"errors\": 0.1247683613235839, \"time-step\": 136}, {\"errors\": 0.12476772944138759, \"time-step\": 137}, {\"errors\": 0.12476709688414411, \"time-step\": 138}, {\"errors\": 0.12476646364321507, \"time-step\": 139}, {\"errors\": 0.12476582971071333, \"time-step\": 140}, {\"errors\": 0.12476519507941201, \"time-step\": 141}, {\"errors\": 0.12476455974266487, \"time-step\": 142}, {\"errors\": 0.1247639236943355, \"time-step\": 143}, {\"errors\": 0.1247632869287359, \"time-step\": 144}, {\"errors\": 0.12476264944057175, \"time-step\": 145}, {\"errors\": 0.12476201122489476, \"time-step\": 146}, {\"errors\": 0.12476137227706025, \"time-step\": 147}, {\"errors\": 0.12476073259269024, \"time-step\": 148}, {\"errors\": 0.12476009216764103, \"time-step\": 149}, {\"errors\": 0.12475945099797411, \"time-step\": 150}, {\"errors\": 0.12475880907993124, \"time-step\": 151}, {\"errors\": 0.12475816640991215, \"time-step\": 152}, {\"errors\": 0.12475752298445497, \"time-step\": 153}, {\"errors\": 0.12475687880021905, \"time-step\": 154}, {\"errors\": 0.1247562338539699, \"time-step\": 155}, {\"errors\": 0.12475558814256588, \"time-step\": 156}, {\"errors\": 0.12475494166294643, \"time-step\": 157}, {\"errors\": 0.12475429441212191, \"time-step\": 158}, {\"errors\": 0.12475364638716444, \"time-step\": 159}, {\"errors\": 0.12475299758519993, \"time-step\": 160}, {\"errors\": 0.12475234800340114, \"time-step\": 161}, {\"errors\": 0.12475169763898157, \"time-step\": 162}, {\"errors\": 0.12475104648918978, \"time-step\": 163}, {\"errors\": 0.12475039455130497, \"time-step\": 164}, {\"errors\": 0.12474974182263254, \"time-step\": 165}, {\"errors\": 0.12474908830050044, \"time-step\": 166}, {\"errors\": 0.1247484339822561, \"time-step\": 167}, {\"errors\": 0.12474777886526325, \"time-step\": 168}, {\"errors\": 0.12474712294689963, \"time-step\": 169}, {\"errors\": 0.12474646622455492, \"time-step\": 170}, {\"errors\": 0.12474580869562829, \"time-step\": 171}, {\"errors\": 0.12474515035752733, \"time-step\": 172}, {\"errors\": 0.12474449120766598, \"time-step\": 173}, {\"errors\": 0.12474383124346361, \"time-step\": 174}, {\"errors\": 0.12474317046234354, \"time-step\": 175}, {\"errors\": 0.1247425088617323, \"time-step\": 176}, {\"errors\": 0.12474184643905854, \"time-step\": 177}, {\"errors\": 0.12474118319175224, \"time-step\": 178}, {\"errors\": 0.1247405191172441, \"time-step\": 179}, {\"errors\": 0.12473985421296485, \"time-step\": 180}, {\"errors\": 0.1247391884763447, \"time-step\": 181}, {\"errors\": 0.124738521904813, \"time-step\": 182}, {\"errors\": 0.12473785449579752, \"time-step\": 183}, {\"errors\": 0.12473718624672449, \"time-step\": 184}, {\"errors\": 0.12473651715501786, \"time-step\": 185}, {\"errors\": 0.12473584721809922, \"time-step\": 186}, {\"errors\": 0.12473517643338758, \"time-step\": 187}, {\"errors\": 0.12473450479829909, \"time-step\": 188}, {\"errors\": 0.1247338323102467, \"time-step\": 189}, {\"errors\": 0.12473315896664022, \"time-step\": 190}, {\"errors\": 0.12473248476488609, \"time-step\": 191}, {\"errors\": 0.12473180970238706, \"time-step\": 192}, {\"errors\": 0.12473113377654227, \"time-step\": 193}, {\"errors\": 0.1247304569847471, \"time-step\": 194}, {\"errors\": 0.12472977932439301, \"time-step\": 195}, {\"errors\": 0.1247291007928675, \"time-step\": 196}, {\"errors\": 0.12472842138755408, \"time-step\": 197}, {\"errors\": 0.12472774110583196, \"time-step\": 198}, {\"errors\": 0.12472705994507637, \"time-step\": 199}, {\"errors\": 0.12472637790265814, \"time-step\": 200}, {\"errors\": 0.1247256949759439, \"time-step\": 201}, {\"errors\": 0.12472501116229584, \"time-step\": 202}, {\"errors\": 0.12472432645907186, \"time-step\": 203}, {\"errors\": 0.12472364086362539, \"time-step\": 204}, {\"errors\": 0.12472295437330536, \"time-step\": 205}, {\"errors\": 0.12472226698545619, \"time-step\": 206}, {\"errors\": 0.12472157869741789, \"time-step\": 207}, {\"errors\": 0.12472088950652575, \"time-step\": 208}, {\"errors\": 0.12472019941011059, \"time-step\": 209}, {\"errors\": 0.12471950840549856, \"time-step\": 210}, {\"errors\": 0.12471881649001118, \"time-step\": 211}, {\"errors\": 0.12471812366096532, \"time-step\": 212}, {\"errors\": 0.12471742991567318, \"time-step\": 213}, {\"errors\": 0.1247167352514422, \"time-step\": 214}, {\"errors\": 0.1247160396655752, \"time-step\": 215}, {\"errors\": 0.12471534315537008, \"time-step\": 216}, {\"errors\": 0.12471464571812024, \"time-step\": 217}, {\"errors\": 0.12471394735111407, \"time-step\": 218}, {\"errors\": 0.12471324805163522, \"time-step\": 219}, {\"errors\": 0.12471254781696263, \"time-step\": 220}, {\"errors\": 0.12471184664437027, \"time-step\": 221}, {\"errors\": 0.12471114453112736, \"time-step\": 222}, {\"errors\": 0.1247104414744982, \"time-step\": 223}, {\"errors\": 0.12470973747174224, \"time-step\": 224}, {\"errors\": 0.12470903252011403, \"time-step\": 225}, {\"errors\": 0.12470832661686312, \"time-step\": 226}, {\"errors\": 0.12470761975923433, \"time-step\": 227}, {\"errors\": 0.12470691194446733, \"time-step\": 228}, {\"errors\": 0.12470620316979696, \"time-step\": 229}, {\"errors\": 0.12470549343245302, \"time-step\": 230}, {\"errors\": 0.12470478272966037, \"time-step\": 231}, {\"errors\": 0.12470407105863882, \"time-step\": 232}, {\"errors\": 0.12470335841660318, \"time-step\": 233}, {\"errors\": 0.12470264480076318, \"time-step\": 234}, {\"errors\": 0.1247019302083236, \"time-step\": 235}, {\"errors\": 0.12470121463648402, \"time-step\": 236}, {\"errors\": 0.1247004980824391, \"time-step\": 237}, {\"errors\": 0.12469978054337824, \"time-step\": 238}, {\"errors\": 0.1246990620164858, \"time-step\": 239}, {\"errors\": 0.12469834249894106, \"time-step\": 240}, {\"errors\": 0.12469762198791808, \"time-step\": 241}, {\"errors\": 0.12469690048058577, \"time-step\": 242}, {\"errors\": 0.1246961779741079, \"time-step\": 243}, {\"errors\": 0.12469545446564304, \"time-step\": 244}, {\"errors\": 0.12469472995234454, \"time-step\": 245}, {\"errors\": 0.12469400443136056, \"time-step\": 246}, {\"errors\": 0.12469327789983398, \"time-step\": 247}, {\"errors\": 0.12469255035490244, \"time-step\": 248}, {\"errors\": 0.12469182179369839, \"time-step\": 249}, {\"errors\": 0.12469109221334887, \"time-step\": 250}, {\"errors\": 0.12469036161097574, \"time-step\": 251}, {\"errors\": 0.12468962998369545, \"time-step\": 252}, {\"errors\": 0.12468889732861918, \"time-step\": 253}, {\"errors\": 0.12468816364285276, \"time-step\": 254}, {\"errors\": 0.12468742892349664, \"time-step\": 255}, {\"errors\": 0.12468669316764591, \"time-step\": 256}, {\"errors\": 0.12468595637239026, \"time-step\": 257}, {\"errors\": 0.12468521853481399, \"time-step\": 258}, {\"errors\": 0.12468447965199593, \"time-step\": 259}, {\"errors\": 0.12468373972100955, \"time-step\": 260}, {\"errors\": 0.12468299873892277, \"time-step\": 261}, {\"errors\": 0.1246822567027981, \"time-step\": 262}, {\"errors\": 0.12468151360969258, \"time-step\": 263}, {\"errors\": 0.12468076945665768, \"time-step\": 264}, {\"errors\": 0.12468002424073946, \"time-step\": 265}, {\"errors\": 0.12467927795897826, \"time-step\": 266}, {\"errors\": 0.12467853060840908, \"time-step\": 267}, {\"errors\": 0.12467778218606121, \"time-step\": 268}, {\"errors\": 0.12467703268895844, \"time-step\": 269}, {\"errors\": 0.1246762821141189, \"time-step\": 270}, {\"errors\": 0.12467553045855512, \"time-step\": 271}, {\"errors\": 0.12467477771927403, \"time-step\": 272}, {\"errors\": 0.12467402389327689, \"time-step\": 273}, {\"errors\": 0.12467326897755929, \"time-step\": 274}, {\"errors\": 0.12467251296911114, \"time-step\": 275}, {\"errors\": 0.12467175586491666, \"time-step\": 276}, {\"errors\": 0.12467099766195439, \"time-step\": 277}, {\"errors\": 0.12467023835719705, \"time-step\": 278}, {\"errors\": 0.12466947794761171, \"time-step\": 279}, {\"errors\": 0.12466871643015967, \"time-step\": 280}, {\"errors\": 0.12466795380179635, \"time-step\": 281}, {\"errors\": 0.12466719005947147, \"time-step\": 282}, {\"errors\": 0.12466642520012894, \"time-step\": 283}, {\"errors\": 0.1246656592207068, \"time-step\": 284}, {\"errors\": 0.12466489211813722, \"time-step\": 285}, {\"errors\": 0.12466412388934661, \"time-step\": 286}, {\"errors\": 0.1246633545312554, \"time-step\": 287}, {\"errors\": 0.12466258404077818, \"time-step\": 288}, {\"errors\": 0.12466181241482362, \"time-step\": 289}, {\"errors\": 0.1246610396502944, \"time-step\": 290}, {\"errors\": 0.12466026574408742, \"time-step\": 291}, {\"errors\": 0.12465949069309337, \"time-step\": 292}, {\"errors\": 0.1246587144941972, \"time-step\": 293}, {\"errors\": 0.1246579371442777, \"time-step\": 294}, {\"errors\": 0.12465715864020771, \"time-step\": 295}, {\"errors\": 0.12465637897885407, \"time-step\": 296}, {\"errors\": 0.12465559815707752, \"time-step\": 297}, {\"errors\": 0.12465481617173278, \"time-step\": 298}, {\"errors\": 0.12465403301966842, \"time-step\": 299}, {\"errors\": 0.12465324869772701, \"time-step\": 300}, {\"errors\": 0.1246524632027449, \"time-step\": 301}, {\"errors\": 0.12465167653155237, \"time-step\": 302}, {\"errors\": 0.12465088868097363, \"time-step\": 303}, {\"errors\": 0.12465009964782647, \"time-step\": 304}, {\"errors\": 0.12464930942892281, \"time-step\": 305}, {\"errors\": 0.12464851802106812, \"time-step\": 306}, {\"errors\": 0.12464772542106181, \"time-step\": 307}, {\"errors\": 0.12464693162569693, \"time-step\": 308}, {\"errors\": 0.1246461366317604, \"time-step\": 309}, {\"errors\": 0.12464534043603279, \"time-step\": 310}, {\"errors\": 0.1246445430352884, \"time-step\": 311}, {\"errors\": 0.12464374442629522, \"time-step\": 312}, {\"errors\": 0.1246429446058149, \"time-step\": 313}, {\"errors\": 0.12464214357060283, \"time-step\": 314}, {\"errors\": 0.12464134131740792, \"time-step\": 315}, {\"errors\": 0.1246405378429728, \"time-step\": 316}, {\"errors\": 0.12463973314403368, \"time-step\": 317}, {\"errors\": 0.12463892721732032, \"time-step\": 318}, {\"errors\": 0.12463812005955617, \"time-step\": 319}, {\"errors\": 0.12463731166745803, \"time-step\": 320}, {\"errors\": 0.12463650203773641, \"time-step\": 321}, {\"errors\": 0.12463569116709532, \"time-step\": 322}, {\"errors\": 0.12463487905223213, \"time-step\": 323}, {\"errors\": 0.12463406568983793, \"time-step\": 324}, {\"errors\": 0.12463325107659703, \"time-step\": 325}, {\"errors\": 0.1246324352091873, \"time-step\": 326}, {\"errors\": 0.12463161808428008, \"time-step\": 327}, {\"errors\": 0.12463079969854007, \"time-step\": 328}, {\"errors\": 0.12462998004862536, \"time-step\": 329}, {\"errors\": 0.12462915913118736, \"time-step\": 330}, {\"errors\": 0.12462833694287101, \"time-step\": 331}, {\"errors\": 0.1246275134803144, \"time-step\": 332}, {\"errors\": 0.124626688740149, \"time-step\": 333}, {\"errors\": 0.12462586271899967, \"time-step\": 334}, {\"errors\": 0.12462503541348444, \"time-step\": 335}, {\"errors\": 0.12462420682021463, \"time-step\": 336}, {\"errors\": 0.12462337693579484, \"time-step\": 337}, {\"errors\": 0.12462254575682293, \"time-step\": 338}, {\"errors\": 0.12462171327988983, \"time-step\": 339}, {\"errors\": 0.12462087950157982, \"time-step\": 340}, {\"errors\": 0.12462004441847027, \"time-step\": 341}, {\"errors\": 0.12461920802713172, \"time-step\": 342}, {\"errors\": 0.1246183703241279, \"time-step\": 343}, {\"errors\": 0.12461753130601555, \"time-step\": 344}, {\"errors\": 0.12461669096934466, \"time-step\": 345}, {\"errors\": 0.12461584931065806, \"time-step\": 346}, {\"errors\": 0.12461500632649192, \"time-step\": 347}, {\"errors\": 0.12461416201337527, \"time-step\": 348}, {\"errors\": 0.12461331636783027, \"time-step\": 349}, {\"errors\": 0.12461246938637201, \"time-step\": 350}, {\"errors\": 0.12461162106550856, \"time-step\": 351}, {\"errors\": 0.1246107714017411, \"time-step\": 352}, {\"errors\": 0.12460992039156356, \"time-step\": 353}, {\"errors\": 0.12460906803146293, \"time-step\": 354}, {\"errors\": 0.1246082143179191, \"time-step\": 355}, {\"errors\": 0.12460735924740482, \"time-step\": 356}, {\"errors\": 0.12460650281638573, \"time-step\": 357}, {\"errors\": 0.12460564502132031, \"time-step\": 358}, {\"errors\": 0.12460478585865996, \"time-step\": 359}, {\"errors\": 0.1246039253248487, \"time-step\": 360}, {\"errors\": 0.12460306341632359, \"time-step\": 361}, {\"errors\": 0.12460220012951431, \"time-step\": 362}, {\"errors\": 0.12460133546084337, \"time-step\": 363}, {\"errors\": 0.12460046940672602, \"time-step\": 364}, {\"errors\": 0.12459960196357012, \"time-step\": 365}, {\"errors\": 0.12459873312777643, \"time-step\": 366}, {\"errors\": 0.12459786289573818, \"time-step\": 367}, {\"errors\": 0.12459699126384147, \"time-step\": 368}, {\"errors\": 0.1245961182284649, \"time-step\": 369}, {\"errors\": 0.12459524378597972, \"time-step\": 370}, {\"errors\": 0.12459436793274983, \"time-step\": 371}, {\"errors\": 0.12459349066513165, \"time-step\": 372}, {\"errors\": 0.1245926119794743, \"time-step\": 373}, {\"errors\": 0.12459173187211925, \"time-step\": 374}, {\"errors\": 0.12459085033940066, \"time-step\": 375}, {\"errors\": 0.12458996737764516, \"time-step\": 376}, {\"errors\": 0.12458908298317176, \"time-step\": 377}, {\"errors\": 0.12458819715229213, \"time-step\": 378}, {\"errors\": 0.12458730988131023, \"time-step\": 379}, {\"errors\": 0.12458642116652249, \"time-step\": 380}, {\"errors\": 0.12458553100421779, \"time-step\": 381}, {\"errors\": 0.1245846393906774, \"time-step\": 382}, {\"errors\": 0.12458374632217488, \"time-step\": 383}, {\"errors\": 0.12458285179497625, \"time-step\": 384}, {\"errors\": 0.12458195580533973, \"time-step\": 385}, {\"errors\": 0.12458105834951595, \"time-step\": 386}, {\"errors\": 0.12458015942374785, \"time-step\": 387}, {\"errors\": 0.1245792590242705, \"time-step\": 388}, {\"errors\": 0.12457835714731141, \"time-step\": 389}, {\"errors\": 0.12457745378909016, \"time-step\": 390}, {\"errors\": 0.12457654894581861, \"time-step\": 391}, {\"errors\": 0.1245756426137008, \"time-step\": 392}, {\"errors\": 0.12457473478893293, \"time-step\": 393}, {\"errors\": 0.1245738254677034, \"time-step\": 394}, {\"errors\": 0.1245729146461926, \"time-step\": 395}, {\"errors\": 0.12457200232057325, \"time-step\": 396}, {\"errors\": 0.1245710884870099, \"time-step\": 397}, {\"errors\": 0.12457017314165941, \"time-step\": 398}, {\"errors\": 0.12456925628067048, \"time-step\": 399}, {\"errors\": 0.12456833790018398, \"time-step\": 400}, {\"errors\": 0.12456741799633275, \"time-step\": 401}, {\"errors\": 0.12456649656524152, \"time-step\": 402}, {\"errors\": 0.1245655736030272, \"time-step\": 403}, {\"errors\": 0.12456464910579837, \"time-step\": 404}, {\"errors\": 0.12456372306965577, \"time-step\": 405}, {\"errors\": 0.12456279549069188, \"time-step\": 406}, {\"errors\": 0.12456186636499118, \"time-step\": 407}, {\"errors\": 0.12456093568862993, \"time-step\": 408}, {\"errors\": 0.12456000345767625, \"time-step\": 409}, {\"errors\": 0.12455906966819008, \"time-step\": 410}, {\"errors\": 0.1245581343162232, \"time-step\": 411}, {\"errors\": 0.12455719739781912, \"time-step\": 412}, {\"errors\": 0.12455625890901309, \"time-step\": 413}, {\"errors\": 0.12455531884583214, \"time-step\": 414}, {\"errors\": 0.12455437720429503, \"time-step\": 415}, {\"errors\": 0.12455343398041216, \"time-step\": 416}, {\"errors\": 0.12455248917018558, \"time-step\": 417}, {\"errors\": 0.12455154276960914, \"time-step\": 418}, {\"errors\": 0.12455059477466808, \"time-step\": 419}, {\"errors\": 0.12454964518133951, \"time-step\": 420}, {\"errors\": 0.12454869398559192, \"time-step\": 421}, {\"errors\": 0.12454774118338546, \"time-step\": 422}, {\"errors\": 0.12454678677067182, \"time-step\": 423}, {\"errors\": 0.12454583074339425, \"time-step\": 424}, {\"errors\": 0.12454487309748738, \"time-step\": 425}, {\"errors\": 0.12454391382887742, \"time-step\": 426}, {\"errors\": 0.12454295293348205, \"time-step\": 427}, {\"errors\": 0.12454199040721031, \"time-step\": 428}, {\"errors\": 0.12454102624596274, \"time-step\": 429}, {\"errors\": 0.12454006044563119, \"time-step\": 430}, {\"errors\": 0.12453909300209892, \"time-step\": 431}, {\"errors\": 0.12453812391124061, \"time-step\": 432}, {\"errors\": 0.12453715316892214, \"time-step\": 433}, {\"errors\": 0.12453618077100079, \"time-step\": 434}, {\"errors\": 0.1245352067133251, \"time-step\": 435}, {\"errors\": 0.12453423099173483, \"time-step\": 436}, {\"errors\": 0.12453325360206105, \"time-step\": 437}, {\"errors\": 0.12453227454012605, \"time-step\": 438}, {\"errors\": 0.12453129380174327, \"time-step\": 439}, {\"errors\": 0.12453031138271733, \"time-step\": 440}, {\"errors\": 0.12452932727884403, \"time-step\": 441}, {\"errors\": 0.12452834148591027, \"time-step\": 442}, {\"errors\": 0.12452735399969411, \"time-step\": 443}, {\"errors\": 0.12452636481596466, \"time-step\": 444}, {\"errors\": 0.12452537393048205, \"time-step\": 445}, {\"errors\": 0.1245243813389976, \"time-step\": 446}, {\"errors\": 0.12452338703725346, \"time-step\": 447}, {\"errors\": 0.12452239102098298, \"time-step\": 448}, {\"errors\": 0.12452139328591028, \"time-step\": 449}, {\"errors\": 0.12452039382775057, \"time-step\": 450}, {\"errors\": 0.12451939264220994, \"time-step\": 451}, {\"errors\": 0.12451838972498544, \"time-step\": 452}, {\"errors\": 0.12451738507176492, \"time-step\": 453}, {\"errors\": 0.12451637867822721, \"time-step\": 454}, {\"errors\": 0.12451537054004178, \"time-step\": 455}, {\"errors\": 0.1245143606528692, \"time-step\": 456}, {\"errors\": 0.12451334901236058, \"time-step\": 457}, {\"errors\": 0.12451233561415798, \"time-step\": 458}, {\"errors\": 0.12451132045389407, \"time-step\": 459}, {\"errors\": 0.12451030352719239, \"time-step\": 460}, {\"errors\": 0.12450928482966706, \"time-step\": 461}, {\"errors\": 0.12450826435692293, \"time-step\": 462}, {\"errors\": 0.12450724210455552, \"time-step\": 463}, {\"errors\": 0.12450621806815096, \"time-step\": 464}, {\"errors\": 0.12450519224328604, \"time-step\": 465}, {\"errors\": 0.1245041646255281, \"time-step\": 466}, {\"errors\": 0.12450313521043506, \"time-step\": 467}, {\"errors\": 0.12450210399355532, \"time-step\": 468}, {\"errors\": 0.12450107097042791, \"time-step\": 469}, {\"errors\": 0.12450003613658228, \"time-step\": 470}, {\"errors\": 0.1244989994875384, \"time-step\": 471}, {\"errors\": 0.12449796101880664, \"time-step\": 472}, {\"errors\": 0.12449692072588783, \"time-step\": 473}, {\"errors\": 0.12449587860427322, \"time-step\": 474}, {\"errors\": 0.12449483464944443, \"time-step\": 475}, {\"errors\": 0.12449378885687337, \"time-step\": 476}, {\"errors\": 0.1244927412220224, \"time-step\": 477}, {\"errors\": 0.12449169174034408, \"time-step\": 478}, {\"errors\": 0.12449064040728129, \"time-step\": 479}, {\"errors\": 0.12448958721826725, \"time-step\": 480}, {\"errors\": 0.12448853216872531, \"time-step\": 481}, {\"errors\": 0.12448747525406909, \"time-step\": 482}, {\"errors\": 0.12448641646970243, \"time-step\": 483}, {\"errors\": 0.12448535581101924, \"time-step\": 484}, {\"errors\": 0.12448429327340366, \"time-step\": 485}, {\"errors\": 0.12448322885222995, \"time-step\": 486}, {\"errors\": 0.12448216254286237, \"time-step\": 487}, {\"errors\": 0.12448109434065541, \"time-step\": 488}, {\"errors\": 0.12448002424095342, \"time-step\": 489}, {\"errors\": 0.12447895223909099, \"time-step\": 490}, {\"errors\": 0.1244778783303925, \"time-step\": 491}, {\"errors\": 0.12447680251017246, \"time-step\": 492}, {\"errors\": 0.12447572477373524, \"time-step\": 493}, {\"errors\": 0.12447464511637518, \"time-step\": 494}, {\"errors\": 0.12447356353337649, \"time-step\": 495}, {\"errors\": 0.12447248002001336, \"time-step\": 496}, {\"errors\": 0.12447139457154965, \"time-step\": 497}, {\"errors\": 0.12447030718323923, \"time-step\": 498}, {\"errors\": 0.12446921785032572, \"time-step\": 499}, {\"errors\": 0.12446812656804243, \"time-step\": 500}, {\"errors\": 0.12446703333161255, \"time-step\": 501}, {\"errors\": 0.12446593813624893, \"time-step\": 502}, {\"errors\": 0.12446484097715416, \"time-step\": 503}, {\"errors\": 0.12446374184952053, \"time-step\": 504}, {\"errors\": 0.12446264074852995, \"time-step\": 505}, {\"errors\": 0.12446153766935397, \"time-step\": 506}, {\"errors\": 0.12446043260715378, \"time-step\": 507}, {\"errors\": 0.12445932555708011, \"time-step\": 508}, {\"errors\": 0.1244582165142733, \"time-step\": 509}, {\"errors\": 0.12445710547386316, \"time-step\": 510}, {\"errors\": 0.12445599243096903, \"time-step\": 511}, {\"errors\": 0.12445487738069982, \"time-step\": 512}, {\"errors\": 0.1244537603181538, \"time-step\": 513}, {\"errors\": 0.12445264123841869, \"time-step\": 514}, {\"errors\": 0.12445152013657165, \"time-step\": 515}, {\"errors\": 0.12445039700767922, \"time-step\": 516}, {\"errors\": 0.1244492718467973, \"time-step\": 517}, {\"errors\": 0.12444814464897105, \"time-step\": 518}, {\"errors\": 0.12444701540923511, \"time-step\": 519}, {\"errors\": 0.12444588412261318, \"time-step\": 520}, {\"errors\": 0.12444475078411843, \"time-step\": 521}, {\"errors\": 0.12444361538875312, \"time-step\": 522}, {\"errors\": 0.1244424779315088, \"time-step\": 523}, {\"errors\": 0.12444133840736611, \"time-step\": 524}, {\"errors\": 0.12444019681129499, \"time-step\": 525}, {\"errors\": 0.12443905313825433, \"time-step\": 526}, {\"errors\": 0.12443790738319231, \"time-step\": 527}, {\"errors\": 0.12443675954104608, \"time-step\": 528}, {\"errors\": 0.12443560960674184, \"time-step\": 529}, {\"errors\": 0.12443445757519486, \"time-step\": 530}, {\"errors\": 0.12443330344130941, \"time-step\": 531}, {\"errors\": 0.1244321471999787, \"time-step\": 532}, {\"errors\": 0.12443098884608494, \"time-step\": 533}, {\"errors\": 0.12442982837449926, \"time-step\": 534}, {\"errors\": 0.12442866578008158, \"time-step\": 535}, {\"errors\": 0.12442750105768087, \"time-step\": 536}, {\"errors\": 0.12442633420213486, \"time-step\": 537}, {\"errors\": 0.12442516520827004, \"time-step\": 538}, {\"errors\": 0.12442399407090182, \"time-step\": 539}, {\"errors\": 0.12442282078483427, \"time-step\": 540}, {\"errors\": 0.1244216453448603, \"time-step\": 541}, {\"errors\": 0.12442046774576145, \"time-step\": 542}, {\"errors\": 0.124419287982308, \"time-step\": 543}, {\"errors\": 0.12441810604925889, \"time-step\": 544}, {\"errors\": 0.12441692194136164, \"time-step\": 545}, {\"errors\": 0.12441573565335245, \"time-step\": 546}, {\"errors\": 0.1244145471799561, \"time-step\": 547}, {\"errors\": 0.12441335651588598, \"time-step\": 548}, {\"errors\": 0.12441216365584382, \"time-step\": 549}, {\"errors\": 0.12441096859452, \"time-step\": 550}, {\"errors\": 0.1244097713265934, \"time-step\": 551}, {\"errors\": 0.12440857184673126, \"time-step\": 552}, {\"errors\": 0.12440737014958939, \"time-step\": 553}, {\"errors\": 0.12440616622981182, \"time-step\": 554}, {\"errors\": 0.12440496008203103, \"time-step\": 555}, {\"errors\": 0.12440375170086784, \"time-step\": 556}, {\"errors\": 0.12440254108093148, \"time-step\": 557}, {\"errors\": 0.12440132821681929, \"time-step\": 558}, {\"errors\": 0.12440011310311704, \"time-step\": 559}, {\"errors\": 0.12439889573439859, \"time-step\": 560}, {\"errors\": 0.12439767610522617, \"time-step\": 561}, {\"errors\": 0.12439645421015011, \"time-step\": 562}, {\"errors\": 0.12439523004370878, \"time-step\": 563}, {\"errors\": 0.12439400360042893, \"time-step\": 564}, {\"errors\": 0.12439277487482517, \"time-step\": 565}, {\"errors\": 0.12439154386140033, \"time-step\": 566}, {\"errors\": 0.12439031055464528, \"time-step\": 567}, {\"errors\": 0.12438907494903882, \"time-step\": 568}, {\"errors\": 0.12438783703904785, \"time-step\": 569}, {\"errors\": 0.12438659681912709, \"time-step\": 570}, {\"errors\": 0.12438535428371934, \"time-step\": 571}, {\"errors\": 0.12438410942725525, \"time-step\": 572}, {\"errors\": 0.1243828622441534, \"time-step\": 573}, {\"errors\": 0.1243816127288201, \"time-step\": 574}, {\"errors\": 0.12438036087564959, \"time-step\": 575}, {\"errors\": 0.12437910667902394, \"time-step\": 576}, {\"errors\": 0.12437785013331286, \"time-step\": 577}, {\"errors\": 0.1243765912328739, \"time-step\": 578}, {\"errors\": 0.1243753299720523, \"time-step\": 579}, {\"errors\": 0.12437406634518107, \"time-step\": 580}, {\"errors\": 0.12437280034658066, \"time-step\": 581}, {\"errors\": 0.12437153197055939, \"time-step\": 582}, {\"errors\": 0.12437026121141304, \"time-step\": 583}, {\"errors\": 0.12436898806342502, \"time-step\": 584}, {\"errors\": 0.12436771252086626, \"time-step\": 585}, {\"errors\": 0.12436643457799522, \"time-step\": 586}, {\"errors\": 0.12436515422905792, \"time-step\": 587}, {\"errors\": 0.1243638714682877, \"time-step\": 588}, {\"errors\": 0.1243625862899054, \"time-step\": 589}, {\"errors\": 0.12436129868811935, \"time-step\": 590}, {\"errors\": 0.12436000865712513, \"time-step\": 591}, {\"errors\": 0.12435871619110574, \"time-step\": 592}, {\"errors\": 0.12435742128423144, \"time-step\": 593}, {\"errors\": 0.1243561239306599, \"time-step\": 594}, {\"errors\": 0.12435482412453588, \"time-step\": 595}, {\"errors\": 0.12435352185999154, \"time-step\": 596}, {\"errors\": 0.12435221713114616, \"time-step\": 597}, {\"errors\": 0.12435090993210622, \"time-step\": 598}, {\"errors\": 0.12434960025696529, \"time-step\": 599}, {\"errors\": 0.12434828809980422, \"time-step\": 600}, {\"errors\": 0.1243469734546907, \"time-step\": 601}, {\"errors\": 0.12434565631567975, \"time-step\": 602}, {\"errors\": 0.12434433667681317, \"time-step\": 603}, {\"errors\": 0.12434301453212002, \"time-step\": 604}, {\"errors\": 0.1243416898756161, \"time-step\": 605}, {\"errors\": 0.1243403627013043, \"time-step\": 606}, {\"errors\": 0.12433903300317442, \"time-step\": 607}, {\"errors\": 0.12433770077520306, \"time-step\": 608}, {\"errors\": 0.12433636601135375, \"time-step\": 609}, {\"errors\": 0.12433502870557686, \"time-step\": 610}, {\"errors\": 0.12433368885180945, \"time-step\": 611}, {\"errors\": 0.12433234644397556, \"time-step\": 612}, {\"errors\": 0.12433100147598575, \"time-step\": 613}, {\"errors\": 0.12432965394173737, \"time-step\": 614}, {\"errors\": 0.12432830383511453, \"time-step\": 615}, {\"errors\": 0.12432695114998785, \"time-step\": 616}, {\"errors\": 0.12432559588021477, \"time-step\": 617}, {\"errors\": 0.12432423801963907, \"time-step\": 618}, {\"errors\": 0.12432287756209134, \"time-step\": 619}, {\"errors\": 0.12432151450138854, \"time-step\": 620}, {\"errors\": 0.12432014883133415, \"time-step\": 621}, {\"errors\": 0.12431878054571824, \"time-step\": 622}, {\"errors\": 0.1243174096383172, \"time-step\": 623}, {\"errors\": 0.12431603610289388, \"time-step\": 624}, {\"errors\": 0.12431465993319751, \"time-step\": 625}, {\"errors\": 0.12431328112296369, \"time-step\": 626}, {\"errors\": 0.12431189966591438, \"time-step\": 627}, {\"errors\": 0.1243105155557577, \"time-step\": 628}, {\"errors\": 0.1243091287861882, \"time-step\": 629}, {\"errors\": 0.12430773935088657, \"time-step\": 630}, {\"errors\": 0.12430634724351966, \"time-step\": 631}, {\"errors\": 0.12430495245774065, \"time-step\": 632}, {\"errors\": 0.12430355498718876, \"time-step\": 633}, {\"errors\": 0.12430215482548926, \"time-step\": 634}, {\"errors\": 0.12430075196625362, \"time-step\": 635}, {\"errors\": 0.12429934640307935, \"time-step\": 636}, {\"errors\": 0.12429793812954992, \"time-step\": 637}, {\"errors\": 0.12429652713923478, \"time-step\": 638}, {\"errors\": 0.1242951134256895, \"time-step\": 639}, {\"errors\": 0.12429369698245535, \"time-step\": 640}, {\"errors\": 0.12429227780305968, \"time-step\": 641}, {\"errors\": 0.12429085588101563, \"time-step\": 642}, {\"errors\": 0.1242894312098222, \"time-step\": 643}, {\"errors\": 0.12428800378296415, \"time-step\": 644}, {\"errors\": 0.1242865735939121, \"time-step\": 645}, {\"errors\": 0.12428514063612232, \"time-step\": 646}, {\"errors\": 0.12428370490303696, \"time-step\": 647}, {\"errors\": 0.12428226638808362, \"time-step\": 648}, {\"errors\": 0.12428082508467572, \"time-step\": 649}, {\"errors\": 0.12427938098621227, \"time-step\": 650}, {\"errors\": 0.12427793408607785, \"time-step\": 651}, {\"errors\": 0.12427648437764258, \"time-step\": 652}, {\"errors\": 0.12427503185426217, \"time-step\": 653}, {\"errors\": 0.1242735765092778, \"time-step\": 654}, {\"errors\": 0.12427211833601604, \"time-step\": 655}, {\"errors\": 0.12427065732778902, \"time-step\": 656}, {\"errors\": 0.12426919347789422, \"time-step\": 657}, {\"errors\": 0.12426772677961447, \"time-step\": 658}, {\"errors\": 0.12426625722621795, \"time-step\": 659}, {\"errors\": 0.12426478481095818, \"time-step\": 660}, {\"errors\": 0.12426330952707393, \"time-step\": 661}, {\"errors\": 0.12426183136778918, \"time-step\": 662}, {\"errors\": 0.1242603503263132, \"time-step\": 663}, {\"errors\": 0.12425886639584037, \"time-step\": 664}, {\"errors\": 0.12425737956955032, \"time-step\": 665}, {\"errors\": 0.12425588984060772, \"time-step\": 666}, {\"errors\": 0.1242543972021623, \"time-step\": 667}, {\"errors\": 0.12425290164734892, \"time-step\": 668}, {\"errors\": 0.12425140316928743, \"time-step\": 669}, {\"errors\": 0.1242499017610826, \"time-step\": 670}, {\"errors\": 0.12424839741582433, \"time-step\": 671}, {\"errors\": 0.12424689012658734, \"time-step\": 672}, {\"errors\": 0.12424537988643114, \"time-step\": 673}, {\"errors\": 0.12424386668840035, \"time-step\": 674}, {\"errors\": 0.12424235052552418, \"time-step\": 675}, {\"errors\": 0.12424083139081687, \"time-step\": 676}, {\"errors\": 0.12423930927727718, \"time-step\": 677}, {\"errors\": 0.12423778417788875, \"time-step\": 678}, {\"errors\": 0.12423625608561992, \"time-step\": 679}, {\"errors\": 0.12423472499342367, \"time-step\": 680}, {\"errors\": 0.12423319089423762, \"time-step\": 681}, {\"errors\": 0.124231653780984, \"time-step\": 682}, {\"errors\": 0.12423011364656955, \"time-step\": 683}, {\"errors\": 0.12422857048388568, \"time-step\": 684}, {\"errors\": 0.1242270242858082, \"time-step\": 685}, {\"errors\": 0.1242254750451974, \"time-step\": 686}, {\"errors\": 0.12422392275489808, \"time-step\": 687}, {\"errors\": 0.12422236740773938, \"time-step\": 688}, {\"errors\": 0.12422080899653484, \"time-step\": 689}, {\"errors\": 0.12421924751408231, \"time-step\": 690}, {\"errors\": 0.12421768295316404, \"time-step\": 691}, {\"errors\": 0.12421611530654644, \"time-step\": 692}, {\"errors\": 0.12421454456698025, \"time-step\": 693}, {\"errors\": 0.12421297072720038, \"time-step\": 694}, {\"errors\": 0.1242113937799259, \"time-step\": 695}, {\"errors\": 0.1242098137178601, \"time-step\": 696}, {\"errors\": 0.1242082305336903, \"time-step\": 697}, {\"errors\": 0.12420664422008794, \"time-step\": 698}, {\"errors\": 0.12420505476970845, \"time-step\": 699}, {\"errors\": 0.12420346217519138, \"time-step\": 700}, {\"errors\": 0.12420186642916016, \"time-step\": 701}, {\"errors\": 0.12420026752422218, \"time-step\": 702}, {\"errors\": 0.12419866545296876, \"time-step\": 703}, {\"errors\": 0.12419706020797514, \"time-step\": 704}, {\"errors\": 0.12419545178180029, \"time-step\": 705}, {\"errors\": 0.12419384016698712, \"time-step\": 706}, {\"errors\": 0.1241922253560622, \"time-step\": 707}, {\"errors\": 0.12419060734153588, \"time-step\": 708}, {\"errors\": 0.12418898611590232, \"time-step\": 709}, {\"errors\": 0.12418736167163918, \"time-step\": 710}, {\"errors\": 0.1241857340012079, \"time-step\": 711}, {\"errors\": 0.12418410309705344, \"time-step\": 712}, {\"errors\": 0.12418246895160441, \"time-step\": 713}, {\"errors\": 0.12418083155727291, \"time-step\": 714}, {\"errors\": 0.1241791909064546, \"time-step\": 715}, {\"errors\": 0.12417754699152848, \"time-step\": 716}, {\"errors\": 0.12417589980485713, \"time-step\": 717}, {\"errors\": 0.12417424933878646, \"time-step\": 718}, {\"errors\": 0.12417259558564575, \"time-step\": 719}, {\"errors\": 0.12417093853774769, \"time-step\": 720}, {\"errors\": 0.12416927818738817, \"time-step\": 721}, {\"errors\": 0.12416761452684641, \"time-step\": 722}, {\"errors\": 0.12416594754838481, \"time-step\": 723}, {\"errors\": 0.12416427724424905, \"time-step\": 724}, {\"errors\": 0.12416260360666787, \"time-step\": 725}, {\"errors\": 0.1241609266278532, \"time-step\": 726}, {\"errors\": 0.1241592463000001, \"time-step\": 727}, {\"errors\": 0.12415756261528657, \"time-step\": 728}, {\"errors\": 0.12415587556587379, \"time-step\": 729}, {\"errors\": 0.12415418514390578, \"time-step\": 730}, {\"errors\": 0.1241524913415096, \"time-step\": 731}, {\"errors\": 0.12415079415079525, \"time-step\": 732}, {\"errors\": 0.1241490935638555, \"time-step\": 733}, {\"errors\": 0.12414738957276616, \"time-step\": 734}, {\"errors\": 0.12414568216958569, \"time-step\": 735}, {\"errors\": 0.12414397134635535, \"time-step\": 736}, {\"errors\": 0.12414225709509924, \"time-step\": 737}, {\"errors\": 0.12414053940782407, \"time-step\": 738}, {\"errors\": 0.12413881827651932, \"time-step\": 739}, {\"errors\": 0.12413709369315702, \"time-step\": 740}, {\"errors\": 0.12413536564969187, \"time-step\": 741}, {\"errors\": 0.12413363413806112, \"time-step\": 742}, {\"errors\": 0.1241318991501845, \"time-step\": 743}, {\"errors\": 0.12413016067796437, \"time-step\": 744}, {\"errors\": 0.12412841871328542, \"time-step\": 745}, {\"errors\": 0.12412667324801485, \"time-step\": 746}, {\"errors\": 0.12412492427400224, \"time-step\": 747}, {\"errors\": 0.12412317178307947, \"time-step\": 748}, {\"errors\": 0.12412141576706082, \"time-step\": 749}, {\"errors\": 0.12411965621774283, \"time-step\": 750}, {\"errors\": 0.1241178931269043, \"time-step\": 751}, {\"errors\": 0.12411612648630616, \"time-step\": 752}, {\"errors\": 0.12411435628769171, \"time-step\": 753}, {\"errors\": 0.12411258252278617, \"time-step\": 754}, {\"errors\": 0.12411080518329706, \"time-step\": 755}, {\"errors\": 0.12410902426091383, \"time-step\": 756}, {\"errors\": 0.12410723974730806, \"time-step\": 757}, {\"errors\": 0.12410545163413328, \"time-step\": 758}, {\"errors\": 0.12410365991302498, \"time-step\": 759}, {\"errors\": 0.12410186457560063, \"time-step\": 760}, {\"errors\": 0.12410006561345957, \"time-step\": 761}, {\"errors\": 0.12409826301818297, \"time-step\": 762}, {\"errors\": 0.12409645678133385, \"time-step\": 763}, {\"errors\": 0.12409464689445703, \"time-step\": 764}, {\"errors\": 0.12409283334907896, \"time-step\": 765}, {\"errors\": 0.12409101613670799, \"time-step\": 766}, {\"errors\": 0.124089195248834, \"time-step\": 767}, {\"errors\": 0.1240873706769286, \"time-step\": 768}, {\"errors\": 0.1240855424124449, \"time-step\": 769}, {\"errors\": 0.1240837104468177, \"time-step\": 770}, {\"errors\": 0.12408187477146322, \"time-step\": 771}, {\"errors\": 0.12408003537777924, \"time-step\": 772}, {\"errors\": 0.12407819225714498, \"time-step\": 773}, {\"errors\": 0.12407634540092108, \"time-step\": 774}, {\"errors\": 0.12407449480044955, \"time-step\": 775}, {\"errors\": 0.12407264044705374, \"time-step\": 776}, {\"errors\": 0.12407078233203836, \"time-step\": 777}, {\"errors\": 0.12406892044668937, \"time-step\": 778}, {\"errors\": 0.1240670547822739, \"time-step\": 779}, {\"errors\": 0.12406518533004036, \"time-step\": 780}, {\"errors\": 0.12406331208121832, \"time-step\": 781}, {\"errors\": 0.12406143502701844, \"time-step\": 782}, {\"errors\": 0.12405955415863247, \"time-step\": 783}, {\"errors\": 0.12405766946723323, \"time-step\": 784}, {\"errors\": 0.12405578094397457, \"time-step\": 785}, {\"errors\": 0.12405388857999121, \"time-step\": 786}, {\"errors\": 0.124051992366399, \"time-step\": 787}, {\"errors\": 0.1240500922942945, \"time-step\": 788}, {\"errors\": 0.12404818835475527, \"time-step\": 789}, {\"errors\": 0.12404628053883965, \"time-step\": 790}, {\"errors\": 0.12404436883758674, \"time-step\": 791}, {\"errors\": 0.12404245324201646, \"time-step\": 792}, {\"errors\": 0.12404053374312937, \"time-step\": 793}, {\"errors\": 0.12403861033190675, \"time-step\": 794}, {\"errors\": 0.1240366829993105, \"time-step\": 795}, {\"errors\": 0.1240347517362832, \"time-step\": 796}, {\"errors\": 0.12403281653374794, \"time-step\": 797}, {\"errors\": 0.12403087738260826, \"time-step\": 798}, {\"errors\": 0.1240289342737483, \"time-step\": 799}, {\"errors\": 0.12402698719803264, \"time-step\": 800}, {\"errors\": 0.12402503614630618, \"time-step\": 801}, {\"errors\": 0.12402308110939433, \"time-step\": 802}, {\"errors\": 0.12402112207810277, \"time-step\": 803}, {\"errors\": 0.12401915904321749, \"time-step\": 804}, {\"errors\": 0.12401719199550468, \"time-step\": 805}, {\"errors\": 0.12401522092571088, \"time-step\": 806}, {\"errors\": 0.12401324582456272, \"time-step\": 807}, {\"errors\": 0.12401126668276702, \"time-step\": 808}, {\"errors\": 0.12400928349101072, \"time-step\": 809}, {\"errors\": 0.12400729623996076, \"time-step\": 810}, {\"errors\": 0.12400530492026421, \"time-step\": 811}, {\"errors\": 0.12400330952254807, \"time-step\": 812}, {\"errors\": 0.12400131003741932, \"time-step\": 813}, {\"errors\": 0.12399930645546489, \"time-step\": 814}, {\"errors\": 0.12399729876725155, \"time-step\": 815}, {\"errors\": 0.12399528696332589, \"time-step\": 816}, {\"errors\": 0.12399327103421436, \"time-step\": 817}, {\"errors\": 0.12399125097042316, \"time-step\": 818}, {\"errors\": 0.12398922676243818, \"time-step\": 819}, {\"errors\": 0.12398719840072506, \"time-step\": 820}, {\"errors\": 0.12398516587572905, \"time-step\": 821}, {\"errors\": 0.12398312917787499, \"time-step\": 822}, {\"errors\": 0.12398108829756735, \"time-step\": 823}, {\"errors\": 0.12397904322519006, \"time-step\": 824}, {\"errors\": 0.12397699395110667, \"time-step\": 825}, {\"errors\": 0.12397494046566007, \"time-step\": 826}, {\"errors\": 0.12397288275917254, \"time-step\": 827}, {\"errors\": 0.12397082082194583, \"time-step\": 828}, {\"errors\": 0.12396875464426105, \"time-step\": 829}, {\"errors\": 0.1239666842163785, \"time-step\": 830}, {\"errors\": 0.12396460952853781, \"time-step\": 831}, {\"errors\": 0.12396253057095788, \"time-step\": 832}, {\"errors\": 0.12396044733383661, \"time-step\": 833}, {\"errors\": 0.12395835980735125, \"time-step\": 834}, {\"errors\": 0.12395626798165807, \"time-step\": 835}, {\"errors\": 0.12395417184689236, \"time-step\": 836}, {\"errors\": 0.12395207139316855, \"time-step\": 837}, {\"errors\": 0.12394996661057993, \"time-step\": 838}, {\"errors\": 0.1239478574891988, \"time-step\": 839}, {\"errors\": 0.12394574401907639, \"time-step\": 840}, {\"errors\": 0.12394362619024274, \"time-step\": 841}, {\"errors\": 0.12394150399270676, \"time-step\": 842}, {\"errors\": 0.12393937741645614, \"time-step\": 843}, {\"errors\": 0.12393724645145732, \"time-step\": 844}, {\"errors\": 0.12393511108765543, \"time-step\": 845}, {\"errors\": 0.12393297131497426, \"time-step\": 846}, {\"errors\": 0.12393082712331631, \"time-step\": 847}, {\"errors\": 0.12392867850256262, \"time-step\": 848}, {\"errors\": 0.12392652544257274, \"time-step\": 849}, {\"errors\": 0.12392436793318476, \"time-step\": 850}, {\"errors\": 0.12392220596421531, \"time-step\": 851}, {\"errors\": 0.12392003952545932, \"time-step\": 852}, {\"errors\": 0.12391786860669021, \"time-step\": 853}, {\"errors\": 0.12391569319765974, \"time-step\": 854}, {\"errors\": 0.12391351328809797, \"time-step\": 855}, {\"errors\": 0.12391132886771315, \"time-step\": 856}, {\"errors\": 0.12390913992619193, \"time-step\": 857}, {\"errors\": 0.12390694645319898, \"time-step\": 858}, {\"errors\": 0.12390474843837727, \"time-step\": 859}, {\"errors\": 0.12390254587134777, \"time-step\": 860}, {\"errors\": 0.12390033874170953, \"time-step\": 861}, {\"errors\": 0.12389812703903971, \"time-step\": 862}, {\"errors\": 0.12389591075289336, \"time-step\": 863}, {\"errors\": 0.12389368987280355, \"time-step\": 864}, {\"errors\": 0.12389146438828123, \"time-step\": 865}, {\"errors\": 0.12388923428881524, \"time-step\": 866}, {\"errors\": 0.12388699956387221, \"time-step\": 867}, {\"errors\": 0.12388476020289657, \"time-step\": 868}, {\"errors\": 0.12388251619531053, \"time-step\": 869}, {\"errors\": 0.12388026753051393, \"time-step\": 870}, {\"errors\": 0.12387801419788436, \"time-step\": 871}, {\"errors\": 0.12387575618677701, \"time-step\": 872}, {\"errors\": 0.12387349348652464, \"time-step\": 873}, {\"errors\": 0.12387122608643754, \"time-step\": 874}, {\"errors\": 0.12386895397580347, \"time-step\": 875}, {\"errors\": 0.1238666771438878, \"time-step\": 876}, {\"errors\": 0.12386439557993315, \"time-step\": 877}, {\"errors\": 0.1238621092731596, \"time-step\": 878}, {\"errors\": 0.12385981821276457, \"time-step\": 879}, {\"errors\": 0.12385752238792273, \"time-step\": 880}, {\"errors\": 0.1238552217877861, \"time-step\": 881}, {\"errors\": 0.12385291640148378, \"time-step\": 882}, {\"errors\": 0.12385060621812218, \"time-step\": 883}, {\"errors\": 0.12384829122678476, \"time-step\": 884}, {\"errors\": 0.12384597141653209, \"time-step\": 885}, {\"errors\": 0.1238436467764018, \"time-step\": 886}, {\"errors\": 0.1238413172954085, \"time-step\": 887}, {\"errors\": 0.12383898296254384, \"time-step\": 888}, {\"errors\": 0.1238366437667763, \"time-step\": 889}, {\"errors\": 0.12383429969705133, \"time-step\": 890}, {\"errors\": 0.12383195074229116, \"time-step\": 891}, {\"errors\": 0.12382959689139485, \"time-step\": 892}, {\"errors\": 0.12382723813323823, \"time-step\": 893}, {\"errors\": 0.12382487445667385, \"time-step\": 894}, {\"errors\": 0.1238225058505309, \"time-step\": 895}, {\"errors\": 0.12382013230361524, \"time-step\": 896}, {\"errors\": 0.1238177538047093, \"time-step\": 897}, {\"errors\": 0.12381537034257212, \"time-step\": 898}, {\"errors\": 0.12381298190593919, \"time-step\": 899}, {\"errors\": 0.12381058848352246, \"time-step\": 900}, {\"errors\": 0.12380819006401036, \"time-step\": 901}, {\"errors\": 0.12380578663606769, \"time-step\": 902}, {\"errors\": 0.12380337818833559, \"time-step\": 903}, {\"errors\": 0.12380096470943144, \"time-step\": 904}, {\"errors\": 0.12379854618794901, \"time-step\": 905}, {\"errors\": 0.12379612261245818, \"time-step\": 906}, {\"errors\": 0.12379369397150503, \"time-step\": 907}, {\"errors\": 0.12379126025361176, \"time-step\": 908}, {\"errors\": 0.12378882144727679, \"time-step\": 909}, {\"errors\": 0.12378637754097435, \"time-step\": 910}, {\"errors\": 0.12378392852315487, \"time-step\": 911}, {\"errors\": 0.12378147438224468, \"time-step\": 912}, {\"errors\": 0.12377901510664609, \"time-step\": 913}, {\"errors\": 0.12377655068473713, \"time-step\": 914}, {\"errors\": 0.12377408110487186, \"time-step\": 915}, {\"errors\": 0.12377160635538004, \"time-step\": 916}, {\"errors\": 0.12376912642456717, \"time-step\": 917}, {\"errors\": 0.12376664130071455, \"time-step\": 918}, {\"errors\": 0.12376415097207899, \"time-step\": 919}, {\"errors\": 0.12376165542689309, \"time-step\": 920}, {\"errors\": 0.12375915465336493, \"time-step\": 921}, {\"errors\": 0.12375664863967817, \"time-step\": 922}, {\"errors\": 0.12375413737399202, \"time-step\": 923}, {\"errors\": 0.12375162084444105, \"time-step\": 924}, {\"errors\": 0.12374909903913522, \"time-step\": 925}, {\"errors\": 0.12374657194616007, \"time-step\": 926}, {\"errors\": 0.12374403955357616, \"time-step\": 927}, {\"errors\": 0.1237415018494196, \"time-step\": 928}, {\"errors\": 0.1237389588217016, \"time-step\": 929}, {\"errors\": 0.12373641045840864, \"time-step\": 930}, {\"errors\": 0.12373385674750231, \"time-step\": 931}, {\"errors\": 0.12373129767691929, \"time-step\": 932}, {\"errors\": 0.12372873323457143, \"time-step\": 933}, {\"errors\": 0.1237261634083455, \"time-step\": 934}, {\"errors\": 0.12372358818610332, \"time-step\": 935}, {\"errors\": 0.1237210075556816, \"time-step\": 936}, {\"errors\": 0.1237184215048921, \"time-step\": 937}, {\"errors\": 0.12371583002152114, \"time-step\": 938}, {\"errors\": 0.12371323309333014, \"time-step\": 939}, {\"errors\": 0.12371063070805517, \"time-step\": 940}, {\"errors\": 0.123708022853407, \"time-step\": 941}, {\"errors\": 0.12370540951707112, \"time-step\": 942}, {\"errors\": 0.12370279068670773, \"time-step\": 943}, {\"errors\": 0.12370016634995146, \"time-step\": 944}, {\"errors\": 0.12369753649441159, \"time-step\": 945}, {\"errors\": 0.12369490110767199, \"time-step\": 946}, {\"errors\": 0.1236922601772908, \"time-step\": 947}, {\"errors\": 0.12368961369080078, \"time-step\": 948}, {\"errors\": 0.12368696163570893, \"time-step\": 949}, {\"errors\": 0.1236843039994967, \"time-step\": 950}, {\"errors\": 0.12368164076961968, \"time-step\": 951}, {\"errors\": 0.1236789719335079, \"time-step\": 952}, {\"errors\": 0.1236762974785654, \"time-step\": 953}, {\"errors\": 0.12367361739217053, \"time-step\": 954}, {\"errors\": 0.1236709316616757, \"time-step\": 955}, {\"errors\": 0.1236682402744074, \"time-step\": 956}, {\"errors\": 0.12366554321766615, \"time-step\": 957}, {\"errors\": 0.12366284047872644, \"time-step\": 958}, {\"errors\": 0.12366013204483672, \"time-step\": 959}, {\"errors\": 0.12365741790321932, \"time-step\": 960}, {\"errors\": 0.1236546980410705, \"time-step\": 961}, {\"errors\": 0.12365197244556028, \"time-step\": 962}, {\"errors\": 0.12364924110383234, \"time-step\": 963}, {\"errors\": 0.12364650400300427, \"time-step\": 964}, {\"errors\": 0.12364376113016723, \"time-step\": 965}, {\"errors\": 0.12364101247238607, \"time-step\": 966}, {\"errors\": 0.1236382580166992, \"time-step\": 967}, {\"errors\": 0.1236354977501185, \"time-step\": 968}, {\"errors\": 0.12363273165962956, \"time-step\": 969}, {\"errors\": 0.12362995973219121, \"time-step\": 970}, {\"errors\": 0.12362718195473585, \"time-step\": 971}, {\"errors\": 0.12362439831416915, \"time-step\": 972}, {\"errors\": 0.12362160879737018, \"time-step\": 973}, {\"errors\": 0.12361881339119124, \"time-step\": 974}, {\"errors\": 0.1236160120824579, \"time-step\": 975}, {\"errors\": 0.12361320485796892, \"time-step\": 976}, {\"errors\": 0.12361039170449623, \"time-step\": 977}, {\"errors\": 0.12360757260878477, \"time-step\": 978}, {\"errors\": 0.12360474755755269, \"time-step\": 979}, {\"errors\": 0.12360191653749103, \"time-step\": 980}, {\"errors\": 0.12359907953526389, \"time-step\": 981}, {\"errors\": 0.12359623653750826, \"time-step\": 982}, {\"errors\": 0.12359338753083396, \"time-step\": 983}, {\"errors\": 0.12359053250182381, \"time-step\": 984}, {\"errors\": 0.12358767143703323, \"time-step\": 985}, {\"errors\": 0.12358480432299052, \"time-step\": 986}, {\"errors\": 0.12358193114619662, \"time-step\": 987}, {\"errors\": 0.1235790518931252, \"time-step\": 988}, {\"errors\": 0.1235761665502225, \"time-step\": 989}, {\"errors\": 0.1235732751039073, \"time-step\": 990}, {\"errors\": 0.12357037754057099, \"time-step\": 991}, {\"errors\": 0.12356747384657735, \"time-step\": 992}, {\"errors\": 0.12356456400826273, \"time-step\": 993}, {\"errors\": 0.12356164801193573, \"time-step\": 994}, {\"errors\": 0.12355872584387737, \"time-step\": 995}, {\"errors\": 0.12355579749034093, \"time-step\": 996}, {\"errors\": 0.12355286293755201, \"time-step\": 997}, {\"errors\": 0.12354992217170845, \"time-step\": 998}, {\"errors\": 0.12354697517898017, \"time-step\": 999}, {\"errors\": 0.12354402194550917, \"time-step\": 1000}, {\"errors\": 0.12354106245740976, \"time-step\": 1001}, {\"errors\": 0.12353809670076801, \"time-step\": 1002}, {\"errors\": 0.12353512466164215, \"time-step\": 1003}, {\"errors\": 0.12353214632606237, \"time-step\": 1004}, {\"errors\": 0.12352916168003061, \"time-step\": 1005}, {\"errors\": 0.12352617070952082, \"time-step\": 1006}, {\"errors\": 0.1235231734004786, \"time-step\": 1007}, {\"errors\": 0.12352016973882157, \"time-step\": 1008}, {\"errors\": 0.12351715971043875, \"time-step\": 1009}, {\"errors\": 0.1235141433011911, \"time-step\": 1010}, {\"errors\": 0.12351112049691107, \"time-step\": 1011}, {\"errors\": 0.12350809128340276, \"time-step\": 1012}, {\"errors\": 0.12350505564644171, \"time-step\": 1013}, {\"errors\": 0.1235020135717751, \"time-step\": 1014}, {\"errors\": 0.12349896504512142, \"time-step\": 1015}, {\"errors\": 0.12349591005217067, \"time-step\": 1016}, {\"errors\": 0.12349284857858417, \"time-step\": 1017}, {\"errors\": 0.12348978060999452, \"time-step\": 1018}, {\"errors\": 0.12348670613200566, \"time-step\": 1019}, {\"errors\": 0.12348362513019259, \"time-step\": 1020}, {\"errors\": 0.1234805375901018, \"time-step\": 1021}, {\"errors\": 0.12347744349725054, \"time-step\": 1022}, {\"errors\": 0.12347434283712744, \"time-step\": 1023}, {\"errors\": 0.123471235595192, \"time-step\": 1024}, {\"errors\": 0.12346812175687483, \"time-step\": 1025}, {\"errors\": 0.1234650013075774, \"time-step\": 1026}, {\"errors\": 0.12346187423267208, \"time-step\": 1027}, {\"errors\": 0.12345874051750222, \"time-step\": 1028}, {\"errors\": 0.12345560014738186, \"time-step\": 1029}, {\"errors\": 0.12345245310759587, \"time-step\": 1030}, {\"errors\": 0.1234492993833998, \"time-step\": 1031}, {\"errors\": 0.12344613896001994, \"time-step\": 1032}, {\"errors\": 0.12344297182265318, \"time-step\": 1033}, {\"errors\": 0.12343979795646697, \"time-step\": 1034}, {\"errors\": 0.12343661734659937, \"time-step\": 1035}, {\"errors\": 0.12343342997815882, \"time-step\": 1036}, {\"errors\": 0.12343023583622435, \"time-step\": 1037}, {\"errors\": 0.12342703490584533, \"time-step\": 1038}, {\"errors\": 0.12342382717204145, \"time-step\": 1039}, {\"errors\": 0.1234206126198028, \"time-step\": 1040}, {\"errors\": 0.12341739123408962, \"time-step\": 1041}, {\"errors\": 0.12341416299983253, \"time-step\": 1042}, {\"errors\": 0.12341092790193217, \"time-step\": 1043}, {\"errors\": 0.12340768592525941, \"time-step\": 1044}, {\"errors\": 0.12340443705465519, \"time-step\": 1045}, {\"errors\": 0.12340118127493047, \"time-step\": 1046}, {\"errors\": 0.12339791857086618, \"time-step\": 1047}, {\"errors\": 0.12339464892721327, \"time-step\": 1048}, {\"errors\": 0.12339137232869254, \"time-step\": 1049}, {\"errors\": 0.12338808875999469, \"time-step\": 1050}, {\"errors\": 0.12338479820578013, \"time-step\": 1051}, {\"errors\": 0.12338150065067915, \"time-step\": 1052}, {\"errors\": 0.12337819607929176, \"time-step\": 1053}, {\"errors\": 0.12337488447618752, \"time-step\": 1054}, {\"errors\": 0.1233715658259058, \"time-step\": 1055}, {\"errors\": 0.12336824011295534, \"time-step\": 1056}, {\"errors\": 0.1233649073218146, \"time-step\": 1057}, {\"errors\": 0.12336156743693144, \"time-step\": 1058}, {\"errors\": 0.12335822044272324, \"time-step\": 1059}, {\"errors\": 0.12335486632357665, \"time-step\": 1060}, {\"errors\": 0.12335150506384783, \"time-step\": 1061}, {\"errors\": 0.12334813664786205, \"time-step\": 1062}, {\"errors\": 0.1233447610599141, \"time-step\": 1063}, {\"errors\": 0.12334137828426778, \"time-step\": 1064}, {\"errors\": 0.1233379883051561, \"time-step\": 1065}, {\"errors\": 0.1233345911067813, \"time-step\": 1066}, {\"errors\": 0.12333118667331457, \"time-step\": 1067}, {\"errors\": 0.12332777498889622, \"time-step\": 1068}, {\"errors\": 0.12332435603763545, \"time-step\": 1069}, {\"errors\": 0.12332092980361054, \"time-step\": 1070}, {\"errors\": 0.12331749627086858, \"time-step\": 1071}, {\"errors\": 0.12331405542342547, \"time-step\": 1072}, {\"errors\": 0.12331060724526605, \"time-step\": 1073}, {\"errors\": 0.12330715172034375, \"time-step\": 1074}, {\"errors\": 0.12330368883258086, \"time-step\": 1075}, {\"errors\": 0.12330021856586823, \"time-step\": 1076}, {\"errors\": 0.12329674090406537, \"time-step\": 1077}, {\"errors\": 0.12329325583100043, \"time-step\": 1078}, {\"errors\": 0.12328976333047001, \"time-step\": 1079}, {\"errors\": 0.12328626338623917, \"time-step\": 1080}, {\"errors\": 0.12328275598204147, \"time-step\": 1081}, {\"errors\": 0.1232792411015789, \"time-step\": 1082}, {\"errors\": 0.12327571872852167, \"time-step\": 1083}, {\"errors\": 0.12327218884650834, \"time-step\": 1084}, {\"errors\": 0.12326865143914582, \"time-step\": 1085}, {\"errors\": 0.1232651064900091, \"time-step\": 1086}, {\"errors\": 0.12326155398264142, \"time-step\": 1087}, {\"errors\": 0.12325799390055409, \"time-step\": 1088}, {\"errors\": 0.1232544262272265, \"time-step\": 1089}, {\"errors\": 0.12325085094610608, \"time-step\": 1090}, {\"errors\": 0.1232472680406082, \"time-step\": 1091}, {\"errors\": 0.12324367749411622, \"time-step\": 1092}, {\"errors\": 0.12324007928998137, \"time-step\": 1093}, {\"errors\": 0.12323647341152268, \"time-step\": 1094}, {\"errors\": 0.12323285984202706, \"time-step\": 1095}, {\"errors\": 0.1232292385647491, \"time-step\": 1096}, {\"errors\": 0.12322560956291112, \"time-step\": 1097}, {\"errors\": 0.1232219728197031, \"time-step\": 1098}, {\"errors\": 0.12321832831828264, \"time-step\": 1099}, {\"errors\": 0.12321467604177488, \"time-step\": 1100}, {\"errors\": 0.12321101597327254, \"time-step\": 1101}, {\"errors\": 0.12320734809583576, \"time-step\": 1102}, {\"errors\": 0.12320367239249218, \"time-step\": 1103}, {\"errors\": 0.1231999888462367, \"time-step\": 1104}, {\"errors\": 0.12319629744003173, \"time-step\": 1105}, {\"errors\": 0.1231925981568068, \"time-step\": 1106}, {\"errors\": 0.12318889097945884, \"time-step\": 1107}, {\"errors\": 0.12318517589085189, \"time-step\": 1108}, {\"errors\": 0.12318145287381721, \"time-step\": 1109}, {\"errors\": 0.12317772191115309, \"time-step\": 1110}, {\"errors\": 0.12317398298562499, \"time-step\": 1111}, {\"errors\": 0.12317023607996533, \"time-step\": 1112}, {\"errors\": 0.12316648117687351, \"time-step\": 1113}, {\"errors\": 0.12316271825901588, \"time-step\": 1114}, {\"errors\": 0.12315894730902566, \"time-step\": 1115}, {\"errors\": 0.12315516830950289, \"time-step\": 1116}, {\"errors\": 0.1231513812430145, \"time-step\": 1117}, {\"errors\": 0.12314758609209404, \"time-step\": 1118}, {\"errors\": 0.12314378283924186, \"time-step\": 1119}, {\"errors\": 0.1231399714669249, \"time-step\": 1120}, {\"errors\": 0.1231361519575768, \"time-step\": 1121}, {\"errors\": 0.12313232429359766, \"time-step\": 1122}, {\"errors\": 0.12312848845735422, \"time-step\": 1123}, {\"errors\": 0.1231246444311796, \"time-step\": 1124}, {\"errors\": 0.12312079219737343, \"time-step\": 1125}, {\"errors\": 0.12311693173820171, \"time-step\": 1126}, {\"errors\": 0.12311306303589671, \"time-step\": 1127}, {\"errors\": 0.12310918607265706, \"time-step\": 1128}, {\"errors\": 0.12310530083064768, \"time-step\": 1129}, {\"errors\": 0.12310140729199964, \"time-step\": 1130}, {\"errors\": 0.1230975054388102, \"time-step\": 1131}, {\"errors\": 0.1230935952531427, \"time-step\": 1132}, {\"errors\": 0.12308967671702663, \"time-step\": 1133}, {\"errors\": 0.1230857498124574, \"time-step\": 1134}, {\"errors\": 0.12308181452139652, \"time-step\": 1135}, {\"errors\": 0.1230778708257714, \"time-step\": 1136}, {\"errors\": 0.12307391870747528, \"time-step\": 1137}, {\"errors\": 0.12306995814836734, \"time-step\": 1138}, {\"errors\": 0.12306598913027252, \"time-step\": 1139}, {\"errors\": 0.1230620116349815, \"time-step\": 1140}, {\"errors\": 0.12305802564425075, \"time-step\": 1141}, {\"errors\": 0.12305403113980232, \"time-step\": 1142}, {\"errors\": 0.123050028103324, \"time-step\": 1143}, {\"errors\": 0.12304601651646904, \"time-step\": 1144}, {\"errors\": 0.1230419963608563, \"time-step\": 1145}, {\"errors\": 0.12303796761807012, \"time-step\": 1146}, {\"errors\": 0.12303393026966031, \"time-step\": 1147}, {\"errors\": 0.12302988429714208, \"time-step\": 1148}, {\"errors\": 0.12302582968199596, \"time-step\": 1149}, {\"errors\": 0.12302176640566781, \"time-step\": 1150}, {\"errors\": 0.12301769444956882, \"time-step\": 1151}, {\"errors\": 0.12301361379507537, \"time-step\": 1152}, {\"errors\": 0.12300952442352904, \"time-step\": 1153}, {\"errors\": 0.12300542631623648, \"time-step\": 1154}, {\"errors\": 0.12300131945446956, \"time-step\": 1155}, {\"errors\": 0.1229972038194651, \"time-step\": 1156}, {\"errors\": 0.12299307939242497, \"time-step\": 1157}, {\"errors\": 0.12298894615451605, \"time-step\": 1158}, {\"errors\": 0.1229848040868701, \"time-step\": 1159}, {\"errors\": 0.12298065317058371, \"time-step\": 1160}, {\"errors\": 0.1229764933867184, \"time-step\": 1161}, {\"errors\": 0.12297232471630046, \"time-step\": 1162}, {\"errors\": 0.12296814714032088, \"time-step\": 1163}, {\"errors\": 0.12296396063973537, \"time-step\": 1164}, {\"errors\": 0.1229597651954644, \"time-step\": 1165}, {\"errors\": 0.12295556078839286, \"time-step\": 1166}, {\"errors\": 0.12295134739937048, \"time-step\": 1167}, {\"errors\": 0.12294712500921126, \"time-step\": 1168}, {\"errors\": 0.12294289359869388, \"time-step\": 1169}, {\"errors\": 0.12293865314856141, \"time-step\": 1170}, {\"errors\": 0.1229344036395213, \"time-step\": 1171}, {\"errors\": 0.12293014505224532, \"time-step\": 1172}, {\"errors\": 0.12292587736736973, \"time-step\": 1173}, {\"errors\": 0.12292160056549487, \"time-step\": 1174}, {\"errors\": 0.12291731462718544, \"time-step\": 1175}, {\"errors\": 0.12291301953297032, \"time-step\": 1176}, {\"errors\": 0.12290871526334246, \"time-step\": 1177}, {\"errors\": 0.12290440179875897, \"time-step\": 1178}, {\"errors\": 0.12290007911964113, \"time-step\": 1179}, {\"errors\": 0.122895747206374, \"time-step\": 1180}, {\"errors\": 0.12289140603930687, \"time-step\": 1181}, {\"errors\": 0.12288705559875279, \"time-step\": 1182}, {\"errors\": 0.1228826958649889, \"time-step\": 1183}, {\"errors\": 0.12287832681825592, \"time-step\": 1184}, {\"errors\": 0.12287394843875869, \"time-step\": 1185}, {\"errors\": 0.12286956070666556, \"time-step\": 1186}, {\"errors\": 0.12286516360210883, \"time-step\": 1187}, {\"errors\": 0.12286075710518432, \"time-step\": 1188}, {\"errors\": 0.12285634119595157, \"time-step\": 1189}, {\"errors\": 0.12285191585443375, \"time-step\": 1190}, {\"errors\": 0.12284748106061755, \"time-step\": 1191}, {\"errors\": 0.12284303679445327, \"time-step\": 1192}, {\"errors\": 0.12283858303585457, \"time-step\": 1193}, {\"errors\": 0.12283411976469863, \"time-step\": 1194}, {\"errors\": 0.12282964696082607, \"time-step\": 1195}, {\"errors\": 0.12282516460404073, \"time-step\": 1196}, {\"errors\": 0.12282067267410998, \"time-step\": 1197}, {\"errors\": 0.12281617115076426, \"time-step\": 1198}, {\"errors\": 0.12281166001369742, \"time-step\": 1199}, {\"errors\": 0.1228071392425664, \"time-step\": 1200}, {\"errors\": 0.12280260881699138, \"time-step\": 1201}, {\"errors\": 0.12279806871655566, \"time-step\": 1202}, {\"errors\": 0.12279351892080552, \"time-step\": 1203}, {\"errors\": 0.12278895940925036, \"time-step\": 1204}, {\"errors\": 0.12278439016136267, \"time-step\": 1205}, {\"errors\": 0.12277981115657768, \"time-step\": 1206}, {\"errors\": 0.12277522237429378, \"time-step\": 1207}, {\"errors\": 0.12277062379387207, \"time-step\": 1208}, {\"errors\": 0.12276601539463665, \"time-step\": 1209}, {\"errors\": 0.12276139715587431, \"time-step\": 1210}, {\"errors\": 0.1227567690568346, \"time-step\": 1211}, {\"errors\": 0.12275213107672989, \"time-step\": 1212}, {\"errors\": 0.12274748319473514, \"time-step\": 1213}, {\"errors\": 0.12274282538998812, \"time-step\": 1214}, {\"errors\": 0.1227381576415891, \"time-step\": 1215}, {\"errors\": 0.12273347992860084, \"time-step\": 1216}, {\"errors\": 0.12272879223004882, \"time-step\": 1217}, {\"errors\": 0.122724094524921, \"time-step\": 1218}, {\"errors\": 0.1227193867921676, \"time-step\": 1219}, {\"errors\": 0.12271466901070155, \"time-step\": 1220}, {\"errors\": 0.12270994115939794, \"time-step\": 1221}, {\"errors\": 0.12270520321709438, \"time-step\": 1222}, {\"errors\": 0.12270045516259066, \"time-step\": 1223}, {\"errors\": 0.12269569697464894, \"time-step\": 1224}, {\"errors\": 0.12269092863199355, \"time-step\": 1225}, {\"errors\": 0.12268615011331108, \"time-step\": 1226}, {\"errors\": 0.12268136139725029, \"time-step\": 1227}, {\"errors\": 0.12267656246242203, \"time-step\": 1228}, {\"errors\": 0.1226717532873993, \"time-step\": 1229}, {\"errors\": 0.12266693385071709, \"time-step\": 1230}, {\"errors\": 0.12266210413087245, \"time-step\": 1231}, {\"errors\": 0.12265726410632441, \"time-step\": 1232}, {\"errors\": 0.12265241375549399, \"time-step\": 1233}, {\"errors\": 0.12264755305676411, \"time-step\": 1234}, {\"errors\": 0.12264268198847952, \"time-step\": 1235}, {\"errors\": 0.12263780052894685, \"time-step\": 1236}, {\"errors\": 0.12263290865643459, \"time-step\": 1237}, {\"errors\": 0.12262800634917301, \"time-step\": 1238}, {\"errors\": 0.12262309358535396, \"time-step\": 1239}, {\"errors\": 0.12261817034313122, \"time-step\": 1240}, {\"errors\": 0.1226132366006201, \"time-step\": 1241}, {\"errors\": 0.12260829233589765, \"time-step\": 1242}, {\"errors\": 0.1226033375270024, \"time-step\": 1243}, {\"errors\": 0.12259837215193464, \"time-step\": 1244}, {\"errors\": 0.122593396188656, \"time-step\": 1245}, {\"errors\": 0.12258840961508977, \"time-step\": 1246}, {\"errors\": 0.12258341240912063, \"time-step\": 1247}, {\"errors\": 0.12257840454859474, \"time-step\": 1248}, {\"errors\": 0.12257338601131965, \"time-step\": 1249}, {\"errors\": 0.12256835677506436, \"time-step\": 1250}, {\"errors\": 0.12256331681755905, \"time-step\": 1251}, {\"errors\": 0.12255826611649544, \"time-step\": 1252}, {\"errors\": 0.12255320464952635, \"time-step\": 1253}, {\"errors\": 0.12254813239426593, \"time-step\": 1254}, {\"errors\": 0.12254304932828955, \"time-step\": 1255}, {\"errors\": 0.12253795542913373, \"time-step\": 1256}, {\"errors\": 0.12253285067429623, \"time-step\": 1257}, {\"errors\": 0.12252773504123585, \"time-step\": 1258}, {\"errors\": 0.12252260850737248, \"time-step\": 1259}, {\"errors\": 0.12251747105008723, \"time-step\": 1260}, {\"errors\": 0.12251232264672204, \"time-step\": 1261}, {\"errors\": 0.12250716327458006, \"time-step\": 1262}, {\"errors\": 0.12250199291092523, \"time-step\": 1263}, {\"errors\": 0.1224968115329826, \"time-step\": 1264}, {\"errors\": 0.12249161911793802, \"time-step\": 1265}, {\"errors\": 0.12248641564293833, \"time-step\": 1266}, {\"errors\": 0.1224812010850912, \"time-step\": 1267}, {\"errors\": 0.12247597542146509, \"time-step\": 1268}, {\"errors\": 0.12247073862908936, \"time-step\": 1269}, {\"errors\": 0.12246549068495406, \"time-step\": 1270}, {\"errors\": 0.12246023156601005, \"time-step\": 1271}, {\"errors\": 0.12245496124916896, \"time-step\": 1272}, {\"errors\": 0.12244967971130297, \"time-step\": 1273}, {\"errors\": 0.12244438692924511, \"time-step\": 1274}, {\"errors\": 0.12243908287978894, \"time-step\": 1275}, {\"errors\": 0.12243376753968871, \"time-step\": 1276}, {\"errors\": 0.1224284408856592, \"time-step\": 1277}, {\"errors\": 0.12242310289437586, \"time-step\": 1278}, {\"errors\": 0.12241775354247457, \"time-step\": 1279}, {\"errors\": 0.12241239280655188, \"time-step\": 1280}, {\"errors\": 0.12240702066316465, \"time-step\": 1281}, {\"errors\": 0.12240163708883034, \"time-step\": 1282}, {\"errors\": 0.12239624206002689, \"time-step\": 1283}, {\"errors\": 0.12239083555319254, \"time-step\": 1284}, {\"errors\": 0.122385417544726, \"time-step\": 1285}, {\"errors\": 0.12237998801098642, \"time-step\": 1286}, {\"errors\": 0.12237454692829319, \"time-step\": 1287}, {\"errors\": 0.12236909427292611, \"time-step\": 1288}, {\"errors\": 0.12236363002112528, \"time-step\": 1289}, {\"errors\": 0.12235815414909108, \"time-step\": 1290}, {\"errors\": 0.12235266663298416, \"time-step\": 1291}, {\"errors\": 0.12234716744892546, \"time-step\": 1292}, {\"errors\": 0.12234165657299605, \"time-step\": 1293}, {\"errors\": 0.1223361339812373, \"time-step\": 1294}, {\"errors\": 0.12233059964965076, \"time-step\": 1295}, {\"errors\": 0.12232505355419807, \"time-step\": 1296}, {\"errors\": 0.12231949567080112, \"time-step\": 1297}, {\"errors\": 0.1223139259753419, \"time-step\": 1298}, {\"errors\": 0.1223083444436624, \"time-step\": 1299}, {\"errors\": 0.12230275105156485, \"time-step\": 1300}, {\"errors\": 0.12229714577481156, \"time-step\": 1301}, {\"errors\": 0.12229152858912475, \"time-step\": 1302}, {\"errors\": 0.12228589947018678, \"time-step\": 1303}, {\"errors\": 0.12228025839364004, \"time-step\": 1304}, {\"errors\": 0.12227460533508691, \"time-step\": 1305}, {\"errors\": 0.12226894027008972, \"time-step\": 1306}, {\"errors\": 0.12226326317417086, \"time-step\": 1307}, {\"errors\": 0.12225757402281254, \"time-step\": 1308}, {\"errors\": 0.12225187279145709, \"time-step\": 1309}, {\"errors\": 0.12224615945550663, \"time-step\": 1310}, {\"errors\": 0.1222404339903233, \"time-step\": 1311}, {\"errors\": 0.122234696371229, \"time-step\": 1312}, {\"errors\": 0.12222894657350566, \"time-step\": 1313}, {\"errors\": 0.12222318457239509, \"time-step\": 1314}, {\"errors\": 0.12221741034309881, \"time-step\": 1315}, {\"errors\": 0.12221162386077829, \"time-step\": 1316}, {\"errors\": 0.12220582510055487, \"time-step\": 1317}, {\"errors\": 0.12220001403750964, \"time-step\": 1318}, {\"errors\": 0.12219419064668358, \"time-step\": 1319}, {\"errors\": 0.12218835490307745, \"time-step\": 1320}, {\"errors\": 0.12218250678165173, \"time-step\": 1321}, {\"errors\": 0.1221766462573268, \"time-step\": 1322}, {\"errors\": 0.12217077330498277, \"time-step\": 1323}, {\"errors\": 0.12216488789945953, \"time-step\": 1324}, {\"errors\": 0.12215899001555666, \"time-step\": 1325}, {\"errors\": 0.12215307962803358, \"time-step\": 1326}, {\"errors\": 0.12214715671160947, \"time-step\": 1327}, {\"errors\": 0.1221412212409631, \"time-step\": 1328}, {\"errors\": 0.12213527319073314, \"time-step\": 1329}, {\"errors\": 0.12212931253551794, \"time-step\": 1330}, {\"errors\": 0.1221233392498755, \"time-step\": 1331}, {\"errors\": 0.12211735330832355, \"time-step\": 1332}, {\"errors\": 0.12211135468533967, \"time-step\": 1333}, {\"errors\": 0.12210534335536094, \"time-step\": 1334}, {\"errors\": 0.12209931929278425, \"time-step\": 1335}, {\"errors\": 0.12209328247196627, \"time-step\": 1336}, {\"errors\": 0.12208723286722316, \"time-step\": 1337}, {\"errors\": 0.12208117045283094, \"time-step\": 1338}, {\"errors\": 0.12207509520302526, \"time-step\": 1339}, {\"errors\": 0.12206900709200158, \"time-step\": 1340}, {\"errors\": 0.12206290609391479, \"time-step\": 1341}, {\"errors\": 0.12205679218287971, \"time-step\": 1342}, {\"errors\": 0.12205066533297079, \"time-step\": 1343}, {\"errors\": 0.12204452551822212, \"time-step\": 1344}, {\"errors\": 0.12203837271262753, \"time-step\": 1345}, {\"errors\": 0.12203220689014056, \"time-step\": 1346}, {\"errors\": 0.12202602802467438, \"time-step\": 1347}, {\"errors\": 0.12201983609010197, \"time-step\": 1348}, {\"errors\": 0.12201363106025592, \"time-step\": 1349}, {\"errors\": 0.12200741290892861, \"time-step\": 1350}, {\"errors\": 0.12200118160987204, \"time-step\": 1351}, {\"errors\": 0.12199493713679799, \"time-step\": 1352}, {\"errors\": 0.121988679463378, \"time-step\": 1353}, {\"errors\": 0.12198240856324331, \"time-step\": 1354}, {\"errors\": 0.12197612440998488, \"time-step\": 1355}, {\"errors\": 0.12196982697715344, \"time-step\": 1356}, {\"errors\": 0.12196351623825946, \"time-step\": 1357}, {\"errors\": 0.12195719216677325, \"time-step\": 1358}, {\"errors\": 0.1219508547361248, \"time-step\": 1359}, {\"errors\": 0.12194450391970393, \"time-step\": 1360}, {\"errors\": 0.12193813969086029, \"time-step\": 1361}, {\"errors\": 0.1219317620229032, \"time-step\": 1362}, {\"errors\": 0.12192537088910203, \"time-step\": 1363}, {\"errors\": 0.12191896626268581, \"time-step\": 1364}, {\"errors\": 0.12191254811684349, \"time-step\": 1365}, {\"errors\": 0.12190611642472379, \"time-step\": 1366}, {\"errors\": 0.12189967115943545, \"time-step\": 1367}, {\"errors\": 0.121893212294047, \"time-step\": 1368}, {\"errors\": 0.1218867398015869, \"time-step\": 1369}, {\"errors\": 0.1218802536550435, \"time-step\": 1370}, {\"errors\": 0.1218737538273652, \"time-step\": 1371}, {\"errors\": 0.12186724029146026, \"time-step\": 1372}, {\"errors\": 0.12186071302019695, \"time-step\": 1373}, {\"errors\": 0.12185417198640354, \"time-step\": 1374}, {\"errors\": 0.12184761716286827, \"time-step\": 1375}, {\"errors\": 0.12184104852233953, \"time-step\": 1376}, {\"errors\": 0.12183446603752565, \"time-step\": 1377}, {\"errors\": 0.1218278696810951, \"time-step\": 1378}, {\"errors\": 0.12182125942567648, \"time-step\": 1379}, {\"errors\": 0.1218146352438585, \"time-step\": 1380}, {\"errors\": 0.12180799710818993, \"time-step\": 1381}, {\"errors\": 0.12180134499117985, \"time-step\": 1382}, {\"errors\": 0.12179467886529749, \"time-step\": 1383}, {\"errors\": 0.12178799870297233, \"time-step\": 1384}, {\"errors\": 0.1217813044765941, \"time-step\": 1385}, {\"errors\": 0.12177459615851277, \"time-step\": 1386}, {\"errors\": 0.12176787372103866, \"time-step\": 1387}, {\"errors\": 0.12176113713644246, \"time-step\": 1388}, {\"errors\": 0.12175438637695526, \"time-step\": 1389}, {\"errors\": 0.12174762141476844, \"time-step\": 1390}, {\"errors\": 0.12174084222203391, \"time-step\": 1391}, {\"errors\": 0.12173404877086402, \"time-step\": 1392}, {\"errors\": 0.12172724103333168, \"time-step\": 1393}, {\"errors\": 0.12172041898147029, \"time-step\": 1394}, {\"errors\": 0.12171358258727374, \"time-step\": 1395}, {\"errors\": 0.12170673182269676, \"time-step\": 1396}, {\"errors\": 0.12169986665965447, \"time-step\": 1397}, {\"errors\": 0.12169298707002285, \"time-step\": 1398}, {\"errors\": 0.12168609302563853, \"time-step\": 1399}, {\"errors\": 0.12167918449829888, \"time-step\": 1400}, {\"errors\": 0.1216722614597622, \"time-step\": 1401}, {\"errors\": 0.12166532388174753, \"time-step\": 1402}, {\"errors\": 0.12165837173593476, \"time-step\": 1403}, {\"errors\": 0.12165140499396482, \"time-step\": 1404}, {\"errors\": 0.12164442362743949, \"time-step\": 1405}, {\"errors\": 0.12163742760792173, \"time-step\": 1406}, {\"errors\": 0.12163041690693539, \"time-step\": 1407}, {\"errors\": 0.12162339149596554, \"time-step\": 1408}, {\"errors\": 0.12161635134645843, \"time-step\": 1409}, {\"errors\": 0.12160929642982135, \"time-step\": 1410}, {\"errors\": 0.12160222671742303, \"time-step\": 1411}, {\"errors\": 0.12159514218059342, \"time-step\": 1412}, {\"errors\": 0.12158804279062385, \"time-step\": 1413}, {\"errors\": 0.121580928518767, \"time-step\": 1414}, {\"errors\": 0.12157379933623715, \"time-step\": 1415}, {\"errors\": 0.12156665521420987, \"time-step\": 1416}, {\"errors\": 0.12155949612382258, \"time-step\": 1417}, {\"errors\": 0.12155232203617405, \"time-step\": 1418}, {\"errors\": 0.12154513292232494, \"time-step\": 1419}, {\"errors\": 0.12153792875329752, \"time-step\": 1420}, {\"errors\": 0.12153070950007597, \"time-step\": 1421}, {\"errors\": 0.1215234751336062, \"time-step\": 1422}, {\"errors\": 0.12151622562479616, \"time-step\": 1423}, {\"errors\": 0.12150896094451571, \"time-step\": 1424}, {\"errors\": 0.12150168106359677, \"time-step\": 1425}, {\"errors\": 0.12149438595283342, \"time-step\": 1426}, {\"errors\": 0.1214870755829818, \"time-step\": 1427}, {\"errors\": 0.12147974992476035, \"time-step\": 1428}, {\"errors\": 0.12147240894884989, \"time-step\": 1429}, {\"errors\": 0.12146505262589355, \"time-step\": 1430}, {\"errors\": 0.12145768092649681, \"time-step\": 1431}, {\"errors\": 0.12145029382122781, \"time-step\": 1432}, {\"errors\": 0.12144289128061725, \"time-step\": 1433}, {\"errors\": 0.12143547327515843, \"time-step\": 1434}, {\"errors\": 0.12142803977530739, \"time-step\": 1435}, {\"errors\": 0.12142059075148302, \"time-step\": 1436}, {\"errors\": 0.12141312617406708, \"time-step\": 1437}, {\"errors\": 0.12140564601340424, \"time-step\": 1438}, {\"errors\": 0.12139815023980229, \"time-step\": 1439}, {\"errors\": 0.12139063882353203, \"time-step\": 1440}, {\"errors\": 0.12138311173482756, \"time-step\": 1441}, {\"errors\": 0.12137556894388621, \"time-step\": 1442}, {\"errors\": 0.12136801042086863, \"time-step\": 1443}, {\"errors\": 0.12136043613589902, \"time-step\": 1444}, {\"errors\": 0.12135284605906503, \"time-step\": 1445}, {\"errors\": 0.12134524016041791, \"time-step\": 1446}, {\"errors\": 0.12133761840997265, \"time-step\": 1447}, {\"errors\": 0.12132998077770804, \"time-step\": 1448}, {\"errors\": 0.12132232723356676, \"time-step\": 1449}, {\"errors\": 0.1213146577474554, \"time-step\": 1450}, {\"errors\": 0.12130697228924468, \"time-step\": 1451}, {\"errors\": 0.12129927082876946, \"time-step\": 1452}, {\"errors\": 0.1212915533358288, \"time-step\": 1453}, {\"errors\": 0.12128381978018621, \"time-step\": 1454}, {\"errors\": 0.12127607013156952, \"time-step\": 1455}, {\"errors\": 0.12126830435967126, \"time-step\": 1456}, {\"errors\": 0.12126052243414842, \"time-step\": 1457}, {\"errors\": 0.1212527243246229, \"time-step\": 1458}, {\"errors\": 0.12124491000068138, \"time-step\": 1459}, {\"errors\": 0.12123707943187546, \"time-step\": 1460}, {\"errors\": 0.12122923258772186, \"time-step\": 1461}, {\"errors\": 0.12122136943770243, \"time-step\": 1462}, {\"errors\": 0.12121348995126424, \"time-step\": 1463}, {\"errors\": 0.12120559409781984, \"time-step\": 1464}, {\"errors\": 0.1211976818467472, \"time-step\": 1465}, {\"errors\": 0.12118975316738995, \"time-step\": 1466}, {\"errors\": 0.12118180802905737, \"time-step\": 1467}, {\"errors\": 0.12117384640102462, \"time-step\": 1468}, {\"errors\": 0.12116586825253277, \"time-step\": 1469}, {\"errors\": 0.12115787355278891, \"time-step\": 1470}, {\"errors\": 0.12114986227096645, \"time-step\": 1471}, {\"errors\": 0.12114183437620499, \"time-step\": 1472}, {\"errors\": 0.12113378983761061, \"time-step\": 1473}, {\"errors\": 0.12112572862425586, \"time-step\": 1474}, {\"errors\": 0.12111765070517998, \"time-step\": 1475}, {\"errors\": 0.12110955604938915, \"time-step\": 1476}, {\"errors\": 0.12110144462585623, \"time-step\": 1477}, {\"errors\": 0.12109331640352135, \"time-step\": 1478}, {\"errors\": 0.12108517135129165, \"time-step\": 1479}, {\"errors\": 0.12107700943804177, \"time-step\": 1480}, {\"errors\": 0.12106883063261362, \"time-step\": 1481}, {\"errors\": 0.12106063490381674, \"time-step\": 1482}, {\"errors\": 0.1210524222204285, \"time-step\": 1483}, {\"errors\": 0.12104419255119395, \"time-step\": 1484}, {\"errors\": 0.12103594586482633, \"time-step\": 1485}, {\"errors\": 0.12102768213000681, \"time-step\": 1486}, {\"errors\": 0.12101940131538501, \"time-step\": 1487}, {\"errors\": 0.12101110338957885, \"time-step\": 1488}, {\"errors\": 0.12100278832117489, \"time-step\": 1489}, {\"errors\": 0.12099445607872841, \"time-step\": 1490}, {\"errors\": 0.1209861066307635, \"time-step\": 1491}, {\"errors\": 0.12097773994577332, \"time-step\": 1492}, {\"errors\": 0.12096935599222018, \"time-step\": 1493}, {\"errors\": 0.12096095473853569, \"time-step\": 1494}, {\"errors\": 0.1209525361531209, \"time-step\": 1495}, {\"errors\": 0.12094410020434664, \"time-step\": 1496}, {\"errors\": 0.12093564686055333, \"time-step\": 1497}, {\"errors\": 0.12092717609005149, \"time-step\": 1498}, {\"errors\": 0.12091868786112173, \"time-step\": 1499}, {\"errors\": 0.12091018214201486, \"time-step\": 1500}, {\"errors\": 0.12090165890095217, \"time-step\": 1501}, {\"errors\": 0.12089311810612569, \"time-step\": 1502}, {\"errors\": 0.12088455972569792, \"time-step\": 1503}, {\"errors\": 0.12087598372780264, \"time-step\": 1504}, {\"errors\": 0.12086739008054453, \"time-step\": 1505}, {\"errors\": 0.12085877875199962, \"time-step\": 1506}, {\"errors\": 0.12085014971021552, \"time-step\": 1507}, {\"errors\": 0.12084150292321125, \"time-step\": 1508}, {\"errors\": 0.12083283835897793, \"time-step\": 1509}, {\"errors\": 0.12082415598547842, \"time-step\": 1510}, {\"errors\": 0.120815455770648, \"time-step\": 1511}, {\"errors\": 0.12080673768239417, \"time-step\": 1512}, {\"errors\": 0.12079800168859704, \"time-step\": 1513}, {\"errors\": 0.12078924775710949, \"time-step\": 1514}, {\"errors\": 0.12078047585575727, \"time-step\": 1515}, {\"errors\": 0.12077168595233931, \"time-step\": 1516}, {\"errors\": 0.12076287801462787, \"time-step\": 1517}, {\"errors\": 0.12075405201036868, \"time-step\": 1518}, {\"errors\": 0.12074520790728122, \"time-step\": 1519}, {\"errors\": 0.12073634567305887, \"time-step\": 1520}, {\"errors\": 0.12072746527536918, \"time-step\": 1521}, {\"errors\": 0.12071856668185392, \"time-step\": 1522}, {\"errors\": 0.12070964986012944, \"time-step\": 1523}, {\"errors\": 0.12070071477778682, \"time-step\": 1524}, {\"errors\": 0.12069176140239202, \"time-step\": 1525}, {\"errors\": 0.12068278970148626, \"time-step\": 1526}, {\"errors\": 0.12067379964258601, \"time-step\": 1527}, {\"errors\": 0.12066479119318341, \"time-step\": 1528}, {\"errors\": 0.1206557643207463, \"time-step\": 1529}, {\"errors\": 0.12064671899271863, \"time-step\": 1530}, {\"errors\": 0.12063765517652045, \"time-step\": 1531}, {\"errors\": 0.12062857283954843, \"time-step\": 1532}, {\"errors\": 0.12061947194917574, \"time-step\": 1533}, {\"errors\": 0.12061035247275262, \"time-step\": 1534}, {\"errors\": 0.12060121437760636, \"time-step\": 1535}, {\"errors\": 0.1205920576310416, \"time-step\": 1536}, {\"errors\": 0.12058288220034055, \"time-step\": 1537}, {\"errors\": 0.12057368805276342, \"time-step\": 1538}, {\"errors\": 0.12056447515554827, \"time-step\": 1539}, {\"errors\": 0.1205552434759116, \"time-step\": 1540}, {\"errors\": 0.12054599298104843, \"time-step\": 1541}, {\"errors\": 0.12053672363813261, \"time-step\": 1542}, {\"errors\": 0.12052743541431687, \"time-step\": 1543}, {\"errors\": 0.12051812827673344, \"time-step\": 1544}, {\"errors\": 0.12050880219249395, \"time-step\": 1545}, {\"errors\": 0.12049945712868981, \"time-step\": 1546}, {\"errors\": 0.12049009305239253, \"time-step\": 1547}, {\"errors\": 0.12048070993065393, \"time-step\": 1548}, {\"errors\": 0.12047130773050632, \"time-step\": 1549}, {\"errors\": 0.12046188641896281, \"time-step\": 1550}, {\"errors\": 0.12045244596301763, \"time-step\": 1551}, {\"errors\": 0.12044298632964635, \"time-step\": 1552}, {\"errors\": 0.12043350748580618, \"time-step\": 1553}, {\"errors\": 0.12042400939843612, \"time-step\": 1554}, {\"errors\": 0.12041449203445737, \"time-step\": 1555}, {\"errors\": 0.12040495536077354, \"time-step\": 1556}, {\"errors\": 0.12039539934427096, \"time-step\": 1557}, {\"errors\": 0.12038582395181899, \"time-step\": 1558}, {\"errors\": 0.12037622915027005, \"time-step\": 1559}, {\"errors\": 0.12036661490646025, \"time-step\": 1560}, {\"errors\": 0.12035698118720956, \"time-step\": 1561}, {\"errors\": 0.12034732795932201, \"time-step\": 1562}, {\"errors\": 0.12033765518958595, \"time-step\": 1563}, {\"errors\": 0.12032796284477455, \"time-step\": 1564}, {\"errors\": 0.1203182508916459, \"time-step\": 1565}, {\"errors\": 0.12030851929694338, \"time-step\": 1566}, {\"errors\": 0.12029876802739599, \"time-step\": 1567}, {\"errors\": 0.12028899704971857, \"time-step\": 1568}, {\"errors\": 0.12027920633061218, \"time-step\": 1569}, {\"errors\": 0.12026939583676438, \"time-step\": 1570}, {\"errors\": 0.12025956553484947, \"time-step\": 1571}, {\"errors\": 0.12024971539152893, \"time-step\": 1572}, {\"errors\": 0.12023984537345168, \"time-step\": 1573}, {\"errors\": 0.12022995544725434, \"time-step\": 1574}, {\"errors\": 0.12022004557956165, \"time-step\": 1575}, {\"errors\": 0.12021011573698664, \"time-step\": 1576}, {\"errors\": 0.12020016588613111, \"time-step\": 1577}, {\"errors\": 0.12019019599358591, \"time-step\": 1578}, {\"errors\": 0.12018020602593124, \"time-step\": 1579}, {\"errors\": 0.12017019594973695, \"time-step\": 1580}, {\"errors\": 0.12016016573156296, \"time-step\": 1581}, {\"errors\": 0.12015011533795952, \"time-step\": 1582}, {\"errors\": 0.12014004473546766, \"time-step\": 1583}, {\"errors\": 0.12012995389061928, \"time-step\": 1584}, {\"errors\": 0.12011984276993791, \"time-step\": 1585}, {\"errors\": 0.12010971133993856, \"time-step\": 1586}, {\"errors\": 0.12009955956712848, \"time-step\": 1587}, {\"errors\": 0.12008938741800732, \"time-step\": 1588}, {\"errors\": 0.12007919485906746, \"time-step\": 1589}, {\"errors\": 0.12006898185679446, \"time-step\": 1590}, {\"errors\": 0.12005874837766738, \"time-step\": 1591}, {\"errors\": 0.12004849438815918, \"time-step\": 1592}, {\"errors\": 0.12003821985473694, \"time-step\": 1593}, {\"errors\": 0.1200279247438624, \"time-step\": 1594}, {\"errors\": 0.1200176090219923, \"time-step\": 1595}, {\"errors\": 0.12000727265557859, \"time-step\": 1596}, {\"errors\": 0.11999691561106904, \"time-step\": 1597}, {\"errors\": 0.11998653785490755, \"time-step\": 1598}, {\"errors\": 0.11997613935353427, \"time-step\": 1599}, {\"errors\": 0.11996572007338638, \"time-step\": 1600}, {\"errors\": 0.11995527998089828, \"time-step\": 1601}, {\"errors\": 0.1199448190425019, \"time-step\": 1602}, {\"errors\": 0.11993433722462726, \"time-step\": 1603}, {\"errors\": 0.11992383449370281, \"time-step\": 1604}, {\"errors\": 0.1199133108161557, \"time-step\": 1605}, {\"errors\": 0.11990276615841233, \"time-step\": 1606}, {\"errors\": 0.11989220048689876, \"time-step\": 1607}, {\"errors\": 0.11988161376804096, \"time-step\": 1608}, {\"errors\": 0.11987100596826541, \"time-step\": 1609}, {\"errors\": 0.11986037705399934, \"time-step\": 1610}, {\"errors\": 0.11984972699167128, \"time-step\": 1611}, {\"errors\": 0.11983905574771135, \"time-step\": 1612}, {\"errors\": 0.11982836328855179, \"time-step\": 1613}, {\"errors\": 0.1198176495806273, \"time-step\": 1614}, {\"errors\": 0.11980691459037557, \"time-step\": 1615}, {\"errors\": 0.11979615828423752, \"time-step\": 1616}, {\"errors\": 0.11978538062865793, \"time-step\": 1617}, {\"errors\": 0.1197745815900858, \"time-step\": 1618}, {\"errors\": 0.11976376113497471, \"time-step\": 1619}, {\"errors\": 0.11975291922978334, \"time-step\": 1620}, {\"errors\": 0.11974205584097596, \"time-step\": 1621}, {\"errors\": 0.1197311709350227, \"time-step\": 1622}, {\"errors\": 0.11972026447840015, \"time-step\": 1623}, {\"errors\": 0.11970933643759178, \"time-step\": 1624}, {\"errors\": 0.11969838677908838, \"time-step\": 1625}, {\"errors\": 0.11968741546938853, \"time-step\": 1626}, {\"errors\": 0.11967642247499896, \"time-step\": 1627}, {\"errors\": 0.1196654077624352, \"time-step\": 1628}, {\"errors\": 0.11965437129822183, \"time-step\": 1629}, {\"errors\": 0.11964331304889309, \"time-step\": 1630}, {\"errors\": 0.1196322329809934, \"time-step\": 1631}, {\"errors\": 0.11962113106107766, \"time-step\": 1632}, {\"errors\": 0.11961000725571183, \"time-step\": 1633}, {\"errors\": 0.1195988615314734, \"time-step\": 1634}, {\"errors\": 0.1195876938549518, \"time-step\": 1635}, {\"errors\": 0.11957650419274915, \"time-step\": 1636}, {\"errors\": 0.11956529251148039, \"time-step\": 1637}, {\"errors\": 0.11955405877777386, \"time-step\": 1638}, {\"errors\": 0.1195428029582721, \"time-step\": 1639}, {\"errors\": 0.1195315250196319, \"time-step\": 1640}, {\"errors\": 0.11952022492852507, \"time-step\": 1641}, {\"errors\": 0.11950890265163899, \"time-step\": 1642}, {\"errors\": 0.11949755815567689, \"time-step\": 1643}, {\"errors\": 0.1194861914073585, \"time-step\": 1644}, {\"errors\": 0.11947480237342062, \"time-step\": 1645}, {\"errors\": 0.11946339102061748, \"time-step\": 1646}, {\"errors\": 0.11945195731572134, \"time-step\": 1647}, {\"errors\": 0.1194405012255231, \"time-step\": 1648}, {\"errors\": 0.11942902271683262, \"time-step\": 1649}, {\"errors\": 0.11941752175647935, \"time-step\": 1650}, {\"errors\": 0.11940599831131311, \"time-step\": 1651}, {\"errors\": 0.11939445234820403, \"time-step\": 1652}, {\"errors\": 0.11938288383404372, \"time-step\": 1653}, {\"errors\": 0.1193712927357454, \"time-step\": 1654}, {\"errors\": 0.11935967902024464, \"time-step\": 1655}, {\"errors\": 0.11934804265449979, \"time-step\": 1656}, {\"errors\": 0.11933638360549254, \"time-step\": 1657}, {\"errors\": 0.11932470184022873, \"time-step\": 1658}, {\"errors\": 0.11931299732573838, \"time-step\": 1659}, {\"errors\": 0.11930127002907684, \"time-step\": 1660}, {\"errors\": 0.11928951991732485, \"time-step\": 1661}, {\"errors\": 0.11927774695758947, \"time-step\": 1662}, {\"errors\": 0.1192659511170044, \"time-step\": 1663}, {\"errors\": 0.11925413236273072, \"time-step\": 1664}, {\"errors\": 0.1192422906619574, \"time-step\": 1665}, {\"errors\": 0.11923042598190185, \"time-step\": 1666}, {\"errors\": 0.11921853828981047, \"time-step\": 1667}, {\"errors\": 0.11920662755295938, \"time-step\": 1668}, {\"errors\": 0.1191946937386549, \"time-step\": 1669}, {\"errors\": 0.11918273681423412, \"time-step\": 1670}, {\"errors\": 0.11917075674706547, \"time-step\": 1671}, {\"errors\": 0.11915875350454957, \"time-step\": 1672}, {\"errors\": 0.11914672705411938, \"time-step\": 1673}, {\"errors\": 0.11913467736324125, \"time-step\": 1674}, {\"errors\": 0.11912260439941522, \"time-step\": 1675}, {\"errors\": 0.11911050813017579, \"time-step\": 1676}, {\"errors\": 0.11909838852309254, \"time-step\": 1677}, {\"errors\": 0.1190862455457705, \"time-step\": 1678}, {\"errors\": 0.11907407916585117, \"time-step\": 1679}, {\"errors\": 0.11906188935101272, \"time-step\": 1680}, {\"errors\": 0.11904967606897107, \"time-step\": 1681}, {\"errors\": 0.11903743928747995, \"time-step\": 1682}, {\"errors\": 0.11902517897433218, \"time-step\": 1683}, {\"errors\": 0.11901289509735972, \"time-step\": 1684}, {\"errors\": 0.1190005876244347, \"time-step\": 1685}, {\"errors\": 0.11898825652346985, \"time-step\": 1686}, {\"errors\": 0.11897590176241926, \"time-step\": 1687}, {\"errors\": 0.11896352330927892, \"time-step\": 1688}, {\"errors\": 0.11895112113208753, \"time-step\": 1689}, {\"errors\": 0.11893869519892697, \"time-step\": 1690}, {\"errors\": 0.11892624547792302, \"time-step\": 1691}, {\"errors\": 0.11891377193724614, \"time-step\": 1692}, {\"errors\": 0.11890127454511193, \"time-step\": 1693}, {\"errors\": 0.11888875326978196, \"time-step\": 1694}, {\"errors\": 0.11887620807956434, \"time-step\": 1695}, {\"errors\": 0.11886363894281443, \"time-step\": 1696}, {\"errors\": 0.11885104582793554, \"time-step\": 1697}, {\"errors\": 0.1188384287033796, \"time-step\": 1698}, {\"errors\": 0.11882578753764775, \"time-step\": 1699}, {\"errors\": 0.1188131222992911, \"time-step\": 1700}, {\"errors\": 0.11880043295691146, \"time-step\": 1701}, {\"errors\": 0.11878771947916206, \"time-step\": 1702}, {\"errors\": 0.118774981834748, \"time-step\": 1703}, {\"errors\": 0.11876221999242714, \"time-step\": 1704}, {\"errors\": 0.11874943392101098, \"time-step\": 1705}, {\"errors\": 0.11873662358936493, \"time-step\": 1706}, {\"errors\": 0.11872378896640928, \"time-step\": 1707}, {\"errors\": 0.11871093002112004, \"time-step\": 1708}, {\"errors\": 0.11869804672252926, \"time-step\": 1709}, {\"errors\": 0.1186851390397262, \"time-step\": 1710}, {\"errors\": 0.11867220694185765, \"time-step\": 1711}, {\"errors\": 0.11865925039812891, \"time-step\": 1712}, {\"errors\": 0.11864626937780434, \"time-step\": 1713}, {\"errors\": 0.11863326385020834, \"time-step\": 1714}, {\"errors\": 0.11862023378472575, \"time-step\": 1715}, {\"errors\": 0.1186071791508029, \"time-step\": 1716}, {\"errors\": 0.11859409991794806, \"time-step\": 1717}, {\"errors\": 0.11858099605573248, \"time-step\": 1718}, {\"errors\": 0.11856786753379084, \"time-step\": 1719}, {\"errors\": 0.11855471432182214, \"time-step\": 1720}, {\"errors\": 0.11854153638959056, \"time-step\": 1721}, {\"errors\": 0.11852833370692596, \"time-step\": 1722}, {\"errors\": 0.11851510624372491, \"time-step\": 1723}, {\"errors\": 0.11850185396995117, \"time-step\": 1724}, {\"errors\": 0.11848857685563663, \"time-step\": 1725}, {\"errors\": 0.11847527487088211, \"time-step\": 1726}, {\"errors\": 0.11846194798585798, \"time-step\": 1727}, {\"errors\": 0.11844859617080498, \"time-step\": 1728}, {\"errors\": 0.11843521939603513, \"time-step\": 1729}, {\"errors\": 0.11842181763193228, \"time-step\": 1730}, {\"errors\": 0.11840839084895308, \"time-step\": 1731}, {\"errors\": 0.1183949390176277, \"time-step\": 1732}, {\"errors\": 0.11838146210856042, \"time-step\": 1733}, {\"errors\": 0.11836796009243084, \"time-step\": 1734}, {\"errors\": 0.11835443293999437, \"time-step\": 1735}, {\"errors\": 0.118340880622083, \"time-step\": 1736}, {\"errors\": 0.11832730310960622, \"time-step\": 1737}, {\"errors\": 0.1183137003735518, \"time-step\": 1738}, {\"errors\": 0.11830007238498663, \"time-step\": 1739}, {\"errors\": 0.11828641911505738, \"time-step\": 1740}, {\"errors\": 0.11827274053499143, \"time-step\": 1741}, {\"errors\": 0.11825903661609768, \"time-step\": 1742}, {\"errors\": 0.11824530732976729, \"time-step\": 1743}, {\"errors\": 0.11823155264747463, \"time-step\": 1744}, {\"errors\": 0.11821777254077795, \"time-step\": 1745}, {\"errors\": 0.1182039669813202, \"time-step\": 1746}, {\"errors\": 0.11819013594083011, \"time-step\": 1747}, {\"errors\": 0.11817627939112262, \"time-step\": 1748}, {\"errors\": 0.11816239730410008, \"time-step\": 1749}, {\"errors\": 0.1181484896517529, \"time-step\": 1750}, {\"errors\": 0.1181345564061603, \"time-step\": 1751}, {\"errors\": 0.11812059753949139, \"time-step\": 1752}, {\"errors\": 0.11810661302400582, \"time-step\": 1753}, {\"errors\": 0.1180926028320547, \"time-step\": 1754}, {\"errors\": 0.11807856693608144, \"time-step\": 1755}, {\"errors\": 0.11806450530862259, \"time-step\": 1756}, {\"errors\": 0.11805041792230872, \"time-step\": 1757}, {\"errors\": 0.11803630474986518, \"time-step\": 1758}, {\"errors\": 0.11802216576411315, \"time-step\": 1759}, {\"errors\": 0.11800800093797027, \"time-step\": 1760}, {\"errors\": 0.11799381024445163, \"time-step\": 1761}, {\"errors\": 0.1179795936566707, \"time-step\": 1762}, {\"errors\": 0.11796535114783999, \"time-step\": 1763}, {\"errors\": 0.11795108269127211, \"time-step\": 1764}, {\"errors\": 0.11793678826038065, \"time-step\": 1765}, {\"errors\": 0.11792246782868085, \"time-step\": 1766}, {\"errors\": 0.11790812136979066, \"time-step\": 1767}, {\"errors\": 0.11789374885743166, \"time-step\": 1768}, {\"errors\": 0.1178793502654297, \"time-step\": 1769}, {\"errors\": 0.11786492556771608, \"time-step\": 1770}, {\"errors\": 0.11785047473832812, \"time-step\": 1771}, {\"errors\": 0.11783599775141047, \"time-step\": 1772}, {\"errors\": 0.11782149458121552, \"time-step\": 1773}, {\"errors\": 0.11780696520210468, \"time-step\": 1774}, {\"errors\": 0.11779240958854909, \"time-step\": 1775}, {\"errors\": 0.11777782771513054, \"time-step\": 1776}, {\"errors\": 0.11776321955654231, \"time-step\": 1777}, {\"errors\": 0.11774858508759031, \"time-step\": 1778}, {\"errors\": 0.1177339242831937, \"time-step\": 1779}, {\"errors\": 0.11771923711838603, \"time-step\": 1780}, {\"errors\": 0.1177045235683159, \"time-step\": 1781}, {\"errors\": 0.11768978360824814, \"time-step\": 1782}, {\"errors\": 0.11767501721356445, \"time-step\": 1783}, {\"errors\": 0.11766022435976467, \"time-step\": 1784}, {\"errors\": 0.11764540502246731, \"time-step\": 1785}, {\"errors\": 0.11763055917741069, \"time-step\": 1786}, {\"errors\": 0.1176156868004539, \"time-step\": 1787}, {\"errors\": 0.11760078786757758, \"time-step\": 1788}, {\"errors\": 0.11758586235488486, \"time-step\": 1789}, {\"errors\": 0.11757091023860243, \"time-step\": 1790}, {\"errors\": 0.1175559314950813, \"time-step\": 1791}, {\"errors\": 0.11754092610079792, \"time-step\": 1792}, {\"errors\": 0.11752589403235483, \"time-step\": 1793}, {\"errors\": 0.11751083526648193, \"time-step\": 1794}, {\"errors\": 0.11749574978003717, \"time-step\": 1795}, {\"errors\": 0.11748063755000754, \"time-step\": 1796}, {\"errors\": 0.1174654985535101, \"time-step\": 1797}, {\"errors\": 0.11745033276779288, \"time-step\": 1798}, {\"errors\": 0.11743514017023562, \"time-step\": 1799}, {\"errors\": 0.11741992073835122, \"time-step\": 1800}, {\"errors\": 0.11740467444978608, \"time-step\": 1801}, {\"errors\": 0.11738940128232142, \"time-step\": 1802}, {\"errors\": 0.11737410121387422, \"time-step\": 1803}, {\"errors\": 0.11735877422249802, \"time-step\": 1804}, {\"errors\": 0.11734342028638389, \"time-step\": 1805}, {\"errors\": 0.1173280393838616, \"time-step\": 1806}, {\"errors\": 0.11731263149340022, \"time-step\": 1807}, {\"errors\": 0.1172971965936094, \"time-step\": 1808}, {\"errors\": 0.11728173466324021, \"time-step\": 1809}, {\"errors\": 0.11726624568118596, \"time-step\": 1810}, {\"errors\": 0.11725072962648342, \"time-step\": 1811}, {\"errors\": 0.1172351864783136, \"time-step\": 1812}, {\"errors\": 0.11721961621600271, \"time-step\": 1813}, {\"errors\": 0.11720401881902323, \"time-step\": 1814}, {\"errors\": 0.11718839426699486, \"time-step\": 1815}, {\"errors\": 0.11717274253968529, \"time-step\": 1816}, {\"errors\": 0.1171570636170115, \"time-step\": 1817}, {\"errors\": 0.11714135747904045, \"time-step\": 1818}, {\"errors\": 0.11712562410599023, \"time-step\": 1819}, {\"errors\": 0.11710986347823077, \"time-step\": 1820}, {\"errors\": 0.11709407557628522, \"time-step\": 1821}, {\"errors\": 0.11707826038083055, \"time-step\": 1822}, {\"errors\": 0.11706241787269869, \"time-step\": 1823}, {\"errors\": 0.11704654803287745, \"time-step\": 1824}, {\"errors\": 0.1170306508425116, \"time-step\": 1825}, {\"errors\": 0.11701472628290369, \"time-step\": 1826}, {\"errors\": 0.11699877433551513, \"time-step\": 1827}, {\"errors\": 0.11698279498196709, \"time-step\": 1828}, {\"errors\": 0.11696678820404163, \"time-step\": 1829}, {\"errors\": 0.11695075398368249, \"time-step\": 1830}, {\"errors\": 0.11693469230299611, \"time-step\": 1831}, {\"errors\": 0.1169186031442527, \"time-step\": 1832}, {\"errors\": 0.11690248648988719, \"time-step\": 1833}, {\"errors\": 0.11688634232250011, \"time-step\": 1834}, {\"errors\": 0.11687017062485863, \"time-step\": 1835}, {\"errors\": 0.11685397137989773, \"time-step\": 1836}, {\"errors\": 0.11683774457072071, \"time-step\": 1837}, {\"errors\": 0.11682149018060067, \"time-step\": 1838}, {\"errors\": 0.11680520819298121, \"time-step\": 1839}, {\"errors\": 0.11678889859147748, \"time-step\": 1840}, {\"errors\": 0.11677256135987714, \"time-step\": 1841}, {\"errors\": 0.11675619648214135, \"time-step\": 1842}, {\"errors\": 0.11673980394240585, \"time-step\": 1843}, {\"errors\": 0.11672338372498173, \"time-step\": 1844}, {\"errors\": 0.11670693581435648, \"time-step\": 1845}, {\"errors\": 0.1166904601951953, \"time-step\": 1846}, {\"errors\": 0.11667395685234147, \"time-step\": 1847}, {\"errors\": 0.11665742577081778, \"time-step\": 1848}, {\"errors\": 0.11664086693582744, \"time-step\": 1849}, {\"errors\": 0.1166242803327549, \"time-step\": 1850}, {\"errors\": 0.11660766594716704, \"time-step\": 1851}, {\"errors\": 0.11659102376481387, \"time-step\": 1852}, {\"errors\": 0.11657435377162986, \"time-step\": 1853}, {\"errors\": 0.1165576559537346, \"time-step\": 1854}, {\"errors\": 0.11654093029743394, \"time-step\": 1855}, {\"errors\": 0.11652417678922097, \"time-step\": 1856}, {\"errors\": 0.1165073954157769, \"time-step\": 1857}, {\"errors\": 0.11649058616397209, \"time-step\": 1858}, {\"errors\": 0.11647374902086709, \"time-step\": 1859}, {\"errors\": 0.11645688397371345, \"time-step\": 1860}, {\"errors\": 0.11643999100995484, \"time-step\": 1861}, {\"errors\": 0.11642307011722791, \"time-step\": 1862}, {\"errors\": 0.11640612128336342, \"time-step\": 1863}, {\"errors\": 0.11638914449638699, \"time-step\": 1864}, {\"errors\": 0.11637213974452026, \"time-step\": 1865}, {\"errors\": 0.11635510701618176, \"time-step\": 1866}, {\"errors\": 0.11633804629998776, \"time-step\": 1867}, {\"errors\": 0.11632095758475361, \"time-step\": 1868}, {\"errors\": 0.11630384085949425, \"time-step\": 1869}, {\"errors\": 0.11628669611342538, \"time-step\": 1870}, {\"errors\": 0.11626952333596458, \"time-step\": 1871}, {\"errors\": 0.1162523225167319, \"time-step\": 1872}, {\"errors\": 0.11623509364555121, \"time-step\": 1873}, {\"errors\": 0.11621783671245081, \"time-step\": 1874}, {\"errors\": 0.11620055170766458, \"time-step\": 1875}, {\"errors\": 0.11618323862163296, \"time-step\": 1876}, {\"errors\": 0.11616589744500377, \"time-step\": 1877}, {\"errors\": 0.11614852816863314, \"time-step\": 1878}, {\"errors\": 0.11613113078358664, \"time-step\": 1879}, {\"errors\": 0.11611370528114015, \"time-step\": 1880}, {\"errors\": 0.11609625165278062, \"time-step\": 1881}, {\"errors\": 0.11607876989020723, \"time-step\": 1882}, {\"errors\": 0.11606125998533229, \"time-step\": 1883}, {\"errors\": 0.11604372193028209, \"time-step\": 1884}, {\"errors\": 0.1160261557173979, \"time-step\": 1885}, {\"errors\": 0.11600856133923691, \"time-step\": 1886}, {\"errors\": 0.11599093878857311, \"time-step\": 1887}, {\"errors\": 0.11597328805839822, \"time-step\": 1888}, {\"errors\": 0.11595560914192268, \"time-step\": 1889}, {\"errors\": 0.11593790203257648, \"time-step\": 1890}, {\"errors\": 0.11592016672401016, \"time-step\": 1891}, {\"errors\": 0.11590240321009565, \"time-step\": 1892}, {\"errors\": 0.11588461148492732, \"time-step\": 1893}, {\"errors\": 0.11586679154282273, \"time-step\": 1894}, {\"errors\": 0.1158489433783235, \"time-step\": 1895}, {\"errors\": 0.11583106698619655, \"time-step\": 1896}, {\"errors\": 0.1158131623614346, \"time-step\": 1897}, {\"errors\": 0.11579522949925725, \"time-step\": 1898}, {\"errors\": 0.11577726839511204, \"time-step\": 1899}, {\"errors\": 0.11575927904467495, \"time-step\": 1900}, {\"errors\": 0.1157412614438516, \"time-step\": 1901}, {\"errors\": 0.11572321558877813, \"time-step\": 1902}, {\"errors\": 0.11570514147582187, \"time-step\": 1903}, {\"errors\": 0.11568703910158243, \"time-step\": 1904}, {\"errors\": 0.11566890846289249, \"time-step\": 1905}, {\"errors\": 0.11565074955681873, \"time-step\": 1906}, {\"errors\": 0.11563256238066252, \"time-step\": 1907}, {\"errors\": 0.1156143469319611, \"time-step\": 1908}, {\"errors\": 0.11559610320848812, \"time-step\": 1909}, {\"errors\": 0.11557783120825471, \"time-step\": 1910}, {\"errors\": 0.11555953092951027, \"time-step\": 1911}, {\"errors\": 0.11554120237074325, \"time-step\": 1912}, {\"errors\": 0.11552284553068223, \"time-step\": 1913}, {\"errors\": 0.11550446040829643, \"time-step\": 1914}, {\"errors\": 0.1154860470027968, \"time-step\": 1915}, {\"errors\": 0.11546760531363673, \"time-step\": 1916}, {\"errors\": 0.11544913534051307, \"time-step\": 1917}, {\"errors\": 0.11543063708336662, \"time-step\": 1918}, {\"errors\": 0.11541211054238332, \"time-step\": 1919}, {\"errors\": 0.11539355571799471, \"time-step\": 1920}, {\"errors\": 0.11537497261087916, \"time-step\": 1921}, {\"errors\": 0.11535636122196227, \"time-step\": 1922}, {\"errors\": 0.11533772155241798, \"time-step\": 1923}, {\"errors\": 0.1153190536036691, \"time-step\": 1924}, {\"errors\": 0.11530035737738839, \"time-step\": 1925}, {\"errors\": 0.11528163287549922, \"time-step\": 1926}, {\"errors\": 0.11526288010017627, \"time-step\": 1927}, {\"errors\": 0.11524409905384642, \"time-step\": 1928}, {\"errors\": 0.11522528973918952, \"time-step\": 1929}, {\"errors\": 0.11520645215913916, \"time-step\": 1930}, {\"errors\": 0.11518758631688336, \"time-step\": 1931}, {\"errors\": 0.11516869221586543, \"time-step\": 1932}, {\"errors\": 0.1151497698597847, \"time-step\": 1933}, {\"errors\": 0.11513081925259723, \"time-step\": 1934}, {\"errors\": 0.11511184039851666, \"time-step\": 1935}, {\"errors\": 0.1150928333020147, \"time-step\": 1936}, {\"errors\": 0.11507379796782226, \"time-step\": 1937}, {\"errors\": 0.11505473440092986, \"time-step\": 1938}, {\"errors\": 0.11503564260658838, \"time-step\": 1939}, {\"errors\": 0.11501652259031003, \"time-step\": 1940}, {\"errors\": 0.11499737435786875, \"time-step\": 1941}, {\"errors\": 0.11497819791530112, \"time-step\": 1942}, {\"errors\": 0.11495899326890695, \"time-step\": 1943}, {\"errors\": 0.11493976042525006, \"time-step\": 1944}, {\"errors\": 0.11492049939115892, \"time-step\": 1945}, {\"errors\": 0.11490121017372738, \"time-step\": 1946}, {\"errors\": 0.11488189278031521, \"time-step\": 1947}, {\"errors\": 0.1148625472185491, \"time-step\": 1948}, {\"errors\": 0.11484317349632278, \"time-step\": 1949}, {\"errors\": 0.11482377162179824, \"time-step\": 1950}, {\"errors\": 0.11480434160340611, \"time-step\": 1951}, {\"errors\": 0.11478488344984628, \"time-step\": 1952}, {\"errors\": 0.11476539717008866, \"time-step\": 1953}, {\"errors\": 0.1147458827733736, \"time-step\": 1954}, {\"errors\": 0.11472634026921294, \"time-step\": 1955}, {\"errors\": 0.11470676966739016, \"time-step\": 1956}, {\"errors\": 0.11468717097796115, \"time-step\": 1957}, {\"errors\": 0.1146675442112551, \"time-step\": 1958}, {\"errors\": 0.11464788937787468, \"time-step\": 1959}, {\"errors\": 0.11462820648869682, \"time-step\": 1960}, {\"errors\": 0.11460849555487336, \"time-step\": 1961}, {\"errors\": 0.11458875658783152, \"time-step\": 1962}, {\"errors\": 0.1145689895992745, \"time-step\": 1963}, {\"errors\": 0.11454919460118215, \"time-step\": 1964}, {\"errors\": 0.11452937160581128, \"time-step\": 1965}, {\"errors\": 0.11450952062569653, \"time-step\": 1966}, {\"errors\": 0.11448964167365064, \"time-step\": 1967}, {\"errors\": 0.11446973476276509, \"time-step\": 1968}, {\"errors\": 0.1144497999064108, \"time-step\": 1969}, {\"errors\": 0.11442983711823826, \"time-step\": 1970}, {\"errors\": 0.11440984641217841, \"time-step\": 1971}, {\"errors\": 0.11438982780244299, \"time-step\": 1972}, {\"errors\": 0.11436978130352501, \"time-step\": 1973}, {\"errors\": 0.11434970693019933, \"time-step\": 1974}, {\"errors\": 0.11432960469752312, \"time-step\": 1975}, {\"errors\": 0.11430947462083621, \"time-step\": 1976}, {\"errors\": 0.11428931671576179, \"time-step\": 1977}, {\"errors\": 0.1142691309982066, \"time-step\": 1978}, {\"errors\": 0.11424891748436164, \"time-step\": 1979}, {\"errors\": 0.11422867619070248, \"time-step\": 1980}, {\"errors\": 0.11420840713398965, \"time-step\": 1981}, {\"errors\": 0.11418811033126916, \"time-step\": 1982}, {\"errors\": 0.1141677857998729, \"time-step\": 1983}, {\"errors\": 0.11414743355741896, \"time-step\": 1984}, {\"errors\": 0.11412705362181223, \"time-step\": 1985}, {\"errors\": 0.11410664601124457, \"time-step\": 1986}, {\"errors\": 0.11408621074419531, \"time-step\": 1987}, {\"errors\": 0.11406574783943163, \"time-step\": 1988}, {\"errors\": 0.11404525731600895, \"time-step\": 1989}, {\"errors\": 0.11402473919327114, \"time-step\": 1990}, {\"errors\": 0.1140041934908511, \"time-step\": 1991}, {\"errors\": 0.11398362022867088, \"time-step\": 1992}, {\"errors\": 0.11396301942694217, \"time-step\": 1993}, {\"errors\": 0.11394239110616654, \"time-step\": 1994}, {\"errors\": 0.11392173528713576, \"time-step\": 1995}, {\"errors\": 0.1139010519909322, \"time-step\": 1996}, {\"errors\": 0.11388034123892901, \"time-step\": 1997}, {\"errors\": 0.11385960305279043, \"time-step\": 1998}, {\"errors\": 0.11383883745447218, \"time-step\": 1999}, {\"errors\": 0.11381804446622155, \"time-step\": 2000}, {\"errors\": 0.11379722411057774, \"time-step\": 2001}, {\"errors\": 0.1137763764103722, \"time-step\": 2002}, {\"errors\": 0.11375550138872875, \"time-step\": 2003}, {\"errors\": 0.11373459906906394, \"time-step\": 2004}, {\"errors\": 0.11371366947508699, \"time-step\": 2005}, {\"errors\": 0.11369271263080044, \"time-step\": 2006}, {\"errors\": 0.11367172856050001, \"time-step\": 2007}, {\"errors\": 0.11365071728877482, \"time-step\": 2008}, {\"errors\": 0.11362967884050783, \"time-step\": 2009}, {\"errors\": 0.11360861324087573, \"time-step\": 2010}, {\"errors\": 0.11358752051534923, \"time-step\": 2011}, {\"errors\": 0.11356640068969324, \"time-step\": 2012}, {\"errors\": 0.113545253789967, \"time-step\": 2013}, {\"errors\": 0.11352407984252409, \"time-step\": 2014}, {\"errors\": 0.11350287887401278, \"time-step\": 2015}, {\"errors\": 0.11348165091137594, \"time-step\": 2016}, {\"errors\": 0.11346039598185134, \"time-step\": 2017}, {\"errors\": 0.1134391141129715, \"time-step\": 2018}, {\"errors\": 0.1134178053325641, \"time-step\": 2019}, {\"errors\": 0.11339646966875169, \"time-step\": 2020}, {\"errors\": 0.11337510714995205, \"time-step\": 2021}, {\"errors\": 0.11335371780487812, \"time-step\": 2022}, {\"errors\": 0.11333230166253803, \"time-step\": 2023}, {\"errors\": 0.11331085875223526, \"time-step\": 2024}, {\"errors\": 0.11328938910356838, \"time-step\": 2025}, {\"errors\": 0.11326789274643147, \"time-step\": 2026}, {\"errors\": 0.11324636971101378, \"time-step\": 2027}, {\"errors\": 0.11322482002779996, \"time-step\": 2028}, {\"errors\": 0.11320324372756978, \"time-step\": 2029}, {\"errors\": 0.11318164084139841, \"time-step\": 2030}, {\"errors\": 0.11316001140065618, \"time-step\": 2031}, {\"errors\": 0.11313835543700859, \"time-step\": 2032}, {\"errors\": 0.1131166729824162, \"time-step\": 2033}, {\"errors\": 0.11309496406913466, \"time-step\": 2034}, {\"errors\": 0.11307322872971465, \"time-step\": 2035}, {\"errors\": 0.11305146699700153, \"time-step\": 2036}, {\"errors\": 0.11302967890413557, \"time-step\": 2037}, {\"errors\": 0.11300786448455169, \"time-step\": 2038}, {\"errors\": 0.11298602377197928, \"time-step\": 2039}, {\"errors\": 0.11296415680044206, \"time-step\": 2040}, {\"errors\": 0.11294226360425824, \"time-step\": 2041}, {\"errors\": 0.11292034421803986, \"time-step\": 2042}, {\"errors\": 0.11289839867669305, \"time-step\": 2043}, {\"errors\": 0.11287642701541771, \"time-step\": 2044}, {\"errors\": 0.11285442926970712, \"time-step\": 2045}, {\"errors\": 0.11283240547534819, \"time-step\": 2046}, {\"errors\": 0.11281035566842072, \"time-step\": 2047}, {\"errors\": 0.1127882798852976, \"time-step\": 2048}, {\"errors\": 0.11276617816264443, \"time-step\": 2049}, {\"errors\": 0.11274405053741918, \"time-step\": 2050}, {\"errors\": 0.11272189704687208, \"time-step\": 2051}, {\"errors\": 0.11269971772854526, \"time-step\": 2052}, {\"errors\": 0.11267751262027262, \"time-step\": 2053}, {\"errors\": 0.11265528176017922, \"time-step\": 2054}, {\"errors\": 0.11263302518668139, \"time-step\": 2055}, {\"errors\": 0.11261074293848615, \"time-step\": 2056}, {\"errors\": 0.11258843505459093, \"time-step\": 2057}, {\"errors\": 0.11256610157428329, \"time-step\": 2058}, {\"errors\": 0.11254374253714063, \"time-step\": 2059}, {\"errors\": 0.11252135798302966, \"time-step\": 2060}, {\"errors\": 0.11249894795210613, \"time-step\": 2061}, {\"errors\": 0.11247651248481452, \"time-step\": 2062}, {\"errors\": 0.11245405162188754, \"time-step\": 2063}, {\"errors\": 0.11243156540434575, \"time-step\": 2064}, {\"errors\": 0.11240905387349728, \"time-step\": 2065}, {\"errors\": 0.11238651707093718, \"time-step\": 2066}, {\"errors\": 0.11236395503854715, \"time-step\": 2067}, {\"errors\": 0.11234136781849513, \"time-step\": 2068}, {\"errors\": 0.11231875545323455, \"time-step\": 2069}, {\"errors\": 0.11229611798550435, \"time-step\": 2070}, {\"errors\": 0.1122734554583279, \"time-step\": 2071}, {\"errors\": 0.11225076791501315, \"time-step\": 2072}, {\"errors\": 0.11222805539915164, \"time-step\": 2073}, {\"errors\": 0.1122053179546181, \"time-step\": 2074}, {\"errors\": 0.11218255562557017, \"time-step\": 2075}, {\"errors\": 0.11215976845644748, \"time-step\": 2076}, {\"errors\": 0.11213695649197143, \"time-step\": 2077}, {\"errors\": 0.11211411977714439, \"time-step\": 2078}, {\"errors\": 0.11209125835724928, \"time-step\": 2079}, {\"errors\": 0.11206837227784894, \"time-step\": 2080}, {\"errors\": 0.11204546158478558, \"time-step\": 2081}, {\"errors\": 0.11202252632417997, \"time-step\": 2082}, {\"errors\": 0.11199956654243115, \"time-step\": 2083}, {\"errors\": 0.11197658228621557, \"time-step\": 2084}, {\"errors\": 0.11195357360248653, \"time-step\": 2085}, {\"errors\": 0.11193054053847346, \"time-step\": 2086}, {\"errors\": 0.11190748314168139, \"time-step\": 2087}, {\"errors\": 0.11188440145989013, \"time-step\": 2088}, {\"errors\": 0.11186129554115368, \"time-step\": 2089}, {\"errors\": 0.11183816543379949, \"time-step\": 2090}, {\"errors\": 0.11181501118642774, \"time-step\": 2091}, {\"errors\": 0.11179183284791078, \"time-step\": 2092}, {\"errors\": 0.11176863046739208, \"time-step\": 2093}, {\"errors\": 0.11174540409428571, \"time-step\": 2094}, {\"errors\": 0.11172215377827577, \"time-step\": 2095}, {\"errors\": 0.11169887956931507, \"time-step\": 2096}, {\"errors\": 0.11167558151762494, \"time-step\": 2097}, {\"errors\": 0.11165225967369408, \"time-step\": 2098}, {\"errors\": 0.11162891408827792, \"time-step\": 2099}, {\"errors\": 0.1116055448123977, \"time-step\": 2100}, {\"errors\": 0.11158215189733978, \"time-step\": 2101}, {\"errors\": 0.11155873539465468, \"time-step\": 2102}, {\"errors\": 0.11153529535615639, \"time-step\": 2103}, {\"errors\": 0.11151183183392133, \"time-step\": 2104}, {\"errors\": 0.11148834488028767, \"time-step\": 2105}, {\"errors\": 0.11146483454785416, \"time-step\": 2106}, {\"errors\": 0.11144130088947973, \"time-step\": 2107}, {\"errors\": 0.11141774395828213, \"time-step\": 2108}, {\"errors\": 0.11139416380763714, \"time-step\": 2109}, {\"errors\": 0.11137056049117791, \"time-step\": 2110}, {\"errors\": 0.11134693406279353, \"time-step\": 2111}, {\"errors\": 0.11132328457662867, \"time-step\": 2112}, {\"errors\": 0.11129961208708217, \"time-step\": 2113}, {\"errors\": 0.1112759166488062, \"time-step\": 2114}, {\"errors\": 0.1112521983167055, \"time-step\": 2115}, {\"errors\": 0.11122845714593604, \"time-step\": 2116}, {\"errors\": 0.11120469319190426, \"time-step\": 2117}, {\"errors\": 0.11118090651026602, \"time-step\": 2118}, {\"errors\": 0.1111570971569256, \"time-step\": 2119}, {\"errors\": 0.11113326518803446, \"time-step\": 2120}, {\"errors\": 0.11110941065999058, \"time-step\": 2121}, {\"errors\": 0.11108553362943707, \"time-step\": 2122}, {\"errors\": 0.11106163415326126, \"time-step\": 2123}, {\"errors\": 0.11103771228859366, \"time-step\": 2124}, {\"errors\": 0.11101376809280673, \"time-step\": 2125}, {\"errors\": 0.11098980162351396, \"time-step\": 2126}, {\"errors\": 0.11096581293856858, \"time-step\": 2127}, {\"errors\": 0.11094180209606276, \"time-step\": 2128}, {\"errors\": 0.11091776915432602, \"time-step\": 2129}, {\"errors\": 0.11089371417192445, \"time-step\": 2130}, {\"errors\": 0.11086963720765958, \"time-step\": 2131}, {\"errors\": 0.11084553832056696, \"time-step\": 2132}, {\"errors\": 0.11082141756991515, \"time-step\": 2133}, {\"errors\": 0.11079727501520463, \"time-step\": 2134}, {\"errors\": 0.11077311071616648, \"time-step\": 2135}, {\"errors\": 0.11074892473276116, \"time-step\": 2136}, {\"errors\": 0.11072471712517742, \"time-step\": 2137}, {\"errors\": 0.11070048795383111, \"time-step\": 2138}, {\"errors\": 0.11067623727936372, \"time-step\": 2139}, {\"errors\": 0.11065196516264136, \"time-step\": 2140}, {\"errors\": 0.1106276716647536, \"time-step\": 2141}, {\"errors\": 0.11060335684701178, \"time-step\": 2142}, {\"errors\": 0.11057902077094822, \"time-step\": 2143}, {\"errors\": 0.11055466349831478, \"time-step\": 2144}, {\"errors\": 0.11053028509108145, \"time-step\": 2145}, {\"errors\": 0.11050588561143516, \"time-step\": 2146}, {\"errors\": 0.11048146512177853, \"time-step\": 2147}, {\"errors\": 0.1104570236847285, \"time-step\": 2148}, {\"errors\": 0.11043256136311494, \"time-step\": 2149}, {\"errors\": 0.11040807821997944, \"time-step\": 2150}, {\"errors\": 0.1103835743185739, \"time-step\": 2151}, {\"errors\": 0.11035904972235916, \"time-step\": 2152}, {\"errors\": 0.11033450449500369, \"time-step\": 2153}, {\"errors\": 0.11030993870038217, \"time-step\": 2154}, {\"errors\": 0.11028535240257423, \"time-step\": 2155}, {\"errors\": 0.11026074566586286, \"time-step\": 2156}, {\"errors\": 0.11023611855473321, \"time-step\": 2157}, {\"errors\": 0.11021147113387106, \"time-step\": 2158}, {\"errors\": 0.11018680346816144, \"time-step\": 2159}, {\"errors\": 0.11016211562268727, \"time-step\": 2160}, {\"errors\": 0.11013740766272778, \"time-step\": 2161}, {\"errors\": 0.11011267965375729, \"time-step\": 2162}, {\"errors\": 0.11008793166144355, \"time-step\": 2163}, {\"errors\": 0.11006316375164633, \"time-step\": 2164}, {\"errors\": 0.1100383759904161, \"time-step\": 2165}, {\"errors\": 0.11001356844399235, \"time-step\": 2166}, {\"errors\": 0.10998874117880224, \"time-step\": 2167}, {\"errors\": 0.10996389426145911, \"time-step\": 2168}, {\"errors\": 0.10993902775876083, \"time-step\": 2169}, {\"errors\": 0.10991414173768858, \"time-step\": 2170}, {\"errors\": 0.10988923626540502, \"time-step\": 2171}, {\"errors\": 0.10986431140925298, \"time-step\": 2172}, {\"errors\": 0.10983936723675379, \"time-step\": 2173}, {\"errors\": 0.1098144038156059, \"time-step\": 2174}, {\"errors\": 0.1097894212136832, \"time-step\": 2175}, {\"errors\": 0.10976441949903347, \"time-step\": 2176}, {\"errors\": 0.1097393987398769, \"time-step\": 2177}, {\"errors\": 0.10971435900460452, \"time-step\": 2178}, {\"errors\": 0.10968930036177649, \"time-step\": 2179}, {\"errors\": 0.10966422288012068, \"time-step\": 2180}, {\"errors\": 0.10963912662853095, \"time-step\": 2181}, {\"errors\": 0.10961401167606556, \"time-step\": 2182}, {\"errors\": 0.10958887809194584, \"time-step\": 2183}, {\"errors\": 0.10956372594555405, \"time-step\": 2184}, {\"errors\": 0.10953855530643229, \"time-step\": 2185}, {\"errors\": 0.10951336624428053, \"time-step\": 2186}, {\"errors\": 0.10948815882895507, \"time-step\": 2187}, {\"errors\": 0.10946293313046701, \"time-step\": 2188}, {\"errors\": 0.10943768921898037, \"time-step\": 2189}, {\"errors\": 0.10941242716481073, \"time-step\": 2190}, {\"errors\": 0.10938714703842337, \"time-step\": 2191}, {\"errors\": 0.10936184891043157, \"time-step\": 2192}, {\"errors\": 0.10933653285159513, \"time-step\": 2193}, {\"errors\": 0.10931119893281846, \"time-step\": 2194}, {\"errors\": 0.10928584722514913, \"time-step\": 2195}, {\"errors\": 0.1092604777997759, \"time-step\": 2196}, {\"errors\": 0.10923509072802745, \"time-step\": 2197}, {\"errors\": 0.10920968608137016, \"time-step\": 2198}, {\"errors\": 0.10918426393140672, \"time-step\": 2199}, {\"errors\": 0.10915882434987444, \"time-step\": 2200}, {\"errors\": 0.10913336740864321, \"time-step\": 2201}, {\"errors\": 0.10910789317971427, \"time-step\": 2202}, {\"errors\": 0.10908240173521805, \"time-step\": 2203}, {\"errors\": 0.10905689314741258, \"time-step\": 2204}, {\"errors\": 0.10903136748868186, \"time-step\": 2205}, {\"errors\": 0.10900582483153387, \"time-step\": 2206}, {\"errors\": 0.10898026524859904, \"time-step\": 2207}, {\"errors\": 0.10895468881262842, \"time-step\": 2208}, {\"errors\": 0.10892909559649183, \"time-step\": 2209}, {\"errors\": 0.10890348567317626, \"time-step\": 2210}, {\"errors\": 0.1088778591157839, \"time-step\": 2211}, {\"errors\": 0.1088522159975305, \"time-step\": 2212}, {\"errors\": 0.10882655639174357, \"time-step\": 2213}, {\"errors\": 0.10880088037186056, \"time-step\": 2214}, {\"errors\": 0.10877518801142716, \"time-step\": 2215}, {\"errors\": 0.10874947938409525, \"time-step\": 2216}, {\"errors\": 0.1087237545636214, \"time-step\": 2217}, {\"errors\": 0.10869801362386494, \"time-step\": 2218}, {\"errors\": 0.10867225663878613, \"time-step\": 2219}, {\"errors\": 0.1086464836824444, \"time-step\": 2220}, {\"errors\": 0.10862069482899644, \"time-step\": 2221}, {\"errors\": 0.10859489015269448, \"time-step\": 2222}, {\"errors\": 0.10856906972788442, \"time-step\": 2223}, {\"errors\": 0.10854323362900407, \"time-step\": 2224}, {\"errors\": 0.10851738193058116, \"time-step\": 2225}, {\"errors\": 0.1084915147072317, \"time-step\": 2226}, {\"errors\": 0.108465632033658, \"time-step\": 2227}, {\"errors\": 0.10843973398464686, \"time-step\": 2228}, {\"errors\": 0.1084138206350678, \"time-step\": 2229}, {\"errors\": 0.1083878920598711, \"time-step\": 2230}, {\"errors\": 0.108361948334086, \"time-step\": 2231}, {\"errors\": 0.10833598953281887, \"time-step\": 2232}, {\"errors\": 0.10831001573125137, \"time-step\": 2233}, {\"errors\": 0.10828402700463848, \"time-step\": 2234}, {\"errors\": 0.10825802342830679, \"time-step\": 2235}, {\"errors\": 0.10823200507765246, \"time-step\": 2236}, {\"errors\": 0.10820597202813952, \"time-step\": 2237}, {\"errors\": 0.10817992435529791, \"time-step\": 2238}, {\"errors\": 0.10815386213472164, \"time-step\": 2239}, {\"errors\": 0.10812778544206689, \"time-step\": 2240}, {\"errors\": 0.10810169435305009, \"time-step\": 2241}, {\"errors\": 0.1080755889434462, \"time-step\": 2242}, {\"errors\": 0.10804946928908671, \"time-step\": 2243}, {\"errors\": 0.10802333546585774, \"time-step\": 2244}, {\"errors\": 0.1079971875496982, \"time-step\": 2245}, {\"errors\": 0.10797102561659787, \"time-step\": 2246}, {\"errors\": 0.10794484974259562, \"time-step\": 2247}, {\"errors\": 0.1079186600037774, \"time-step\": 2248}, {\"errors\": 0.10789245647627435, \"time-step\": 2249}, {\"errors\": 0.10786623923626104, \"time-step\": 2250}, {\"errors\": 0.10784000835995343, \"time-step\": 2251}, {\"errors\": 0.10781376392360704, \"time-step\": 2252}, {\"errors\": 0.10778750600351514, \"time-step\": 2253}, {\"errors\": 0.1077612346760066, \"time-step\": 2254}, {\"errors\": 0.10773495001744433, \"time-step\": 2255}, {\"errors\": 0.10770865210422303, \"time-step\": 2256}, {\"errors\": 0.10768234101276768, \"time-step\": 2257}, {\"errors\": 0.10765601681953131, \"time-step\": 2258}, {\"errors\": 0.10762967960099329, \"time-step\": 2259}, {\"errors\": 0.10760332943365736, \"time-step\": 2260}, {\"errors\": 0.10757696639404965, \"time-step\": 2261}, {\"errors\": 0.10755059055871703, \"time-step\": 2262}, {\"errors\": 0.107524202004225, \"time-step\": 2263}, {\"errors\": 0.10749780080715576, \"time-step\": 2264}, {\"errors\": 0.10747138704410646, \"time-step\": 2265}, {\"errors\": 0.10744496079168733, \"time-step\": 2266}, {\"errors\": 0.10741852212651944, \"time-step\": 2267}, {\"errors\": 0.10739207112523337, \"time-step\": 2268}, {\"errors\": 0.1073656078644667, \"time-step\": 2269}, {\"errors\": 0.1073391324208626, \"time-step\": 2270}, {\"errors\": 0.10731264487106759, \"time-step\": 2271}, {\"errors\": 0.10728614529173001, \"time-step\": 2272}, {\"errors\": 0.10725963375949765, \"time-step\": 2273}, {\"errors\": 0.10723311035101621, \"time-step\": 2274}, {\"errors\": 0.10720657514292739, \"time-step\": 2275}, {\"errors\": 0.10718002821186678, \"time-step\": 2276}, {\"errors\": 0.10715346963446222, \"time-step\": 2277}, {\"errors\": 0.1071268994873317, \"time-step\": 2278}, {\"errors\": 0.10710031784708168, \"time-step\": 2279}, {\"errors\": 0.10707372479030487, \"time-step\": 2280}, {\"errors\": 0.10704712039357886, \"time-step\": 2281}, {\"errors\": 0.10702050473346364, \"time-step\": 2282}, {\"errors\": 0.10699387788650021, \"time-step\": 2283}, {\"errors\": 0.10696723992920851, \"time-step\": 2284}, {\"errors\": 0.10694059093808536, \"time-step\": 2285}, {\"errors\": 0.10691393098960295, \"time-step\": 2286}, {\"errors\": 0.10688726016020662, \"time-step\": 2287}, {\"errors\": 0.10686057852631327, \"time-step\": 2288}, {\"errors\": 0.10683388616430922, \"time-step\": 2289}, {\"errors\": 0.10680718315054863, \"time-step\": 2290}, {\"errors\": 0.10678046956135132, \"time-step\": 2291}, {\"errors\": 0.10675374547300118, \"time-step\": 2292}, {\"errors\": 0.10672701096174422, \"time-step\": 2293}, {\"errors\": 0.10670026610378655, \"time-step\": 2294}, {\"errors\": 0.10667351097529282, \"time-step\": 2295}, {\"errors\": 0.10664674565238408, \"time-step\": 2296}, {\"errors\": 0.10661997021113613, \"time-step\": 2297}, {\"errors\": 0.10659318472757759, \"time-step\": 2298}, {\"errors\": 0.10656638927768804, \"time-step\": 2299}, {\"errors\": 0.10653958393739621, \"time-step\": 2300}, {\"errors\": 0.10651276878257815, \"time-step\": 2301}, {\"errors\": 0.10648594388905541, \"time-step\": 2302}, {\"errors\": 0.10645910933259306, \"time-step\": 2303}, {\"errors\": 0.10643226518889812, \"time-step\": 2304}, {\"errors\": 0.10640541153361743, \"time-step\": 2305}, {\"errors\": 0.10637854844233618, \"time-step\": 2306}, {\"errors\": 0.10635167599057582, \"time-step\": 2307}, {\"errors\": 0.10632479425379227, \"time-step\": 2308}, {\"errors\": 0.10629790330737418, \"time-step\": 2309}, {\"errors\": 0.10627100322664124, \"time-step\": 2310}, {\"errors\": 0.10624409408684204, \"time-step\": 2311}, {\"errors\": 0.10621717596315267, \"time-step\": 2312}, {\"errors\": 0.10619024893067461, \"time-step\": 2313}, {\"errors\": 0.10616331306443308, \"time-step\": 2314}, {\"errors\": 0.10613636843937535, \"time-step\": 2315}, {\"errors\": 0.10610941513036862, \"time-step\": 2316}, {\"errors\": 0.1060824532121987, \"time-step\": 2317}, {\"errors\": 0.1060554827595678, \"time-step\": 2318}, {\"errors\": 0.10602850384709311, \"time-step\": 2319}, {\"errors\": 0.10600151654930479, \"time-step\": 2320}, {\"errors\": 0.10597452094064434, \"time-step\": 2321}, {\"errors\": 0.10594751709546285, \"time-step\": 2322}, {\"errors\": 0.10592050508801912, \"time-step\": 2323}, {\"errors\": 0.10589348499247814, \"time-step\": 2324}, {\"errors\": 0.105866456882909, \"time-step\": 2325}, {\"errors\": 0.10583942083328357, \"time-step\": 2326}, {\"errors\": 0.10581237691747444, \"time-step\": 2327}, {\"errors\": 0.10578532520925346, \"time-step\": 2328}, {\"errors\": 0.10575826578228961, \"time-step\": 2329}, {\"errors\": 0.10573119871014786, \"time-step\": 2330}, {\"errors\": 0.1057041240662869, \"time-step\": 2331}, {\"errors\": 0.10567704192405789, \"time-step\": 2332}, {\"errors\": 0.10564995235670235, \"time-step\": 2333}, {\"errors\": 0.1056228554373509, \"time-step\": 2334}, {\"errors\": 0.10559575123902105, \"time-step\": 2335}, {\"errors\": 0.10556863983461615, \"time-step\": 2336}, {\"errors\": 0.10554152129692315, \"time-step\": 2337}, {\"errors\": 0.1055143956986111, \"time-step\": 2338}, {\"errors\": 0.1054872631122297, \"time-step\": 2339}, {\"errors\": 0.10546012361020736, \"time-step\": 2340}, {\"errors\": 0.10543297726484974, \"time-step\": 2341}, {\"errors\": 0.1054058241483379, \"time-step\": 2342}, {\"errors\": 0.10537866433272688, \"time-step\": 2343}, {\"errors\": 0.1053514978899439, \"time-step\": 2344}, {\"errors\": 0.10532432489178686, \"time-step\": 2345}, {\"errors\": 0.10529714540992244, \"time-step\": 2346}, {\"errors\": 0.105269959515885, \"time-step\": 2347}, {\"errors\": 0.10524276728107437, \"time-step\": 2348}, {\"errors\": 0.10521556877675467, \"time-step\": 2349}, {\"errors\": 0.10518836407405258, \"time-step\": 2350}, {\"errors\": 0.1051611532439555, \"time-step\": 2351}, {\"errors\": 0.10513393635731061, \"time-step\": 2352}, {\"errors\": 0.10510671348482245, \"time-step\": 2353}, {\"errors\": 0.10507948469705206, \"time-step\": 2354}, {\"errors\": 0.10505225006441499, \"time-step\": 2355}, {\"errors\": 0.1050250096571799, \"time-step\": 2356}, {\"errors\": 0.10499776354546697, \"time-step\": 2357}, {\"errors\": 0.10497051179924642, \"time-step\": 2358}, {\"errors\": 0.10494325448833686, \"time-step\": 2359}, {\"errors\": 0.10491599168240379, \"time-step\": 2360}, {\"errors\": 0.10488872345095802, \"time-step\": 2361}, {\"errors\": 0.10486144986335452, \"time-step\": 2362}, {\"errors\": 0.10483417098879022, \"time-step\": 2363}, {\"errors\": 0.10480688689630316, \"time-step\": 2364}, {\"errors\": 0.10477959765477053, \"time-step\": 2365}, {\"errors\": 0.10475230333290764, \"time-step\": 2366}, {\"errors\": 0.1047250039992659, \"time-step\": 2367}, {\"errors\": 0.10469769972223171, \"time-step\": 2368}, {\"errors\": 0.10467039057002489, \"time-step\": 2369}, {\"errors\": 0.10464307661069719, \"time-step\": 2370}, {\"errors\": 0.10461575791213093, \"time-step\": 2371}, {\"errors\": 0.10458843454203742, \"time-step\": 2372}, {\"errors\": 0.1045611065679555, \"time-step\": 2373}, {\"errors\": 0.10453377405725037, \"time-step\": 2374}, {\"errors\": 0.10450643707711185, \"time-step\": 2375}, {\"errors\": 0.10447909569455309, \"time-step\": 2376}, {\"errors\": 0.10445174997640923, \"time-step\": 2377}, {\"errors\": 0.1044243999893358, \"time-step\": 2378}, {\"errors\": 0.10439704579980758, \"time-step\": 2379}, {\"errors\": 0.10436968747411701, \"time-step\": 2380}, {\"errors\": 0.1043423250783729, \"time-step\": 2381}, {\"errors\": 0.10431495867849902, \"time-step\": 2382}, {\"errors\": 0.10428758834023269, \"time-step\": 2383}, {\"errors\": 0.10426021412912356, \"time-step\": 2384}, {\"errors\": 0.10423283611053213, \"time-step\": 2385}, {\"errors\": 0.10420545434962852, \"time-step\": 2386}, {\"errors\": 0.10417806891139095, \"time-step\": 2387}, {\"errors\": 0.10415067986060467, \"time-step\": 2388}, {\"errors\": 0.10412328726186035, \"time-step\": 2389}, {\"errors\": 0.10409589117955308, \"time-step\": 2390}, {\"errors\": 0.10406849167788079, \"time-step\": 2391}, {\"errors\": 0.10404108882084306, \"time-step\": 2392}, {\"errors\": 0.10401368267223998, \"time-step\": 2393}, {\"errors\": 0.1039862732956706, \"time-step\": 2394}, {\"errors\": 0.10395886075453178, \"time-step\": 2395}, {\"errors\": 0.10393144511201707, \"time-step\": 2396}, {\"errors\": 0.10390402643111514, \"time-step\": 2397}, {\"errors\": 0.10387660477460893, \"time-step\": 2398}, {\"errors\": 0.1038491802050739, \"time-step\": 2399}, {\"errors\": 0.1038217527848774, \"time-step\": 2400}, {\"errors\": 0.10379432257617698, \"time-step\": 2401}, {\"errors\": 0.10376688964091925, \"time-step\": 2402}, {\"errors\": 0.10373945404083887, \"time-step\": 2403}, {\"errors\": 0.10371201583745726, \"time-step\": 2404}, {\"errors\": 0.10368457509208134, \"time-step\": 2405}, {\"errors\": 0.1036571318658023, \"time-step\": 2406}, {\"errors\": 0.10362968621949466, \"time-step\": 2407}, {\"errors\": 0.10360223821381483, \"time-step\": 2408}, {\"errors\": 0.10357478790920013, \"time-step\": 2409}, {\"errors\": 0.10354733536586765, \"time-step\": 2410}, {\"errors\": 0.10351988064381296, \"time-step\": 2411}, {\"errors\": 0.10349242380280907, \"time-step\": 2412}, {\"errors\": 0.10346496490240539, \"time-step\": 2413}, {\"errors\": 0.1034375040019263, \"time-step\": 2414}, {\"errors\": 0.10341004116047053, \"time-step\": 2415}, {\"errors\": 0.10338257643690961, \"time-step\": 2416}, {\"errors\": 0.10335510988988705, \"time-step\": 2417}, {\"errors\": 0.10332764157781701, \"time-step\": 2418}, {\"errors\": 0.1033001715588836, \"time-step\": 2419}, {\"errors\": 0.10327269989103945, \"time-step\": 2420}, {\"errors\": 0.10324522663200483, \"time-step\": 2421}, {\"errors\": 0.10321775183926649, \"time-step\": 2422}, {\"errors\": 0.10319027557007679, \"time-step\": 2423}, {\"errors\": 0.10316279788145244, \"time-step\": 2424}, {\"errors\": 0.10313531883017381, \"time-step\": 2425}, {\"errors\": 0.1031078384727834, \"time-step\": 2426}, {\"errors\": 0.10308035686558538, \"time-step\": 2427}, {\"errors\": 0.10305287406464418, \"time-step\": 2428}, {\"errors\": 0.1030253901257838, \"time-step\": 2429}, {\"errors\": 0.10299790510458655, \"time-step\": 2430}, {\"errors\": 0.10297041905639227, \"time-step\": 2431}, {\"errors\": 0.10294293203629726, \"time-step\": 2432}, {\"errors\": 0.10291544409915342, \"time-step\": 2433}, {\"errors\": 0.10288795529956724, \"time-step\": 2434}, {\"errors\": 0.10286046569189874, \"time-step\": 2435}, {\"errors\": 0.10283297533026076, \"time-step\": 2436}, {\"errors\": 0.10280548426851788, \"time-step\": 2437}, {\"errors\": 0.10277799256028565, \"time-step\": 2438}, {\"errors\": 0.10275050025892941, \"time-step\": 2439}, {\"errors\": 0.1027230074175637, \"time-step\": 2440}, {\"errors\": 0.10269551408905114, \"time-step\": 2441}, {\"errors\": 0.1026680203260017, \"time-step\": 2442}, {\"errors\": 0.10264052618077169, \"time-step\": 2443}, {\"errors\": 0.10261303170546299, \"time-step\": 2444}, {\"errors\": 0.10258553695192224, \"time-step\": 2445}, {\"errors\": 0.10255804197173973, \"time-step\": 2446}, {\"errors\": 0.10253054681624882, \"time-step\": 2447}, {\"errors\": 0.10250305153652522, \"time-step\": 2448}, {\"errors\": 0.10247555618338558, \"time-step\": 2449}, {\"errors\": 0.10244806080738741, \"time-step\": 2450}, {\"errors\": 0.10242056545882766, \"time-step\": 2451}, {\"errors\": 0.1023930701877424, \"time-step\": 2452}, {\"errors\": 0.10236557504390559, \"time-step\": 2453}, {\"errors\": 0.1023380800768287, \"time-step\": 2454}, {\"errors\": 0.10231058533575961, \"time-step\": 2455}, {\"errors\": 0.10228309086968201, \"time-step\": 2456}, {\"errors\": 0.10225559672731466, \"time-step\": 2457}, {\"errors\": 0.10222810295711049, \"time-step\": 2458}, {\"errors\": 0.102200609607256, \"time-step\": 2459}, {\"errors\": 0.10217311672567043, \"time-step\": 2460}, {\"errors\": 0.1021456243600052, \"time-step\": 2461}, {\"errors\": 0.10211813255764282, \"time-step\": 2462}, {\"errors\": 0.10209064136569672, \"time-step\": 2463}, {\"errors\": 0.10206315083100997, \"time-step\": 2464}, {\"errors\": 0.10203566100015506, \"time-step\": 2465}, {\"errors\": 0.10200817191943296, \"time-step\": 2466}, {\"errors\": 0.10198068363487234, \"time-step\": 2467}, {\"errors\": 0.1019531961922293, \"time-step\": 2468}, {\"errors\": 0.10192570963698636, \"time-step\": 2469}, {\"errors\": 0.10189822401435182, \"time-step\": 2470}, {\"errors\": 0.10187073936925932, \"time-step\": 2471}, {\"errors\": 0.10184325574636696, \"time-step\": 2472}, {\"errors\": 0.10181577319005694, \"time-step\": 2473}, {\"errors\": 0.1017882917444346, \"time-step\": 2474}, {\"errors\": 0.10176081145332812, \"time-step\": 2475}, {\"errors\": 0.1017333323602877, \"time-step\": 2476}, {\"errors\": 0.10170585450858502, \"time-step\": 2477}, {\"errors\": 0.10167837794121276, \"time-step\": 2478}, {\"errors\": 0.10165090270088384, \"time-step\": 2479}, {\"errors\": 0.10162342883003089, \"time-step\": 2480}, {\"errors\": 0.10159595637080583, \"time-step\": 2481}, {\"errors\": 0.10156848536507912, \"time-step\": 2482}, {\"errors\": 0.10154101585443913, \"time-step\": 2483}, {\"errors\": 0.10151354788019198, \"time-step\": 2484}, {\"errors\": 0.10148608148336066, \"time-step\": 2485}, {\"errors\": 0.10145861670468462, \"time-step\": 2486}, {\"errors\": 0.10143115358461902, \"time-step\": 2487}, {\"errors\": 0.10140369216333475, \"time-step\": 2488}, {\"errors\": 0.10137623248071735, \"time-step\": 2489}, {\"errors\": 0.10134877457636682, \"time-step\": 2490}, {\"errors\": 0.10132131848959709, \"time-step\": 2491}, {\"errors\": 0.10129386425943544, \"time-step\": 2492}, {\"errors\": 0.10126641192462203, \"time-step\": 2493}, {\"errors\": 0.10123896152360971, \"time-step\": 2494}, {\"errors\": 0.10121151309456292, \"time-step\": 2495}, {\"errors\": 0.10118406667535798, \"time-step\": 2496}, {\"errors\": 0.10115662230358227, \"time-step\": 2497}, {\"errors\": 0.10112918001653358, \"time-step\": 2498}, {\"errors\": 0.10110173985122006, \"time-step\": 2499}, {\"errors\": 0.10107430184435964, \"time-step\": 2500}, {\"errors\": 0.10104686603237965, \"time-step\": 2501}, {\"errors\": 0.10101943245141631, \"time-step\": 2502}, {\"errors\": 0.10099200113731421, \"time-step\": 2503}, {\"errors\": 0.10096457212562643, \"time-step\": 2504}, {\"errors\": 0.10093714545161352, \"time-step\": 2505}, {\"errors\": 0.10090972115024349, \"time-step\": 2506}, {\"errors\": 0.10088229925619133, \"time-step\": 2507}, {\"errors\": 0.10085487980383864, \"time-step\": 2508}, {\"errors\": 0.10082746282727323, \"time-step\": 2509}, {\"errors\": 0.10080004836028886, \"time-step\": 2510}, {\"errors\": 0.10077263643638473, \"time-step\": 2511}, {\"errors\": 0.10074522708876538, \"time-step\": 2512}, {\"errors\": 0.10071782035034006, \"time-step\": 2513}, {\"errors\": 0.1006904162537227, \"time-step\": 2514}, {\"errors\": 0.10066301483123116, \"time-step\": 2515}, {\"errors\": 0.10063561611488758, \"time-step\": 2516}, {\"errors\": 0.10060822013641726, \"time-step\": 2517}, {\"errors\": 0.10058082692724912, \"time-step\": 2518}, {\"errors\": 0.10055343651851484, \"time-step\": 2519}, {\"errors\": 0.10052604894104882, \"time-step\": 2520}, {\"errors\": 0.10049866422538796, \"time-step\": 2521}, {\"errors\": 0.10047128240177115, \"time-step\": 2522}, {\"errors\": 0.10044390350013926, \"time-step\": 2523}, {\"errors\": 0.10041652755013458, \"time-step\": 2524}, {\"errors\": 0.10038915458110094, \"time-step\": 2525}, {\"errors\": 0.10036178462208298, \"time-step\": 2526}, {\"errors\": 0.10033441770182638, \"time-step\": 2527}, {\"errors\": 0.10030705384877746, \"time-step\": 2528}, {\"errors\": 0.10027969309108253, \"time-step\": 2529}, {\"errors\": 0.10025233545658851, \"time-step\": 2530}, {\"errors\": 0.10022498097284194, \"time-step\": 2531}, {\"errors\": 0.100197629667089, \"time-step\": 2532}, {\"errors\": 0.10017028156627567, \"time-step\": 2533}, {\"errors\": 0.10014293669704685, \"time-step\": 2534}, {\"errors\": 0.10011559508574669, \"time-step\": 2535}, {\"errors\": 0.10008825675841831, \"time-step\": 2536}, {\"errors\": 0.10006092174080344, \"time-step\": 2537}, {\"errors\": 0.1000335900583423, \"time-step\": 2538}, {\"errors\": 0.10000626173617364, \"time-step\": 2539}, {\"errors\": 0.09997893679913412, \"time-step\": 2540}, {\"errors\": 0.09995161527175878, \"time-step\": 2541}, {\"errors\": 0.09992429717828026, \"time-step\": 2542}, {\"errors\": 0.09989698254262902, \"time-step\": 2543}, {\"errors\": 0.09986967138843306, \"time-step\": 2544}, {\"errors\": 0.0998423637390179, \"time-step\": 2545}, {\"errors\": 0.0998150596174063, \"time-step\": 2546}, {\"errors\": 0.09978775904631823, \"time-step\": 2547}, {\"errors\": 0.09976046204817077, \"time-step\": 2548}, {\"errors\": 0.0997331686450777, \"time-step\": 2549}, {\"errors\": 0.09970587885884993, \"time-step\": 2550}, {\"errors\": 0.09967859271099505, \"time-step\": 2551}, {\"errors\": 0.09965131022271698, \"time-step\": 2552}, {\"errors\": 0.09962403141491652, \"time-step\": 2553}, {\"errors\": 0.09959675630819073, \"time-step\": 2554}, {\"errors\": 0.09956948492283302, \"time-step\": 2555}, {\"errors\": 0.09954221727883317, \"time-step\": 2556}, {\"errors\": 0.09951495339587707, \"time-step\": 2557}, {\"errors\": 0.09948769329334674, \"time-step\": 2558}, {\"errors\": 0.09946043699032027, \"time-step\": 2559}, {\"errors\": 0.09943318450557186, \"time-step\": 2560}, {\"errors\": 0.09940593585757149, \"time-step\": 2561}, {\"errors\": 0.09937869106448516, \"time-step\": 2562}, {\"errors\": 0.09935145014417465, \"time-step\": 2563}, {\"errors\": 0.09932421311419769, \"time-step\": 2564}, {\"errors\": 0.09929697999180762, \"time-step\": 2565}, {\"errors\": 0.09926975079395359, \"time-step\": 2566}, {\"errors\": 0.09924252553728061, \"time-step\": 2567}, {\"errors\": 0.09921530423812913, \"time-step\": 2568}, {\"errors\": 0.09918808691253561, \"time-step\": 2569}, {\"errors\": 0.09916087357623188, \"time-step\": 2570}, {\"errors\": 0.09913366424464569, \"time-step\": 2571}, {\"errors\": 0.0991064589329003, \"time-step\": 2572}, {\"errors\": 0.09907925765581468, \"time-step\": 2573}, {\"errors\": 0.09905206042790352, \"time-step\": 2574}, {\"errors\": 0.09902486726337713, \"time-step\": 2575}, {\"errors\": 0.09899767817614166, \"time-step\": 2576}, {\"errors\": 0.09897049317979878, \"time-step\": 2577}, {\"errors\": 0.0989433122876461, \"time-step\": 2578}, {\"errors\": 0.09891613551267692, \"time-step\": 2579}, {\"errors\": 0.09888896286758032, \"time-step\": 2580}, {\"errors\": 0.09886179436474124, \"time-step\": 2581}, {\"errors\": 0.09883463001624056, \"time-step\": 2582}, {\"errors\": 0.09880746983385508, \"time-step\": 2583}, {\"errors\": 0.09878031382905751, \"time-step\": 2584}, {\"errors\": 0.09875316201301665, \"time-step\": 2585}, {\"errors\": 0.09872601439659737, \"time-step\": 2586}, {\"errors\": 0.09869887099036075, \"time-step\": 2587}, {\"errors\": 0.09867173180456393, \"time-step\": 2588}, {\"errors\": 0.09864459684916055, \"time-step\": 2589}, {\"errors\": 0.09861746613380042, \"time-step\": 2590}, {\"errors\": 0.09859033966782982, \"time-step\": 2591}, {\"errors\": 0.09856321746029167, \"time-step\": 2592}, {\"errors\": 0.09853609951992531, \"time-step\": 2593}, {\"errors\": 0.09850898585516688, \"time-step\": 2594}, {\"errors\": 0.09848187647414916, \"time-step\": 2595}, {\"errors\": 0.0984547713847019, \"time-step\": 2596}, {\"errors\": 0.09842767059435188, \"time-step\": 2597}, {\"errors\": 0.09840057411032277, \"time-step\": 2598}, {\"errors\": 0.09837348193953549, \"time-step\": 2599}, {\"errors\": 0.09834639408860828, \"time-step\": 2600}, {\"errors\": 0.09831931056385662, \"time-step\": 2601}, {\"errors\": 0.09829223137129375, \"time-step\": 2602}, {\"errors\": 0.09826515651663019, \"time-step\": 2603}, {\"errors\": 0.0982380860052745, \"time-step\": 2604}, {\"errors\": 0.09821101984233292, \"time-step\": 2605}, {\"errors\": 0.09818395803260974, \"time-step\": 2606}, {\"errors\": 0.09815690058060739, \"time-step\": 2607}, {\"errors\": 0.09812984749052647, \"time-step\": 2608}, {\"errors\": 0.09810279876626612, \"time-step\": 2609}, {\"errors\": 0.09807575441142383, \"time-step\": 2610}, {\"errors\": 0.0980487144292959, \"time-step\": 2611}, {\"errors\": 0.09802167882287727, \"time-step\": 2612}, {\"errors\": 0.09799464759486212, \"time-step\": 2613}, {\"errors\": 0.09796762074764351, \"time-step\": 2614}, {\"errors\": 0.0979405982833138, \"time-step\": 2615}, {\"errors\": 0.09791358020366489, \"time-step\": 2616}, {\"errors\": 0.09788656651018812, \"time-step\": 2617}, {\"errors\": 0.09785955720407463, \"time-step\": 2618}, {\"errors\": 0.09783255228621551, \"time-step\": 2619}, {\"errors\": 0.0978055517572019, \"time-step\": 2620}, {\"errors\": 0.09777855561732512, \"time-step\": 2621}, {\"errors\": 0.09775156386657699, \"time-step\": 2622}, {\"errors\": 0.09772457650464983, \"time-step\": 2623}, {\"errors\": 0.09769759353093684, \"time-step\": 2624}, {\"errors\": 0.09767061494453204, \"time-step\": 2625}, {\"errors\": 0.09764364074423063, \"time-step\": 2626}, {\"errors\": 0.09761667092852915, \"time-step\": 2627}, {\"errors\": 0.0975897054956256, \"time-step\": 2628}, {\"errors\": 0.09756274444341959, \"time-step\": 2629}, {\"errors\": 0.09753578776951277, \"time-step\": 2630}, {\"errors\": 0.0975088354712087, \"time-step\": 2631}, {\"errors\": 0.09748188754551321, \"time-step\": 2632}, {\"errors\": 0.0974549439891347, \"time-step\": 2633}, {\"errors\": 0.09742800479848418, \"time-step\": 2634}, {\"errors\": 0.09740106996967532, \"time-step\": 2635}, {\"errors\": 0.09737413949852519, \"time-step\": 2636}, {\"errors\": 0.09734721338055383, \"time-step\": 2637}, {\"errors\": 0.09732029161098485, \"time-step\": 2638}, {\"errors\": 0.09729337418474557, \"time-step\": 2639}, {\"errors\": 0.09726646109646711, \"time-step\": 2640}, {\"errors\": 0.09723955234048476, \"time-step\": 2641}, {\"errors\": 0.09721264791083807, \"time-step\": 2642}, {\"errors\": 0.0971857478012711, \"time-step\": 2643}, {\"errors\": 0.09715885200523272, \"time-step\": 2644}, {\"errors\": 0.09713196051587661, \"time-step\": 2645}, {\"errors\": 0.0971050733260618, \"time-step\": 2646}, {\"errors\": 0.09707819042835267, \"time-step\": 2647}, {\"errors\": 0.09705131181501911, \"time-step\": 2648}, {\"errors\": 0.09702443747803695, \"time-step\": 2649}, {\"errors\": 0.09699756740908805, \"time-step\": 2650}, {\"errors\": 0.0969707015995607, \"time-step\": 2651}, {\"errors\": 0.0969438400405494, \"time-step\": 2652}, {\"errors\": 0.0969169827228557, \"time-step\": 2653}, {\"errors\": 0.09689012963698805, \"time-step\": 2654}, {\"errors\": 0.09686328077316211, \"time-step\": 2655}, {\"errors\": 0.09683643612130091, \"time-step\": 2656}, {\"errors\": 0.09680959567103525, \"time-step\": 2657}, {\"errors\": 0.09678275941170385, \"time-step\": 2658}, {\"errors\": 0.09675592733235353, \"time-step\": 2659}, {\"errors\": 0.09672909942173952, \"time-step\": 2660}, {\"errors\": 0.09670227566832579, \"time-step\": 2661}, {\"errors\": 0.09667545606028499, \"time-step\": 2662}, {\"errors\": 0.09664864058549899, \"time-step\": 2663}, {\"errors\": 0.09662182923155901, \"time-step\": 2664}, {\"errors\": 0.09659502198576586, \"time-step\": 2665}, {\"errors\": 0.09656821883513018, \"time-step\": 2666}, {\"errors\": 0.09654141976637273, \"time-step\": 2667}, {\"errors\": 0.0965146247659245, \"time-step\": 2668}, {\"errors\": 0.09648783381992718, \"time-step\": 2669}, {\"errors\": 0.09646104691423316, \"time-step\": 2670}, {\"errors\": 0.09643426403440598, \"time-step\": 2671}, {\"errors\": 0.09640748516572042, \"time-step\": 2672}, {\"errors\": 0.09638071029316299, \"time-step\": 2673}, {\"errors\": 0.09635393940143175, \"time-step\": 2674}, {\"errors\": 0.09632717247493706, \"time-step\": 2675}, {\"errors\": 0.09630040949780137, \"time-step\": 2676}, {\"errors\": 0.09627365045386, \"time-step\": 2677}, {\"errors\": 0.0962468953266607, \"time-step\": 2678}, {\"errors\": 0.09622014409946454, \"time-step\": 2679}, {\"errors\": 0.09619339675524585, \"time-step\": 2680}, {\"errors\": 0.09616665327669251, \"time-step\": 2681}, {\"errors\": 0.09613991364620625, \"time-step\": 2682}, {\"errors\": 0.09611317784590281, \"time-step\": 2683}, {\"errors\": 0.09608644585761231, \"time-step\": 2684}, {\"errors\": 0.09605971766287932, \"time-step\": 2685}, {\"errors\": 0.09603299324296352, \"time-step\": 2686}, {\"errors\": 0.0960062725788394, \"time-step\": 2687}, {\"errors\": 0.0959795556511969, \"time-step\": 2688}, {\"errors\": 0.09595284244044153, \"time-step\": 2689}, {\"errors\": 0.09592613292669461, \"time-step\": 2690}, {\"errors\": 0.09589942708979364, \"time-step\": 2691}, {\"errors\": 0.09587272490929247, \"time-step\": 2692}, {\"errors\": 0.09584602636446135, \"time-step\": 2693}, {\"errors\": 0.09581933143428778, \"time-step\": 2694}, {\"errors\": 0.09579264009747598, \"time-step\": 2695}, {\"errors\": 0.09576595233244783, \"time-step\": 2696}, {\"errors\": 0.09573926811734257, \"time-step\": 2697}, {\"errors\": 0.09571258743001756, \"time-step\": 2698}, {\"errors\": 0.09568591024804814, \"time-step\": 2699}, {\"errors\": 0.09565923654872799, \"time-step\": 2700}, {\"errors\": 0.09563256630906963, \"time-step\": 2701}, {\"errors\": 0.0956058995058042, \"time-step\": 2702}, {\"errors\": 0.09557923611538216, \"time-step\": 2703}, {\"errors\": 0.0955525761139733, \"time-step\": 2704}, {\"errors\": 0.09552591947746703, \"time-step\": 2705}, {\"errors\": 0.09549926618147261, \"time-step\": 2706}, {\"errors\": 0.09547261620131967, \"time-step\": 2707}, {\"errors\": 0.09544596951205782, \"time-step\": 2708}, {\"errors\": 0.09541932608845774, \"time-step\": 2709}, {\"errors\": 0.09539268590501071, \"time-step\": 2710}, {\"errors\": 0.09536604893592922, \"time-step\": 2711}, {\"errors\": 0.09533941515514724, \"time-step\": 2712}, {\"errors\": 0.09531278453632022, \"time-step\": 2713}, {\"errors\": 0.09528615705282556, \"time-step\": 2714}, {\"errors\": 0.0952595326777629, \"time-step\": 2715}, {\"errors\": 0.09523291138395393, \"time-step\": 2716}, {\"errors\": 0.0952062931439433, \"time-step\": 2717}, {\"errors\": 0.09517967792999835, \"time-step\": 2718}, {\"errors\": 0.09515306571410953, \"time-step\": 2719}, {\"errors\": 0.09512645646799066, \"time-step\": 2720}, {\"errors\": 0.09509985016307912, \"time-step\": 2721}, {\"errors\": 0.09507324677053616, \"time-step\": 2722}, {\"errors\": 0.09504664626124701, \"time-step\": 2723}, {\"errors\": 0.09502004860582133, \"time-step\": 2724}, {\"errors\": 0.0949934537745932, \"time-step\": 2725}, {\"errors\": 0.0949668617376215, \"time-step\": 2726}, {\"errors\": 0.09494027246469026, \"time-step\": 2727}, {\"errors\": 0.09491368592530855, \"time-step\": 2728}, {\"errors\": 0.09488710208871112, \"time-step\": 2729}, {\"errors\": 0.09486052092385835, \"time-step\": 2730}, {\"errors\": 0.09483394239943652, \"time-step\": 2731}, {\"errors\": 0.09480736648385821, \"time-step\": 2732}, {\"errors\": 0.0947807931452623, \"time-step\": 2733}, {\"errors\": 0.0947542223515144, \"time-step\": 2734}, {\"errors\": 0.09472765407020699, \"time-step\": 2735}, {\"errors\": 0.0947010882686595, \"time-step\": 2736}, {\"errors\": 0.09467452491391891, \"time-step\": 2737}, {\"errors\": 0.09464796397275961, \"time-step\": 2738}, {\"errors\": 0.09462140541168373, \"time-step\": 2739}, {\"errors\": 0.09459484919692146, \"time-step\": 2740}, {\"errors\": 0.09456829529443127, \"time-step\": 2741}, {\"errors\": 0.09454174366989984, \"time-step\": 2742}, {\"errors\": 0.09451519428874271, \"time-step\": 2743}, {\"errors\": 0.09448864711610426, \"time-step\": 2744}, {\"errors\": 0.09446210211685782, \"time-step\": 2745}, {\"errors\": 0.09443555925560612, \"time-step\": 2746}, {\"errors\": 0.09440901849668144, \"time-step\": 2747}, {\"errors\": 0.09438247980414566, \"time-step\": 2748}, {\"errors\": 0.09435594314179066, \"time-step\": 2749}, {\"errors\": 0.09432940847313848, \"time-step\": 2750}, {\"errors\": 0.09430287576144142, \"time-step\": 2751}, {\"errors\": 0.09427634496968249, \"time-step\": 2752}, {\"errors\": 0.09424981606057514, \"time-step\": 2753}, {\"errors\": 0.0942232889965642, \"time-step\": 2754}, {\"errors\": 0.09419676373982534, \"time-step\": 2755}, {\"errors\": 0.09417024025226571, \"time-step\": 2756}, {\"errors\": 0.09414371849552394, \"time-step\": 2757}, {\"errors\": 0.09411719843097055, \"time-step\": 2758}, {\"errors\": 0.09409068001970781, \"time-step\": 2759}, {\"errors\": 0.09406416322257036, \"time-step\": 2760}, {\"errors\": 0.0940376480001249, \"time-step\": 2761}, {\"errors\": 0.09401113431267087, \"time-step\": 2762}, {\"errors\": 0.09398462212024032, \"time-step\": 2763}, {\"errors\": 0.09395811138259819, \"time-step\": 2764}, {\"errors\": 0.0939316020592425, \"time-step\": 2765}, {\"errors\": 0.09390509410940459, \"time-step\": 2766}, {\"errors\": 0.09387858749204916, \"time-step\": 2767}, {\"errors\": 0.09385208216587451, \"time-step\": 2768}, {\"errors\": 0.09382557808931286, \"time-step\": 2769}, {\"errors\": 0.09379907522053019, \"time-step\": 2770}, {\"errors\": 0.09377257351742692, \"time-step\": 2771}, {\"errors\": 0.09374607293763752, \"time-step\": 2772}, {\"errors\": 0.09371957343853109, \"time-step\": 2773}, {\"errors\": 0.0936930749772113, \"time-step\": 2774}, {\"errors\": 0.09366657751051669, \"time-step\": 2775}, {\"errors\": 0.09364008099502076, \"time-step\": 2776}, {\"errors\": 0.09361358538703227, \"time-step\": 2777}, {\"errors\": 0.09358709064259502, \"time-step\": 2778}, {\"errors\": 0.09356059671748854, \"time-step\": 2779}, {\"errors\": 0.09353410356722792, \"time-step\": 2780}, {\"errors\": 0.09350761114706391, \"time-step\": 2781}, {\"errors\": 0.0934811194119833, \"time-step\": 2782}, {\"errors\": 0.09345462831670892, \"time-step\": 2783}, {\"errors\": 0.09342813781569989, \"time-step\": 2784}, {\"errors\": 0.09340164786315155, \"time-step\": 2785}, {\"errors\": 0.09337515841299593, \"time-step\": 2786}, {\"errors\": 0.0933486694189016, \"time-step\": 2787}, {\"errors\": 0.0933221808342741, \"time-step\": 2788}, {\"errors\": 0.09329569261225562, \"time-step\": 2789}, {\"errors\": 0.09326920470572574, \"time-step\": 2790}, {\"errors\": 0.09324271706730097, \"time-step\": 2791}, {\"errors\": 0.09321622964933539, \"time-step\": 2792}, {\"errors\": 0.09318974240392043, \"time-step\": 2793}, {\"errors\": 0.09316325528288516, \"time-step\": 2794}, {\"errors\": 0.09313676823779635, \"time-step\": 2795}, {\"errors\": 0.09311028121995861, \"time-step\": 2796}, {\"errors\": 0.09308379418041454, \"time-step\": 2797}, {\"errors\": 0.09305730706994483, \"time-step\": 2798}, {\"errors\": 0.09303081983906844, \"time-step\": 2799}, {\"errors\": 0.09300433243804246, \"time-step\": 2800}, {\"errors\": 0.09297784481686264, \"time-step\": 2801}, {\"errors\": 0.09295135692526305, \"time-step\": 2802}, {\"errors\": 0.09292486871271657, \"time-step\": 2803}, {\"errors\": 0.09289838012843486, \"time-step\": 2804}, {\"errors\": 0.09287189112136829, \"time-step\": 2805}, {\"errors\": 0.09284540164020626, \"time-step\": 2806}, {\"errors\": 0.0928189116333773, \"time-step\": 2807}, {\"errors\": 0.09279242104904895, \"time-step\": 2808}, {\"errors\": 0.09276592983512816, \"time-step\": 2809}, {\"errors\": 0.09273943793926116, \"time-step\": 2810}, {\"errors\": 0.09271294530883348, \"time-step\": 2811}, {\"errors\": 0.0926864518909704, \"time-step\": 2812}, {\"errors\": 0.09265995763253665, \"time-step\": 2813}, {\"errors\": 0.09263346248013671, \"time-step\": 2814}, {\"errors\": 0.09260696638011476, \"time-step\": 2815}, {\"errors\": 0.09258046927855491, \"time-step\": 2816}, {\"errors\": 0.09255397112128123, \"time-step\": 2817}, {\"errors\": 0.09252747185385762, \"time-step\": 2818}, {\"errors\": 0.09250097142158814, \"time-step\": 2819}, {\"errors\": 0.09247446976951713, \"time-step\": 2820}, {\"errors\": 0.09244796684242883, \"time-step\": 2821}, {\"errors\": 0.09242146258484799, \"time-step\": 2822}, {\"errors\": 0.0923949569410396, \"time-step\": 2823}, {\"errors\": 0.09236844985500908, \"time-step\": 2824}, {\"errors\": 0.09234194127050217, \"time-step\": 2825}, {\"errors\": 0.09231543113100531, \"time-step\": 2826}, {\"errors\": 0.09228891937974534, \"time-step\": 2827}, {\"errors\": 0.09226240595968979, \"time-step\": 2828}, {\"errors\": 0.09223589081354674, \"time-step\": 2829}, {\"errors\": 0.09220937388376513, \"time-step\": 2830}, {\"errors\": 0.0921828551125344, \"time-step\": 2831}, {\"errors\": 0.092156334441785, \"time-step\": 2832}, {\"errors\": 0.09212981181318806, \"time-step\": 2833}, {\"errors\": 0.09210328716815566, \"time-step\": 2834}, {\"errors\": 0.09207676044784066, \"time-step\": 2835}, {\"errors\": 0.09205023159313686, \"time-step\": 2836}, {\"errors\": 0.09202370054467907, \"time-step\": 2837}, {\"errors\": 0.09199716724284304, \"time-step\": 2838}, {\"errors\": 0.09197063162774544, \"time-step\": 2839}, {\"errors\": 0.09194409363924408, \"time-step\": 2840}, {\"errors\": 0.09191755321693774, \"time-step\": 2841}, {\"errors\": 0.0918910103001662, \"time-step\": 2842}, {\"errors\": 0.09186446482801039, \"time-step\": 2843}, {\"errors\": 0.09183791673929224, \"time-step\": 2844}, {\"errors\": 0.09181136597257486, \"time-step\": 2845}, {\"errors\": 0.09178481246616238, \"time-step\": 2846}, {\"errors\": 0.09175825615810007, \"time-step\": 2847}, {\"errors\": 0.09173169698617423, \"time-step\": 2848}, {\"errors\": 0.09170513488791229, \"time-step\": 2849}, {\"errors\": 0.09167856980058275, \"time-step\": 2850}, {\"errors\": 0.09165200166119533, \"time-step\": 2851}, {\"errors\": 0.09162543040650059, \"time-step\": 2852}, {\"errors\": 0.09159885597299045, \"time-step\": 2853}, {\"errors\": 0.09157227829689757, \"time-step\": 2854}, {\"errors\": 0.09154569731419594, \"time-step\": 2855}, {\"errors\": 0.09151911296060045, \"time-step\": 2856}, {\"errors\": 0.09149252517156695, \"time-step\": 2857}, {\"errors\": 0.09146593388229234, \"time-step\": 2858}, {\"errors\": 0.09143933902771445, \"time-step\": 2859}, {\"errors\": 0.09141274054251217, \"time-step\": 2860}, {\"errors\": 0.09138613836110504, \"time-step\": 2861}, {\"errors\": 0.09135953241765368, \"time-step\": 2862}, {\"errors\": 0.0913329226460595, \"time-step\": 2863}, {\"errors\": 0.09130630897996461, \"time-step\": 2864}, {\"errors\": 0.0912796913527521, \"time-step\": 2865}, {\"errors\": 0.09125306969754554, \"time-step\": 2866}, {\"errors\": 0.09122644394720938, \"time-step\": 2867}, {\"errors\": 0.09119981403434856, \"time-step\": 2868}, {\"errors\": 0.09117317989130869, \"time-step\": 2869}, {\"errors\": 0.09114654145017591, \"time-step\": 2870}, {\"errors\": 0.09111989864277678, \"time-step\": 2871}, {\"errors\": 0.09109325140067831, \"time-step\": 2872}, {\"errors\": 0.09106659965518804, \"time-step\": 2873}, {\"errors\": 0.0910399433373536, \"time-step\": 2874}, {\"errors\": 0.09101328237796297, \"time-step\": 2875}, {\"errors\": 0.09098661670754431, \"time-step\": 2876}, {\"errors\": 0.090959946256366, \"time-step\": 2877}, {\"errors\": 0.09093327095443623, \"time-step\": 2878}, {\"errors\": 0.09090659073150341, \"time-step\": 2879}, {\"errors\": 0.0908799055170558, \"time-step\": 2880}, {\"errors\": 0.09085321524032142, \"time-step\": 2881}, {\"errors\": 0.0908265198302681, \"time-step\": 2882}, {\"errors\": 0.09079981921560351, \"time-step\": 2883}, {\"errors\": 0.09077311332477457, \"time-step\": 2884}, {\"errors\": 0.09074640208596799, \"time-step\": 2885}, {\"errors\": 0.09071968542710986, \"time-step\": 2886}, {\"errors\": 0.09069296327586557, \"time-step\": 2887}, {\"errors\": 0.09066623555963982, \"time-step\": 2888}, {\"errors\": 0.09063950220557632, \"time-step\": 2889}, {\"errors\": 0.09061276314055808, \"time-step\": 2890}, {\"errors\": 0.09058601829120695, \"time-step\": 2891}, {\"errors\": 0.09055926758388366, \"time-step\": 2892}, {\"errors\": 0.09053251094468767, \"time-step\": 2893}, {\"errors\": 0.09050574829945723, \"time-step\": 2894}, {\"errors\": 0.09047897957376909, \"time-step\": 2895}, {\"errors\": 0.09045220469293841, \"time-step\": 2896}, {\"errors\": 0.09042542358201881, \"time-step\": 2897}, {\"errors\": 0.09039863616580208, \"time-step\": 2898}, {\"errors\": 0.09037184236881823, \"time-step\": 2899}, {\"errors\": 0.0903450421153352, \"time-step\": 2900}, {\"errors\": 0.09031823532935879, \"time-step\": 2901}, {\"errors\": 0.09029142193463274, \"time-step\": 2902}, {\"errors\": 0.09026460185463839, \"time-step\": 2903}, {\"errors\": 0.09023777501259451, \"time-step\": 2904}, {\"errors\": 0.09021094133145749, \"time-step\": 2905}, {\"errors\": 0.09018410073392086, \"time-step\": 2906}, {\"errors\": 0.09015725314241543, \"time-step\": 2907}, {\"errors\": 0.09013039847910895, \"time-step\": 2908}, {\"errors\": 0.09010353666590615, \"time-step\": 2909}, {\"errors\": 0.0900766676244486, \"time-step\": 2910}, {\"errors\": 0.09004979127611437, \"time-step\": 2911}, {\"errors\": 0.0900229075420181, \"time-step\": 2912}, {\"errors\": 0.08999601634301088, \"time-step\": 2913}, {\"errors\": 0.08996911759968002, \"time-step\": 2914}, {\"errors\": 0.0899422112323488, \"time-step\": 2915}, {\"errors\": 0.08991529716107655, \"time-step\": 2916}, {\"errors\": 0.08988837530565845, \"time-step\": 2917}, {\"errors\": 0.08986144558562534, \"time-step\": 2918}, {\"errors\": 0.0898345079202435, \"time-step\": 2919}, {\"errors\": 0.08980756222851469, \"time-step\": 2920}, {\"errors\": 0.08978060842917575, \"time-step\": 2921}, {\"errors\": 0.08975364644069883, \"time-step\": 2922}, {\"errors\": 0.08972667618129074, \"time-step\": 2923}, {\"errors\": 0.08969969756889326, \"time-step\": 2924}, {\"errors\": 0.08967271052118267, \"time-step\": 2925}, {\"errors\": 0.08964571495556972, \"time-step\": 2926}, {\"errors\": 0.08961871078919967, \"time-step\": 2927}, {\"errors\": 0.08959169793895164, \"time-step\": 2928}, {\"errors\": 0.0895646763214388, \"time-step\": 2929}, {\"errors\": 0.08953764585300832, \"time-step\": 2930}, {\"errors\": 0.08951060644974082, \"time-step\": 2931}, {\"errors\": 0.08948355802745057, \"time-step\": 2932}, {\"errors\": 0.08945650050168517, \"time-step\": 2933}, {\"errors\": 0.08942943378772525, \"time-step\": 2934}, {\"errors\": 0.08940235780058461, \"time-step\": 2935}, {\"errors\": 0.08937527245500985, \"time-step\": 2936}, {\"errors\": 0.08934817766548014, \"time-step\": 2937}, {\"errors\": 0.0893210733462074, \"time-step\": 2938}, {\"errors\": 0.08929395941113555, \"time-step\": 2939}, {\"errors\": 0.08926683577394091, \"time-step\": 2940}, {\"errors\": 0.08923970234803176, \"time-step\": 2941}, {\"errors\": 0.08921255904654812, \"time-step\": 2942}, {\"errors\": 0.08918540578236178, \"time-step\": 2943}, {\"errors\": 0.08915824246807583, \"time-step\": 2944}, {\"errors\": 0.08913106901602483, \"time-step\": 2945}, {\"errors\": 0.0891038853382744, \"time-step\": 2946}, {\"errors\": 0.08907669134662108, \"time-step\": 2947}, {\"errors\": 0.08904948695259227, \"time-step\": 2948}, {\"errors\": 0.08902227206744585, \"time-step\": 2949}, {\"errors\": 0.08899504660217025, \"time-step\": 2950}, {\"errors\": 0.08896781046748403, \"time-step\": 2951}, {\"errors\": 0.08894056357383587, \"time-step\": 2952}, {\"errors\": 0.08891330583140433, \"time-step\": 2953}, {\"errors\": 0.08888603715009775, \"time-step\": 2954}, {\"errors\": 0.08885875743955393, \"time-step\": 2955}, {\"errors\": 0.08883146660913997, \"time-step\": 2956}, {\"errors\": 0.08880416456795226, \"time-step\": 2957}, {\"errors\": 0.08877685122481616, \"time-step\": 2958}, {\"errors\": 0.08874952648828571, \"time-step\": 2959}, {\"errors\": 0.08872219026664388, \"time-step\": 2960}, {\"errors\": 0.0886948424679018, \"time-step\": 2961}, {\"errors\": 0.08866748299979907, \"time-step\": 2962}, {\"errors\": 0.08864011176980328, \"time-step\": 2963}, {\"errors\": 0.08861272868511003, \"time-step\": 2964}, {\"errors\": 0.0885853336526426, \"time-step\": 2965}, {\"errors\": 0.08855792657905193, \"time-step\": 2966}, {\"errors\": 0.08853050737071622, \"time-step\": 2967}, {\"errors\": 0.08850307593374093, \"time-step\": 2968}, {\"errors\": 0.08847563217395873, \"time-step\": 2969}, {\"errors\": 0.08844817599692882, \"time-step\": 2970}, {\"errors\": 0.08842070730793739, \"time-step\": 2971}, {\"errors\": 0.08839322601199692, \"time-step\": 2972}, {\"errors\": 0.08836573201384643, \"time-step\": 2973}, {\"errors\": 0.0883382252179509, \"time-step\": 2974}, {\"errors\": 0.0883107055285014, \"time-step\": 2975}, {\"errors\": 0.08828317284941486, \"time-step\": 2976}, {\"errors\": 0.08825562708433371, \"time-step\": 2977}, {\"errors\": 0.08822806813662602, \"time-step\": 2978}, {\"errors\": 0.08820049590938506, \"time-step\": 2979}, {\"errors\": 0.08817291030542927, \"time-step\": 2980}, {\"errors\": 0.08814531122730207, \"time-step\": 2981}, {\"errors\": 0.08811769857727161, \"time-step\": 2982}, {\"errors\": 0.0880900722573308, \"time-step\": 2983}, {\"errors\": 0.08806243216919693, \"time-step\": 2984}, {\"errors\": 0.08803477821431166, \"time-step\": 2985}, {\"errors\": 0.0880071102938407, \"time-step\": 2986}, {\"errors\": 0.08797942830867389, \"time-step\": 2987}, {\"errors\": 0.08795173215942483, \"time-step\": 2988}, {\"errors\": 0.08792402174643088, \"time-step\": 2989}, {\"errors\": 0.08789629696975274, \"time-step\": 2990}, {\"errors\": 0.0878685577291746, \"time-step\": 2991}, {\"errors\": 0.08784080392420396, \"time-step\": 2992}, {\"errors\": 0.08781303545407129, \"time-step\": 2993}, {\"errors\": 0.08778525221772987, \"time-step\": 2994}, {\"errors\": 0.08775745411385603, \"time-step\": 2995}, {\"errors\": 0.08772964104084854, \"time-step\": 2996}, {\"errors\": 0.08770181289682871, \"time-step\": 2997}, {\"errors\": 0.08767396957964022, \"time-step\": 2998}, {\"errors\": 0.08764611098684894, \"time-step\": 2999}, {\"errors\": 0.08761823701574281, \"time-step\": 3000}, {\"errors\": 0.08759034756333195, \"time-step\": 3001}, {\"errors\": 0.08756244252634794, \"time-step\": 3002}, {\"errors\": 0.08753452180124432, \"time-step\": 3003}, {\"errors\": 0.08750658528419614, \"time-step\": 3004}, {\"errors\": 0.08747863287109989, \"time-step\": 3005}, {\"errors\": 0.08745066445757338, \"time-step\": 3006}, {\"errors\": 0.08742267993895578, \"time-step\": 3007}, {\"errors\": 0.08739467921030708, \"time-step\": 3008}, {\"errors\": 0.08736666216640866, \"time-step\": 3009}, {\"errors\": 0.08733862870176241, \"time-step\": 3010}, {\"errors\": 0.08731057871059131, \"time-step\": 3011}, {\"errors\": 0.08728251208683895, \"time-step\": 3012}, {\"errors\": 0.08725442872416936, \"time-step\": 3013}, {\"errors\": 0.08722632851596734, \"time-step\": 3014}, {\"errors\": 0.08719821135533783, \"time-step\": 3015}, {\"errors\": 0.08717007713510638, \"time-step\": 3016}, {\"errors\": 0.0871419257478186, \"time-step\": 3017}, {\"errors\": 0.08711375708574035, \"time-step\": 3018}, {\"errors\": 0.08708557104085748, \"time-step\": 3019}, {\"errors\": 0.0870573675048761, \"time-step\": 3020}, {\"errors\": 0.08702914636922202, \"time-step\": 3021}, {\"errors\": 0.08700090752504118, \"time-step\": 3022}, {\"errors\": 0.08697265086319915, \"time-step\": 3023}, {\"errors\": 0.0869443762742815, \"time-step\": 3024}, {\"errors\": 0.08691608364859335, \"time-step\": 3025}, {\"errors\": 0.0868877728761597, \"time-step\": 3026}, {\"errors\": 0.08685944384672513, \"time-step\": 3027}, {\"errors\": 0.08683109644975376, \"time-step\": 3028}, {\"errors\": 0.08680273057442951, \"time-step\": 3029}, {\"errors\": 0.08677434610965562, \"time-step\": 3030}, {\"errors\": 0.08674594294405512, \"time-step\": 3031}, {\"errors\": 0.08671752096597046, \"time-step\": 3032}, {\"errors\": 0.08668908006346367, \"time-step\": 3033}, {\"errors\": 0.08666062012431619, \"time-step\": 3034}, {\"errors\": 0.0866321410360291, \"time-step\": 3035}, {\"errors\": 0.08660364268582293, \"time-step\": 3036}, {\"errors\": 0.08657512496063799, \"time-step\": 3037}, {\"errors\": 0.08654658774713378, \"time-step\": 3038}, {\"errors\": 0.08651803093168972, \"time-step\": 3039}, {\"errors\": 0.08648945440040465, \"time-step\": 3040}, {\"errors\": 0.08646085803909709, \"time-step\": 3041}, {\"errors\": 0.08643224173330541, \"time-step\": 3042}, {\"errors\": 0.08640360536828756, \"time-step\": 3043}, {\"errors\": 0.08637494882902136, \"time-step\": 3044}, {\"errors\": 0.08634627200020445, \"time-step\": 3045}, {\"errors\": 0.0863175747662545, \"time-step\": 3046}, {\"errors\": 0.08628885701130914, \"time-step\": 3047}, {\"errors\": 0.08626011861922597, \"time-step\": 3048}, {\"errors\": 0.08623135947358296, \"time-step\": 3049}, {\"errors\": 0.08620257945767823, \"time-step\": 3050}, {\"errors\": 0.08617377845453036, \"time-step\": 3051}, {\"errors\": 0.08614495634687828, \"time-step\": 3052}, {\"errors\": 0.08611611301718174, \"time-step\": 3053}, {\"errors\": 0.08608724834762098, \"time-step\": 3054}, {\"errors\": 0.08605836222009733, \"time-step\": 3055}, {\"errors\": 0.08602945451623287, \"time-step\": 3056}, {\"errors\": 0.08600052511737112, \"time-step\": 3057}, {\"errors\": 0.08597157390457663, \"time-step\": 3058}, {\"errors\": 0.0859426007586356, \"time-step\": 3059}, {\"errors\": 0.08591360556005588, \"time-step\": 3060}, {\"errors\": 0.08588458818906697, \"time-step\": 3061}, {\"errors\": 0.08585554852562065, \"time-step\": 3062}, {\"errors\": 0.0858264864493907, \"time-step\": 3063}, {\"errors\": 0.08579740183977333, \"time-step\": 3064}, {\"errors\": 0.08576829457588755, \"time-step\": 3065}, {\"errors\": 0.0857391645365751, \"time-step\": 3066}, {\"errors\": 0.08571001160040084, \"time-step\": 3067}, {\"errors\": 0.08568083564565296, \"time-step\": 3068}, {\"errors\": 0.08565163655034325, \"time-step\": 3069}, {\"errors\": 0.08562241419220737, \"time-step\": 3070}, {\"errors\": 0.08559316844870507, \"time-step\": 3071}, {\"errors\": 0.08556389919702052, \"time-step\": 3072}, {\"errors\": 0.08553460631406266, \"time-step\": 3073}, {\"errors\": 0.08550528967646535, \"time-step\": 3074}, {\"errors\": 0.08547594916058768, \"time-step\": 3075}, {\"errors\": 0.08544658464251459, \"time-step\": 3076}, {\"errors\": 0.08541719599805674, \"time-step\": 3077}, {\"errors\": 0.08538778310275132, \"time-step\": 3078}, {\"errors\": 0.085358345831862, \"time-step\": 3079}, {\"errors\": 0.08532888406037961, \"time-step\": 3080}, {\"errors\": 0.08529939766302227, \"time-step\": 3081}, {\"errors\": 0.085269886514236, \"time-step\": 3082}, {\"errors\": 0.08524035048819499, \"time-step\": 3083}, {\"errors\": 0.0852107894588019, \"time-step\": 3084}, {\"errors\": 0.08518120329968851, \"time-step\": 3085}, {\"errors\": 0.08515159188421603, \"time-step\": 3086}, {\"errors\": 0.0851219550854756, \"time-step\": 3087}, {\"errors\": 0.08509229277628866, \"time-step\": 3088}, {\"errors\": 0.08506260482920747, \"time-step\": 3089}, {\"errors\": 0.08503289111651563, \"time-step\": 3090}, {\"errors\": 0.08500315151022844, \"time-step\": 3091}, {\"errors\": 0.08497338588209374, \"time-step\": 3092}, {\"errors\": 0.08494359410359181, \"time-step\": 3093}, {\"errors\": 0.08491377604593664, \"time-step\": 3094}, {\"errors\": 0.0848839315800759, \"time-step\": 3095}, {\"errors\": 0.08485406057669176, \"time-step\": 3096}, {\"errors\": 0.08482416290620147, \"time-step\": 3097}, {\"errors\": 0.08479423843875782, \"time-step\": 3098}, {\"errors\": 0.08476428704424988, \"time-step\": 3099}, {\"errors\": 0.08473430859230352, \"time-step\": 3100}, {\"errors\": 0.08470430295228198, \"time-step\": 3101}, {\"errors\": 0.08467426999328663, \"time-step\": 3102}, {\"errors\": 0.08464420958415765, \"time-step\": 3103}, {\"errors\": 0.08461412159347459, \"time-step\": 3104}, {\"errors\": 0.08458400588955707, \"time-step\": 3105}, {\"errors\": 0.08455386234046545, \"time-step\": 3106}, {\"errors\": 0.08452369081400174, \"time-step\": 3107}, {\"errors\": 0.08449349117771011, \"time-step\": 3108}, {\"errors\": 0.08446326329887768, \"time-step\": 3109}, {\"errors\": 0.08443300704453534, \"time-step\": 3110}, {\"errors\": 0.08440272228145848, \"time-step\": 3111}, {\"errors\": 0.08437240887616786, \"time-step\": 3112}, {\"errors\": 0.08434206669493025, \"time-step\": 3113}, {\"errors\": 0.08431169560375945, \"time-step\": 3114}, {\"errors\": 0.08428129546841688, \"time-step\": 3115}, {\"errors\": 0.08425086615441281, \"time-step\": 3116}, {\"errors\": 0.08422040752700677, \"time-step\": 3117}, {\"errors\": 0.08418991945120888, \"time-step\": 3118}, {\"errors\": 0.08415940179178044, \"time-step\": 3119}, {\"errors\": 0.08412885441323492, \"time-step\": 3120}, {\"errors\": 0.08409827717983906, \"time-step\": 3121}, {\"errors\": 0.08406766995561367, \"time-step\": 3122}, {\"errors\": 0.0840370326043346, \"time-step\": 3123}, {\"errors\": 0.08400636498953384, \"time-step\": 3124}, {\"errors\": 0.08397566697450037, \"time-step\": 3125}, {\"errors\": 0.08394493842228132, \"time-step\": 3126}, {\"errors\": 0.0839141791956831, \"time-step\": 3127}, {\"errors\": 0.08388338915727224, \"time-step\": 3128}, {\"errors\": 0.08385256816937647, \"time-step\": 3129}, {\"errors\": 0.08382171609408613, \"time-step\": 3130}, {\"errors\": 0.08379083279325497, \"time-step\": 3131}, {\"errors\": 0.08375991812850145, \"time-step\": 3132}, {\"errors\": 0.08372897196120976, \"time-step\": 3133}, {\"errors\": 0.08369799415253133, \"time-step\": 3134}, {\"errors\": 0.08366698456338553, \"time-step\": 3135}, {\"errors\": 0.08363594305446129, \"time-step\": 3136}, {\"errors\": 0.08360486948621815, \"time-step\": 3137}, {\"errors\": 0.08357376371888758, \"time-step\": 3138}, {\"errors\": 0.08354262561247427, \"time-step\": 3139}, {\"errors\": 0.08351145502675739, \"time-step\": 3140}, {\"errors\": 0.08348025182129187, \"time-step\": 3141}, {\"errors\": 0.08344901585540984, \"time-step\": 3142}, {\"errors\": 0.08341774698822202, \"time-step\": 3143}, {\"errors\": 0.08338644507861878, \"time-step\": 3144}, {\"errors\": 0.08335510998527208, \"time-step\": 3145}, {\"errors\": 0.08332374156663641, \"time-step\": 3146}, {\"errors\": 0.08329233968095043, \"time-step\": 3147}, {\"errors\": 0.08326090418623852, \"time-step\": 3148}, {\"errors\": 0.08322943494031214, \"time-step\": 3149}, {\"errors\": 0.08319793180077134, \"time-step\": 3150}, {\"errors\": 0.08316639462500647, \"time-step\": 3151}, {\"errors\": 0.08313482327019947, \"time-step\": 3152}, {\"errors\": 0.08310321759332562, \"time-step\": 3153}, {\"errors\": 0.0830715774511552, \"time-step\": 3154}, {\"errors\": 0.08303990270025491, \"time-step\": 3155}, {\"errors\": 0.08300819319698965, \"time-step\": 3156}, {\"errors\": 0.08297644879752425, \"time-step\": 3157}, {\"errors\": 0.082944669357825, \"time-step\": 3158}, {\"errors\": 0.08291285473366149, \"time-step\": 3159}, {\"errors\": 0.08288100478060834, \"time-step\": 3160}, {\"errors\": 0.08284911935404693, \"time-step\": 3161}, {\"errors\": 0.08281719830916724, \"time-step\": 3162}, {\"errors\": 0.08278524150096955, \"time-step\": 3163}, {\"errors\": 0.08275324878426644, \"time-step\": 3164}, {\"errors\": 0.08272122001368457, \"time-step\": 3165}, {\"errors\": 0.0826891550436666, \"time-step\": 3166}, {\"errors\": 0.08265705372847296, \"time-step\": 3167}, {\"errors\": 0.08262491592218404, \"time-step\": 3168}, {\"errors\": 0.08259274147870205, \"time-step\": 3169}, {\"errors\": 0.08256053025175285, \"time-step\": 3170}, {\"errors\": 0.08252828209488824, \"time-step\": 3171}, {\"errors\": 0.08249599686148776, \"time-step\": 3172}, {\"errors\": 0.0824636744047609, \"time-step\": 3173}, {\"errors\": 0.0824313145777492, \"time-step\": 3174}, {\"errors\": 0.08239891723332833, \"time-step\": 3175}, {\"errors\": 0.08236648222421013, \"time-step\": 3176}, {\"errors\": 0.08233400940294502, \"time-step\": 3177}, {\"errors\": 0.08230149862192393, \"time-step\": 3178}, {\"errors\": 0.08226894973338084, \"time-step\": 3179}, {\"errors\": 0.08223636258939476, \"time-step\": 3180}, {\"errors\": 0.08220373704189211, \"time-step\": 3181}, {\"errors\": 0.08217107294264904, \"time-step\": 3182}, {\"errors\": 0.08213837014329378, \"time-step\": 3183}, {\"errors\": 0.082105628495309, \"time-step\": 3184}, {\"errors\": 0.08207284785003402, \"time-step\": 3185}, {\"errors\": 0.08204002805866772, \"time-step\": 3186}, {\"errors\": 0.08200716897227037, \"time-step\": 3187}, {\"errors\": 0.08197427044176653, \"time-step\": 3188}, {\"errors\": 0.0819413323179474, \"time-step\": 3189}, {\"errors\": 0.08190835445147342, \"time-step\": 3190}, {\"errors\": 0.08187533669287674, \"time-step\": 3191}, {\"errors\": 0.08184227889256385, \"time-step\": 3192}, {\"errors\": 0.08180918090081829, \"time-step\": 3193}, {\"errors\": 0.08177604256780327, \"time-step\": 3194}, {\"errors\": 0.08174286374356404, \"time-step\": 3195}, {\"errors\": 0.08170964427803118, \"time-step\": 3196}, {\"errors\": 0.08167638402102281, \"time-step\": 3197}, {\"errors\": 0.08164308282224766, \"time-step\": 3198}, {\"errors\": 0.0816097405313077, \"time-step\": 3199}, {\"errors\": 0.08157635699770122, \"time-step\": 3200}, {\"errors\": 0.08154293207082522, \"time-step\": 3201}, {\"errors\": 0.08150946559997888, \"time-step\": 3202}, {\"errors\": 0.081475957434366, \"time-step\": 3203}, {\"errors\": 0.08144240742309819, \"time-step\": 3204}, {\"errors\": 0.08140881541519776, \"time-step\": 3205}, {\"errors\": 0.08137518125960082, \"time-step\": 3206}, {\"errors\": 0.08134150480516017, \"time-step\": 3207}, {\"errors\": 0.08130778590064856, \"time-step\": 3208}, {\"errors\": 0.08127402439476163, \"time-step\": 3209}, {\"errors\": 0.08124022013612114, \"time-step\": 3210}, {\"errors\": 0.08120637297327808, \"time-step\": 3211}, {\"errors\": 0.08117248275471589, \"time-step\": 3212}, {\"errors\": 0.08113854932885364, \"time-step\": 3213}, {\"errors\": 0.08110457254404946, \"time-step\": 3214}, {\"errors\": 0.08107055224860352, \"time-step\": 3215}, {\"errors\": 0.08103648829076165, \"time-step\": 3216}, {\"errors\": 0.08100238051871865, \"time-step\": 3217}, {\"errors\": 0.08096822878062138, \"time-step\": 3218}, {\"errors\": 0.08093403292457255, \"time-step\": 3219}, {\"errors\": 0.08089979279863407, \"time-step\": 3220}, {\"errors\": 0.08086550825083025, \"time-step\": 3221}, {\"errors\": 0.08083117912915182, \"time-step\": 3222}, {\"errors\": 0.08079680528155903, \"time-step\": 3223}, {\"errors\": 0.08076238655598539, \"time-step\": 3224}, {\"errors\": 0.08072792280034137, \"time-step\": 3225}, {\"errors\": 0.08069341386251797, \"time-step\": 3226}, {\"errors\": 0.08065885959039021, \"time-step\": 3227}, {\"errors\": 0.08062425983182124, \"time-step\": 3228}, {\"errors\": 0.0805896144346657, \"time-step\": 3229}, {\"errors\": 0.08055492324677369, \"time-step\": 3230}, {\"errors\": 0.0805201861159946, \"time-step\": 3231}, {\"errors\": 0.0804854028901807, \"time-step\": 3232}, {\"errors\": 0.08045057341719139, \"time-step\": 3233}, {\"errors\": 0.08041569754489683, \"time-step\": 3234}, {\"errors\": 0.08038077512118187, \"time-step\": 3235}, {\"errors\": 0.08034580599395028, \"time-step\": 3236}, {\"errors\": 0.08031079001112834, \"time-step\": 3237}, {\"errors\": 0.0802757270206693, \"time-step\": 3238}, {\"errors\": 0.08024061687055725, \"time-step\": 3239}, {\"errors\": 0.08020545940881121, \"time-step\": 3240}, {\"errors\": 0.08017025448348912, \"time-step\": 3241}, {\"errors\": 0.08013500194269242, \"time-step\": 3242}, {\"errors\": 0.08009970163456992, \"time-step\": 3243}, {\"errors\": 0.08006435340732201, \"time-step\": 3244}, {\"errors\": 0.08002895710920516, \"time-step\": 3245}, {\"errors\": 0.07999351258853615, \"time-step\": 3246}, {\"errors\": 0.07995801969369615, \"time-step\": 3247}, {\"errors\": 0.07992247827313545, \"time-step\": 3248}, {\"errors\": 0.07988688817537769, \"time-step\": 3249}, {\"errors\": 0.07985124924902415, \"time-step\": 3250}, {\"errors\": 0.07981556134275852, \"time-step\": 3251}, {\"errors\": 0.07977982430535119, \"time-step\": 3252}, {\"errors\": 0.07974403798566373, \"time-step\": 3253}, {\"errors\": 0.07970820223265379, \"time-step\": 3254}, {\"errors\": 0.07967231689537921, \"time-step\": 3255}, {\"errors\": 0.07963638182300299, \"time-step\": 3256}, {\"errors\": 0.07960039686479789, \"time-step\": 3257}, {\"errors\": 0.07956436187015106, \"time-step\": 3258}, {\"errors\": 0.07952827668856885, \"time-step\": 3259}, {\"errors\": 0.0794921411696814, \"time-step\": 3260}, {\"errors\": 0.07945595516324772, \"time-step\": 3261}, {\"errors\": 0.07941971851916022, \"time-step\": 3262}, {\"errors\": 0.07938343108744976, \"time-step\": 3263}, {\"errors\": 0.07934709271829041, \"time-step\": 3264}, {\"errors\": 0.07931070326200446, \"time-step\": 3265}, {\"errors\": 0.07927426256906736, \"time-step\": 3266}, {\"errors\": 0.07923777049011266, \"time-step\": 3267}, {\"errors\": 0.07920122687593714, \"time-step\": 3268}, {\"errors\": 0.07916463157750567, \"time-step\": 3269}, {\"errors\": 0.0791279844459564, \"time-step\": 3270}, {\"errors\": 0.07909128533260593, \"time-step\": 3271}, {\"errors\": 0.07905453408895438, \"time-step\": 3272}, {\"errors\": 0.07901773056669051, \"time-step\": 3273}, {\"errors\": 0.07898087461769702, \"time-step\": 3274}, {\"errors\": 0.07894396609405582, \"time-step\": 3275}, {\"errors\": 0.07890700484805314, \"time-step\": 3276}, {\"errors\": 0.07886999073218492, \"time-step\": 3277}, {\"errors\": 0.07883292359916225, \"time-step\": 3278}, {\"errors\": 0.07879580330191646, \"time-step\": 3279}, {\"errors\": 0.07875862969360481, \"time-step\": 3280}, {\"errors\": 0.07872140262761562, \"time-step\": 3281}, {\"errors\": 0.078684121957574, \"time-step\": 3282}, {\"errors\": 0.07864678753734705, \"time-step\": 3283}, {\"errors\": 0.07860939922104965, \"time-step\": 3284}, {\"errors\": 0.07857195686304971, \"time-step\": 3285}, {\"errors\": 0.07853446031797406, \"time-step\": 3286}, {\"errors\": 0.07849690944071375, \"time-step\": 3287}, {\"errors\": 0.07845930408642973, \"time-step\": 3288}, {\"errors\": 0.07842164411055878, \"time-step\": 3289}, {\"errors\": 0.07838392936881877, \"time-step\": 3290}, {\"errors\": 0.07834615971721459, \"time-step\": 3291}, {\"errors\": 0.07830833501204401, \"time-step\": 3292}, {\"errors\": 0.0782704551099032, \"time-step\": 3293}, {\"errors\": 0.07823251986769264, \"time-step\": 3294}, {\"errors\": 0.07819452914262301, \"time-step\": 3295}, {\"errors\": 0.07815648279222084, \"time-step\": 3296}, {\"errors\": 0.07811838067433459, \"time-step\": 3297}, {\"errors\": 0.07808022264714037, \"time-step\": 3298}, {\"errors\": 0.07804200856914795, \"time-step\": 3299}, {\"errors\": 0.07800373829920688, \"time-step\": 3300}, {\"errors\": 0.0779654116965121, \"time-step\": 3301}, {\"errors\": 0.0779270286206103, \"time-step\": 3302}, {\"errors\": 0.07788858893140557, \"time-step\": 3303}, {\"errors\": 0.07785009248916591, \"time-step\": 3304}, {\"errors\": 0.07781153915452901, \"time-step\": 3305}, {\"errors\": 0.07777292878850832, \"time-step\": 3306}, {\"errors\": 0.07773426125249938, \"time-step\": 3307}, {\"errors\": 0.07769553640828569, \"time-step\": 3308}, {\"errors\": 0.07765675411804525, \"time-step\": 3309}, {\"errors\": 0.0776179142443564, \"time-step\": 3310}, {\"errors\": 0.07757901665020417, \"time-step\": 3311}, {\"errors\": 0.07754006119898667, \"time-step\": 3312}, {\"errors\": 0.07750104775452113, \"time-step\": 3313}, {\"errors\": 0.07746197618105022, \"time-step\": 3314}, {\"errors\": 0.07742284634324847, \"time-step\": 3315}, {\"errors\": 0.07738365810622855, \"time-step\": 3316}, {\"errors\": 0.07734441133554751, \"time-step\": 3317}, {\"errors\": 0.07730510589721327, \"time-step\": 3318}, {\"errors\": 0.07726574165769098, \"time-step\": 3319}, {\"errors\": 0.07722631848390936, \"time-step\": 3320}, {\"errors\": 0.07718683624326711, \"time-step\": 3321}, {\"errors\": 0.07714729480363966, \"time-step\": 3322}, {\"errors\": 0.07710769403338502, \"time-step\": 3323}, {\"errors\": 0.07706803380135091, \"time-step\": 3324}, {\"errors\": 0.07702831397688086, \"time-step\": 3325}, {\"errors\": 0.07698853442982076, \"time-step\": 3326}, {\"errors\": 0.07694869503052555, \"time-step\": 3327}, {\"errors\": 0.07690879564986564, \"time-step\": 3328}, {\"errors\": 0.07686883615923348, \"time-step\": 3329}, {\"errors\": 0.0768288164305501, \"time-step\": 3330}, {\"errors\": 0.07678873633627195, \"time-step\": 3331}, {\"errors\": 0.07674859574939717, \"time-step\": 3332}, {\"errors\": 0.07670839454347224, \"time-step\": 3333}, {\"errors\": 0.076668132592599, \"time-step\": 3334}, {\"errors\": 0.07662780977144082, \"time-step\": 3335}, {\"errors\": 0.07658742595522955, \"time-step\": 3336}, {\"errors\": 0.07654698101977198, \"time-step\": 3337}, {\"errors\": 0.0765064748414568, \"time-step\": 3338}, {\"errors\": 0.07646590729726108, \"time-step\": 3339}, {\"errors\": 0.07642527826475687, \"time-step\": 3340}, {\"errors\": 0.07638458762211847, \"time-step\": 3341}, {\"errors\": 0.07634383524812832, \"time-step\": 3342}, {\"errors\": 0.07630302102218445, \"time-step\": 3343}, {\"errors\": 0.07626214482430696, \"time-step\": 3344}, {\"errors\": 0.0762212065351445, \"time-step\": 3345}, {\"errors\": 0.07618020603598155, \"time-step\": 3346}, {\"errors\": 0.0761391432087449, \"time-step\": 3347}, {\"errors\": 0.07609801793601029, \"time-step\": 3348}, {\"errors\": 0.07605683010100955, \"time-step\": 3349}, {\"errors\": 0.07601557958763697, \"time-step\": 3350}, {\"errors\": 0.07597426628045648, \"time-step\": 3351}, {\"errors\": 0.07593289006470827, \"time-step\": 3352}, {\"errors\": 0.07589145082631549, \"time-step\": 3353}, {\"errors\": 0.07584994845189115, \"time-step\": 3354}, {\"errors\": 0.07580838282874502, \"time-step\": 3355}, {\"errors\": 0.07576675384489037, \"time-step\": 3356}, {\"errors\": 0.07572506138905064, \"time-step\": 3357}, {\"errors\": 0.07568330535066645, \"time-step\": 3358}, {\"errors\": 0.07564148561990239, \"time-step\": 3359}, {\"errors\": 0.07559960208765358, \"time-step\": 3360}, {\"errors\": 0.07555765464555297, \"time-step\": 3361}, {\"errors\": 0.07551564318597767, \"time-step\": 3362}, {\"errors\": 0.07547356760205606, \"time-step\": 3363}, {\"errors\": 0.0754314277876744, \"time-step\": 3364}, {\"errors\": 0.07538922363748388, \"time-step\": 3365}, {\"errors\": 0.07534695504690714, \"time-step\": 3366}, {\"errors\": 0.07530462191214546, \"time-step\": 3367}, {\"errors\": 0.07526222413018496, \"time-step\": 3368}, {\"errors\": 0.07521976159880411, \"time-step\": 3369}, {\"errors\": 0.07517723421657982, \"time-step\": 3370}, {\"errors\": 0.07513464188289493, \"time-step\": 3371}, {\"errors\": 0.0750919844979443, \"time-step\": 3372}, {\"errors\": 0.07504926196274204, \"time-step\": 3373}, {\"errors\": 0.07500647417912812, \"time-step\": 3374}, {\"errors\": 0.07496362104977507, \"time-step\": 3375}, {\"errors\": 0.07492070247819488, \"time-step\": 3376}, {\"errors\": 0.0748777183687456, \"time-step\": 3377}, {\"errors\": 0.07483466862663807, \"time-step\": 3378}, {\"errors\": 0.07479155315794264, \"time-step\": 3379}, {\"errors\": 0.07474837186959604, \"time-step\": 3380}, {\"errors\": 0.07470512466940779, \"time-step\": 3381}, {\"errors\": 0.07466181146606715, \"time-step\": 3382}, {\"errors\": 0.07461843216914954, \"time-step\": 3383}, {\"errors\": 0.07457498668912349, \"time-step\": 3384}, {\"errors\": 0.07453147493735685, \"time-step\": 3385}, {\"errors\": 0.07448789682612392, \"time-step\": 3386}, {\"errors\": 0.0744442522686117, \"time-step\": 3387}, {\"errors\": 0.07440054117892661, \"time-step\": 3388}, {\"errors\": 0.07435676347210102, \"time-step\": 3389}, {\"errors\": 0.07431291906409992, \"time-step\": 3390}, {\"errors\": 0.07426900787182736, \"time-step\": 3391}, {\"errors\": 0.07422502981313293, \"time-step\": 3392}, {\"errors\": 0.07418098480681845, \"time-step\": 3393}, {\"errors\": 0.07413687277264429, \"time-step\": 3394}, {\"errors\": 0.07409269363133592, \"time-step\": 3395}, {\"errors\": 0.07404844730459023, \"time-step\": 3396}, {\"errors\": 0.07400413371508228, \"time-step\": 3397}, {\"errors\": 0.07395975278647118, \"time-step\": 3398}, {\"errors\": 0.07391530444340705, \"time-step\": 3399}, {\"errors\": 0.073870788611537, \"time-step\": 3400}, {\"errors\": 0.07382620521751138, \"time-step\": 3401}, {\"errors\": 0.0737815541889906, \"time-step\": 3402}, {\"errors\": 0.07373683545465085, \"time-step\": 3403}, {\"errors\": 0.07369204894419067, \"time-step\": 3404}, {\"errors\": 0.07364719458833716, \"time-step\": 3405}, {\"errors\": 0.07360227231885214, \"time-step\": 3406}, {\"errors\": 0.07355728206853826, \"time-step\": 3407}, {\"errors\": 0.07351222377124536, \"time-step\": 3408}, {\"errors\": 0.07346709736187629, \"time-step\": 3409}, {\"errors\": 0.07342190277639335, \"time-step\": 3410}, {\"errors\": 0.07337663995182414, \"time-step\": 3411}, {\"errors\": 0.07333130882626769, \"time-step\": 3412}, {\"errors\": 0.07328590933890032, \"time-step\": 3413}, {\"errors\": 0.07324044142998193, \"time-step\": 3414}, {\"errors\": 0.07319490504086146, \"time-step\": 3415}, {\"errors\": 0.07314930011398328, \"time-step\": 3416}, {\"errors\": 0.07310362659289299, \"time-step\": 3417}, {\"errors\": 0.07305788442224287, \"time-step\": 3418}, {\"errors\": 0.0730120735477982, \"time-step\": 3419}, {\"errors\": 0.07296619391644282, \"time-step\": 3420}, {\"errors\": 0.07292024547618475, \"time-step\": 3421}, {\"errors\": 0.07287422817616215, \"time-step\": 3422}, {\"errors\": 0.07282814196664882, \"time-step\": 3423}, {\"errors\": 0.0727819867990599, \"time-step\": 3424}, {\"errors\": 0.07273576262595749, \"time-step\": 3425}, {\"errors\": 0.07268946940105625, \"time-step\": 3426}, {\"errors\": 0.07264310707922875, \"time-step\": 3427}, {\"errors\": 0.07259667561651112, \"time-step\": 3428}, {\"errors\": 0.07255017497010852, \"time-step\": 3429}, {\"errors\": 0.07250360509840048, \"time-step\": 3430}, {\"errors\": 0.07245696596094622, \"time-step\": 3431}, {\"errors\": 0.07241025751849008, \"time-step\": 3432}, {\"errors\": 0.0723634797329667, \"time-step\": 3433}, {\"errors\": 0.07231663256750655, \"time-step\": 3434}, {\"errors\": 0.0722697159864407, \"time-step\": 3435}, {\"errors\": 0.07222272995530635, \"time-step\": 3436}, {\"errors\": 0.07217567444085182, \"time-step\": 3437}, {\"errors\": 0.07212854941104152, \"time-step\": 3438}, {\"errors\": 0.07208135483506117, \"time-step\": 3439}, {\"errors\": 0.07203409068332278, \"time-step\": 3440}, {\"errors\": 0.07198675692746945, \"time-step\": 3441}, {\"errors\": 0.07193935354038028, \"time-step\": 3442}, {\"errors\": 0.07189188049617551, \"time-step\": 3443}, {\"errors\": 0.07184433777022112, \"time-step\": 3444}, {\"errors\": 0.07179672533913332, \"time-step\": 3445}, {\"errors\": 0.07174904318078393, \"time-step\": 3446}, {\"errors\": 0.07170129127430441, \"time-step\": 3447}, {\"errors\": 0.071653469600091, \"time-step\": 3448}, {\"errors\": 0.07160557813980886, \"time-step\": 3449}, {\"errors\": 0.07155761687639683, \"time-step\": 3450}, {\"errors\": 0.07150958579407207, \"time-step\": 3451}, {\"errors\": 0.071461484878334, \"time-step\": 3452}, {\"errors\": 0.07141331411596932, \"time-step\": 3453}, {\"errors\": 0.07136507349505582, \"time-step\": 3454}, {\"errors\": 0.07131676300496691, \"time-step\": 3455}, {\"errors\": 0.07126838263637587, \"time-step\": 3456}, {\"errors\": 0.07121993238125998, \"time-step\": 3457}, {\"errors\": 0.07117141223290452, \"time-step\": 3458}, {\"errors\": 0.07112282218590726, \"time-step\": 3459}, {\"errors\": 0.071074162236182, \"time-step\": 3460}, {\"errors\": 0.07102543238096284, \"time-step\": 3461}, {\"errors\": 0.07097663261880816, \"time-step\": 3462}, {\"errors\": 0.07092776294960423, \"time-step\": 3463}, {\"errors\": 0.07087882337456933, \"time-step\": 3464}, {\"errors\": 0.07082981389625734, \"time-step\": 3465}, {\"errors\": 0.0707807345185615, \"time-step\": 3466}, {\"errors\": 0.07073158524671815, \"time-step\": 3467}, {\"errors\": 0.07068236608731016, \"time-step\": 3468}, {\"errors\": 0.07063307704827085, \"time-step\": 3469}, {\"errors\": 0.07058371813888696, \"time-step\": 3470}, {\"errors\": 0.07053428936980266, \"time-step\": 3471}, {\"errors\": 0.07048479075302255, \"time-step\": 3472}, {\"errors\": 0.0704352223019152, \"time-step\": 3473}, {\"errors\": 0.07038558403121642, \"time-step\": 3474}, {\"errors\": 0.07033587595703235, \"time-step\": 3475}, {\"errors\": 0.07028609809684291, \"time-step\": 3476}, {\"errors\": 0.07023625046950469, \"time-step\": 3477}, {\"errors\": 0.07018633309525404, \"time-step\": 3478}, {\"errors\": 0.07013634599571023, \"time-step\": 3479}, {\"errors\": 0.07008628919387817, \"time-step\": 3480}, {\"errors\": 0.07003616271415172, \"time-step\": 3481}, {\"errors\": 0.06998596658231604, \"time-step\": 3482}, {\"errors\": 0.06993570082555059, \"time-step\": 3483}, {\"errors\": 0.06988536547243215, \"time-step\": 3484}, {\"errors\": 0.06983496055293695, \"time-step\": 3485}, {\"errors\": 0.06978448609844376, \"time-step\": 3486}, {\"errors\": 0.06973394214173613, \"time-step\": 3487}, {\"errors\": 0.06968332871700511, \"time-step\": 3488}, {\"errors\": 0.06963264585985166, \"time-step\": 3489}, {\"errors\": 0.06958189360728884, \"time-step\": 3490}, {\"errors\": 0.06953107199774447, \"time-step\": 3491}, {\"errors\": 0.06948018107106323, \"time-step\": 3492}, {\"errors\": 0.06942922086850888, \"time-step\": 3493}, {\"errors\": 0.06937819143276638, \"time-step\": 3494}, {\"errors\": 0.06932709280794419, \"time-step\": 3495}, {\"errors\": 0.06927592503957615, \"time-step\": 3496}, {\"errors\": 0.06922468817462342, \"time-step\": 3497}, {\"errors\": 0.06917338226147668, \"time-step\": 3498}, {\"errors\": 0.06912200734995769, \"time-step\": 3499}, {\"errors\": 0.0690705634913214, \"time-step\": 3500}, {\"errors\": 0.06901905073825752, \"time-step\": 3501}, {\"errors\": 0.06896746914489223, \"time-step\": 3502}, {\"errors\": 0.06891581876678994, \"time-step\": 3503}, {\"errors\": 0.06886409966095494, \"time-step\": 3504}, {\"errors\": 0.0688123118858325, \"time-step\": 3505}, {\"errors\": 0.0687604555013111, \"time-step\": 3506}, {\"errors\": 0.06870853056872306, \"time-step\": 3507}, {\"errors\": 0.06865653715084641, \"time-step\": 3508}, {\"errors\": 0.06860447531190603, \"time-step\": 3509}, {\"errors\": 0.06855234511757508, \"time-step\": 3510}, {\"errors\": 0.06850014663497565, \"time-step\": 3511}, {\"errors\": 0.06844787993268066, \"time-step\": 3512}, {\"errors\": 0.06839554508071428, \"time-step\": 3513}, {\"errors\": 0.0683431421505534, \"time-step\": 3514}, {\"errors\": 0.0682906712151283, \"time-step\": 3515}, {\"errors\": 0.06823813234882388, \"time-step\": 3516}, {\"errors\": 0.06818552562748002, \"time-step\": 3517}, {\"errors\": 0.06813285112839276, \"time-step\": 3518}, {\"errors\": 0.06808010893031505, \"time-step\": 3519}, {\"errors\": 0.06802729911345727, \"time-step\": 3520}, {\"errors\": 0.06797442175948781, \"time-step\": 3521}, {\"errors\": 0.06792147695153389, \"time-step\": 3522}, {\"errors\": 0.06786846477418175, \"time-step\": 3523}, {\"errors\": 0.06781538531347737, \"time-step\": 3524}, {\"errors\": 0.06776223865692688, \"time-step\": 3525}, {\"errors\": 0.06770902489349657, \"time-step\": 3526}, {\"errors\": 0.06765574411361364, \"time-step\": 3527}, {\"errors\": 0.06760239640916613, \"time-step\": 3528}, {\"errors\": 0.06754898187350307, \"time-step\": 3529}, {\"errors\": 0.06749550060143489, \"time-step\": 3530}, {\"errors\": 0.06744195268923328, \"time-step\": 3531}, {\"errors\": 0.0673883382346312, \"time-step\": 3532}, {\"errors\": 0.06733465733682292, \"time-step\": 3533}, {\"errors\": 0.06728091009646385, \"time-step\": 3534}, {\"errors\": 0.06722709661567053, \"time-step\": 3535}, {\"errors\": 0.06717321699802023, \"time-step\": 3536}, {\"errors\": 0.06711927134855086, \"time-step\": 3537}, {\"errors\": 0.06706525977376063, \"time-step\": 3538}, {\"errors\": 0.06701118238160757, \"time-step\": 3539}, {\"errors\": 0.06695703928150937, \"time-step\": 3540}, {\"errors\": 0.06690283058434246, \"time-step\": 3541}, {\"errors\": 0.06684855640244214, \"time-step\": 3542}, {\"errors\": 0.06679421684960135, \"time-step\": 3543}, {\"errors\": 0.06673981204107046, \"time-step\": 3544}, {\"errors\": 0.06668534209355649, \"time-step\": 3545}, {\"errors\": 0.06663080712522225, \"time-step\": 3546}, {\"errors\": 0.06657620725568571, \"time-step\": 3547}, {\"errors\": 0.06652154260601915, \"time-step\": 3548}, {\"errors\": 0.06646681329874816, \"time-step\": 3549}, {\"errors\": 0.06641201945785083, \"time-step\": 3550}, {\"errors\": 0.06635716120875677, \"time-step\": 3551}, {\"errors\": 0.06630223867834589, \"time-step\": 3552}, {\"errors\": 0.06624725199494741, \"time-step\": 3553}, {\"errors\": 0.0661922012883388, \"time-step\": 3554}, {\"errors\": 0.06613708668974455, \"time-step\": 3555}, {\"errors\": 0.06608190833183489, \"time-step\": 3556}, {\"errors\": 0.06602666634872445, \"time-step\": 3557}, {\"errors\": 0.06597136087597086, \"time-step\": 3558}, {\"errors\": 0.06591599205057369, \"time-step\": 3559}, {\"errors\": 0.06586056001097271, \"time-step\": 3560}, {\"errors\": 0.06580506489704642, \"time-step\": 3561}, {\"errors\": 0.0657495068501106, \"time-step\": 3562}, {\"errors\": 0.06569388601291669, \"time-step\": 3563}, {\"errors\": 0.0656382025296501, \"time-step\": 3564}, {\"errors\": 0.06558245654592865, \"time-step\": 3565}, {\"errors\": 0.06552664820880061, \"time-step\": 3566}, {\"errors\": 0.06547077766674335, \"time-step\": 3567}, {\"errors\": 0.06541484506966094, \"time-step\": 3568}, {\"errors\": 0.06535885056888267, \"time-step\": 3569}, {\"errors\": 0.06530279431716102, \"time-step\": 3570}, {\"errors\": 0.06524667646866969, \"time-step\": 3571}, {\"errors\": 0.06519049717900155, \"time-step\": 3572}, {\"errors\": 0.06513425660516658, \"time-step\": 3573}, {\"errors\": 0.06507795490558979, \"time-step\": 3574}, {\"errors\": 0.06502159224010907, \"time-step\": 3575}, {\"errors\": 0.064965168769973, \"time-step\": 3576}, {\"errors\": 0.06490868465783844, \"time-step\": 3577}, {\"errors\": 0.0648521400677684, \"time-step\": 3578}, {\"errors\": 0.06479553516522973, \"time-step\": 3579}, {\"errors\": 0.06473887011709072, \"time-step\": 3580}, {\"errors\": 0.06468214509161825, \"time-step\": 3581}, {\"errors\": 0.06462536025847607, \"time-step\": 3582}, {\"errors\": 0.06456851578872169, \"time-step\": 3583}, {\"errors\": 0.06451161185480404, \"time-step\": 3584}, {\"errors\": 0.06445464863056077, \"time-step\": 3585}, {\"errors\": 0.06439762629121565, \"time-step\": 3586}, {\"errors\": 0.06434054501337588, \"time-step\": 3587}, {\"errors\": 0.0642834049750294, \"time-step\": 3588}, {\"errors\": 0.06422620635554185, \"time-step\": 3589}, {\"errors\": 0.0641689493356541, \"time-step\": 3590}, {\"errors\": 0.06411163409747912, \"time-step\": 3591}, {\"errors\": 0.06405426082449912, \"time-step\": 3592}, {\"errors\": 0.06399682970156259, \"time-step\": 3593}, {\"errors\": 0.06393934091488147, \"time-step\": 3594}, {\"errors\": 0.06388179465202763, \"time-step\": 3595}, {\"errors\": 0.0638241911019305, \"time-step\": 3596}, {\"errors\": 0.06376653045487307, \"time-step\": 3597}, {\"errors\": 0.06370881290248968, \"time-step\": 3598}, {\"errors\": 0.06365103863776189, \"time-step\": 3599}, {\"errors\": 0.06359320785501592, \"time-step\": 3600}, {\"errors\": 0.0635353207499189, \"time-step\": 3601}, {\"errors\": 0.06347737751947569, \"time-step\": 3602}, {\"errors\": 0.06341937836202564, \"time-step\": 3603}, {\"errors\": 0.06336132347723891, \"time-step\": 3604}, {\"errors\": 0.06330321306611307, \"time-step\": 3605}, {\"errors\": 0.06324504733096982, \"time-step\": 3606}, {\"errors\": 0.06318682647545117, \"time-step\": 3607}, {\"errors\": 0.06312855070451591, \"time-step\": 3608}, {\"errors\": 0.0630702202244359, \"time-step\": 3609}, {\"errors\": 0.06301183524279286, \"time-step\": 3610}, {\"errors\": 0.06295339596847396, \"time-step\": 3611}, {\"errors\": 0.06289490261166855, \"time-step\": 3612}, {\"errors\": 0.06283635538386426, \"time-step\": 3613}, {\"errors\": 0.06277775449784312, \"time-step\": 3614}, {\"errors\": 0.06271910016767769, \"time-step\": 3615}, {\"errors\": 0.06266039260872716, \"time-step\": 3616}, {\"errors\": 0.06260163203763328, \"time-step\": 3617}, {\"errors\": 0.06254281867231683, \"time-step\": 3618}, {\"errors\": 0.062483952731972825, \"time-step\": 3619}, {\"errors\": 0.06242503443706708, \"time-step\": 3620}, {\"errors\": 0.062366064009331895, \"time-step\": 3621}, {\"errors\": 0.06230704167176171, \"time-step\": 3622}, {\"errors\": 0.06224796764860923, \"time-step\": 3623}, {\"errors\": 0.062188842165380995, \"time-step\": 3624}, {\"errors\": 0.06212966544883317, \"time-step\": 3625}, {\"errors\": 0.06207043772696719, \"time-step\": 3626}, {\"errors\": 0.06201115922902539, \"time-step\": 3627}, {\"errors\": 0.061951830185486854, \"time-step\": 3628}, {\"errors\": 0.061892450828062634, \"time-step\": 3629}, {\"errors\": 0.061833021389691385, \"time-step\": 3630}, {\"errors\": 0.061773542104535145, \"time-step\": 3631}, {\"errors\": 0.0617140132079744, \"time-step\": 3632}, {\"errors\": 0.06165443493660358, \"time-step\": 3633}, {\"errors\": 0.061594807528226866, \"time-step\": 3634}, {\"errors\": 0.06153513122185275, \"time-step\": 3635}, {\"errors\": 0.061475406257690005, \"time-step\": 3636}, {\"errors\": 0.06141563287714272, \"time-step\": 3637}, {\"errors\": 0.061355811322805376, \"time-step\": 3638}, {\"errors\": 0.061295941838458295, \"time-step\": 3639}, {\"errors\": 0.061236024669062424, \"time-step\": 3640}, {\"errors\": 0.06117606006075492, \"time-step\": 3641}, {\"errors\": 0.06111604826084377, \"time-step\": 3642}, {\"errors\": 0.06105598951780314, \"time-step\": 3643}, {\"errors\": 0.060995884081268034, \"time-step\": 3644}, {\"errors\": 0.06093573220202972, \"time-step\": 3645}, {\"errors\": 0.06087553413203009, \"time-step\": 3646}, {\"errors\": 0.060815290124356866, \"time-step\": 3647}, {\"errors\": 0.060755000433238615, \"time-step\": 3648}, {\"errors\": 0.060694665314038956, \"time-step\": 3649}, {\"errors\": 0.060634285023251897, \"time-step\": 3650}, {\"errors\": 0.06057385981849624, \"time-step\": 3651}, {\"errors\": 0.06051338995851034, \"time-step\": 3652}, {\"errors\": 0.06045287570314685, \"time-step\": 3653}, {\"errors\": 0.06039231731336702, \"time-step\": 3654}, {\"errors\": 0.060331715051235746, \"time-step\": 3655}, {\"errors\": 0.06027106917991564, \"time-step\": 3656}, {\"errors\": 0.06021037996366174, \"time-step\": 3657}, {\"errors\": 0.06014964766781597, \"time-step\": 3658}, {\"errors\": 0.06008887255880152, \"time-step\": 3659}, {\"errors\": 0.060028054904117126, \"time-step\": 3660}, {\"errors\": 0.059967194972331606, \"time-step\": 3661}, {\"errors\": 0.059906293033077956, \"time-step\": 3662}, {\"errors\": 0.05984534935704779, \"time-step\": 3663}, {\"errors\": 0.05978436421598536, \"time-step\": 3664}, {\"errors\": 0.059723337882681915, \"time-step\": 3665}, {\"errors\": 0.059662270630969884, \"time-step\": 3666}, {\"errors\": 0.059601162735716647, \"time-step\": 3667}, {\"errors\": 0.059540014472819015, \"time-step\": 3668}, {\"errors\": 0.05947882611919706, \"time-step\": 3669}, {\"errors\": 0.059417597952788156, \"time-step\": 3670}, {\"errors\": 0.05935633025254086, \"time-step\": 3671}, {\"errors\": 0.059295023298408925, \"time-step\": 3672}, {\"errors\": 0.059233677371345064, \"time-step\": 3673}, {\"errors\": 0.05917229275329492, \"time-step\": 3674}, {\"errors\": 0.05911086972719091, \"time-step\": 3675}, {\"errors\": 0.059049408576945656, \"time-step\": 3676}, {\"errors\": 0.058987909587446166, \"time-step\": 3677}, {\"errors\": 0.05892637304454713, \"time-step\": 3678}, {\"errors\": 0.05886479923506498, \"time-step\": 3679}, {\"errors\": 0.05880318844677103, \"time-step\": 3680}, {\"errors\": 0.058741540968385325, \"time-step\": 3681}, {\"errors\": 0.058679857089570325, \"time-step\": 3682}, {\"errors\": 0.05861813710092404, \"time-step\": 3683}, {\"errors\": 0.05855638129397369, \"time-step\": 3684}, {\"errors\": 0.058494589961169186, \"time-step\": 3685}, {\"errors\": 0.05843276339587651, \"time-step\": 3686}, {\"errors\": 0.058370901892370694, \"time-step\": 3687}, {\"errors\": 0.0583090057458298, \"time-step\": 3688}, {\"errors\": 0.05824707525232753, \"time-step\": 3689}, {\"errors\": 0.058185110708826995, \"time-step\": 3690}, {\"errors\": 0.05812311241317353, \"time-step\": 3691}, {\"errors\": 0.05806108066408801, \"time-step\": 3692}, {\"errors\": 0.057999015761160094, \"time-step\": 3693}, {\"errors\": 0.057936918004840944, \"time-step\": 3694}, {\"errors\": 0.05787478769643687, \"time-step\": 3695}, {\"errors\": 0.0578126251381015, \"time-step\": 3696}, {\"errors\": 0.05775043063282978, \"time-step\": 3697}, {\"errors\": 0.0576882044844499, \"time-step\": 3698}, {\"errors\": 0.05762594699761694, \"time-step\": 3699}, {\"errors\": 0.05756365847780551, \"time-step\": 3700}, {\"errors\": 0.05750133923130223, \"time-step\": 3701}, {\"errors\": 0.057438989565199175, \"time-step\": 3702}, {\"errors\": 0.057376609787386054, \"time-step\": 3703}, {\"errors\": 0.057314200206543174, \"time-step\": 3704}, {\"errors\": 0.05725176113213415, \"time-step\": 3705}, {\"errors\": 0.05718929287439849, \"time-step\": 3706}, {\"errors\": 0.05712679574434419, \"time-step\": 3707}, {\"errors\": 0.057064270053740374, \"time-step\": 3708}, {\"errors\": 0.05700171611510978, \"time-step\": 3709}, {\"errors\": 0.056939134241721166, \"time-step\": 3710}, {\"errors\": 0.05687652474758204, \"time-step\": 3711}, {\"errors\": 0.056813887947430794, \"time-step\": 3712}, {\"errors\": 0.05675122415672938, \"time-step\": 3713}, {\"errors\": 0.05668853369165536, \"time-step\": 3714}, {\"errors\": 0.05662581686909457, \"time-step\": 3715}, {\"errors\": 0.056563074006633074, \"time-step\": 3716}, {\"errors\": 0.056500305422549704, \"time-step\": 3717}, {\"errors\": 0.056437511435808205, \"time-step\": 3718}, {\"errors\": 0.056374692366049126, \"time-step\": 3719}, {\"errors\": 0.0563118485335825, \"time-step\": 3720}, {\"errors\": 0.05624898025937959, \"time-step\": 3721}, {\"errors\": 0.05618608786506509, \"time-step\": 3722}, {\"errors\": 0.05612317167290902, \"time-step\": 3723}, {\"errors\": 0.0560602320058191, \"time-step\": 3724}, {\"errors\": 0.05599726918733236, \"time-step\": 3725}, {\"errors\": 0.05593428354160729, \"time-step\": 3726}, {\"errors\": 0.05587127539341574, \"time-step\": 3727}, {\"errors\": 0.055808245068134754, \"time-step\": 3728}, {\"errors\": 0.05574519289173844, \"time-step\": 3729}, {\"errors\": 0.05568211919078983, \"time-step\": 3730}, {\"errors\": 0.055619024292432574, \"time-step\": 3731}, {\"errors\": 0.05555590852438288, \"time-step\": 3732}, {\"errors\": 0.055492772214921, \"time-step\": 3733}, {\"errors\": 0.05542961569288317, \"time-step\": 3734}, {\"errors\": 0.05536643928765299, \"time-step\": 3735}, {\"errors\": 0.05530324332915343, \"time-step\": 3736}, {\"errors\": 0.055240028147837975, \"time-step\": 3737}, {\"errors\": 0.055176794074682685, \"time-step\": 3738}, {\"errors\": 0.055113541441177305, \"time-step\": 3739}, {\"errors\": 0.05505027057931708, \"time-step\": 3740}, {\"errors\": 0.05498698182159406, \"time-step\": 3741}, {\"errors\": 0.05492367550098871, \"time-step\": 3742}, {\"errors\": 0.054860351950961186, \"time-step\": 3743}, {\"errors\": 0.05479701150544286, \"time-step\": 3744}, {\"errors\": 0.05473365449882746, \"time-step\": 3745}, {\"errors\": 0.054670281265962725, \"time-step\": 3746}, {\"errors\": 0.054606892142141636, \"time-step\": 3747}, {\"errors\": 0.054543487463093454, \"time-step\": 3748}, {\"errors\": 0.054480067564975226, \"time-step\": 3749}, {\"errors\": 0.054416632784363074, \"time-step\": 3750}, {\"errors\": 0.05435318345824312, \"time-step\": 3751}, {\"errors\": 0.054289719924003006, \"time-step\": 3752}, {\"errors\": 0.05422624251942271, \"time-step\": 3753}, {\"errors\": 0.05416275158266596, \"time-step\": 3754}, {\"errors\": 0.05409924745227127, \"time-step\": 3755}, {\"errors\": 0.054035730467142815, \"time-step\": 3756}, {\"errors\": 0.053972200966541775, \"time-step\": 3757}, {\"errors\": 0.053908659290077335, \"time-step\": 3758}, {\"errors\": 0.053845105777697425, \"time-step\": 3759}, {\"errors\": 0.053781540769680045, \"time-step\": 3760}, {\"errors\": 0.0537179646066241, \"time-step\": 3761}, {\"errors\": 0.05365437762944025, \"time-step\": 3762}, {\"errors\": 0.053590780179341935, \"time-step\": 3763}, {\"errors\": 0.053527172597836264, \"time-step\": 3764}, {\"errors\": 0.0534635552267151, \"time-step\": 3765}, {\"errors\": 0.053399928408045375, \"time-step\": 3766}, {\"errors\": 0.0533362924841605, \"time-step\": 3767}, {\"errors\": 0.053272647797650965, \"time-step\": 3768}, {\"errors\": 0.05320899469135512, \"time-step\": 3769}, {\"errors\": 0.053145333508349935, \"time-step\": 3770}, {\"errors\": 0.053081664591941906, \"time-step\": 3771}, {\"errors\": 0.05301798828565771, \"time-step\": 3772}, {\"errors\": 0.052954304933234886, \"time-step\": 3773}, {\"errors\": 0.0528906148786127, \"time-step\": 3774}, {\"errors\": 0.052826918465922766, \"time-step\": 3775}, {\"errors\": 0.052763216039479616, \"time-step\": 3776}, {\"errors\": 0.0526995079437717, \"time-step\": 3777}, {\"errors\": 0.05263579452345167, \"time-step\": 3778}, {\"errors\": 0.052572076123327205, \"time-step\": 3779}, {\"errors\": 0.05250835308835168, \"time-step\": 3780}, {\"errors\": 0.05244462576361471, \"time-step\": 3781}, {\"errors\": 0.05238089449433264, \"time-step\": 3782}, {\"errors\": 0.05231715962583952, \"time-step\": 3783}, {\"errors\": 0.05225342150357714, \"time-step\": 3784}, {\"errors\": 0.05218968047308617, \"time-step\": 3785}, {\"errors\": 0.05212593687999621, \"time-step\": 3786}, {\"errors\": 0.05206219107001667, \"time-step\": 3787}, {\"errors\": 0.05199844338892711, \"time-step\": 3788}, {\"errors\": 0.05193469418256805, \"time-step\": 3789}, {\"errors\": 0.05187094379683116, \"time-step\": 3790}, {\"errors\": 0.051807192577649916, \"time-step\": 3791}, {\"errors\": 0.05174344087099016, \"time-step\": 3792}, {\"errors\": 0.05167968902284056, \"time-step\": 3793}, {\"errors\": 0.051615937379203156, \"time-step\": 3794}, {\"errors\": 0.05155218628608367, \"time-step\": 3795}, {\"errors\": 0.05148843608948211, \"time-step\": 3796}, {\"errors\": 0.05142468713538343, \"time-step\": 3797}, {\"errors\": 0.051360939769747635, \"time-step\": 3798}, {\"errors\": 0.051297194338500524, \"time-step\": 3799}, {\"errors\": 0.051233451187524134, \"time-step\": 3800}, {\"errors\": 0.051169710662647014, \"time-step\": 3801}, {\"errors\": 0.05110597310963502, \"time-step\": 3802}, {\"errors\": 0.0510422388741815, \"time-step\": 3803}, {\"errors\": 0.05097850830189779, \"time-step\": 3804}, {\"errors\": 0.05091478173830391, \"time-step\": 3805}, {\"errors\": 0.0508510595288187, \"time-step\": 3806}, {\"errors\": 0.050787342018750535, \"time-step\": 3807}, {\"errors\": 0.05072362955328781, \"time-step\": 3808}, {\"errors\": 0.0506599224774891, \"time-step\": 3809}, {\"errors\": 0.05059622113627406, \"time-step\": 3810}, {\"errors\": 0.0505325258744136, \"time-step\": 3811}, {\"errors\": 0.050468837036520484, \"time-step\": 3812}, {\"errors\": 0.050405154967039754, \"time-step\": 3813}, {\"errors\": 0.050341480010239414, \"time-step\": 3814}, {\"errors\": 0.050277812510200665, \"time-step\": 3815}, {\"errors\": 0.05021415281080868, \"time-step\": 3816}, {\"errors\": 0.050150501255742774, \"time-step\": 3817}, {\"errors\": 0.050086858188467365, \"time-step\": 3818}, {\"errors\": 0.050023223952222085, \"time-step\": 3819}, {\"errors\": 0.04995959889001271, \"time-step\": 3820}, {\"errors\": 0.04989598334460135, \"time-step\": 3821}, {\"errors\": 0.04983237765849734, \"time-step\": 3822}, {\"errors\": 0.04976878217394748, \"time-step\": 3823}, {\"errors\": 0.049705197232926976, \"time-step\": 3824}, {\"errors\": 0.04964162317712975, \"time-step\": 3825}, {\"errors\": 0.04957806034795926, \"time-step\": 3826}, {\"errors\": 0.04951450908651889, \"time-step\": 3827}, {\"errors\": 0.049450969733602815, \"time-step\": 3828}, {\"errors\": 0.049387442629686626, \"time-step\": 3829}, {\"errors\": 0.04932392811491784, \"time-step\": 3830}, {\"errors\": 0.04926042652910685, \"time-step\": 3831}, {\"errors\": 0.049196938211717244, \"time-step\": 3832}, {\"errors\": 0.049133463501856975, \"time-step\": 3833}, {\"errors\": 0.04907000273826878, \"time-step\": 3834}, {\"errors\": 0.04900655625932099, \"time-step\": 3835}, {\"errors\": 0.04894312440299839, \"time-step\": 3836}, {\"errors\": 0.04887970750689313, \"time-step\": 3837}, {\"errors\": 0.04881630590819519, \"time-step\": 3838}, {\"errors\": 0.04875291994368347, \"time-step\": 3839}, {\"errors\": 0.0486895499497167, \"time-step\": 3840}, {\"errors\": 0.048626196262224225, \"time-step\": 3841}, {\"errors\": 0.04856285921669673, \"time-step\": 3842}, {\"errors\": 0.04849953914817751, \"time-step\": 3843}, {\"errors\": 0.04843623639125323, \"time-step\": 3844}, {\"errors\": 0.04837295128004513, \"time-step\": 3845}, {\"errors\": 0.04830968414819942, \"time-step\": 3846}, {\"errors\": 0.04824643532887912, \"time-step\": 3847}, {\"errors\": 0.04818320515475455, \"time-step\": 3848}, {\"errors\": 0.048119993957994614, \"time-step\": 3849}, {\"errors\": 0.04805680207025785, \"time-step\": 3850}, {\"errors\": 0.047993629822683744, \"time-step\": 3851}, {\"errors\": 0.04793047754588363, \"time-step\": 3852}, {\"errors\": 0.047867345569932065, \"time-step\": 3853}, {\"errors\": 0.04780423422435809, \"time-step\": 3854}, {\"errors\": 0.047741143838136324, \"time-step\": 3855}, {\"errors\": 0.047678074739678285, \"time-step\": 3856}, {\"errors\": 0.04761502725682399, \"time-step\": 3857}, {\"errors\": 0.0475520017168329, \"time-step\": 3858}, {\"errors\": 0.04748899844637559, \"time-step\": 3859}, {\"errors\": 0.04742601777152507, \"time-step\": 3860}, {\"errors\": 0.047363060017748336, \"time-step\": 3861}, {\"errors\": 0.047300125509897574, \"time-step\": 3862}, {\"errors\": 0.047237214572202126, \"time-step\": 3863}, {\"errors\": 0.04717432752825962, \"time-step\": 3864}, {\"errors\": 0.04711146470102798, \"time-step\": 3865}, {\"errors\": 0.04704862641281665, \"time-step\": 3866}, {\"errors\": 0.046985812985278555, \"time-step\": 3867}, {\"errors\": 0.04692302473940179, \"time-step\": 3868}, {\"errors\": 0.04686026199550118, \"time-step\": 3869}, {\"errors\": 0.0467975250732103, \"time-step\": 3870}, {\"errors\": 0.046734814291473074, \"time-step\": 3871}, {\"errors\": 0.046672129968535904, \"time-step\": 3872}, {\"errors\": 0.04660947242193932, \"time-step\": 3873}, {\"errors\": 0.04654684196851015, \"time-step\": 3874}, {\"errors\": 0.04648423892435333, \"time-step\": 3875}, {\"errors\": 0.04642166360484408, \"time-step\": 3876}, {\"errors\": 0.046359116324619934, \"time-step\": 3877}, {\"errors\": 0.04629659739757272, \"time-step\": 3878}, {\"errors\": 0.04623410713684109, \"time-step\": 3879}, {\"errors\": 0.046171645854802254, \"time-step\": 3880}, {\"errors\": 0.04610921386306457, \"time-step\": 3881}, {\"errors\": 0.04604681147245976, \"time-step\": 3882}, {\"errors\": 0.04598443899303516, \"time-step\": 3883}, {\"errors\": 0.04592209673404632, \"time-step\": 3884}, {\"errors\": 0.04585978500394913, \"time-step\": 3885}, {\"errors\": 0.04579750411039264, \"time-step\": 3886}, {\"errors\": 0.04573525436021128, \"time-step\": 3887}, {\"errors\": 0.04567303605941774, \"time-step\": 3888}, {\"errors\": 0.04561084951319531, \"time-step\": 3889}, {\"errors\": 0.045548695025890686, \"time-step\": 3890}, {\"errors\": 0.04548657290100686, \"time-step\": 3891}, {\"errors\": 0.04542448344119552, \"time-step\": 3892}, {\"errors\": 0.04536242694825025, \"time-step\": 3893}, {\"errors\": 0.0453004037230991, \"time-step\": 3894}, {\"errors\": 0.0452384140657978, \"time-step\": 3895}, {\"errors\": 0.04517645827552248, \"time-step\": 3896}, {\"errors\": 0.04511453665056284, \"time-step\": 3897}, {\"errors\": 0.04505264948831518, \"time-step\": 3898}, {\"errors\": 0.044990797085275654, \"time-step\": 3899}, {\"errors\": 0.04492897973703307, \"time-step\": 3900}, {\"errors\": 0.04486719773826282, \"time-step\": 3901}, {\"errors\": 0.04480545138271941, \"time-step\": 3902}, {\"errors\": 0.04474374096323032, \"time-step\": 3903}, {\"errors\": 0.04468206677168925, \"time-step\": 3904}, {\"errors\": 0.04462042909904951, \"time-step\": 3905}, {\"errors\": 0.04455882823531764, \"time-step\": 3906}, {\"errors\": 0.04449726446954691, \"time-step\": 3907}, {\"errors\": 0.044435738089830895, \"time-step\": 3908}, {\"errors\": 0.044374249383297315, \"time-step\": 3909}, {\"errors\": 0.044312798636101616, \"time-step\": 3910}, {\"errors\": 0.044251386133420806, \"time-step\": 3911}, {\"errors\": 0.04419001215944729, \"time-step\": 3912}, {\"errors\": 0.0441286769973828, \"time-step\": 3913}, {\"errors\": 0.04406738092943246, \"time-step\": 3914}, {\"errors\": 0.04400612423679842, \"time-step\": 3915}, {\"errors\": 0.04394490719967452, \"time-step\": 3916}, {\"errors\": 0.04388373009723985, \"time-step\": 3917}, {\"errors\": 0.0438225932076534, \"time-step\": 3918}, {\"errors\": 0.04376149680804799, \"time-step\": 3919}, {\"errors\": 0.04370044117452467, \"time-step\": 3920}, {\"errors\": 0.043639426582147325, \"time-step\": 3921}, {\"errors\": 0.04357845330493672, \"time-step\": 3922}, {\"errors\": 0.0435175216158652, \"time-step\": 3923}, {\"errors\": 0.04345663178685142, \"time-step\": 3924}, {\"errors\": 0.04339578408875443, \"time-step\": 3925}, {\"errors\": 0.04333497879136886, \"time-step\": 3926}, {\"errors\": 0.04327421616341953, \"time-step\": 3927}, {\"errors\": 0.04321349647255601, \"time-step\": 3928}, {\"errors\": 0.04315281998534779, \"time-step\": 3929}, {\"errors\": 0.04309218696727885, \"time-step\": 3930}, {\"errors\": 0.04303159768274306, \"time-step\": 3931}, {\"errors\": 0.042971052395038845, \"time-step\": 3932}, {\"errors\": 0.04291055136636446, \"time-step\": 3933}, {\"errors\": 0.04285009485781305, \"time-step\": 3934}, {\"errors\": 0.04278968312936811, \"time-step\": 3935}, {\"errors\": 0.04272931643989843, \"time-step\": 3936}, {\"errors\": 0.042668995047153754, \"time-step\": 3937}, {\"errors\": 0.04260871920775991, \"time-step\": 3938}, {\"errors\": 0.04254848917721457, \"time-step\": 3939}, {\"errors\": 0.042488305209882476, \"time-step\": 3940}, {\"errors\": 0.04242816755899138, \"time-step\": 3941}, {\"errors\": 0.04236807647662742, \"time-step\": 3942}, {\"errors\": 0.04230803221373105, \"time-step\": 3943}, {\"errors\": 0.04224803502009257, \"time-step\": 3944}, {\"errors\": 0.04218808514434829, \"time-step\": 3945}, {\"errors\": 0.04212818283397626, \"time-step\": 3946}, {\"errors\": 0.0420683283352922, \"time-step\": 3947}, {\"errors\": 0.04200852189344574, \"time-step\": 3948}, {\"errors\": 0.04194876375241635, \"time-step\": 3949}, {\"errors\": 0.041889054155009535, \"time-step\": 3950}, {\"errors\": 0.04182939334285323, \"time-step\": 3951}, {\"errors\": 0.04176978155639379, \"time-step\": 3952}, {\"errors\": 0.04171021903489261, \"time-step\": 3953}, {\"errors\": 0.04165070601642251, \"time-step\": 3954}, {\"errors\": 0.04159124273786406, \"time-step\": 3955}, {\"errors\": 0.0415318294349024, \"time-step\": 3956}, {\"errors\": 0.041472466342023534, \"time-step\": 3957}, {\"errors\": 0.041413153692511265, \"time-step\": 3958}, {\"errors\": 0.04135389171844388, \"time-step\": 3959}, {\"errors\": 0.04129468065069081, \"time-step\": 3960}, {\"errors\": 0.04123552071890969, \"time-step\": 3961}, {\"errors\": 0.04117641215154332, \"time-step\": 3962}, {\"errors\": 0.04111735517581634, \"time-step\": 3963}, {\"errors\": 0.04105835001773262, \"time-step\": 3964}, {\"errors\": 0.04099939690207233, \"time-step\": 3965}, {\"errors\": 0.04094049605238895, \"time-step\": 3966}, {\"errors\": 0.04088164769100672, \"time-step\": 3967}, {\"errors\": 0.040822852039017865, \"time-step\": 3968}, {\"errors\": 0.04076410931628004, \"time-step\": 3969}, {\"errors\": 0.04070541974141367, \"time-step\": 3970}, {\"errors\": 0.04064678353179948, \"time-step\": 3971}, {\"errors\": 0.04058820090357611, \"time-step\": 3972}, {\"errors\": 0.040529672071637796, \"time-step\": 3973}, {\"errors\": 0.040471197249631934, \"time-step\": 3974}, {\"errors\": 0.04041277664995686, \"time-step\": 3975}, {\"errors\": 0.04035441048375989, \"time-step\": 3976}, {\"errors\": 0.040296098960934834, \"time-step\": 3977}, {\"errors\": 0.0402378422901202, \"time-step\": 3978}, {\"errors\": 0.04017964067869719, \"time-step\": 3979}, {\"errors\": 0.0401214943327877, \"time-step\": 3980}, {\"errors\": 0.04006340345725244, \"time-step\": 3981}, {\"errors\": 0.0400053682556892, \"time-step\": 3982}, {\"errors\": 0.039947388930431066, \"time-step\": 3983}, {\"errors\": 0.0398894656825448, \"time-step\": 3984}, {\"errors\": 0.03983159871182905, \"time-step\": 3985}, {\"errors\": 0.039773788216813016, \"time-step\": 3986}, {\"errors\": 0.03971603439475485, \"time-step\": 3987}, {\"errors\": 0.0396583374416402, \"time-step\": 3988}, {\"errors\": 0.039600697552180854, \"time-step\": 3989}, {\"errors\": 0.03954311491981349, \"time-step\": 3990}, {\"errors\": 0.03948558973669822, \"time-step\": 3991}, {\"errors\": 0.039428122193717885, \"time-step\": 3992}, {\"errors\": 0.039370712480476217, \"time-step\": 3993}, {\"errors\": 0.03931336078529733, \"time-step\": 3994}, {\"errors\": 0.03925606729522453, \"time-step\": 3995}, {\"errors\": 0.03919883219601937, \"time-step\": 3996}, {\"errors\": 0.039141655672160755, \"time-step\": 3997}, {\"errors\": 0.03908453790684395, \"time-step\": 3998}, {\"errors\": 0.039027479081980246, \"time-step\": 3999}, {\"errors\": 0.03897047937819571, \"time-step\": 4000}, {\"errors\": 0.038913538974830957, \"time-step\": 4001}, {\"errors\": 0.03885665804994024, \"time-step\": 4002}, {\"errors\": 0.03879983678029131, \"time-step\": 4003}, {\"errors\": 0.038743075341364376, \"time-step\": 4004}, {\"errors\": 0.03868637390735222, \"time-step\": 4005}, {\"errors\": 0.03862973265115956, \"time-step\": 4006}, {\"errors\": 0.03857315174440268, \"time-step\": 4007}, {\"errors\": 0.03851663135740943, \"time-step\": 4008}, {\"errors\": 0.038460171659218875, \"time-step\": 4009}, {\"errors\": 0.03840377281758112, \"time-step\": 4010}, {\"errors\": 0.03834743499895733, \"time-step\": 4011}, {\"errors\": 0.038291158368519665, \"time-step\": 4012}, {\"errors\": 0.03823494309015138, \"time-step\": 4013}, {\"errors\": 0.0381787893264467, \"time-step\": 4014}, {\"errors\": 0.038122697238711256, \"time-step\": 4015}, {\"errors\": 0.03806666698696205, \"time-step\": 4016}, {\"errors\": 0.038010698729927836, \"time-step\": 4017}, {\"errors\": 0.03795479262504943, \"time-step\": 4018}, {\"errors\": 0.03789894882847989, \"time-step\": 4019}, {\"errors\": 0.03784316749508517, \"time-step\": 4020}, {\"errors\": 0.03778744877844458, \"time-step\": 4021}, {\"errors\": 0.03773179283085101, \"time-step\": 4022}, {\"errors\": 0.037676199803311855, \"time-step\": 4023}, {\"errors\": 0.03762066984554934, \"time-step\": 4024}, {\"errors\": 0.03756520310600169, \"time-step\": 4025}, {\"errors\": 0.03750979973182311, \"time-step\": 4026}, {\"errors\": 0.03745445986888524, \"time-step\": 4027}, {\"errors\": 0.037399183661777705, \"time-step\": 4028}, {\"errors\": 0.03734397125380897, \"time-step\": 4029}, {\"errors\": 0.03728882278700737, \"time-step\": 4030}, {\"errors\": 0.03723373840212204, \"time-step\": 4031}, {\"errors\": 0.03717871823862401, \"time-step\": 4032}, {\"errors\": 0.037123762434707164, \"time-step\": 4033}, {\"errors\": 0.037068871127289627, \"time-step\": 4034}, {\"errors\": 0.03701404445201468, \"time-step\": 4035}, {\"errors\": 0.03695928254325202, \"time-step\": 4036}, {\"errors\": 0.03690458553409927, \"time-step\": 4037}, {\"errors\": 0.036849953556383076, \"time-step\": 4038}, {\"errors\": 0.03679538674066065, \"time-step\": 4039}, {\"errors\": 0.036740885216221, \"time-step\": 4040}, {\"errors\": 0.03668644911108658, \"time-step\": 4041}, {\"errors\": 0.03663207855201474, \"time-step\": 4042}, {\"errors\": 0.036577773664499276, \"time-step\": 4043}, {\"errors\": 0.03652353457277209, \"time-step\": 4044}, {\"errors\": 0.036469361399804646, \"time-step\": 4045}, {\"errors\": 0.0364152542673102, \"time-step\": 4046}, {\"errors\": 0.03636121329574477, \"time-step\": 4047}, {\"errors\": 0.03630723860430964, \"time-step\": 4048}, {\"errors\": 0.0362533303109527, \"time-step\": 4049}, {\"errors\": 0.036199488532370705, \"time-step\": 4050}, {\"errors\": 0.036145713384010736, \"time-step\": 4051}, {\"errors\": 0.03609200498007278, \"time-step\": 4052}, {\"errors\": 0.036038363433511064, \"time-step\": 4053}, {\"errors\": 0.0359847888560367, \"time-step\": 4054}, {\"errors\": 0.03593128135811936, \"time-step\": 4055}, {\"errors\": 0.03587784104898967, \"time-step\": 4056}, {\"errors\": 0.03582446803664115, \"time-step\": 4057}, {\"errors\": 0.035771162427832605, \"time-step\": 4058}, {\"errors\": 0.03571792432809035, \"time-step\": 4059}, {\"errors\": 0.03566475384171058, \"time-step\": 4060}, {\"errors\": 0.035611651071761445, \"time-step\": 4061}, {\"errors\": 0.03555861612008565, \"time-step\": 4062}, {\"errors\": 0.035505649087302846, \"time-step\": 4063}, {\"errors\": 0.035452750072812025, \"time-step\": 4064}, {\"errors\": 0.035399919174794056, \"time-step\": 4065}, {\"errors\": 0.03534715649021417, \"time-step\": 4066}, {\"errors\": 0.03529446211482456, \"time-step\": 4067}, {\"errors\": 0.03524183614316692, \"time-step\": 4068}, {\"errors\": 0.03518927866857516, \"time-step\": 4069}, {\"errors\": 0.03513678978317815, \"time-step\": 4070}, {\"errors\": 0.03508436957790219, \"time-step\": 4071}, {\"errors\": 0.03503201814247394, \"time-step\": 4072}, {\"errors\": 0.03497973556542334, \"time-step\": 4073}, {\"errors\": 0.03492752193408599, \"time-step\": 4074}, {\"errors\": 0.034875377334606425, \"time-step\": 4075}, {\"errors\": 0.03482330185194078, \"time-step\": 4076}, {\"errors\": 0.034771295569859854, \"time-step\": 4077}, {\"errors\": 0.03471935857095189, \"time-step\": 4078}, {\"errors\": 0.03466749093662573, \"time-step\": 4079}, {\"errors\": 0.034615692747113624, \"time-step\": 4080}, {\"errors\": 0.03456396408147453, \"time-step\": 4081}, {\"errors\": 0.03451230501759702, \"time-step\": 4082}, {\"errors\": 0.03446071563220248, \"time-step\": 4083}, {\"errors\": 0.03440919600084814, \"time-step\": 4084}, {\"errors\": 0.034357746197930444, \"time-step\": 4085}, {\"errors\": 0.034306366296688, \"time-step\": 4086}, {\"errors\": 0.034255056369205054, \"time-step\": 4087}, {\"errors\": 0.03420381648641466, \"time-step\": 4088}, {\"errors\": 0.03415264671810184, \"time-step\": 4089}, {\"errors\": 0.03410154713290718, \"time-step\": 4090}, {\"errors\": 0.03405051779832986, \"time-step\": 4091}, {\"errors\": 0.033999558780731354, \"time-step\": 4092}, {\"errors\": 0.03394867014533867, \"time-step\": 4093}, {\"errors\": 0.03389785195624764, \"time-step\": 4094}, {\"errors\": 0.03384710427642669, \"time-step\": 4095}, {\"errors\": 0.03379642716772004, \"time-step\": 4096}, {\"errors\": 0.03374582069085146, \"time-step\": 4097}, {\"errors\": 0.03369528490542756, \"time-step\": 4098}, {\"errors\": 0.033644819869941535, \"time-step\": 4099}, {\"errors\": 0.03359442564177673, \"time-step\": 4100}, {\"errors\": 0.033544102277210205, \"time-step\": 4101}, {\"errors\": 0.03349384983141626, \"time-step\": 4102}, {\"errors\": 0.03344366835847033, \"time-step\": 4103}, {\"errors\": 0.033393557911352525, \"time-step\": 4104}, {\"errors\": 0.03334351854195136, \"time-step\": 4105}, {\"errors\": 0.033293550301067426, \"time-step\": 4106}, {\"errors\": 0.0332436532384173, \"time-step\": 4107}, {\"errors\": 0.03319382740263711, \"time-step\": 4108}, {\"errors\": 0.03314407284128647, \"time-step\": 4109}, {\"errors\": 0.033094389600852286, \"time-step\": 4110}, {\"errors\": 0.03304477772675244, \"time-step\": 4111}, {\"errors\": 0.03299523726333993, \"time-step\": 4112}, {\"errors\": 0.03294576825390649, \"time-step\": 4113}, {\"errors\": 0.03289637074068655, \"time-step\": 4114}, {\"errors\": 0.03284704476486121, \"time-step\": 4115}, {\"errors\": 0.03279779036656213, \"time-step\": 4116}, {\"errors\": 0.032748607584875564, \"time-step\": 4117}, {\"errors\": 0.03269949645784607, \"time-step\": 4118}, {\"errors\": 0.03265045702248087, \"time-step\": 4119}, {\"errors\": 0.03260148931475363, \"time-step\": 4120}, {\"errors\": 0.03255259336960845, \"time-step\": 4121}, {\"errors\": 0.03250376922096404, \"time-step\": 4122}, {\"errors\": 0.03245501690171771, \"time-step\": 4123}, {\"errors\": 0.03240633644374939, \"time-step\": 4124}, {\"errors\": 0.03235772787792586, \"time-step\": 4125}, {\"errors\": 0.032309191234104695, \"time-step\": 4126}, {\"errors\": 0.03226072654113852, \"time-step\": 4127}, {\"errors\": 0.03221233382687899, \"time-step\": 4128}, {\"errors\": 0.03216401311818118, \"time-step\": 4129}, {\"errors\": 0.03211576444090737, \"time-step\": 4130}, {\"errors\": 0.03206758781993167, \"time-step\": 4131}, {\"errors\": 0.03201948327914388, \"time-step\": 4132}, {\"errors\": 0.03197145084145373, \"time-step\": 4133}, {\"errors\": 0.031923490528795354, \"time-step\": 4134}, {\"errors\": 0.031875602362131106, \"time-step\": 4135}, {\"errors\": 0.03182778636145615, \"time-step\": 4136}, {\"errors\": 0.03178004254580255, \"time-step\": 4137}, {\"errors\": 0.03173237093324358, \"time-step\": 4138}, {\"errors\": 0.031684771540897994, \"time-step\": 4139}, {\"errors\": 0.031637244384934204, \"time-step\": 4140}, {\"errors\": 0.03158978948057475, \"time-step\": 4141}, {\"errors\": 0.03154240684210052, \"time-step\": 4142}, {\"errors\": 0.03149509648285501, \"time-step\": 4143}, {\"errors\": 0.03144785841524883, \"time-step\": 4144}, {\"errors\": 0.031400692650763784, \"time-step\": 4145}, {\"errors\": 0.031353599199957366, \"time-step\": 4146}, {\"errors\": 0.03130657807246719, \"time-step\": 4147}, {\"errors\": 0.03125962927701515, \"time-step\": 4148}, {\"errors\": 0.031212752821411928, \"time-step\": 4149}, {\"errors\": 0.03116594871256127, \"time-step\": 4150}, {\"errors\": 0.03111921695646454, \"time-step\": 4151}, {\"errors\": 0.031072557558224904, \"time-step\": 4152}, {\"errors\": 0.03102597052205181, \"time-step\": 4153}, {\"errors\": 0.030979455851265478, \"time-step\": 4154}, {\"errors\": 0.03093301354830118, \"time-step\": 4155}, {\"errors\": 0.030886643614713688, \"time-step\": 4156}, {\"errors\": 0.030840346051181793, \"time-step\": 4157}, {\"errors\": 0.030794120857512576, \"time-step\": 4158}, {\"errors\": 0.030747968032645956, \"time-step\": 4159}, {\"errors\": 0.030701887574659067, \"time-step\": 4160}, {\"errors\": 0.030655879480770712, \"time-step\": 4161}, {\"errors\": 0.03060994374734579, \"time-step\": 4162}, {\"errors\": 0.03056408036989991, \"time-step\": 4163}, {\"errors\": 0.03051828934310348, \"time-step\": 4164}, {\"errors\": 0.030472570660786555, \"time-step\": 4165}, {\"errors\": 0.030426924315943057, \"time-step\": 4166}, {\"errors\": 0.030381350300735355, \"time-step\": 4167}, {\"errors\": 0.030335848606498603, \"time-step\": 4168}, {\"errors\": 0.030290419223745292, \"time-step\": 4169}, {\"errors\": 0.030245062142169758, \"time-step\": 4170}, {\"errors\": 0.03019977735065263, \"time-step\": 4171}, {\"errors\": 0.030154564837265196, \"time-step\": 4172}, {\"errors\": 0.03010942458927395, \"time-step\": 4173}, {\"errors\": 0.03006435659314518, \"time-step\": 4174}, {\"errors\": 0.03001936083454923, \"time-step\": 4175}, {\"errors\": 0.029974437298365186, \"time-step\": 4176}, {\"errors\": 0.02992958596868515, \"time-step\": 4177}, {\"errors\": 0.029884806828818843, \"time-step\": 4178}, {\"errors\": 0.02984009986129807, \"time-step\": 4179}, {\"errors\": 0.02979546504788117, \"time-step\": 4180}, {\"errors\": 0.029750902369557557, \"time-step\": 4181}, {\"errors\": 0.029706411806552, \"time-step\": 4182}, {\"errors\": 0.02966199333832942, \"time-step\": 4183}, {\"errors\": 0.029617646943598933, \"time-step\": 4184}, {\"errors\": 0.029573372600318858, \"time-step\": 4185}, {\"errors\": 0.02952917028570059, \"time-step\": 4186}, {\"errors\": 0.029485039976213587, \"time-step\": 4187}, {\"errors\": 0.029440981647589487, \"time-step\": 4188}, {\"errors\": 0.02939699527482675, \"time-step\": 4189}, {\"errors\": 0.02935308083219508, \"time-step\": 4190}, {\"errors\": 0.02930923829323975, \"time-step\": 4191}, {\"errors\": 0.02926546763078633, \"time-step\": 4192}, {\"errors\": 0.029221768816944875, \"time-step\": 4193}, {\"errors\": 0.029178141823114387, \"time-step\": 4194}, {\"errors\": 0.02913458661998755, \"time-step\": 4195}, {\"errors\": 0.029091103177554756, \"time-step\": 4196}, {\"errors\": 0.02904769146510886, \"time-step\": 4197}, {\"errors\": 0.029004351451249438, \"time-step\": 4198}, {\"errors\": 0.02896108310388728, \"time-step\": 4199}, {\"errors\": 0.02891788639024874, \"time-step\": 4200}, {\"errors\": 0.028874761276880295, \"time-step\": 4201}, {\"errors\": 0.02883170772965278, \"time-step\": 4202}, {\"errors\": 0.02878872571376595, \"time-step\": 4203}, {\"errors\": 0.02874581519375274, \"time-step\": 4204}, {\"errors\": 0.028702976133483778, \"time-step\": 4205}, {\"errors\": 0.028660208496171638, \"time-step\": 4206}, {\"errors\": 0.028617512244375372, \"time-step\": 4207}, {\"errors\": 0.028574887340004858, \"time-step\": 4208}, {\"errors\": 0.028532333744324966, \"time-step\": 4209}, {\"errors\": 0.028489851417960246, \"time-step\": 4210}, {\"errors\": 0.028447440320899027, \"time-step\": 4211}, {\"errors\": 0.028405100412497858, \"time-step\": 4212}, {\"errors\": 0.028362831651485943, \"time-step\": 4213}, {\"errors\": 0.0283206339959692, \"time-step\": 4214}, {\"errors\": 0.02827850740343493, \"time-step\": 4215}, {\"errors\": 0.02823645183075588, \"time-step\": 4216}, {\"errors\": 0.028194467234194727, \"time-step\": 4217}, {\"errors\": 0.028152553569408163, \"time-step\": 4218}, {\"errors\": 0.02811071079145144, \"time-step\": 4219}, {\"errors\": 0.028068938854782573, \"time-step\": 4220}, {\"errors\": 0.028027237713266456, \"time-step\": 4221}, {\"errors\": 0.02798560732017938, \"time-step\": 4222}, {\"errors\": 0.027944047628213148, \"time-step\": 4223}, {\"errors\": 0.02790255858947932, \"time-step\": 4224}, {\"errors\": 0.027861140155513553, \"time-step\": 4225}, {\"errors\": 0.02781979227727973, \"time-step\": 4226}, {\"errors\": 0.02777851490517424, \"time-step\": 4227}, {\"errors\": 0.027737307989030256, \"time-step\": 4228}, {\"errors\": 0.027696171478121718, \"time-step\": 4229}, {\"errors\": 0.02765510532116784, \"time-step\": 4230}, {\"errors\": 0.027614109466337078, \"time-step\": 4231}, {\"errors\": 0.02757318386125126, \"time-step\": 4232}, {\"errors\": 0.027532328452990047, \"time-step\": 4233}, {\"errors\": 0.027491543188094797, \"time-step\": 4234}, {\"errors\": 0.02745082801257282, \"time-step\": 4235}, {\"errors\": 0.027410182871901452, \"time-step\": 4236}, {\"errors\": 0.027369607711032397, \"time-step\": 4237}, {\"errors\": 0.027329102474395524, \"time-step\": 4238}, {\"errors\": 0.027288667105903126, \"time-step\": 4239}, {\"errors\": 0.02724830154895413, \"time-step\": 4240}, {\"errors\": 0.027208005746437964, \"time-step\": 4241}, {\"errors\": 0.027167779640738788, \"time-step\": 4242}, {\"errors\": 0.027127623173739387, \"time-step\": 4243}, {\"errors\": 0.027087536286825427, \"time-step\": 4244}, {\"errors\": 0.027047518920889323, \"time-step\": 4245}, {\"errors\": 0.02700757101633433, \"time-step\": 4246}, {\"errors\": 0.02696769251307856, \"time-step\": 4247}, {\"errors\": 0.026927883350558943, \"time-step\": 4248}, {\"errors\": 0.026888143467735312, \"time-step\": 4249}, {\"errors\": 0.02684847280309426, \"time-step\": 4250}, {\"errors\": 0.026808871294653085, \"time-step\": 4251}, {\"errors\": 0.02676933887996395, \"time-step\": 4252}, {\"errors\": 0.026729875496117675, \"time-step\": 4253}, {\"errors\": 0.02669048107974756, \"time-step\": 4254}, {\"errors\": 0.026651155567033506, \"time-step\": 4255}, {\"errors\": 0.02661189889370583, \"time-step\": 4256}, {\"errors\": 0.026572710995049147, \"time-step\": 4257}, {\"errors\": 0.026533591805906212, \"time-step\": 4258}, {\"errors\": 0.02649454126068189, \"time-step\": 4259}, {\"errors\": 0.026455559293346927, \"time-step\": 4260}, {\"errors\": 0.026416645837441823, \"time-step\": 4261}, {\"errors\": 0.026377800826080586, \"time-step\": 4262}, {\"errors\": 0.026339024191954732, \"time-step\": 4263}, {\"errors\": 0.02630031586733677, \"time-step\": 4264}, {\"errors\": 0.026261675784084292, \"time-step\": 4265}, {\"errors\": 0.02622310387364367, \"time-step\": 4266}, {\"errors\": 0.026184600067053684, \"time-step\": 4267}, {\"errors\": 0.026146164294949363, \"time-step\": 4268}, {\"errors\": 0.026107796487565785, \"time-step\": 4269}, {\"errors\": 0.02606949657474166, \"time-step\": 4270}, {\"errors\": 0.02603126448592314, \"time-step\": 4271}, {\"errors\": 0.02599310015016741, \"time-step\": 4272}, {\"errors\": 0.025955003496146514, \"time-step\": 4273}, {\"errors\": 0.025916974452150875, \"time-step\": 4274}, {\"errors\": 0.025879012946092975, \"time-step\": 4275}, {\"errors\": 0.025841118905511107, \"time-step\": 4276}, {\"errors\": 0.02580329225757287, \"time-step\": 4277}, {\"errors\": 0.025765532929078804, \"time-step\": 4278}, {\"errors\": 0.025727840846465948, \"time-step\": 4279}, {\"errors\": 0.02569021593581161, \"time-step\": 4280}, {\"errors\": 0.02565265812283663, \"time-step\": 4281}, {\"errors\": 0.025615167332909222, \"time-step\": 4282}, {\"errors\": 0.025577743491048327, \"time-step\": 4283}, {\"errors\": 0.02554038652192718, \"time-step\": 4284}, {\"errors\": 0.025503096349876818, \"time-step\": 4285}, {\"errors\": 0.02546587289888968, \"time-step\": 4286}, {\"errors\": 0.025428716092622854, \"time-step\": 4287}, {\"errors\": 0.025391625854401828, \"time-step\": 4288}, {\"errors\": 0.025354602107223685, \"time-step\": 4289}, {\"errors\": 0.0253176447737607, \"time-step\": 4290}, {\"errors\": 0.0252807537763637, \"time-step\": 4291}, {\"errors\": 0.025243929037065425, \"time-step\": 4292}, {\"errors\": 0.025207170477584136, \"time-step\": 4293}, {\"errors\": 0.02517047801932661, \"time-step\": 4294}, {\"errors\": 0.025133851583391913, \"time-step\": 4295}, {\"errors\": 0.025097291090574445, \"time-step\": 4296}, {\"errors\": 0.025060796461367447, \"time-step\": 4297}, {\"errors\": 0.025024367615966228, \"time-step\": 4298}, {\"errors\": 0.024988004474271543, \"time-step\": 4299}, {\"errors\": 0.024951706955892817, \"time-step\": 4300}, {\"errors\": 0.02491547498015139, \"time-step\": 4301}, {\"errors\": 0.02487930846608392, \"time-step\": 4302}, {\"errors\": 0.024843207332445473, \"time-step\": 4303}, {\"errors\": 0.024807171497712804, \"time-step\": 4304}, {\"errors\": 0.02477120088008767, \"time-step\": 4305}, {\"errors\": 0.024735295397499777, \"time-step\": 4306}, {\"errors\": 0.024699454967610307, \"time-step\": 4307}, {\"errors\": 0.02466367950781478, \"time-step\": 4308}, {\"errors\": 0.024627968935246373, \"time-step\": 4309}, {\"errors\": 0.02459232316677901, \"time-step\": 4310}, {\"errors\": 0.024556742119030542, \"time-step\": 4311}, {\"errors\": 0.024521225708365752, \"time-step\": 4312}, {\"errors\": 0.024485773850899534, \"time-step\": 4313}, {\"errors\": 0.024450386462499918, \"time-step\": 4314}, {\"errors\": 0.024415063458791197, \"time-step\": 4315}, {\"errors\": 0.0243798047551569, \"time-step\": 4316}, {\"errors\": 0.0243446102667429, \"time-step\": 4317}, {\"errors\": 0.02430947990846035, \"time-step\": 4318}, {\"errors\": 0.024274413594988796, \"time-step\": 4319}, {\"errors\": 0.02423941124077902, \"time-step\": 4320}, {\"errors\": 0.02420447276005612, \"time-step\": 4321}, {\"errors\": 0.024169598066822468, \"time-step\": 4322}, {\"errors\": 0.024134787074860636, \"time-step\": 4323}, {\"errors\": 0.024100039697736227, \"time-step\": 4324}, {\"errors\": 0.024065355848801047, \"time-step\": 4325}, {\"errors\": 0.02403073544119557, \"time-step\": 4326}, {\"errors\": 0.023996178387852295, \"time-step\": 4327}, {\"errors\": 0.02396168460149833, \"time-step\": 4328}, {\"errors\": 0.023927253994658282, \"time-step\": 4329}, {\"errors\": 0.023892886479657142, \"time-step\": 4330}, {\"errors\": 0.023858581968623116, \"time-step\": 4331}, {\"errors\": 0.023824340373490377, \"time-step\": 4332}, {\"errors\": 0.023790161606001836, \"time-step\": 4333}, {\"errors\": 0.02375604557771205, \"time-step\": 4334}, {\"errors\": 0.02372199219998987, \"time-step\": 4335}, {\"errors\": 0.023688001384021162, \"time-step\": 4336}, {\"errors\": 0.023654073040811747, \"time-step\": 4337}, {\"errors\": 0.02362020708118974, \"time-step\": 4338}, {\"errors\": 0.023586403415808664, \"time-step\": 4339}, {\"errors\": 0.023552661955149823, \"time-step\": 4340}, {\"errors\": 0.023518982609525237, \"time-step\": 4341}, {\"errors\": 0.02348536528908, \"time-step\": 4342}, {\"errors\": 0.023451809903795223, \"time-step\": 4343}, {\"errors\": 0.023418316363490448, \"time-step\": 4344}, {\"errors\": 0.023384884577826302, \"time-step\": 4345}, {\"errors\": 0.02335151445630721, \"time-step\": 4346}, {\"errors\": 0.02331820590828383, \"time-step\": 4347}, {\"errors\": 0.02328495884295575, \"time-step\": 4348}, {\"errors\": 0.023251773169373886, \"time-step\": 4349}, {\"errors\": 0.023218648796443135, \"time-step\": 4350}, {\"errors\": 0.023185585632924954, \"time-step\": 4351}, {\"errors\": 0.023152583587439664, \"time-step\": 4352}, {\"errors\": 0.023119642568469115, \"time-step\": 4353}, {\"errors\": 0.02308676248435914, \"time-step\": 4354}, {\"errors\": 0.02305394324332198, \"time-step\": 4355}, {\"errors\": 0.023021184753438728, \"time-step\": 4356}, {\"errors\": 0.02298848692266177, \"time-step\": 4357}, {\"errors\": 0.02295584965881732, \"time-step\": 4358}, {\"errors\": 0.02292327286960761, \"time-step\": 4359}, {\"errors\": 0.02289075646261343, \"time-step\": 4360}, {\"errors\": 0.02285830034529646, \"time-step\": 4361}, {\"errors\": 0.022825904425001778, \"time-step\": 4362}, {\"errors\": 0.022793568608959855, \"time-step\": 4363}, {\"errors\": 0.02276129280428927, \"time-step\": 4364}, {\"errors\": 0.022729076917998806, \"time-step\": 4365}, {\"errors\": 0.02269692085698987, \"time-step\": 4366}, {\"errors\": 0.022664824528058607, \"time-step\": 4367}, {\"errors\": 0.02263278783789846, \"time-step\": 4368}, {\"errors\": 0.022600810693102123, \"time-step\": 4369}, {\"errors\": 0.022568893000164066, \"time-step\": 4370}, {\"errors\": 0.02253703466548252, \"time-step\": 4371}, {\"errors\": 0.02250523559536194, \"time-step\": 4372}, {\"errors\": 0.022473495696015013, \"time-step\": 4373}, {\"errors\": 0.022441814873564895, \"time-step\": 4374}, {\"errors\": 0.02241019303404749, \"time-step\": 4375}, {\"errors\": 0.022378630083413502, \"time-step\": 4376}, {\"errors\": 0.022347125927530628, \"time-step\": 4377}, {\"errors\": 0.022315680472185687, \"time-step\": 4378}, {\"errors\": 0.022284293623086742, \"time-step\": 4379}, {\"errors\": 0.02225296528586517, \"time-step\": 4380}, {\"errors\": 0.02222169536607787, \"time-step\": 4381}, {\"errors\": 0.02219048376920923, \"time-step\": 4382}, {\"errors\": 0.022159330400673166, \"time-step\": 4383}, {\"errors\": 0.022128235165815364, \"time-step\": 4384}, {\"errors\": 0.02209719796991507, \"time-step\": 4385}, {\"errors\": 0.02206621871818732, \"time-step\": 4386}, {\"errors\": 0.02203529731578483, \"time-step\": 4387}, {\"errors\": 0.02200443366779999, \"time-step\": 4388}, {\"errors\": 0.02197362767926702, \"time-step\": 4389}, {\"errors\": 0.021942879255163764, \"time-step\": 4390}, {\"errors\": 0.021912188300413554, \"time-step\": 4391}, {\"errors\": 0.021881554719887508, \"time-step\": 4392}, {\"errors\": 0.0218509784184061, \"time-step\": 4393}, {\"errors\": 0.021820459300741293, \"time-step\": 4394}, {\"errors\": 0.021789997271618317, \"time-step\": 4395}, {\"errors\": 0.021759592235717752, \"time-step\": 4396}, {\"errors\": 0.02172924409767715, \"time-step\": 4397}, {\"errors\": 0.02169895276209308, \"time-step\": 4398}, {\"errors\": 0.021668718133522863, \"time-step\": 4399}, {\"errors\": 0.02163854011648654, \"time-step\": 4400}, {\"errors\": 0.02160841861546858, \"time-step\": 4401}, {\"errors\": 0.021578353534919804, \"time-step\": 4402}, {\"errors\": 0.02154834477925905, \"time-step\": 4403}, {\"errors\": 0.0215183922528751, \"time-step\": 4404}, {\"errors\": 0.02148849586012836, \"time-step\": 4405}, {\"errors\": 0.021458655505352614, \"time-step\": 4406}, {\"errors\": 0.02142887109285682, \"time-step\": 4407}, {\"errors\": 0.021399142526926866, \"time-step\": 4408}, {\"errors\": 0.02136946971182726, \"time-step\": 4409}, {\"errors\": 0.021339852551802818, \"time-step\": 4410}, {\"errors\": 0.02131029095108036, \"time-step\": 4411}, {\"errors\": 0.02128078481387047, \"time-step\": 4412}, {\"errors\": 0.02125133404436913, \"time-step\": 4413}, {\"errors\": 0.02122193854675931, \"time-step\": 4414}, {\"errors\": 0.02119259822521273, \"time-step\": 4415}, {\"errors\": 0.02116331298389141, \"time-step\": 4416}, {\"errors\": 0.02113408272694932, \"time-step\": 4417}, {\"errors\": 0.021104907358534125, \"time-step\": 4418}, {\"errors\": 0.02107578678278842, \"time-step\": 4419}, {\"errors\": 0.021046720903851783, \"time-step\": 4420}, {\"errors\": 0.02101770962586202, \"time-step\": 4421}, {\"errors\": 0.020988752852956837, \"time-step\": 4422}, {\"errors\": 0.02095985048927539, \"time-step\": 4423}, {\"errors\": 0.020931002438959866, \"time-step\": 4424}, {\"errors\": 0.020902208606156887, \"time-step\": 4425}, {\"errors\": 0.02087346889501917, \"time-step\": 4426}, {\"errors\": 0.020844783209706966, \"time-step\": 4427}, {\"errors\": 0.02081615145438952, \"time-step\": 4428}, {\"errors\": 0.02078757353324657, \"time-step\": 4429}, {\"errors\": 0.020759049350469884, \"time-step\": 4430}, {\"errors\": 0.02073057881026463, \"time-step\": 4431}, {\"errors\": 0.020702161816850903, \"time-step\": 4432}, {\"errors\": 0.02067379827446501, \"time-step\": 4433}, {\"errors\": 0.020645488087361087, \"time-step\": 4434}, {\"errors\": 0.02061723115981238, \"time-step\": 4435}, {\"errors\": 0.02058902739611273, \"time-step\": 4436}, {\"errors\": 0.020560876700577855, \"time-step\": 4437}, {\"errors\": 0.020532778977546833, \"time-step\": 4438}, {\"errors\": 0.020504734131383387, \"time-step\": 4439}, {\"errors\": 0.020476742066477316, \"time-step\": 4440}, {\"errors\": 0.02044880268724583, \"time-step\": 4441}, {\"errors\": 0.02042091589813474, \"time-step\": 4442}, {\"errors\": 0.020393081603620036, \"time-step\": 4443}, {\"errors\": 0.02036529970820891, \"time-step\": 4444}, {\"errors\": 0.02033757011644137, \"time-step\": 4445}, {\"errors\": 0.02030989273289128, \"time-step\": 4446}, {\"errors\": 0.02028226746216769, \"time-step\": 4447}, {\"errors\": 0.020254694208916228, \"time-step\": 4448}, {\"errors\": 0.020227172877820172, \"time-step\": 4449}, {\"errors\": 0.020199703373601868, \"time-step\": 4450}, {\"errors\": 0.02017228560102388, \"time-step\": 4451}, {\"errors\": 0.020144919464890186, \"time-step\": 4452}, {\"errors\": 0.02011760487004749, \"time-step\": 4453}, {\"errors\": 0.02009034172138634, \"time-step\": 4454}, {\"errors\": 0.020063129923842352, \"time-step\": 4455}, {\"errors\": 0.020035969382397427, \"time-step\": 4456}, {\"errors\": 0.020008860002080856, \"time-step\": 4457}, {\"errors\": 0.01998180168797058, \"time-step\": 4458}, {\"errors\": 0.019954794345194263, \"time-step\": 4459}, {\"errors\": 0.019927837878930436, \"time-step\": 4460}, {\"errors\": 0.01990093219440965, \"time-step\": 4461}, {\"errors\": 0.01987407719691567, \"time-step\": 4462}, {\"errors\": 0.01984727279178648, \"time-step\": 4463}, {\"errors\": 0.019820518884415418, \"time-step\": 4464}, {\"errors\": 0.019793815380252273, \"time-step\": 4465}, {\"errors\": 0.019767162184804468, \"time-step\": 4466}, {\"errors\": 0.019740559203637962, \"time-step\": 4467}, {\"errors\": 0.019714006342378344, \"time-step\": 4468}, {\"errors\": 0.019687503506712098, \"time-step\": 4469}, {\"errors\": 0.019661050602387365, \"time-step\": 4470}, {\"errors\": 0.01963464753521514, \"time-step\": 4471}, {\"errors\": 0.01960829421107027, \"time-step\": 4472}, {\"errors\": 0.019581990535892477, \"time-step\": 4473}, {\"errors\": 0.019555736415687322, \"time-step\": 4474}, {\"errors\": 0.019529531756527253, \"time-step\": 4475}, {\"errors\": 0.01950337646455259, \"time-step\": 4476}, {\"errors\": 0.019477270445972396, \"time-step\": 4477}, {\"errors\": 0.019451213607065677, \"time-step\": 4478}, {\"errors\": 0.01942520585418211, \"time-step\": 4479}, {\"errors\": 0.01939924709374312, \"time-step\": 4480}, {\"errors\": 0.01937333723224278, \"time-step\": 4481}, {\"errors\": 0.01934747617624876, \"time-step\": 4482}, {\"errors\": 0.019321663832403264, \"time-step\": 4483}, {\"errors\": 0.01929590010742396, \"time-step\": 4484}, {\"errors\": 0.019270184908104757, \"time-step\": 4485}, {\"errors\": 0.019244518141316933, \"time-step\": 4486}, {\"errors\": 0.01921889971400976, \"time-step\": 4487}, {\"errors\": 0.019193329533211637, \"time-step\": 4488}, {\"errors\": 0.01916780750603079, \"time-step\": 4489}, {\"errors\": 0.01914233353965622, \"time-step\": 4490}, {\"errors\": 0.01911690754135846, \"time-step\": 4491}, {\"errors\": 0.01909152941849059, \"time-step\": 4492}, {\"errors\": 0.01906619907848891, \"time-step\": 4493}, {\"errors\": 0.019040916428873837, \"time-step\": 4494}, {\"errors\": 0.019015681377250727, \"time-step\": 4495}, {\"errors\": 0.018990493831310712, \"time-step\": 4496}, {\"errors\": 0.018965353698831455, \"time-step\": 4497}, {\"errors\": 0.018940260887677945, \"time-step\": 4498}, {\"errors\": 0.01891521530580339, \"time-step\": 4499}, {\"errors\": 0.018890216861249778, \"time-step\": 4500}, {\"errors\": 0.01886526546214887, \"time-step\": 4501}, {\"errors\": 0.01884036101672295, \"time-step\": 4502}, {\"errors\": 0.018815503433285342, \"time-step\": 4503}, {\"errors\": 0.01879069262024142, \"time-step\": 4504}, {\"errors\": 0.01876592848608931, \"time-step\": 4505}, {\"errors\": 0.01874121093942044, \"time-step\": 4506}, {\"errors\": 0.01871653988892047, \"time-step\": 4507}, {\"errors\": 0.018691915243369852, \"time-step\": 4508}, {\"errors\": 0.01866733691164476, \"time-step\": 4509}, {\"errors\": 0.018642804802717464, \"time-step\": 4510}, {\"errors\": 0.01861831882565737, \"time-step\": 4511}, {\"errors\": 0.018593878889631363, \"time-step\": 4512}, {\"errors\": 0.01856948490390481, \"time-step\": 4513}, {\"errors\": 0.01854513677784202, \"time-step\": 4514}, {\"errors\": 0.018520834420907, \"time-step\": 4515}, {\"errors\": 0.018496577742664017, \"time-step\": 4516}, {\"errors\": 0.01847236665277839, \"time-step\": 4517}, {\"errors\": 0.01844820106101701, \"time-step\": 4518}, {\"errors\": 0.018424080877248988, \"time-step\": 4519}, {\"errors\": 0.018400006011446347, \"time-step\": 4520}, {\"errors\": 0.01837597637368461, \"time-step\": 4521}, {\"errors\": 0.01835199187414338, \"time-step\": 4522}, {\"errors\": 0.01832805242310696, \"time-step\": 4523}, {\"errors\": 0.018304157930965043, \"time-step\": 4524}, {\"errors\": 0.018280308308213103, \"time-step\": 4525}, {\"errors\": 0.018256503465453155, \"time-step\": 4526}, {\"errors\": 0.018232743313394313, \"time-step\": 4527}, {\"errors\": 0.018209027762853266, \"time-step\": 4528}, {\"errors\": 0.018185356724754947, \"time-step\": 4529}, {\"errors\": 0.018161730110132966, \"time-step\": 4530}, {\"errors\": 0.01813814783013036, \"time-step\": 4531}, {\"errors\": 0.018114609795999846, \"time-step\": 4532}, {\"errors\": 0.018091115919104696, \"time-step\": 4533}, {\"errors\": 0.01806766611091897, \"time-step\": 4534}, {\"errors\": 0.01804426028302827, \"time-step\": 4535}, {\"errors\": 0.018020898347130058, \"time-step\": 4536}, {\"errors\": 0.01799758021503428, \"time-step\": 4537}, {\"errors\": 0.0179743057986639, \"time-step\": 4538}, {\"errors\": 0.01795107501005534, \"time-step\": 4539}, {\"errors\": 0.017927887761358913, \"time-step\": 4540}, {\"errors\": 0.017904743964839494, \"time-step\": 4541}, {\"errors\": 0.017881643532876752, \"time-step\": 4542}, {\"errors\": 0.017858586377965825, \"time-step\": 4543}, {\"errors\": 0.017835572412717743, \"time-step\": 4544}, {\"errors\": 0.017812601549859773, \"time-step\": 4545}, {\"errors\": 0.017789673702236025, \"time-step\": 4546}, {\"errors\": 0.017766788782807835, \"time-step\": 4547}, {\"errors\": 0.017743946704654148, \"time-step\": 4548}, {\"errors\": 0.017721147380972066, \"time-step\": 4549}, {\"errors\": 0.0176983907250772, \"time-step\": 4550}, {\"errors\": 0.017675676650404145, \"time-step\": 4551}, {\"errors\": 0.017653005070506857, \"time-step\": 4552}, {\"errors\": 0.01763037589905911, \"time-step\": 4553}, {\"errors\": 0.017607789049854827, \"time-step\": 4554}, {\"errors\": 0.017585244436808523, \"time-step\": 4555}, {\"errors\": 0.017562741973955784, \"time-step\": 4556}, {\"errors\": 0.01754028157545348, \"time-step\": 4557}, {\"errors\": 0.01751786315558037, \"time-step\": 4558}, {\"errors\": 0.01749548662873722, \"time-step\": 4559}, {\"errors\": 0.017473151909447444, \"time-step\": 4560}, {\"errors\": 0.017450858912357224, \"time-step\": 4561}, {\"errors\": 0.017428607552236096, \"time-step\": 4562}, {\"errors\": 0.01740639774397714, \"time-step\": 4563}, {\"errors\": 0.01738422940259744, \"time-step\": 4564}, {\"errors\": 0.017362102443238315, \"time-step\": 4565}, {\"errors\": 0.01734001678116579, \"time-step\": 4566}, {\"errors\": 0.017317972331770813, \"time-step\": 4567}, {\"errors\": 0.01729596901056973, \"time-step\": 4568}, {\"errors\": 0.01727400673320446, \"time-step\": 4569}, {\"errors\": 0.017252085415442833, \"time-step\": 4570}, {\"errors\": 0.01723020497317907, \"time-step\": 4571}, {\"errors\": 0.017208365322433847, \"time-step\": 4572}, {\"errors\": 0.017186566379354784, \"time-step\": 4573}, {\"errors\": 0.01716480806021673, \"time-step\": 4574}, {\"errors\": 0.017143090281421886, \"time-step\": 4575}, {\"errors\": 0.017121412959500298, \"time-step\": 4576}, {\"errors\": 0.017099776011110082, \"time-step\": 4577}, {\"errors\": 0.01707817935303764, \"time-step\": 4578}, {\"errors\": 0.01705662290219804, \"time-step\": 4579}, {\"errors\": 0.017035106575635155, \"time-step\": 4580}, {\"errors\": 0.017013630290522004, \"time-step\": 4581}, {\"errors\": 0.016992193964161083, \"time-step\": 4582}, {\"errors\": 0.016970797513984483, \"time-step\": 4583}, {\"errors\": 0.016949440857554225, \"time-step\": 4584}, {\"errors\": 0.016928123912562473, \"time-step\": 4585}, {\"errors\": 0.01690684659683177, \"time-step\": 4586}, {\"errors\": 0.01688560882831537, \"time-step\": 4587}, {\"errors\": 0.01686441052509733, \"time-step\": 4588}, {\"errors\": 0.01684325160539282, \"time-step\": 4589}, {\"errors\": 0.016822131987548315, \"time-step\": 4590}, {\"errors\": 0.016801051590041874, \"time-step\": 4591}, {\"errors\": 0.016780010331483287, \"time-step\": 4592}, {\"errors\": 0.016759008130614327, \"time-step\": 4593}, {\"errors\": 0.016738044906308897, \"time-step\": 4594}, {\"errors\": 0.016717120577573304, \"time-step\": 4595}, {\"errors\": 0.016696235063546457, \"time-step\": 4596}, {\"errors\": 0.016675388283499987, \"time-step\": 4597}, {\"errors\": 0.01665458015683855, \"time-step\": 4598}, {\"errors\": 0.016633810603099826, \"time-step\": 4599}, {\"errors\": 0.016613079541954904, \"time-step\": 4600}, {\"errors\": 0.0165923868932084, \"time-step\": 4601}, {\"errors\": 0.01657173257679853, \"time-step\": 4602}, {\"errors\": 0.01655111651279741, \"time-step\": 4603}, {\"errors\": 0.01653053862141112, \"time-step\": 4604}, {\"errors\": 0.016509998822979967, \"time-step\": 4605}, {\"errors\": 0.016489497037978532, \"time-step\": 4606}, {\"errors\": 0.01646903318701591, \"time-step\": 4607}, {\"errors\": 0.01644860719083577, \"time-step\": 4608}, {\"errors\": 0.01642821897031667, \"time-step\": 4609}, {\"errors\": 0.016407868446471956, \"time-step\": 4610}, {\"errors\": 0.016387555540450086, \"time-step\": 4611}, {\"errors\": 0.016367280173534775, \"time-step\": 4612}, {\"errors\": 0.01634704226714491, \"time-step\": 4613}, {\"errors\": 0.016326841742834945, \"time-step\": 4614}, {\"errors\": 0.016306678522294865, \"time-step\": 4615}, {\"errors\": 0.016286552527350326, \"time-step\": 4616}, {\"errors\": 0.016266463679962862, \"time-step\": 4617}, {\"errors\": 0.016246411902229828, \"time-step\": 4618}, {\"errors\": 0.01622639711638465, \"time-step\": 4619}, {\"errors\": 0.016206419244796873, \"time-step\": 4620}, {\"errors\": 0.01618647820997231, \"time-step\": 4621}, {\"errors\": 0.016166573934553098, \"time-step\": 4622}, {\"errors\": 0.016146706341317717, \"time-step\": 4623}, {\"errors\": 0.016126875353181316, \"time-step\": 4624}, {\"errors\": 0.016107080893195506, \"time-step\": 4625}, {\"errors\": 0.01608732288454866, \"time-step\": 4626}, {\"errors\": 0.016067601250565933, \"time-step\": 4627}, {\"errors\": 0.016047915914709308, \"time-step\": 4628}, {\"errors\": 0.016028266800577676, \"time-step\": 4629}, {\"errors\": 0.016008653831906968, \"time-step\": 4630}, {\"errors\": 0.01598907693257014, \"time-step\": 4631}, {\"errors\": 0.01596953602657728, \"time-step\": 4632}, {\"errors\": 0.015950031038075747, \"time-step\": 4633}, {\"errors\": 0.015930561891349997, \"time-step\": 4634}, {\"errors\": 0.015911128510821968, \"time-step\": 4635}, {\"errors\": 0.015891730821050835, \"time-step\": 4636}, {\"errors\": 0.015872368746733184, \"time-step\": 4637}, {\"errors\": 0.01585304221270315, \"time-step\": 4638}, {\"errors\": 0.015833751143932297, \"time-step\": 4639}, {\"errors\": 0.01581449546552975, \"time-step\": 4640}, {\"errors\": 0.015795275102742194, \"time-step\": 4641}, {\"errors\": 0.01577608998095396, \"time-step\": 4642}, {\"errors\": 0.015756940025686977, \"time-step\": 4643}, {\"errors\": 0.01573782516260089, \"time-step\": 4644}, {\"errors\": 0.015718745317493024, \"time-step\": 4645}, {\"errors\": 0.015699700416298444, \"time-step\": 4646}, {\"errors\": 0.015680690385089922, \"time-step\": 4647}, {\"errors\": 0.01566171515007806, \"time-step\": 4648}, {\"errors\": 0.015642774637611163, \"time-step\": 4649}, {\"errors\": 0.015623868774175344, \"time-step\": 4650}, {\"errors\": 0.01560499748639457, \"time-step\": 4651}, {\"errors\": 0.015586160701030534, \"time-step\": 4652}, {\"errors\": 0.015567358344982785, \"time-step\": 4653}, {\"errors\": 0.015548590345288684, \"time-step\": 4654}, {\"errors\": 0.015529856629123366, \"time-step\": 4655}, {\"errors\": 0.015511157123799862, \"time-step\": 4656}, {\"errors\": 0.015492491756768874, \"time-step\": 4657}, {\"errors\": 0.015473860455618993, \"time-step\": 4658}, {\"errors\": 0.015455263148076548, \"time-step\": 4659}, {\"errors\": 0.015436699762005675, \"time-step\": 4660}, {\"errors\": 0.015418170225408246, \"time-step\": 4661}, {\"errors\": 0.015399674466423803, \"time-step\": 4662}, {\"errors\": 0.015381212413329681, \"time-step\": 4663}, {\"errors\": 0.015362783994540902, \"time-step\": 4664}, {\"errors\": 0.015344389138610049, \"time-step\": 4665}, {\"errors\": 0.01532602777422749, \"time-step\": 4666}, {\"errors\": 0.015307699830221063, \"time-step\": 4667}, {\"errors\": 0.01528940523555625, \"time-step\": 4668}, {\"errors\": 0.015271143919336098, \"time-step\": 4669}, {\"errors\": 0.01525291581080104, \"time-step\": 4670}, {\"errors\": 0.015234720839329075, \"time-step\": 4671}, {\"errors\": 0.015216558934435562, \"time-step\": 4672}, {\"errors\": 0.015198430025773275, \"time-step\": 4673}, {\"errors\": 0.015180334043132234, \"time-step\": 4674}, {\"errors\": 0.015162270916439863, \"time-step\": 4675}, {\"errors\": 0.015144240575760692, \"time-step\": 4676}, {\"errors\": 0.015126242951296531, \"time-step\": 4677}, {\"errors\": 0.015108277973386198, \"time-step\": 4678}, {\"errors\": 0.01509034557250567, \"time-step\": 4679}, {\"errors\": 0.015072445679267878, \"time-step\": 4680}, {\"errors\": 0.01505457822442273, \"time-step\": 4681}, {\"errors\": 0.01503674313885696, \"time-step\": 4682}, {\"errors\": 0.01501894035359421, \"time-step\": 4683}, {\"errors\": 0.015001169799794753, \"time-step\": 4684}, {\"errors\": 0.01498343140875565, \"time-step\": 4685}, {\"errors\": 0.014965725111910497, \"time-step\": 4686}, {\"errors\": 0.014948050840829473, \"time-step\": 4687}, {\"errors\": 0.014930408527219163, \"time-step\": 4688}, {\"errors\": 0.01491279810292261, \"time-step\": 4689}, {\"errors\": 0.014895219499919092, \"time-step\": 4690}, {\"errors\": 0.014877672650324181, \"time-step\": 4691}, {\"errors\": 0.014860157486389533, \"time-step\": 4692}, {\"errors\": 0.014842673940502885, \"time-step\": 4693}, {\"errors\": 0.014825221945187966, \"time-step\": 4694}, {\"errors\": 0.014807801433104385, \"time-step\": 4695}, {\"errors\": 0.014790412337047473, \"time-step\": 4696}, {\"errors\": 0.014773054589948396, \"time-step\": 4697}, {\"errors\": 0.01475572812487385, \"time-step\": 4698}, {\"errors\": 0.014738432875026072, \"time-step\": 4699}, {\"errors\": 0.014721168773742683, \"time-step\": 4700}, {\"errors\": 0.014703935754496706, \"time-step\": 4701}, {\"errors\": 0.014686733750896342, \"time-step\": 4702}, {\"errors\": 0.014669562696684877, \"time-step\": 4703}, {\"errors\": 0.014652422525740703, \"time-step\": 4704}, {\"errors\": 0.014635313172077065, \"time-step\": 4705}, {\"errors\": 0.014618234569842035, \"time-step\": 4706}, {\"errors\": 0.014601186653318388, \"time-step\": 4707}, {\"errors\": 0.014584169356923509, \"time-step\": 4708}, {\"errors\": 0.014567182615209225, \"time-step\": 4709}, {\"errors\": 0.014550226362861794, \"time-step\": 4710}, {\"errors\": 0.014533300534701688, \"time-step\": 4711}, {\"errors\": 0.014516405065683516, \"time-step\": 4712}, {\"errors\": 0.014499539890895953, \"time-step\": 4713}, {\"errors\": 0.014482704945561545, \"time-step\": 4714}, {\"errors\": 0.014465900165036644, \"time-step\": 4715}, {\"errors\": 0.01444912548481125, \"time-step\": 4716}, {\"errors\": 0.014432380840508888, \"time-step\": 4717}, {\"errors\": 0.014415666167886611, \"time-step\": 4718}, {\"errors\": 0.014398981402834644, \"time-step\": 4719}, {\"errors\": 0.014382326481376426, \"time-step\": 4720}, {\"errors\": 0.014365701339668462, \"time-step\": 4721}, {\"errors\": 0.01434910591400013, \"time-step\": 4722}, {\"errors\": 0.014332540140793607, \"time-step\": 4723}, {\"errors\": 0.014316003956603747, \"time-step\": 4724}, {\"errors\": 0.014299497298117858, \"time-step\": 4725}, {\"errors\": 0.014283020102155684, \"time-step\": 4726}, {\"errors\": 0.014266572305669217, \"time-step\": 4727}, {\"errors\": 0.014250153845742481, \"time-step\": 4728}, {\"errors\": 0.014233764659591606, \"time-step\": 4729}, {\"errors\": 0.014217404684564451, \"time-step\": 4730}, {\"errors\": 0.014201073858140565, \"time-step\": 4731}, {\"errors\": 0.014184772117931111, \"time-step\": 4732}, {\"errors\": 0.014168499401678617, \"time-step\": 4733}, {\"errors\": 0.0141522556472569, \"time-step\": 4734}, {\"errors\": 0.014136040792670872, \"time-step\": 4735}, {\"errors\": 0.014119854776056394, \"time-step\": 4736}, {\"errors\": 0.014103697535680224, \"time-step\": 4737}, {\"errors\": 0.01408756900993974, \"time-step\": 4738}, {\"errors\": 0.01407146913736285, \"time-step\": 4739}, {\"errors\": 0.01405539785660788, \"time-step\": 4740}, {\"errors\": 0.014039355106463319, \"time-step\": 4741}, {\"errors\": 0.01402334082584776, \"time-step\": 4742}, {\"errors\": 0.01400735495380974, \"time-step\": 4743}, {\"errors\": 0.013991397429527517, \"time-step\": 4744}, {\"errors\": 0.01397546819230893, \"time-step\": 4745}, {\"errors\": 0.01395956718159137, \"time-step\": 4746}, {\"errors\": 0.013943694336941424, \"time-step\": 4747}, {\"errors\": 0.013927849598054796, \"time-step\": 4748}, {\"errors\": 0.0139120329047563, \"time-step\": 4749}, {\"errors\": 0.013896244196999424, \"time-step\": 4750}, {\"errors\": 0.013880483414866385, \"time-step\": 4751}, {\"errors\": 0.013864750498567831, \"time-step\": 4752}, {\"errors\": 0.013849045388442748, \"time-step\": 4753}, {\"errors\": 0.01383336802495837, \"time-step\": 4754}, {\"errors\": 0.013817718348709748, \"time-step\": 4755}, {\"errors\": 0.013802096300419973, \"time-step\": 4756}, {\"errors\": 0.013786501820939625, \"time-step\": 4757}, {\"errors\": 0.01377093485124689, \"time-step\": 4758}, {\"errors\": 0.013755395332447178, \"time-step\": 4759}, {\"errors\": 0.013739883205773146, \"time-step\": 4760}, {\"errors\": 0.013724398412584389, \"time-step\": 4761}, {\"errors\": 0.01370894089436733, \"time-step\": 4762}, {\"errors\": 0.013693510592735032, \"time-step\": 4763}, {\"errors\": 0.01367810744942703, \"time-step\": 4764}, {\"errors\": 0.013662731406309095, \"time-step\": 4765}, {\"errors\": 0.013647382405373235, \"time-step\": 4766}, {\"errors\": 0.013632060388737304, \"time-step\": 4767}, {\"errors\": 0.013616765298644987, \"time-step\": 4768}, {\"errors\": 0.013601497077465493, \"time-step\": 4769}, {\"errors\": 0.013586255667693517, \"time-step\": 4770}, {\"errors\": 0.013571041011948975, \"time-step\": 4771}, {\"errors\": 0.013555853052976803, \"time-step\": 4772}, {\"errors\": 0.01354069173364686, \"time-step\": 4773}, {\"errors\": 0.01352555699695368, \"time-step\": 4774}, {\"errors\": 0.013510448786016326, \"time-step\": 4775}, {\"errors\": 0.013495367044078194, \"time-step\": 4776}, {\"errors\": 0.013480311714506824, \"time-step\": 4777}, {\"errors\": 0.013465282740793748, \"time-step\": 4778}, {\"errors\": 0.013450280066554262, \"time-step\": 4779}, {\"errors\": 0.01343530363552732, \"time-step\": 4780}, {\"errors\": 0.013420353391575206, \"time-step\": 4781}, {\"errors\": 0.01340542927868352, \"time-step\": 4782}, {\"errors\": 0.013390531240960898, \"time-step\": 4783}, {\"errors\": 0.013375659222638786, \"time-step\": 4784}, {\"errors\": 0.013360813168071358, \"time-step\": 4785}, {\"errors\": 0.01334599302173526, \"time-step\": 4786}, {\"errors\": 0.013331198728229412, \"time-step\": 4787}, {\"errors\": 0.013316430232274887, \"time-step\": 4788}, {\"errors\": 0.013301687478714647, \"time-step\": 4789}, {\"errors\": 0.013286970412513435, \"time-step\": 4790}, {\"errors\": 0.013272278978757452, \"time-step\": 4791}, {\"errors\": 0.013257613122654322, \"time-step\": 4792}, {\"errors\": 0.01324297278953283, \"time-step\": 4793}, {\"errors\": 0.013228357924842667, \"time-step\": 4794}, {\"errors\": 0.013213768474154345, \"time-step\": 4795}, {\"errors\": 0.013199204383158936, \"time-step\": 4796}, {\"errors\": 0.013184665597667943, \"time-step\": 4797}, {\"errors\": 0.013170152063613036, \"time-step\": 4798}, {\"errors\": 0.013155663727045873, \"time-step\": 4799}, {\"errors\": 0.013141200534137951, \"time-step\": 4800}, {\"errors\": 0.013126762431180335, \"time-step\": 4801}, {\"errors\": 0.01311234936458358, \"time-step\": 4802}, {\"errors\": 0.013097961280877373, \"time-step\": 4803}, {\"errors\": 0.013083598126710484, \"time-step\": 4804}, {\"errors\": 0.01306925984885051, \"time-step\": 4805}, {\"errors\": 0.013054946394183668, \"time-step\": 4806}, {\"errors\": 0.013040657709714572, \"time-step\": 4807}, {\"errors\": 0.013026393742566148, \"time-step\": 4808}, {\"errors\": 0.013012154439979272, \"time-step\": 4809}, {\"errors\": 0.012997939749312768, \"time-step\": 4810}, {\"errors\": 0.012983749618042998, \"time-step\": 4811}, {\"errors\": 0.012969583993763797, \"time-step\": 4812}, {\"errors\": 0.012955442824186258, \"time-step\": 4813}, {\"errors\": 0.012941326057138505, \"time-step\": 4814}, {\"errors\": 0.012927233640565514, \"time-step\": 4815}, {\"errors\": 0.012913165522528865, \"time-step\": 4816}, {\"errors\": 0.012899121651206647, \"time-step\": 4817}, {\"errors\": 0.012885101974893095, \"time-step\": 4818}, {\"errors\": 0.012871106441998563, \"time-step\": 4819}, {\"errors\": 0.012857135001049201, \"time-step\": 4820}, {\"errors\": 0.012843187600686794, \"time-step\": 4821}, {\"errors\": 0.012829264189668552, \"time-step\": 4822}, {\"errors\": 0.012815364716866937, \"time-step\": 4823}, {\"errors\": 0.01280148913126939, \"time-step\": 4824}, {\"errors\": 0.012787637381978245, \"time-step\": 4825}, {\"errors\": 0.01277380941821041, \"time-step\": 4826}, {\"errors\": 0.012760005189297197, \"time-step\": 4827}, {\"errors\": 0.012746224644684133, \"time-step\": 4828}, {\"errors\": 0.012732467733930785, \"time-step\": 4829}, {\"errors\": 0.012718734406710494, \"time-step\": 4830}, {\"errors\": 0.012705024612810194, \"time-step\": 4831}, {\"errors\": 0.01269133830213023, \"time-step\": 4832}, {\"errors\": 0.01267767542468415, \"time-step\": 4833}, {\"errors\": 0.012664035930598415, \"time-step\": 4834}, {\"errors\": 0.012650419770112373, \"time-step\": 4835}, {\"errors\": 0.012636826893577851, \"time-step\": 4836}, {\"errors\": 0.012623257251459056, \"time-step\": 4837}, {\"errors\": 0.01260971079433238, \"time-step\": 4838}, {\"errors\": 0.01259618747288618, \"time-step\": 4839}, {\"errors\": 0.012582687237920553, \"time-step\": 4840}, {\"errors\": 0.012569210040347105, \"time-step\": 4841}, {\"errors\": 0.012555755831188804, \"time-step\": 4842}, {\"errors\": 0.012542324561579736, \"time-step\": 4843}, {\"errors\": 0.012528916182764928, \"time-step\": 4844}, {\"errors\": 0.012515530646100104, \"time-step\": 4845}, {\"errors\": 0.012502167903051493, \"time-step\": 4846}, {\"errors\": 0.012488827905195626, \"time-step\": 4847}, {\"errors\": 0.012475510604219139, \"time-step\": 4848}, {\"errors\": 0.012462215951918546, \"time-step\": 4849}, {\"errors\": 0.012448943900200037, \"time-step\": 4850}, {\"errors\": 0.012435694401079275, \"time-step\": 4851}, {\"errors\": 0.012422467406681171, \"time-step\": 4852}, {\"errors\": 0.012409262869239695, \"time-step\": 4853}, {\"errors\": 0.012396080741097677, \"time-step\": 4854}, {\"errors\": 0.012382920974706613, \"time-step\": 4855}, {\"errors\": 0.01236978352262635, \"time-step\": 4856}, {\"errors\": 0.012356668337525013, \"time-step\": 4857}, {\"errors\": 0.012343575372178714, \"time-step\": 4858}, {\"errors\": 0.012330504579471404, \"time-step\": 4859}, {\"errors\": 0.012317455912394599, \"time-step\": 4860}, {\"errors\": 0.012304429324047243, \"time-step\": 4861}, {\"errors\": 0.012291424767635402, \"time-step\": 4862}, {\"errors\": 0.012278442196472145, \"time-step\": 4863}, {\"errors\": 0.012265481563977308, \"time-step\": 4864}, {\"errors\": 0.012252542823677298, \"time-step\": 4865}, {\"errors\": 0.012239625929204832, \"time-step\": 4866}, {\"errors\": 0.012226730834298753, \"time-step\": 4867}, {\"errors\": 0.012213857492803896, \"time-step\": 4868}, {\"errors\": 0.012201005858670743, \"time-step\": 4869}, {\"errors\": 0.012188175885955319, \"time-step\": 4870}, {\"errors\": 0.01217536752881898, \"time-step\": 4871}, {\"errors\": 0.012162580741528145, \"time-step\": 4872}, {\"errors\": 0.012149815478454097, \"time-step\": 4873}, {\"errors\": 0.012137071694072845, \"time-step\": 4874}, {\"errors\": 0.012124349342964812, \"time-step\": 4875}, {\"errors\": 0.012111648379814745, \"time-step\": 4876}, {\"errors\": 0.012098968759411355, \"time-step\": 4877}, {\"errors\": 0.012086310436647282, \"time-step\": 4878}, {\"errors\": 0.012073673366518736, \"time-step\": 4879}, {\"errors\": 0.012061057504125373, \"time-step\": 4880}, {\"errors\": 0.012048462804670087, \"time-step\": 4881}, {\"errors\": 0.012035889223458746, \"time-step\": 4882}, {\"errors\": 0.012023336715900022, \"time-step\": 4883}, {\"errors\": 0.012010805237505178, \"time-step\": 4884}, {\"errors\": 0.0119982947438879, \"time-step\": 4885}, {\"errors\": 0.011985805190763966, \"time-step\": 4886}, {\"errors\": 0.011973336533951202, \"time-step\": 4887}, {\"errors\": 0.01196088872936912, \"time-step\": 4888}, {\"errors\": 0.011948461733038877, \"time-step\": 4889}, {\"errors\": 0.011936055501082857, \"time-step\": 4890}, {\"errors\": 0.011923669989724644, \"time-step\": 4891}, {\"errors\": 0.011911305155288737, \"time-step\": 4892}, {\"errors\": 0.011898960954200339, \"time-step\": 4893}, {\"errors\": 0.011886637342985194, \"time-step\": 4894}, {\"errors\": 0.011874334278269321, \"time-step\": 4895}, {\"errors\": 0.011862051716778808, \"time-step\": 4896}, {\"errors\": 0.011849789615339695, \"time-step\": 4897}, {\"errors\": 0.011837547930877663, \"time-step\": 4898}, {\"errors\": 0.011825326620417864, \"time-step\": 4899}, {\"errors\": 0.01181312564108473, \"time-step\": 4900}, {\"errors\": 0.011800944950101722, \"time-step\": 4901}, {\"errors\": 0.011788784504791178, \"time-step\": 4902}, {\"errors\": 0.011776644262574104, \"time-step\": 4903}, {\"errors\": 0.01176452418096988, \"time-step\": 4904}, {\"errors\": 0.011752424217596159, \"time-step\": 4905}, {\"errors\": 0.011740344330168627, \"time-step\": 4906}, {\"errors\": 0.011728284476500745, \"time-step\": 4907}, {\"errors\": 0.01171624461450364, \"time-step\": 4908}, {\"errors\": 0.011704224702185791, \"time-step\": 4909}, {\"errors\": 0.011692224697652926, \"time-step\": 4910}, {\"errors\": 0.011680244559107739, \"time-step\": 4911}, {\"errors\": 0.011668284244849749, \"time-step\": 4912}, {\"errors\": 0.011656343713274949, \"time-step\": 4913}, {\"errors\": 0.011644422922875867, \"time-step\": 4914}, {\"errors\": 0.01163252183224109, \"time-step\": 4915}, {\"errors\": 0.011620640400055185, \"time-step\": 4916}, {\"errors\": 0.011608778585098541, \"time-step\": 4917}, {\"errors\": 0.011596936346247057, \"time-step\": 4918}, {\"errors\": 0.011585113642471983, \"time-step\": 4919}, {\"errors\": 0.011573310432839734, \"time-step\": 4920}, {\"errors\": 0.01156152667651168, \"time-step\": 4921}, {\"errors\": 0.011549762332743884, \"time-step\": 4922}, {\"errors\": 0.011538017360887004, \"time-step\": 4923}, {\"errors\": 0.011526291720386012, \"time-step\": 4924}, {\"errors\": 0.011514585370779961, \"time-step\": 4925}, {\"errors\": 0.011502898271701858, \"time-step\": 4926}, {\"errors\": 0.011491230382878501, \"time-step\": 4927}, {\"errors\": 0.011479581664130123, \"time-step\": 4928}, {\"errors\": 0.01146795207537029, \"time-step\": 4929}, {\"errors\": 0.011456341576605689, \"time-step\": 4930}, {\"errors\": 0.01144475012793592, \"time-step\": 4931}, {\"errors\": 0.011433177689553303, \"time-step\": 4932}, {\"errors\": 0.011421624221742645, \"time-step\": 4933}, {\"errors\": 0.011410089684881053, \"time-step\": 4934}, {\"errors\": 0.011398574039437743, \"time-step\": 4935}, {\"errors\": 0.011387077245973888, \"time-step\": 4936}, {\"errors\": 0.011375599265142275, \"time-step\": 4937}, {\"errors\": 0.011364140057687235, \"time-step\": 4938}, {\"errors\": 0.011352699584444358, \"time-step\": 4939}, {\"errors\": 0.011341277806340413, \"time-step\": 4940}, {\"errors\": 0.01132987468439298, \"time-step\": 4941}, {\"errors\": 0.01131849017971039, \"time-step\": 4942}, {\"errors\": 0.011307124253491455, \"time-step\": 4943}, {\"errors\": 0.011295776867025261, \"time-step\": 4944}, {\"errors\": 0.011284447981691028, \"time-step\": 4945}, {\"errors\": 0.011273137558957856, \"time-step\": 4946}, {\"errors\": 0.011261845560384552, \"time-step\": 4947}, {\"errors\": 0.01125057194761942, \"time-step\": 4948}, {\"errors\": 0.011239316682400032, \"time-step\": 4949}, {\"errors\": 0.01122807972655311, \"time-step\": 4950}, {\"errors\": 0.01121686104199429, \"time-step\": 4951}, {\"errors\": 0.011205660590727817, \"time-step\": 4952}, {\"errors\": 0.011194478334846594, \"time-step\": 4953}, {\"errors\": 0.011183314236531705, \"time-step\": 4954}, {\"errors\": 0.011172168258052432, \"time-step\": 4955}, {\"errors\": 0.011161040361765927, \"time-step\": 4956}, {\"errors\": 0.011149930510117072, \"time-step\": 4957}, {\"errors\": 0.011138838665638275, \"time-step\": 4958}, {\"errors\": 0.01112776479094928, \"time-step\": 4959}, {\"errors\": 0.011116708848756962, \"time-step\": 4960}, {\"errors\": 0.011105670801855113, \"time-step\": 4961}, {\"errors\": 0.011094650613124259, \"time-step\": 4962}, {\"errors\": 0.01108364824553154, \"time-step\": 4963}, {\"errors\": 0.011072663662130335, \"time-step\": 4964}, {\"errors\": 0.011061696826060265, \"time-step\": 4965}, {\"errors\": 0.011050747700546855, \"time-step\": 4966}, {\"errors\": 0.011039816248901466, \"time-step\": 4967}, {\"errors\": 0.01102890243452093, \"time-step\": 4968}, {\"errors\": 0.011018006220887559, \"time-step\": 4969}, {\"errors\": 0.011007127571568786, \"time-step\": 4970}, {\"errors\": 0.010996266450217016, \"time-step\": 4971}, {\"errors\": 0.010985422820569565, \"time-step\": 4972}, {\"errors\": 0.010974596646448183, \"time-step\": 4973}, {\"errors\": 0.010963787891759195, \"time-step\": 4974}, {\"errors\": 0.01095299652049303, \"time-step\": 4975}, {\"errors\": 0.010942222496724224, \"time-step\": 4976}, {\"errors\": 0.010931465784611115, \"time-step\": 4977}, {\"errors\": 0.010920726348395702, \"time-step\": 4978}, {\"errors\": 0.010910004152403362, \"time-step\": 4979}, {\"errors\": 0.010899299161042882, \"time-step\": 4980}, {\"errors\": 0.01088861133880599, \"time-step\": 4981}, {\"errors\": 0.010877940650267358, \"time-step\": 4982}, {\"errors\": 0.01086728706008433, \"time-step\": 4983}, {\"errors\": 0.01085665053299678, \"time-step\": 4984}, {\"errors\": 0.010846031033826867, \"time-step\": 4985}, {\"errors\": 0.010835428527478892, \"time-step\": 4986}, {\"errors\": 0.010824842978939087, \"time-step\": 4987}, {\"errors\": 0.01081427435327541, \"time-step\": 4988}, {\"errors\": 0.010803722615637392, \"time-step\": 4989}, {\"errors\": 0.010793187731255973, \"time-step\": 4990}, {\"errors\": 0.010782669665443199, \"time-step\": 4991}, {\"errors\": 0.010772168383592181, \"time-step\": 4992}, {\"errors\": 0.010761683851176804, \"time-step\": 4993}, {\"errors\": 0.010751216033751588, \"time-step\": 4994}, {\"errors\": 0.010740764896951471, \"time-step\": 4995}, {\"errors\": 0.010730330406491618, \"time-step\": 4996}, {\"errors\": 0.010719912528167366, \"time-step\": 4997}, {\"errors\": 0.010709511227853777, \"time-step\": 4998}, {\"errors\": 0.010699126471505706, \"time-step\": 4999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"errors\":errors, \"time-step\": np.arange(0, len(errors))})\n",
    "\n",
    "alt.Chart(df).mark_line().encode(x=\"time-step\", y=\"errors\").properties(title='Chart 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error curve is revealing. After the first few iterations the error dropped fast to around 0.13, and from there went down more gradually. If you are wondering how the accuracy is 100% although the error is not zero, remember that the binary predictions have no business in the error computation and that many different sets of weights may generate the correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: multilayer perceptron with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we implemented our own multilayer perceptron was for **pedagogical purposes**. Richard Feynman once famously said: \"**What I cannot create I do not understand**\", which is probably an exaggeration but I personally agree with the principle of \"learning by creating\". Learning to build neural networks is similar to learn math (maybe because they are *literally* math): yes, you'll end up using a calculator to compute almost everything, yet, we still do the exercise of computing systems of equations by hand when learning algebra. There is a deeper level of understanding that is unlocked when you actually get to build something from scratch.\n",
    "\n",
    "Nonetheless, there is no need to go through this process every time. Nowadays, we have access to very good libraries to build neural networks. [Keras](https://keras.io/) is a popular Python library for this. Keras main strength is the simplicity and elegance of its interface (sometimes people call it \"API\"). Keras hides most of the computations to the users and provides a way to define neural networks that match with what you would normally do when drawing a diagram. There are many other libraries you may hear about (Tensorflow, PyTorch, MXNet, Caffe, etc.) but I'll use this one because is the best for beginners in my opinion.\n",
    "\n",
    "Next, we will build another multi-layer perceptron to solve the same XOR Problem and to illustrate how simple is the process with Keras. \n",
    "\n",
    "This time, I'll put together a network with the following characteristics:\n",
    "\n",
    "- **Input layer** with 2 neurons (i.e., the two features).\n",
    "- **One hidden** layer with 16 neurons with sigmoid activation functions.\n",
    "- **Output layer** with 1 neuron with a sigmoid activation (i.e., a target value of 0 or 1).\n",
    "- **Mean squared error** as the cost (or loss) function.\n",
    "- **\"Adam\" optimizer**. This a variation of gradient descent that (sometimes) speed up the process by adapting the learning rate for each parameter in the network. It has the advantage that we don't need to manually search for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected values\n",
    "y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "# features\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the model definition:\n",
    "- `Sequential()` specifies that the network is a linear stack of layers\n",
    "- `model.add()` adds the hidden layer.\n",
    "- `Dense` means that neurons between layers are fully connected\n",
    "- `input_dim` defines the number of features in the training dataset\n",
    "- `activation` defines the activation function\n",
    "- `loss` selects the cost function\n",
    "- `optimizer` selects the learning algorithm\n",
    "- `metrics` selects the performance metrics to be saved for further analysis\n",
    "- `model.fit()` initialize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mean_squared_error'])\n",
    "\n",
    "history = model.fit(X, y, epochs=3000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-965d938cb73d459ebbc9f63b5d44f5e0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-965d938cb73d459ebbc9f63b5d44f5e0\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-71ca5bffe698eb73fe9a92b756feac6d\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"time-step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"errors\"}}, \"title\": \"Chart 3\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-71ca5bffe698eb73fe9a92b756feac6d\": [{\"errors\": 0.3597352206707001, \"time-step\": 0}, {\"errors\": 0.3587172329425812, \"time-step\": 1}, {\"errors\": 0.35769712924957275, \"time-step\": 2}, {\"errors\": 0.3566751182079315, \"time-step\": 3}, {\"errors\": 0.35565119981765747, \"time-step\": 4}, {\"errors\": 0.3546254336833954, \"time-step\": 5}, {\"errors\": 0.3535979390144348, \"time-step\": 6}, {\"errors\": 0.3525688052177429, \"time-step\": 7}, {\"errors\": 0.3515380620956421, \"time-step\": 8}, {\"errors\": 0.3505057990550995, \"time-step\": 9}, {\"errors\": 0.34947216510772705, \"time-step\": 10}, {\"errors\": 0.34843719005584717, \"time-step\": 11}, {\"errors\": 0.34740105271339417, \"time-step\": 12}, {\"errors\": 0.34636378288269043, \"time-step\": 13}, {\"errors\": 0.34532544016838074, \"time-step\": 14}, {\"errors\": 0.3442862629890442, \"time-step\": 15}, {\"errors\": 0.34324631094932556, \"time-step\": 16}, {\"errors\": 0.3422057032585144, \"time-step\": 17}, {\"errors\": 0.34116458892822266, \"time-step\": 18}, {\"errors\": 0.3401229977607727, \"time-step\": 19}, {\"errors\": 0.33908119797706604, \"time-step\": 20}, {\"errors\": 0.33803924918174744, \"time-step\": 21}, {\"errors\": 0.33699730038642883, \"time-step\": 22}, {\"errors\": 0.33595550060272217, \"time-step\": 23}, {\"errors\": 0.334913969039917, \"time-step\": 24}, {\"errors\": 0.3338729739189148, \"time-step\": 25}, {\"errors\": 0.33283254504203796, \"time-step\": 26}, {\"errors\": 0.3317928612232208, \"time-step\": 27}, {\"errors\": 0.3307540714740753, \"time-step\": 28}, {\"errors\": 0.32971638441085815, \"time-step\": 29}, {\"errors\": 0.3286799192428589, \"time-step\": 30}, {\"errors\": 0.327644944190979, \"time-step\": 31}, {\"errors\": 0.3266115188598633, \"time-step\": 32}, {\"errors\": 0.32557982206344604, \"time-step\": 33}, {\"errors\": 0.3245500922203064, \"time-step\": 34}, {\"errors\": 0.32352250814437866, \"time-step\": 35}, {\"errors\": 0.3224971890449524, \"time-step\": 36}, {\"errors\": 0.3214743137359619, \"time-step\": 37}, {\"errors\": 0.32045406103134155, \"time-step\": 38}, {\"errors\": 0.3194366693496704, \"time-step\": 39}, {\"errors\": 0.3184223473072052, \"time-step\": 40}, {\"errors\": 0.31741124391555786, \"time-step\": 41}, {\"errors\": 0.31640344858169556, \"time-step\": 42}, {\"errors\": 0.3153993487358093, \"time-step\": 43}, {\"errors\": 0.3143990635871887, \"time-step\": 44}, {\"errors\": 0.3134027123451233, \"time-step\": 45}, {\"errors\": 0.31241053342819214, \"time-step\": 46}, {\"errors\": 0.31142276525497437, \"time-step\": 47}, {\"errors\": 0.3104395866394043, \"time-step\": 48}, {\"errors\": 0.3094611167907715, \"time-step\": 49}, {\"errors\": 0.3084877133369446, \"time-step\": 50}, {\"errors\": 0.30751943588256836, \"time-step\": 51}, {\"errors\": 0.30655646324157715, \"time-step\": 52}, {\"errors\": 0.3055991232395172, \"time-step\": 53}, {\"errors\": 0.3046475052833557, \"time-step\": 54}, {\"errors\": 0.30370181798934937, \"time-step\": 55}, {\"errors\": 0.3027622699737549, \"time-step\": 56}, {\"errors\": 0.30182915925979614, \"time-step\": 57}, {\"errors\": 0.3009023666381836, \"time-step\": 58}, {\"errors\": 0.2999823987483978, \"time-step\": 59}, {\"errors\": 0.29906922578811646, \"time-step\": 60}, {\"errors\": 0.29816311597824097, \"time-step\": 61}, {\"errors\": 0.2972642779350281, \"time-step\": 62}, {\"errors\": 0.29637283086776733, \"time-step\": 63}, {\"errors\": 0.2954889237880707, \"time-step\": 64}, {\"errors\": 0.2946127653121948, \"time-step\": 65}, {\"errors\": 0.2937444746494293, \"time-step\": 66}, {\"errors\": 0.29288429021835327, \"time-step\": 67}, {\"errors\": 0.29203230142593384, \"time-step\": 68}, {\"errors\": 0.29118862748146057, \"time-step\": 69}, {\"errors\": 0.2903535068035126, \"time-step\": 70}, {\"errors\": 0.289527028799057, \"time-step\": 71}, {\"errors\": 0.28870928287506104, \"time-step\": 72}, {\"errors\": 0.28790047764778137, \"time-step\": 73}, {\"errors\": 0.2871006727218628, \"time-step\": 74}, {\"errors\": 0.2863100469112396, \"time-step\": 75}, {\"errors\": 0.2855287194252014, \"time-step\": 76}, {\"errors\": 0.28475672006607056, \"time-step\": 77}, {\"errors\": 0.283994197845459, \"time-step\": 78}, {\"errors\": 0.28324127197265625, \"time-step\": 79}, {\"errors\": 0.2824980318546295, \"time-step\": 80}, {\"errors\": 0.28176456689834595, \"time-step\": 81}, {\"errors\": 0.28104090690612793, \"time-step\": 82}, {\"errors\": 0.2803272306919098, \"time-step\": 83}, {\"errors\": 0.27962350845336914, \"time-step\": 84}, {\"errors\": 0.27892979979515076, \"time-step\": 85}, {\"errors\": 0.27824628353118896, \"time-step\": 86}, {\"errors\": 0.2775728404521942, \"time-step\": 87}, {\"errors\": 0.2769097089767456, \"time-step\": 88}, {\"errors\": 0.2762567400932312, \"time-step\": 89}, {\"errors\": 0.27561408281326294, \"time-step\": 90}, {\"errors\": 0.2749817669391632, \"time-step\": 91}, {\"errors\": 0.2743597626686096, \"time-step\": 92}, {\"errors\": 0.2737480700016022, \"time-step\": 93}, {\"errors\": 0.2731468081474304, \"time-step\": 94}, {\"errors\": 0.2725558876991272, \"time-step\": 95}, {\"errors\": 0.2719752788543701, \"time-step\": 96}, {\"errors\": 0.27140507102012634, \"time-step\": 97}, {\"errors\": 0.2708452045917511, \"time-step\": 98}, {\"errors\": 0.2702956199645996, \"time-step\": 99}, {\"errors\": 0.2697538435459137, \"time-step\": 100}, {\"errors\": 0.2692224681377411, \"time-step\": 101}, {\"errors\": 0.26870137453079224, \"time-step\": 102}, {\"errors\": 0.26819056272506714, \"time-step\": 103}, {\"errors\": 0.2676900327205658, \"time-step\": 104}, {\"errors\": 0.26719969511032104, \"time-step\": 105}, {\"errors\": 0.2667195200920105, \"time-step\": 106}, {\"errors\": 0.2662494480609894, \"time-step\": 107}, {\"errors\": 0.26578933000564575, \"time-step\": 108}, {\"errors\": 0.2653391659259796, \"time-step\": 109}, {\"errors\": 0.2648988962173462, \"time-step\": 110}, {\"errors\": 0.26446837186813354, \"time-step\": 111}, {\"errors\": 0.2640492916107178, \"time-step\": 112}, {\"errors\": 0.26363807916641235, \"time-step\": 113}, {\"errors\": 0.2632363736629486, \"time-step\": 114}, {\"errors\": 0.26284411549568176, \"time-step\": 115}, {\"errors\": 0.2624611556529999, \"time-step\": 116}, {\"errors\": 0.2620874047279358, \"time-step\": 117}, {\"errors\": 0.26172271370887756, \"time-step\": 118}, {\"errors\": 0.2613670527935028, \"time-step\": 119}, {\"errors\": 0.2610202431678772, \"time-step\": 120}, {\"errors\": 0.26068222522735596, \"time-step\": 121}, {\"errors\": 0.26035284996032715, \"time-step\": 122}, {\"errors\": 0.2600319981575012, \"time-step\": 123}, {\"errors\": 0.2597195506095886, \"time-step\": 124}, {\"errors\": 0.2594153583049774, \"time-step\": 125}, {\"errors\": 0.25911930203437805, \"time-step\": 126}, {\"errors\": 0.258831262588501, \"time-step\": 127}, {\"errors\": 0.2585511803627014, \"time-step\": 128}, {\"errors\": 0.2582787573337555, \"time-step\": 129}, {\"errors\": 0.2580140233039856, \"time-step\": 130}, {\"errors\": 0.25775763392448425, \"time-step\": 131}, {\"errors\": 0.2575085461139679, \"time-step\": 132}, {\"errors\": 0.25726574659347534, \"time-step\": 133}, {\"errors\": 0.2570309042930603, \"time-step\": 134}, {\"errors\": 0.2568029463291168, \"time-step\": 135}, {\"errors\": 0.2565809190273285, \"time-step\": 136}, {\"errors\": 0.2563663423061371, \"time-step\": 137}, {\"errors\": 0.2561575174331665, \"time-step\": 138}, {\"errors\": 0.2559557259082794, \"time-step\": 139}, {\"errors\": 0.25575950741767883, \"time-step\": 140}, {\"errors\": 0.2555693984031677, \"time-step\": 141}, {\"errors\": 0.25538527965545654, \"time-step\": 142}, {\"errors\": 0.2552069425582886, \"time-step\": 143}, {\"errors\": 0.25503435730934143, \"time-step\": 144}, {\"errors\": 0.2548673152923584, \"time-step\": 145}, {\"errors\": 0.2547056972980499, \"time-step\": 146}, {\"errors\": 0.25454938411712646, \"time-step\": 147}, {\"errors\": 0.2543981969356537, \"time-step\": 148}, {\"errors\": 0.2542521059513092, \"time-step\": 149}, {\"errors\": 0.2541108727455139, \"time-step\": 150}, {\"errors\": 0.25397443771362305, \"time-step\": 151}, {\"errors\": 0.25384265184402466, \"time-step\": 152}, {\"errors\": 0.2537153661251068, \"time-step\": 153}, {\"errors\": 0.25359252095222473, \"time-step\": 154}, {\"errors\": 0.2534739077091217, \"time-step\": 155}, {\"errors\": 0.25335949659347534, \"time-step\": 156}, {\"errors\": 0.2532491385936737, \"time-step\": 157}, {\"errors\": 0.25314268469810486, \"time-step\": 158}, {\"errors\": 0.25304001569747925, \"time-step\": 159}, {\"errors\": 0.2529411017894745, \"time-step\": 160}, {\"errors\": 0.25284573435783386, \"time-step\": 161}, {\"errors\": 0.2527540922164917, \"time-step\": 162}, {\"errors\": 0.252665638923645, \"time-step\": 163}, {\"errors\": 0.2525804042816162, \"time-step\": 164}, {\"errors\": 0.2524982988834381, \"time-step\": 165}, {\"errors\": 0.25241929292678833, \"time-step\": 166}, {\"errors\": 0.2523432672023773, \"time-step\": 167}, {\"errors\": 0.2522701025009155, \"time-step\": 168}, {\"errors\": 0.2521997094154358, \"time-step\": 169}, {\"errors\": 0.25213202834129333, \"time-step\": 170}, {\"errors\": 0.2520669102668762, \"time-step\": 171}, {\"errors\": 0.25200432538986206, \"time-step\": 172}, {\"errors\": 0.2519441843032837, \"time-step\": 173}, {\"errors\": 0.2518863379955292, \"time-step\": 174}, {\"errors\": 0.2518307566642761, \"time-step\": 175}, {\"errors\": 0.25177738070487976, \"time-step\": 176}, {\"errors\": 0.25172609090805054, \"time-step\": 177}, {\"errors\": 0.2516768276691437, \"time-step\": 178}, {\"errors\": 0.2516295313835144, \"time-step\": 179}, {\"errors\": 0.25158411264419556, \"time-step\": 180}, {\"errors\": 0.25154054164886475, \"time-step\": 181}, {\"errors\": 0.25149863958358765, \"time-step\": 182}, {\"errors\": 0.25145846605300903, \"time-step\": 183}, {\"errors\": 0.25141990184783936, \"time-step\": 184}, {\"errors\": 0.2513829171657562, \"time-step\": 185}, {\"errors\": 0.2513474225997925, \"time-step\": 186}, {\"errors\": 0.25131332874298096, \"time-step\": 187}, {\"errors\": 0.25128066539764404, \"time-step\": 188}, {\"errors\": 0.2512493133544922, \"time-step\": 189}, {\"errors\": 0.25121933221817017, \"time-step\": 190}, {\"errors\": 0.25119051337242126, \"time-step\": 191}, {\"errors\": 0.25116291642189026, \"time-step\": 192}, {\"errors\": 0.2511364221572876, \"time-step\": 193}, {\"errors\": 0.2511109709739685, \"time-step\": 194}, {\"errors\": 0.251086562871933, \"time-step\": 195}, {\"errors\": 0.25106319785118103, \"time-step\": 196}, {\"errors\": 0.2510407269001007, \"time-step\": 197}, {\"errors\": 0.2510192394256592, \"time-step\": 198}, {\"errors\": 0.2509985864162445, \"time-step\": 199}, {\"errors\": 0.2509787678718567, \"time-step\": 200}, {\"errors\": 0.2509597837924957, \"time-step\": 201}, {\"errors\": 0.25094154477119446, \"time-step\": 202}, {\"errors\": 0.2509240508079529, \"time-step\": 203}, {\"errors\": 0.250907301902771, \"time-step\": 204}, {\"errors\": 0.25089120864868164, \"time-step\": 205}, {\"errors\": 0.2508757710456848, \"time-step\": 206}, {\"errors\": 0.25086092948913574, \"time-step\": 207}, {\"errors\": 0.2508466839790344, \"time-step\": 208}, {\"errors\": 0.25083303451538086, \"time-step\": 209}, {\"errors\": 0.2508198618888855, \"time-step\": 210}, {\"errors\": 0.2508072257041931, \"time-step\": 211}, {\"errors\": 0.2507951855659485, \"time-step\": 212}, {\"errors\": 0.25078344345092773, \"time-step\": 213}, {\"errors\": 0.25077226758003235, \"time-step\": 214}, {\"errors\": 0.250761479139328, \"time-step\": 215}, {\"errors\": 0.2507511079311371, \"time-step\": 216}, {\"errors\": 0.2507411241531372, \"time-step\": 217}, {\"errors\": 0.250731498003006, \"time-step\": 218}, {\"errors\": 0.2507222294807434, \"time-step\": 219}, {\"errors\": 0.2507133483886719, \"time-step\": 220}, {\"errors\": 0.25070470571517944, \"time-step\": 221}, {\"errors\": 0.2506963908672333, \"time-step\": 222}, {\"errors\": 0.25068843364715576, \"time-step\": 223}, {\"errors\": 0.25068068504333496, \"time-step\": 224}, {\"errors\": 0.2506732642650604, \"time-step\": 225}, {\"errors\": 0.2506660223007202, \"time-step\": 226}, {\"errors\": 0.25065910816192627, \"time-step\": 227}, {\"errors\": 0.25065234303474426, \"time-step\": 228}, {\"errors\": 0.25064584612846375, \"time-step\": 229}, {\"errors\": 0.25063952803611755, \"time-step\": 230}, {\"errors\": 0.2506334185600281, \"time-step\": 231}, {\"errors\": 0.25062745809555054, \"time-step\": 232}, {\"errors\": 0.2506217360496521, \"time-step\": 233}, {\"errors\": 0.25061607360839844, \"time-step\": 234}, {\"errors\": 0.25061067938804626, \"time-step\": 235}, {\"errors\": 0.25060540437698364, \"time-step\": 236}, {\"errors\": 0.25060030817985535, \"time-step\": 237}, {\"errors\": 0.2505953311920166, \"time-step\": 238}, {\"errors\": 0.250590443611145, \"time-step\": 239}, {\"errors\": 0.2505857050418854, \"time-step\": 240}, {\"errors\": 0.2505810856819153, \"time-step\": 241}, {\"errors\": 0.25057658553123474, \"time-step\": 242}, {\"errors\": 0.25057217478752136, \"time-step\": 243}, {\"errors\": 0.25056788325309753, \"time-step\": 244}, {\"errors\": 0.25056368112564087, \"time-step\": 245}, {\"errors\": 0.25055956840515137, \"time-step\": 246}, {\"errors\": 0.2505555748939514, \"time-step\": 247}, {\"errors\": 0.25055158138275146, \"time-step\": 248}, {\"errors\": 0.25054770708084106, \"time-step\": 249}, {\"errors\": 0.2505439519882202, \"time-step\": 250}, {\"errors\": 0.25054019689559937, \"time-step\": 251}, {\"errors\": 0.2505365014076233, \"time-step\": 252}, {\"errors\": 0.2505328953266144, \"time-step\": 253}, {\"errors\": 0.25052937865257263, \"time-step\": 254}, {\"errors\": 0.25052595138549805, \"time-step\": 255}, {\"errors\": 0.2505224943161011, \"time-step\": 256}, {\"errors\": 0.2505190968513489, \"time-step\": 257}, {\"errors\": 0.25051575899124146, \"time-step\": 258}, {\"errors\": 0.2505124807357788, \"time-step\": 259}, {\"errors\": 0.25050926208496094, \"time-step\": 260}, {\"errors\": 0.25050604343414307, \"time-step\": 261}, {\"errors\": 0.25050294399261475, \"time-step\": 262}, {\"errors\": 0.25049978494644165, \"time-step\": 263}, {\"errors\": 0.2504967153072357, \"time-step\": 264}, {\"errors\": 0.2504936754703522, \"time-step\": 265}, {\"errors\": 0.25049060583114624, \"time-step\": 266}, {\"errors\": 0.25048762559890747, \"time-step\": 267}, {\"errors\": 0.2504846453666687, \"time-step\": 268}, {\"errors\": 0.2504817247390747, \"time-step\": 269}, {\"errors\": 0.2504787743091583, \"time-step\": 270}, {\"errors\": 0.2504759430885315, \"time-step\": 271}, {\"errors\": 0.2504730820655823, \"time-step\": 272}, {\"errors\": 0.25047022104263306, \"time-step\": 273}, {\"errors\": 0.250467449426651, \"time-step\": 274}, {\"errors\": 0.25046461820602417, \"time-step\": 275}, {\"errors\": 0.2504618465900421, \"time-step\": 276}, {\"errors\": 0.25045910477638245, \"time-step\": 277}, {\"errors\": 0.2504563331604004, \"time-step\": 278}, {\"errors\": 0.2504535913467407, \"time-step\": 279}, {\"errors\": 0.25045090913772583, \"time-step\": 280}, {\"errors\": 0.2504482567310333, \"time-step\": 281}, {\"errors\": 0.25044554471969604, \"time-step\": 282}, {\"errors\": 0.2504429221153259, \"time-step\": 283}, {\"errors\": 0.25044021010398865, \"time-step\": 284}, {\"errors\": 0.25043755769729614, \"time-step\": 285}, {\"errors\": 0.250434935092926, \"time-step\": 286}, {\"errors\": 0.2504323720932007, \"time-step\": 287}, {\"errors\": 0.25042974948883057, \"time-step\": 288}, {\"errors\": 0.25042715668678284, \"time-step\": 289}, {\"errors\": 0.2504245638847351, \"time-step\": 290}, {\"errors\": 0.25042200088500977, \"time-step\": 291}, {\"errors\": 0.25041940808296204, \"time-step\": 292}, {\"errors\": 0.2504168748855591, \"time-step\": 293}, {\"errors\": 0.25041434168815613, \"time-step\": 294}, {\"errors\": 0.2504118084907532, \"time-step\": 295}, {\"errors\": 0.2504093050956726, \"time-step\": 296}, {\"errors\": 0.25040680170059204, \"time-step\": 297}, {\"errors\": 0.2504042387008667, \"time-step\": 298}, {\"errors\": 0.25040173530578613, \"time-step\": 299}, {\"errors\": 0.25039926171302795, \"time-step\": 300}, {\"errors\": 0.2503967881202698, \"time-step\": 301}, {\"errors\": 0.2503942847251892, \"time-step\": 302}, {\"errors\": 0.25039181113243103, \"time-step\": 303}, {\"errors\": 0.25038933753967285, \"time-step\": 304}, {\"errors\": 0.25038689374923706, \"time-step\": 305}, {\"errors\": 0.25038444995880127, \"time-step\": 306}, {\"errors\": 0.2503819465637207, \"time-step\": 307}, {\"errors\": 0.2503795325756073, \"time-step\": 308}, {\"errors\": 0.2503770887851715, \"time-step\": 309}, {\"errors\": 0.2503746747970581, \"time-step\": 310}, {\"errors\": 0.2503722310066223, \"time-step\": 311}, {\"errors\": 0.2503698170185089, \"time-step\": 312}, {\"errors\": 0.2503674030303955, \"time-step\": 313}, {\"errors\": 0.2503649890422821, \"time-step\": 314}, {\"errors\": 0.2503625750541687, \"time-step\": 315}, {\"errors\": 0.2503601312637329, \"time-step\": 316}, {\"errors\": 0.2503577768802643, \"time-step\": 317}, {\"errors\": 0.25035539269447327, \"time-step\": 318}, {\"errors\": 0.25035297870635986, \"time-step\": 319}, {\"errors\": 0.25035062432289124, \"time-step\": 320}, {\"errors\": 0.2503482401371002, \"time-step\": 321}, {\"errors\": 0.2503458559513092, \"time-step\": 322}, {\"errors\": 0.2503435015678406, \"time-step\": 323}, {\"errors\": 0.2503410875797272, \"time-step\": 324}, {\"errors\": 0.25033873319625854, \"time-step\": 325}, {\"errors\": 0.2503363788127899, \"time-step\": 326}, {\"errors\": 0.2503340542316437, \"time-step\": 327}, {\"errors\": 0.25033169984817505, \"time-step\": 328}, {\"errors\": 0.2503293454647064, \"time-step\": 329}, {\"errors\": 0.2503269910812378, \"time-step\": 330}, {\"errors\": 0.25032466650009155, \"time-step\": 331}, {\"errors\": 0.2503223121166229, \"time-step\": 332}, {\"errors\": 0.2503199875354767, \"time-step\": 333}, {\"errors\": 0.25031766295433044, \"time-step\": 334}, {\"errors\": 0.2503153383731842, \"time-step\": 335}, {\"errors\": 0.25031304359436035, \"time-step\": 336}, {\"errors\": 0.2503107190132141, \"time-step\": 337}, {\"errors\": 0.25030839443206787, \"time-step\": 338}, {\"errors\": 0.25030606985092163, \"time-step\": 339}, {\"errors\": 0.2503037452697754, \"time-step\": 340}, {\"errors\": 0.25030145049095154, \"time-step\": 341}, {\"errors\": 0.2502991557121277, \"time-step\": 342}, {\"errors\": 0.25029683113098145, \"time-step\": 343}, {\"errors\": 0.25029456615448, \"time-step\": 344}, {\"errors\": 0.25029227137565613, \"time-step\": 345}, {\"errors\": 0.2502899765968323, \"time-step\": 346}, {\"errors\": 0.2502876818180084, \"time-step\": 347}, {\"errors\": 0.25028538703918457, \"time-step\": 348}, {\"errors\": 0.2502831518650055, \"time-step\": 349}, {\"errors\": 0.25028082728385925, \"time-step\": 350}, {\"errors\": 0.2502785623073578, \"time-step\": 351}, {\"errors\": 0.25027626752853394, \"time-step\": 352}, {\"errors\": 0.25027400255203247, \"time-step\": 353}, {\"errors\": 0.2502717673778534, \"time-step\": 354}, {\"errors\": 0.25026947259902954, \"time-step\": 355}, {\"errors\": 0.25026723742485046, \"time-step\": 356}, {\"errors\": 0.250264972448349, \"time-step\": 357}, {\"errors\": 0.2502627372741699, \"time-step\": 358}, {\"errors\": 0.25026047229766846, \"time-step\": 359}, {\"errors\": 0.250258207321167, \"time-step\": 360}, {\"errors\": 0.2502559721469879, \"time-step\": 361}, {\"errors\": 0.25025373697280884, \"time-step\": 362}, {\"errors\": 0.2502514719963074, \"time-step\": 363}, {\"errors\": 0.2502492666244507, \"time-step\": 364}, {\"errors\": 0.2502470314502716, \"time-step\": 365}, {\"errors\": 0.25024476647377014, \"time-step\": 366}, {\"errors\": 0.25024253129959106, \"time-step\": 367}, {\"errors\": 0.250240296125412, \"time-step\": 368}, {\"errors\": 0.2502380609512329, \"time-step\": 369}, {\"errors\": 0.2502358555793762, \"time-step\": 370}, {\"errors\": 0.25023362040519714, \"time-step\": 371}, {\"errors\": 0.25023144483566284, \"time-step\": 372}, {\"errors\": 0.2502291798591614, \"time-step\": 373}, {\"errors\": 0.2502270042896271, \"time-step\": 374}, {\"errors\": 0.250224769115448, \"time-step\": 375}, {\"errors\": 0.2502225339412689, \"time-step\": 376}, {\"errors\": 0.25022032856941223, \"time-step\": 377}, {\"errors\": 0.25021815299987793, \"time-step\": 378}, {\"errors\": 0.25021594762802124, \"time-step\": 379}, {\"errors\": 0.25021371245384216, \"time-step\": 380}, {\"errors\": 0.25021153688430786, \"time-step\": 381}, {\"errors\": 0.25020933151245117, \"time-step\": 382}, {\"errors\": 0.2502071261405945, \"time-step\": 383}, {\"errors\": 0.2502049505710602, \"time-step\": 384}, {\"errors\": 0.2502027750015259, \"time-step\": 385}, {\"errors\": 0.2502005696296692, \"time-step\": 386}, {\"errors\": 0.2501983642578125, \"time-step\": 387}, {\"errors\": 0.2501962184906006, \"time-step\": 388}, {\"errors\": 0.2501940131187439, \"time-step\": 389}, {\"errors\": 0.2501918375492096, \"time-step\": 390}, {\"errors\": 0.2501896619796753, \"time-step\": 391}, {\"errors\": 0.2501874566078186, \"time-step\": 392}, {\"errors\": 0.2501852512359619, \"time-step\": 393}, {\"errors\": 0.2501831352710724, \"time-step\": 394}, {\"errors\": 0.2501809597015381, \"time-step\": 395}, {\"errors\": 0.2501787543296814, \"time-step\": 396}, {\"errors\": 0.25017663836479187, \"time-step\": 397}, {\"errors\": 0.2501744329929352, \"time-step\": 398}, {\"errors\": 0.25017228722572327, \"time-step\": 399}, {\"errors\": 0.25017011165618896, \"time-step\": 400}, {\"errors\": 0.25016793608665466, \"time-step\": 401}, {\"errors\": 0.25016579031944275, \"time-step\": 402}, {\"errors\": 0.25016361474990845, \"time-step\": 403}, {\"errors\": 0.2501614987850189, \"time-step\": 404}, {\"errors\": 0.2501593232154846, \"time-step\": 405}, {\"errors\": 0.2501571476459503, \"time-step\": 406}, {\"errors\": 0.2501550018787384, \"time-step\": 407}, {\"errors\": 0.2501528561115265, \"time-step\": 408}, {\"errors\": 0.2501507103443146, \"time-step\": 409}, {\"errors\": 0.25014856457710266, \"time-step\": 410}, {\"errors\": 0.25014638900756836, \"time-step\": 411}, {\"errors\": 0.2501443028450012, \"time-step\": 412}, {\"errors\": 0.25014209747314453, \"time-step\": 413}, {\"errors\": 0.250139981508255, \"time-step\": 414}, {\"errors\": 0.2501378357410431, \"time-step\": 415}, {\"errors\": 0.25013571977615356, \"time-step\": 416}, {\"errors\": 0.25013357400894165, \"time-step\": 417}, {\"errors\": 0.2501314580440521, \"time-step\": 418}, {\"errors\": 0.2501293122768402, \"time-step\": 419}, {\"errors\": 0.2501271665096283, \"time-step\": 420}, {\"errors\": 0.25012505054473877, \"time-step\": 421}, {\"errors\": 0.25012290477752686, \"time-step\": 422}, {\"errors\": 0.25012078881263733, \"time-step\": 423}, {\"errors\": 0.2501186430454254, \"time-step\": 424}, {\"errors\": 0.2501165270805359, \"time-step\": 425}, {\"errors\": 0.250114381313324, \"time-step\": 426}, {\"errors\": 0.25011223554611206, \"time-step\": 427}, {\"errors\": 0.2501101493835449, \"time-step\": 428}, {\"errors\": 0.2501080334186554, \"time-step\": 429}, {\"errors\": 0.25010591745376587, \"time-step\": 430}, {\"errors\": 0.25010377168655396, \"time-step\": 431}, {\"errors\": 0.2501016855239868, \"time-step\": 432}, {\"errors\": 0.2500995397567749, \"time-step\": 433}, {\"errors\": 0.2500974237918854, \"time-step\": 434}, {\"errors\": 0.25009530782699585, \"time-step\": 435}, {\"errors\": 0.2500932216644287, \"time-step\": 436}, {\"errors\": 0.2500910758972168, \"time-step\": 437}, {\"errors\": 0.25008898973464966, \"time-step\": 438}, {\"errors\": 0.25008684396743774, \"time-step\": 439}, {\"errors\": 0.2500847578048706, \"time-step\": 440}, {\"errors\": 0.2500826418399811, \"time-step\": 441}, {\"errors\": 0.25008058547973633, \"time-step\": 442}, {\"errors\": 0.2500784397125244, \"time-step\": 443}, {\"errors\": 0.2500762939453125, \"time-step\": 444}, {\"errors\": 0.25007423758506775, \"time-step\": 445}, {\"errors\": 0.2500721216201782, \"time-step\": 446}, {\"errors\": 0.2500700056552887, \"time-step\": 447}, {\"errors\": 0.25006791949272156, \"time-step\": 448}, {\"errors\": 0.25006577372550964, \"time-step\": 449}, {\"errors\": 0.2500636875629425, \"time-step\": 450}, {\"errors\": 0.250061571598053, \"time-step\": 451}, {\"errors\": 0.25005945563316345, \"time-step\": 452}, {\"errors\": 0.2500573992729187, \"time-step\": 453}, {\"errors\": 0.2500552535057068, \"time-step\": 454}, {\"errors\": 0.25005319714546204, \"time-step\": 455}, {\"errors\": 0.2500510513782501, \"time-step\": 456}, {\"errors\": 0.250048965215683, \"time-step\": 457}, {\"errors\": 0.25004687905311584, \"time-step\": 458}, {\"errors\": 0.2500447928905487, \"time-step\": 459}, {\"errors\": 0.25004270672798157, \"time-step\": 460}, {\"errors\": 0.25004059076309204, \"time-step\": 461}, {\"errors\": 0.2500384747982025, \"time-step\": 462}, {\"errors\": 0.2500363886356354, \"time-step\": 463}, {\"errors\": 0.25003430247306824, \"time-step\": 464}, {\"errors\": 0.2500321865081787, \"time-step\": 465}, {\"errors\": 0.25003013014793396, \"time-step\": 466}, {\"errors\": 0.2500280439853668, \"time-step\": 467}, {\"errors\": 0.2500258982181549, \"time-step\": 468}, {\"errors\": 0.25002384185791016, \"time-step\": 469}, {\"errors\": 0.25002172589302063, \"time-step\": 470}, {\"errors\": 0.2500196397304535, \"time-step\": 471}, {\"errors\": 0.25001752376556396, \"time-step\": 472}, {\"errors\": 0.2500154376029968, \"time-step\": 473}, {\"errors\": 0.2500133216381073, \"time-step\": 474}, {\"errors\": 0.25001129508018494, \"time-step\": 475}, {\"errors\": 0.2500091791152954, \"time-step\": 476}, {\"errors\": 0.25000709295272827, \"time-step\": 477}, {\"errors\": 0.25000497698783875, \"time-step\": 478}, {\"errors\": 0.250002920627594, \"time-step\": 479}, {\"errors\": 0.25000080466270447, \"time-step\": 480}, {\"errors\": 0.24999868869781494, \"time-step\": 481}, {\"errors\": 0.2499966323375702, \"time-step\": 482}, {\"errors\": 0.24999454617500305, \"time-step\": 483}, {\"errors\": 0.24999244511127472, \"time-step\": 484}, {\"errors\": 0.249990314245224, \"time-step\": 485}, {\"errors\": 0.24998824298381805, \"time-step\": 486}, {\"errors\": 0.2499861717224121, \"time-step\": 487}, {\"errors\": 0.24998405575752258, \"time-step\": 488}, {\"errors\": 0.24998196959495544, \"time-step\": 489}, {\"errors\": 0.2499798685312271, \"time-step\": 490}, {\"errors\": 0.24997779726982117, \"time-step\": 491}, {\"errors\": 0.24997571110725403, \"time-step\": 492}, {\"errors\": 0.2499735951423645, \"time-step\": 493}, {\"errors\": 0.24997150897979736, \"time-step\": 494}, {\"errors\": 0.24996939301490784, \"time-step\": 495}, {\"errors\": 0.2499672919511795, \"time-step\": 496}, {\"errors\": 0.24996519088745117, \"time-step\": 497}, {\"errors\": 0.24996310472488403, \"time-step\": 498}, {\"errors\": 0.2499610185623169, \"time-step\": 499}, {\"errors\": 0.24995890259742737, \"time-step\": 500}, {\"errors\": 0.24995683133602142, \"time-step\": 501}, {\"errors\": 0.2499547004699707, \"time-step\": 502}, {\"errors\": 0.24995261430740356, \"time-step\": 503}, {\"errors\": 0.24995049834251404, \"time-step\": 504}, {\"errors\": 0.2499484121799469, \"time-step\": 505}, {\"errors\": 0.24994629621505737, \"time-step\": 506}, {\"errors\": 0.24994423985481262, \"time-step\": 507}, {\"errors\": 0.2499421238899231, \"time-step\": 508}, {\"errors\": 0.24993997812271118, \"time-step\": 509}, {\"errors\": 0.24993792176246643, \"time-step\": 510}, {\"errors\": 0.24993577599525452, \"time-step\": 511}, {\"errors\": 0.24993373453617096, \"time-step\": 512}, {\"errors\": 0.24993157386779785, \"time-step\": 513}, {\"errors\": 0.24992945790290833, \"time-step\": 514}, {\"errors\": 0.2499273717403412, \"time-step\": 515}, {\"errors\": 0.24992528557777405, \"time-step\": 516}, {\"errors\": 0.24992315471172333, \"time-step\": 517}, {\"errors\": 0.249921053647995, \"time-step\": 518}, {\"errors\": 0.24991896748542786, \"time-step\": 519}, {\"errors\": 0.24991682171821594, \"time-step\": 520}, {\"errors\": 0.24991470575332642, \"time-step\": 521}, {\"errors\": 0.2499125897884369, \"time-step\": 522}, {\"errors\": 0.24991047382354736, \"time-step\": 523}, {\"errors\": 0.24990838766098022, \"time-step\": 524}, {\"errors\": 0.2499062418937683, \"time-step\": 525}, {\"errors\": 0.24990412592887878, \"time-step\": 526}, {\"errors\": 0.24990203976631165, \"time-step\": 527}, {\"errors\": 0.24989992380142212, \"time-step\": 528}, {\"errors\": 0.2498977780342102, \"time-step\": 529}, {\"errors\": 0.24989566206932068, \"time-step\": 530}, {\"errors\": 0.24989353120326996, \"time-step\": 531}, {\"errors\": 0.24989138543605804, \"time-step\": 532}, {\"errors\": 0.2498892843723297, \"time-step\": 533}, {\"errors\": 0.249887153506279, \"time-step\": 534}, {\"errors\": 0.24988503754138947, \"time-step\": 535}, {\"errors\": 0.24988290667533875, \"time-step\": 536}, {\"errors\": 0.24988076090812683, \"time-step\": 537}, {\"errors\": 0.24987861514091492, \"time-step\": 538}, {\"errors\": 0.249876469373703, \"time-step\": 539}, {\"errors\": 0.2498743236064911, \"time-step\": 540}, {\"errors\": 0.24987220764160156, \"time-step\": 541}, {\"errors\": 0.24987006187438965, \"time-step\": 542}, {\"errors\": 0.24986793100833893, \"time-step\": 543}, {\"errors\": 0.24986577033996582, \"time-step\": 544}, {\"errors\": 0.2498636245727539, \"time-step\": 545}, {\"errors\": 0.249861478805542, \"time-step\": 546}, {\"errors\": 0.24985933303833008, \"time-step\": 547}, {\"errors\": 0.24985718727111816, \"time-step\": 548}, {\"errors\": 0.24985502660274506, \"time-step\": 549}, {\"errors\": 0.24985289573669434, \"time-step\": 550}, {\"errors\": 0.24985072016716003, \"time-step\": 551}, {\"errors\": 0.24984858930110931, \"time-step\": 552}, {\"errors\": 0.24984639883041382, \"time-step\": 553}, {\"errors\": 0.2498442530632019, \"time-step\": 554}, {\"errors\": 0.24984210729599, \"time-step\": 555}, {\"errors\": 0.2498399019241333, \"time-step\": 556}, {\"errors\": 0.24983777105808258, \"time-step\": 557}, {\"errors\": 0.24983558058738708, \"time-step\": 558}, {\"errors\": 0.24983340501785278, \"time-step\": 559}, {\"errors\": 0.24983125925064087, \"time-step\": 560}, {\"errors\": 0.24982908368110657, \"time-step\": 561}, {\"errors\": 0.24982690811157227, \"time-step\": 562}, {\"errors\": 0.24982468783855438, \"time-step\": 563}, {\"errors\": 0.24982252717018127, \"time-step\": 564}, {\"errors\": 0.24982035160064697, \"time-step\": 565}, {\"errors\": 0.24981814622879028, \"time-step\": 566}, {\"errors\": 0.2498159408569336, \"time-step\": 567}, {\"errors\": 0.2498137503862381, \"time-step\": 568}, {\"errors\": 0.2498115748167038, \"time-step\": 569}, {\"errors\": 0.2498093545436859, \"time-step\": 570}, {\"errors\": 0.2498071789741516, \"time-step\": 571}, {\"errors\": 0.24980497360229492, \"time-step\": 572}, {\"errors\": 0.24980276823043823, \"time-step\": 573}, {\"errors\": 0.24980053305625916, \"time-step\": 574}, {\"errors\": 0.24979835748672485, \"time-step\": 575}, {\"errors\": 0.24979612231254578, \"time-step\": 576}, {\"errors\": 0.24979393184185028, \"time-step\": 577}, {\"errors\": 0.24979165196418762, \"time-step\": 578}, {\"errors\": 0.24978944659233093, \"time-step\": 579}, {\"errors\": 0.24978724122047424, \"time-step\": 580}, {\"errors\": 0.24978499114513397, \"time-step\": 581}, {\"errors\": 0.2497827708721161, \"time-step\": 582}, {\"errors\": 0.24978052079677582, \"time-step\": 583}, {\"errors\": 0.24977833032608032, \"time-step\": 584}, {\"errors\": 0.24977608025074005, \"time-step\": 585}, {\"errors\": 0.24977383017539978, \"time-step\": 586}, {\"errors\": 0.2497715801000595, \"time-step\": 587}, {\"errors\": 0.24976933002471924, \"time-step\": 588}, {\"errors\": 0.24976709485054016, \"time-step\": 589}, {\"errors\": 0.24976485967636108, \"time-step\": 590}, {\"errors\": 0.24976254999637604, \"time-step\": 591}, {\"errors\": 0.24976029992103577, \"time-step\": 592}, {\"errors\": 0.2497580647468567, \"time-step\": 593}, {\"errors\": 0.24975576996803284, \"time-step\": 594}, {\"errors\": 0.24975349009037018, \"time-step\": 595}, {\"errors\": 0.2497512251138687, \"time-step\": 596}, {\"errors\": 0.24974894523620605, \"time-step\": 597}, {\"errors\": 0.2497466504573822, \"time-step\": 598}, {\"errors\": 0.24974438548088074, \"time-step\": 599}, {\"errors\": 0.24974209070205688, \"time-step\": 600}, {\"errors\": 0.24973979592323303, \"time-step\": 601}, {\"errors\": 0.24973750114440918, \"time-step\": 602}, {\"errors\": 0.24973517656326294, \"time-step\": 603}, {\"errors\": 0.24973289668560028, \"time-step\": 604}, {\"errors\": 0.24973057210445404, \"time-step\": 605}, {\"errors\": 0.2497282475233078, \"time-step\": 606}, {\"errors\": 0.24972596764564514, \"time-step\": 607}, {\"errors\": 0.2497236430644989, \"time-step\": 608}, {\"errors\": 0.24972131848335266, \"time-step\": 609}, {\"errors\": 0.24971894919872284, \"time-step\": 610}, {\"errors\": 0.2497166395187378, \"time-step\": 611}, {\"errors\": 0.24971431493759155, \"time-step\": 612}, {\"errors\": 0.24971197545528412, \"time-step\": 613}, {\"errors\": 0.24970963597297668, \"time-step\": 614}, {\"errors\": 0.24970726668834686, \"time-step\": 615}, {\"errors\": 0.24970491230487823, \"time-step\": 616}, {\"errors\": 0.2497025430202484, \"time-step\": 617}, {\"errors\": 0.24970018863677979, \"time-step\": 618}, {\"errors\": 0.24969781935214996, \"time-step\": 619}, {\"errors\": 0.24969545006752014, \"time-step\": 620}, {\"errors\": 0.24969308078289032, \"time-step\": 621}, {\"errors\": 0.24969065189361572, \"time-step\": 622}, {\"errors\": 0.24968832731246948, \"time-step\": 623}, {\"errors\": 0.24968591332435608, \"time-step\": 624}, {\"errors\": 0.24968349933624268, \"time-step\": 625}, {\"errors\": 0.24968110024929047, \"time-step\": 626}, {\"errors\": 0.24967873096466064, \"time-step\": 627}, {\"errors\": 0.24967631697654724, \"time-step\": 628}, {\"errors\": 0.24967387318611145, \"time-step\": 629}, {\"errors\": 0.24967148900032043, \"time-step\": 630}, {\"errors\": 0.24966903030872345, \"time-step\": 631}, {\"errors\": 0.24966660141944885, \"time-step\": 632}, {\"errors\": 0.24966415762901306, \"time-step\": 633}, {\"errors\": 0.24966171383857727, \"time-step\": 634}, {\"errors\": 0.24965928494930267, \"time-step\": 635}, {\"errors\": 0.2496568262577057, \"time-step\": 636}, {\"errors\": 0.2496543973684311, \"time-step\": 637}, {\"errors\": 0.24965190887451172, \"time-step\": 638}, {\"errors\": 0.24964945018291473, \"time-step\": 639}, {\"errors\": 0.24964700639247894, \"time-step\": 640}, {\"errors\": 0.24964448809623718, \"time-step\": 641}, {\"errors\": 0.249642014503479, \"time-step\": 642}, {\"errors\": 0.24963951110839844, \"time-step\": 643}, {\"errors\": 0.24963702261447906, \"time-step\": 644}, {\"errors\": 0.2496345043182373, \"time-step\": 645}, {\"errors\": 0.24963198602199554, \"time-step\": 646}, {\"errors\": 0.24962948262691498, \"time-step\": 647}, {\"errors\": 0.24962696433067322, \"time-step\": 648}, {\"errors\": 0.24962446093559265, \"time-step\": 649}, {\"errors\": 0.2496219128370285, \"time-step\": 650}, {\"errors\": 0.24961939454078674, \"time-step\": 651}, {\"errors\": 0.2496168464422226, \"time-step\": 652}, {\"errors\": 0.24961426854133606, \"time-step\": 653}, {\"errors\": 0.2496117204427719, \"time-step\": 654}, {\"errors\": 0.24960918724536896, \"time-step\": 655}, {\"errors\": 0.24960657954216003, \"time-step\": 656}, {\"errors\": 0.2496040165424347, \"time-step\": 657}, {\"errors\": 0.24960142374038696, \"time-step\": 658}, {\"errors\": 0.249598890542984, \"time-step\": 659}, {\"errors\": 0.2495962530374527, \"time-step\": 660}, {\"errors\": 0.24959364533424377, \"time-step\": 661}, {\"errors\": 0.24959105253219604, \"time-step\": 662}, {\"errors\": 0.24958841502666473, \"time-step\": 663}, {\"errors\": 0.24958577752113342, \"time-step\": 664}, {\"errors\": 0.2495831549167633, \"time-step\": 665}, {\"errors\": 0.2495805323123932, \"time-step\": 666}, {\"errors\": 0.24957789480686188, \"time-step\": 667}, {\"errors\": 0.24957525730133057, \"time-step\": 668}, {\"errors\": 0.24957256019115448, \"time-step\": 669}, {\"errors\": 0.24956989288330078, \"time-step\": 670}, {\"errors\": 0.24956722557544708, \"time-step\": 671}, {\"errors\": 0.2495645433664322, \"time-step\": 672}, {\"errors\": 0.2495618760585785, \"time-step\": 673}, {\"errors\": 0.2495591938495636, \"time-step\": 674}, {\"errors\": 0.2495564967393875, \"time-step\": 675}, {\"errors\": 0.24955376982688904, \"time-step\": 676}, {\"errors\": 0.24955107271671295, \"time-step\": 677}, {\"errors\": 0.24954834580421448, \"time-step\": 678}, {\"errors\": 0.24954557418823242, \"time-step\": 679}, {\"errors\": 0.24954283237457275, \"time-step\": 680}, {\"errors\": 0.24954009056091309, \"time-step\": 681}, {\"errors\": 0.2495373785495758, \"time-step\": 682}, {\"errors\": 0.24953454732894897, \"time-step\": 683}, {\"errors\": 0.2495318204164505, \"time-step\": 684}, {\"errors\": 0.24952901899814606, \"time-step\": 685}, {\"errors\": 0.2495262324810028, \"time-step\": 686}, {\"errors\": 0.24952343106269836, \"time-step\": 687}, {\"errors\": 0.24952061474323273, \"time-step\": 688}, {\"errors\": 0.24951781332492828, \"time-step\": 689}, {\"errors\": 0.24951499700546265, \"time-step\": 690}, {\"errors\": 0.24951213598251343, \"time-step\": 691}, {\"errors\": 0.24950933456420898, \"time-step\": 692}, {\"errors\": 0.24950645864009857, \"time-step\": 693}, {\"errors\": 0.24950358271598816, \"time-step\": 694}, {\"errors\": 0.24950070679187775, \"time-step\": 695}, {\"errors\": 0.24949783086776733, \"time-step\": 696}, {\"errors\": 0.24949495494365692, \"time-step\": 697}, {\"errors\": 0.24949204921722412, \"time-step\": 698}, {\"errors\": 0.2494891881942749, \"time-step\": 699}, {\"errors\": 0.2494862675666809, \"time-step\": 700}, {\"errors\": 0.24948333203792572, \"time-step\": 701}, {\"errors\": 0.24948036670684814, \"time-step\": 702}, {\"errors\": 0.24947744607925415, \"time-step\": 703}, {\"errors\": 0.24947448074817657, \"time-step\": 704}, {\"errors\": 0.249471515417099, \"time-step\": 705}, {\"errors\": 0.24946856498718262, \"time-step\": 706}, {\"errors\": 0.24946558475494385, \"time-step\": 707}, {\"errors\": 0.2494625747203827, \"time-step\": 708}, {\"errors\": 0.24945956468582153, \"time-step\": 709}, {\"errors\": 0.24945655465126038, \"time-step\": 710}, {\"errors\": 0.24945354461669922, \"time-step\": 711}, {\"errors\": 0.24945050477981567, \"time-step\": 712}, {\"errors\": 0.24944749474525452, \"time-step\": 713}, {\"errors\": 0.2494444102048874, \"time-step\": 714}, {\"errors\": 0.24944132566452026, \"time-step\": 715}, {\"errors\": 0.24943828582763672, \"time-step\": 716}, {\"errors\": 0.2494351863861084, \"time-step\": 717}, {\"errors\": 0.24943208694458008, \"time-step\": 718}, {\"errors\": 0.24942898750305176, \"time-step\": 719}, {\"errors\": 0.24942582845687866, \"time-step\": 720}, {\"errors\": 0.24942272901535034, \"time-step\": 721}, {\"errors\": 0.24941961467266083, \"time-step\": 722}, {\"errors\": 0.24941645562648773, \"time-step\": 723}, {\"errors\": 0.24941328167915344, \"time-step\": 724}, {\"errors\": 0.24941013753414154, \"time-step\": 725}, {\"errors\": 0.2494068741798401, \"time-step\": 726}, {\"errors\": 0.2494037002325058, \"time-step\": 727}, {\"errors\": 0.2494005262851715, \"time-step\": 728}, {\"errors\": 0.24939727783203125, \"time-step\": 729}, {\"errors\": 0.2493940144777298, \"time-step\": 730}, {\"errors\": 0.24939079582691193, \"time-step\": 731}, {\"errors\": 0.24938754737377167, \"time-step\": 732}, {\"errors\": 0.24938428401947021, \"time-step\": 733}, {\"errors\": 0.24938100576400757, \"time-step\": 734}, {\"errors\": 0.24937768280506134, \"time-step\": 735}, {\"errors\": 0.2493743598461151, \"time-step\": 736}, {\"errors\": 0.24937105178833008, \"time-step\": 737}, {\"errors\": 0.24936771392822266, \"time-step\": 738}, {\"errors\": 0.24936437606811523, \"time-step\": 739}, {\"errors\": 0.2493610680103302, \"time-step\": 740}, {\"errors\": 0.249357670545578, \"time-step\": 741}, {\"errors\": 0.2493542730808258, \"time-step\": 742}, {\"errors\": 0.2493508756160736, \"time-step\": 743}, {\"errors\": 0.2493475079536438, \"time-step\": 744}, {\"errors\": 0.24934405088424683, \"time-step\": 745}, {\"errors\": 0.24934060871601105, \"time-step\": 746}, {\"errors\": 0.24933718144893646, \"time-step\": 747}, {\"errors\": 0.2493337243795395, \"time-step\": 748}, {\"errors\": 0.24933022260665894, \"time-step\": 749}, {\"errors\": 0.24932676553726196, \"time-step\": 750}, {\"errors\": 0.24932321906089783, \"time-step\": 751}, {\"errors\": 0.24931971728801727, \"time-step\": 752}, {\"errors\": 0.24931618571281433, \"time-step\": 753}, {\"errors\": 0.2493126392364502, \"time-step\": 754}, {\"errors\": 0.24930906295776367, \"time-step\": 755}, {\"errors\": 0.24930551648139954, \"time-step\": 756}, {\"errors\": 0.24930192530155182, \"time-step\": 757}, {\"errors\": 0.24929825961589813, \"time-step\": 758}, {\"errors\": 0.24929465353488922, \"time-step\": 759}, {\"errors\": 0.2492910474538803, \"time-step\": 760}, {\"errors\": 0.24928736686706543, \"time-step\": 761}, {\"errors\": 0.24928373098373413, \"time-step\": 762}, {\"errors\": 0.24928003549575806, \"time-step\": 763}, {\"errors\": 0.2492763251066208, \"time-step\": 764}, {\"errors\": 0.2492726445198059, \"time-step\": 765}, {\"errors\": 0.24926891922950745, \"time-step\": 766}, {\"errors\": 0.2492651343345642, \"time-step\": 767}, {\"errors\": 0.24926139414310455, \"time-step\": 768}, {\"errors\": 0.2492576241493225, \"time-step\": 769}, {\"errors\": 0.24925380945205688, \"time-step\": 770}, {\"errors\": 0.24925002455711365, \"time-step\": 771}, {\"errors\": 0.24924618005752563, \"time-step\": 772}, {\"errors\": 0.24924233555793762, \"time-step\": 773}, {\"errors\": 0.2492384910583496, \"time-step\": 774}, {\"errors\": 0.2492346316576004, \"time-step\": 775}, {\"errors\": 0.24923071265220642, \"time-step\": 776}, {\"errors\": 0.24922680854797363, \"time-step\": 777}, {\"errors\": 0.24922287464141846, \"time-step\": 778}, {\"errors\": 0.24921897053718567, \"time-step\": 779}, {\"errors\": 0.24921496212482452, \"time-step\": 780}, {\"errors\": 0.24921098351478577, \"time-step\": 781}, {\"errors\": 0.2492070198059082, \"time-step\": 782}, {\"errors\": 0.24920298159122467, \"time-step\": 783}, {\"errors\": 0.24919897317886353, \"time-step\": 784}, {\"errors\": 0.2491949051618576, \"time-step\": 785}, {\"errors\": 0.2491908222436905, \"time-step\": 786}, {\"errors\": 0.24918675422668457, \"time-step\": 787}, {\"errors\": 0.24918264150619507, \"time-step\": 788}, {\"errors\": 0.24917852878570557, \"time-step\": 789}, {\"errors\": 0.24917438626289368, \"time-step\": 790}, {\"errors\": 0.2491702139377594, \"time-step\": 791}, {\"errors\": 0.24916604161262512, \"time-step\": 792}, {\"errors\": 0.24916186928749084, \"time-step\": 793}, {\"errors\": 0.2491576075553894, \"time-step\": 794}, {\"errors\": 0.24915337562561035, \"time-step\": 795}, {\"errors\": 0.2491491436958313, \"time-step\": 796}, {\"errors\": 0.24914485216140747, \"time-step\": 797}, {\"errors\": 0.24914056062698364, \"time-step\": 798}, {\"errors\": 0.24913623929023743, \"time-step\": 799}, {\"errors\": 0.2491319179534912, \"time-step\": 800}, {\"errors\": 0.2491275519132614, \"time-step\": 801}, {\"errors\": 0.24912317097187042, \"time-step\": 802}, {\"errors\": 0.24911877512931824, \"time-step\": 803}, {\"errors\": 0.24911434948444366, \"time-step\": 804}, {\"errors\": 0.2491099238395691, \"time-step\": 805}, {\"errors\": 0.24910546839237213, \"time-step\": 806}, {\"errors\": 0.2491009682416916, \"time-step\": 807}, {\"errors\": 0.24909645318984985, \"time-step\": 808}, {\"errors\": 0.2490919828414917, \"time-step\": 809}, {\"errors\": 0.249087393283844, \"time-step\": 810}, {\"errors\": 0.24908284842967987, \"time-step\": 811}, {\"errors\": 0.24907822906970978, \"time-step\": 812}, {\"errors\": 0.24907362461090088, \"time-step\": 813}, {\"errors\": 0.2490689903497696, \"time-step\": 814}, {\"errors\": 0.2490643560886383, \"time-step\": 815}, {\"errors\": 0.24905966222286224, \"time-step\": 816}, {\"errors\": 0.2490549385547638, \"time-step\": 817}, {\"errors\": 0.24905021488666534, \"time-step\": 818}, {\"errors\": 0.2490454912185669, \"time-step\": 819}, {\"errors\": 0.24904067814350128, \"time-step\": 820}, {\"errors\": 0.24903592467308044, \"time-step\": 821}, {\"errors\": 0.24903109669685364, \"time-step\": 822}, {\"errors\": 0.24902625381946564, \"time-step\": 823}, {\"errors\": 0.24902136623859406, \"time-step\": 824}, {\"errors\": 0.24901646375656128, \"time-step\": 825}, {\"errors\": 0.2490115910768509, \"time-step\": 826}, {\"errors\": 0.24900662899017334, \"time-step\": 827}, {\"errors\": 0.24900171160697937, \"time-step\": 828}, {\"errors\": 0.24899668991565704, \"time-step\": 829}, {\"errors\": 0.24899165332317352, \"time-step\": 830}, {\"errors\": 0.24898661673069, \"time-step\": 831}, {\"errors\": 0.24898158013820648, \"time-step\": 832}, {\"errors\": 0.248976469039917, \"time-step\": 833}, {\"errors\": 0.2489713728427887, \"time-step\": 834}, {\"errors\": 0.24896621704101562, \"time-step\": 835}, {\"errors\": 0.24896106123924255, \"time-step\": 836}, {\"errors\": 0.2489558607339859, \"time-step\": 837}, {\"errors\": 0.24895066022872925, \"time-step\": 838}, {\"errors\": 0.24894538521766663, \"time-step\": 839}, {\"errors\": 0.2489401400089264, \"time-step\": 840}, {\"errors\": 0.24893483519554138, \"time-step\": 841}, {\"errors\": 0.2489294856786728, \"time-step\": 842}, {\"errors\": 0.2489241361618042, \"time-step\": 843}, {\"errors\": 0.24891877174377441, \"time-step\": 844}, {\"errors\": 0.24891333281993866, \"time-step\": 845}, {\"errors\": 0.2489079236984253, \"time-step\": 846}, {\"errors\": 0.24890242516994476, \"time-step\": 847}, {\"errors\": 0.24889695644378662, \"time-step\": 848}, {\"errors\": 0.2488914132118225, \"time-step\": 849}, {\"errors\": 0.2488858550786972, \"time-step\": 850}, {\"errors\": 0.2488802969455719, \"time-step\": 851}, {\"errors\": 0.24887466430664062, \"time-step\": 852}, {\"errors\": 0.24886903166770935, \"time-step\": 853}, {\"errors\": 0.2488633692264557, \"time-step\": 854}, {\"errors\": 0.24885767698287964, \"time-step\": 855}, {\"errors\": 0.2488519698381424, \"time-step\": 856}, {\"errors\": 0.248846173286438, \"time-step\": 857}, {\"errors\": 0.24884040653705597, \"time-step\": 858}, {\"errors\": 0.24883458018302917, \"time-step\": 859}, {\"errors\": 0.24882872402668, \"time-step\": 860}, {\"errors\": 0.2488228678703308, \"time-step\": 861}, {\"errors\": 0.24881693720817566, \"time-step\": 862}, {\"errors\": 0.2488110065460205, \"time-step\": 863}, {\"errors\": 0.24880501627922058, \"time-step\": 864}, {\"errors\": 0.24879898130893707, \"time-step\": 865}, {\"errors\": 0.24879294633865356, \"time-step\": 866}, {\"errors\": 0.24878691136837006, \"time-step\": 867}, {\"errors\": 0.24878078699111938, \"time-step\": 868}, {\"errors\": 0.24877463281154633, \"time-step\": 869}, {\"errors\": 0.24876844882965088, \"time-step\": 870}, {\"errors\": 0.24876224994659424, \"time-step\": 871}, {\"errors\": 0.2487560361623764, \"time-step\": 872}, {\"errors\": 0.2487497627735138, \"time-step\": 873}, {\"errors\": 0.24874347448349, \"time-step\": 874}, {\"errors\": 0.24873711168766022, \"time-step\": 875}, {\"errors\": 0.24873071908950806, \"time-step\": 876}, {\"errors\": 0.2487243115901947, \"time-step\": 877}, {\"errors\": 0.24871788918972015, \"time-step\": 878}, {\"errors\": 0.24871140718460083, \"time-step\": 879}, {\"errors\": 0.24870489537715912, \"time-step\": 880}, {\"errors\": 0.24869832396507263, \"time-step\": 881}, {\"errors\": 0.24869173765182495, \"time-step\": 882}, {\"errors\": 0.24868512153625488, \"time-step\": 883}, {\"errors\": 0.24867847561836243, \"time-step\": 884}, {\"errors\": 0.2486717700958252, \"time-step\": 885}, {\"errors\": 0.24866503477096558, \"time-step\": 886}, {\"errors\": 0.24865826964378357, \"time-step\": 887}, {\"errors\": 0.24865147471427917, \"time-step\": 888}, {\"errors\": 0.2486446350812912, \"time-step\": 889}, {\"errors\": 0.24863773584365845, \"time-step\": 890}, {\"errors\": 0.24863079190254211, \"time-step\": 891}, {\"errors\": 0.2486238181591034, \"time-step\": 892}, {\"errors\": 0.24861684441566467, \"time-step\": 893}, {\"errors\": 0.24860981106758118, \"time-step\": 894}, {\"errors\": 0.2486027181148529, \"time-step\": 895}, {\"errors\": 0.24859561026096344, \"time-step\": 896}, {\"errors\": 0.2485884577035904, \"time-step\": 897}, {\"errors\": 0.24858126044273376, \"time-step\": 898}, {\"errors\": 0.24857401847839355, \"time-step\": 899}, {\"errors\": 0.24856677651405334, \"time-step\": 900}, {\"errors\": 0.24855944514274597, \"time-step\": 901}, {\"errors\": 0.2485520839691162, \"time-step\": 902}, {\"errors\": 0.24854467809200287, \"time-step\": 903}, {\"errors\": 0.24853719770908356, \"time-step\": 904}, {\"errors\": 0.24852974712848663, \"time-step\": 905}, {\"errors\": 0.24852219223976135, \"time-step\": 906}, {\"errors\": 0.24851465225219727, \"time-step\": 907}, {\"errors\": 0.2485070526599884, \"time-step\": 908}, {\"errors\": 0.24849939346313477, \"time-step\": 909}, {\"errors\": 0.24849167466163635, \"time-step\": 910}, {\"errors\": 0.24848394095897675, \"time-step\": 911}, {\"errors\": 0.24847614765167236, \"time-step\": 912}, {\"errors\": 0.2484683096408844, \"time-step\": 913}, {\"errors\": 0.24846044182777405, \"time-step\": 914}, {\"errors\": 0.24845252931118011, \"time-step\": 915}, {\"errors\": 0.2484445571899414, \"time-step\": 916}, {\"errors\": 0.24843654036521912, \"time-step\": 917}, {\"errors\": 0.24842849373817444, \"time-step\": 918}, {\"errors\": 0.2484203726053238, \"time-step\": 919}, {\"errors\": 0.24841223657131195, \"time-step\": 920}, {\"errors\": 0.24840402603149414, \"time-step\": 921}, {\"errors\": 0.24839577078819275, \"time-step\": 922}, {\"errors\": 0.24838747084140778, \"time-step\": 923}, {\"errors\": 0.24837914109230042, \"time-step\": 924}, {\"errors\": 0.24837073683738708, \"time-step\": 925}, {\"errors\": 0.24836231768131256, \"time-step\": 926}, {\"errors\": 0.24835382401943207, \"time-step\": 927}, {\"errors\": 0.248345285654068, \"time-step\": 928}, {\"errors\": 0.24833667278289795, \"time-step\": 929}, {\"errors\": 0.2483280599117279, \"time-step\": 930}, {\"errors\": 0.24831938743591309, \"time-step\": 931}, {\"errors\": 0.2483106553554535, \"time-step\": 932}, {\"errors\": 0.24830187857151031, \"time-step\": 933}, {\"errors\": 0.24829301238059998, \"time-step\": 934}, {\"errors\": 0.24828410148620605, \"time-step\": 935}, {\"errors\": 0.24827516078948975, \"time-step\": 936}, {\"errors\": 0.24826619029045105, \"time-step\": 937}, {\"errors\": 0.24825716018676758, \"time-step\": 938}, {\"errors\": 0.24824805557727814, \"time-step\": 939}, {\"errors\": 0.24823890626430511, \"time-step\": 940}, {\"errors\": 0.24822968244552612, \"time-step\": 941}, {\"errors\": 0.24822041392326355, \"time-step\": 942}, {\"errors\": 0.2482111155986786, \"time-step\": 943}, {\"errors\": 0.24820172786712646, \"time-step\": 944}, {\"errors\": 0.24819232523441315, \"time-step\": 945}, {\"errors\": 0.24818283319473267, \"time-step\": 946}, {\"errors\": 0.2481733113527298, \"time-step\": 947}, {\"errors\": 0.24816371500492096, \"time-step\": 948}, {\"errors\": 0.24815407395362854, \"time-step\": 949}, {\"errors\": 0.24814435839653015, \"time-step\": 950}, {\"errors\": 0.248134583234787, \"time-step\": 951}, {\"errors\": 0.24812477827072144, \"time-step\": 952}, {\"errors\": 0.24811488389968872, \"time-step\": 953}, {\"errors\": 0.24810494482517242, \"time-step\": 954}, {\"errors\": 0.24809497594833374, \"time-step\": 955}, {\"errors\": 0.2480849176645279, \"time-step\": 956}, {\"errors\": 0.24807482957839966, \"time-step\": 957}, {\"errors\": 0.24806462228298187, \"time-step\": 958}, {\"errors\": 0.2480543702840805, \"time-step\": 959}, {\"errors\": 0.24804410338401794, \"time-step\": 960}, {\"errors\": 0.24803374707698822, \"time-step\": 961}, {\"errors\": 0.24802333116531372, \"time-step\": 962}, {\"errors\": 0.24801285564899445, \"time-step\": 963}, {\"errors\": 0.248002290725708, \"time-step\": 964}, {\"errors\": 0.2479916661977768, \"time-step\": 965}, {\"errors\": 0.2479810118675232, \"time-step\": 966}, {\"errors\": 0.24797026813030243, \"time-step\": 967}, {\"errors\": 0.24795949459075928, \"time-step\": 968}, {\"errors\": 0.24794861674308777, \"time-step\": 969}, {\"errors\": 0.24793770909309387, \"time-step\": 970}, {\"errors\": 0.2479267120361328, \"time-step\": 971}, {\"errors\": 0.24791565537452698, \"time-step\": 972}, {\"errors\": 0.24790450930595398, \"time-step\": 973}, {\"errors\": 0.247893288731575, \"time-step\": 974}, {\"errors\": 0.24788205325603485, \"time-step\": 975}, {\"errors\": 0.24787074327468872, \"time-step\": 976}, {\"errors\": 0.24785934388637543, \"time-step\": 977}, {\"errors\": 0.24784788489341736, \"time-step\": 978}, {\"errors\": 0.24783635139465332, \"time-step\": 979}, {\"errors\": 0.2478247582912445, \"time-step\": 980}, {\"errors\": 0.24781307578086853, \"time-step\": 981}, {\"errors\": 0.2478013038635254, \"time-step\": 982}, {\"errors\": 0.24778953194618225, \"time-step\": 983}, {\"errors\": 0.24777761101722717, \"time-step\": 984}, {\"errors\": 0.2477656602859497, \"time-step\": 985}, {\"errors\": 0.24775364995002747, \"time-step\": 986}, {\"errors\": 0.24774155020713806, \"time-step\": 987}, {\"errors\": 0.2477293610572815, \"time-step\": 988}, {\"errors\": 0.24771711230278015, \"time-step\": 989}, {\"errors\": 0.24770483374595642, \"time-step\": 990}, {\"errors\": 0.24769239127635956, \"time-step\": 991}, {\"errors\": 0.2476799488067627, \"time-step\": 992}, {\"errors\": 0.2476673573255539, \"time-step\": 993}, {\"errors\": 0.2476547658443451, \"time-step\": 994}, {\"errors\": 0.24764207005500793, \"time-step\": 995}, {\"errors\": 0.2476292848587036, \"time-step\": 996}, {\"errors\": 0.24761642515659332, \"time-step\": 997}, {\"errors\": 0.24760347604751587, \"time-step\": 998}, {\"errors\": 0.24759045243263245, \"time-step\": 999}, {\"errors\": 0.24757736921310425, \"time-step\": 1000}, {\"errors\": 0.24756422638893127, \"time-step\": 1001}, {\"errors\": 0.24755099415779114, \"time-step\": 1002}, {\"errors\": 0.24753764271736145, \"time-step\": 1003}, {\"errors\": 0.24752426147460938, \"time-step\": 1004}, {\"errors\": 0.24751073122024536, \"time-step\": 1005}, {\"errors\": 0.24749712646007538, \"time-step\": 1006}, {\"errors\": 0.2474835067987442, \"time-step\": 1007}, {\"errors\": 0.2474697381258011, \"time-step\": 1008}, {\"errors\": 0.2474559247493744, \"time-step\": 1009}, {\"errors\": 0.24744199216365814, \"time-step\": 1010}, {\"errors\": 0.2474280297756195, \"time-step\": 1011}, {\"errors\": 0.24741393327713013, \"time-step\": 1012}, {\"errors\": 0.24739977717399597, \"time-step\": 1013}, {\"errors\": 0.24738554656505585, \"time-step\": 1014}, {\"errors\": 0.2473711520433426, \"time-step\": 1015}, {\"errors\": 0.24735674262046814, \"time-step\": 1016}, {\"errors\": 0.24734222888946533, \"time-step\": 1017}, {\"errors\": 0.24732765555381775, \"time-step\": 1018}, {\"errors\": 0.24731290340423584, \"time-step\": 1019}, {\"errors\": 0.24729813635349274, \"time-step\": 1020}, {\"errors\": 0.24728325009346008, \"time-step\": 1021}, {\"errors\": 0.24726828932762146, \"time-step\": 1022}, {\"errors\": 0.24725323915481567, \"time-step\": 1023}, {\"errors\": 0.24723808467388153, \"time-step\": 1024}, {\"errors\": 0.2472228705883026, \"time-step\": 1025}, {\"errors\": 0.24720753729343414, \"time-step\": 1026}, {\"errors\": 0.24719209969043732, \"time-step\": 1027}, {\"errors\": 0.24717655777931213, \"time-step\": 1028}, {\"errors\": 0.24716094136238098, \"time-step\": 1029}, {\"errors\": 0.24714520573616028, \"time-step\": 1030}, {\"errors\": 0.2471294105052948, \"time-step\": 1031}, {\"errors\": 0.24711351096630096, \"time-step\": 1032}, {\"errors\": 0.24709752202033997, \"time-step\": 1033}, {\"errors\": 0.24708141386508942, \"time-step\": 1034}, {\"errors\": 0.2470652163028717, \"time-step\": 1035}, {\"errors\": 0.24704889953136444, \"time-step\": 1036}, {\"errors\": 0.2470325380563736, \"time-step\": 1037}, {\"errors\": 0.24701598286628723, \"time-step\": 1038}, {\"errors\": 0.24699938297271729, \"time-step\": 1039}, {\"errors\": 0.24698270857334137, \"time-step\": 1040}, {\"errors\": 0.24696588516235352, \"time-step\": 1041}, {\"errors\": 0.2469490021467209, \"time-step\": 1042}, {\"errors\": 0.24693195521831512, \"time-step\": 1043}, {\"errors\": 0.24691486358642578, \"time-step\": 1044}, {\"errors\": 0.2468976378440857, \"time-step\": 1045}, {\"errors\": 0.24688029289245605, \"time-step\": 1046}, {\"errors\": 0.24686284363269806, \"time-step\": 1047}, {\"errors\": 0.2468453198671341, \"time-step\": 1048}, {\"errors\": 0.24682766199111938, \"time-step\": 1049}, {\"errors\": 0.2468099296092987, \"time-step\": 1050}, {\"errors\": 0.2467920482158661, \"time-step\": 1051}, {\"errors\": 0.2467740923166275, \"time-step\": 1052}, {\"errors\": 0.24675597250461578, \"time-step\": 1053}, {\"errors\": 0.2467377781867981, \"time-step\": 1054}, {\"errors\": 0.24671947956085205, \"time-step\": 1055}, {\"errors\": 0.24670109152793884, \"time-step\": 1056}, {\"errors\": 0.2466825395822525, \"time-step\": 1057}, {\"errors\": 0.2466638833284378, \"time-step\": 1058}, {\"errors\": 0.24664513766765594, \"time-step\": 1059}, {\"errors\": 0.24662622809410095, \"time-step\": 1060}, {\"errors\": 0.24660725891590118, \"time-step\": 1061}, {\"errors\": 0.24658815562725067, \"time-step\": 1062}, {\"errors\": 0.2465689480304718, \"time-step\": 1063}, {\"errors\": 0.2465495765209198, \"time-step\": 1064}, {\"errors\": 0.24653010070323944, \"time-step\": 1065}, {\"errors\": 0.2465105503797531, \"time-step\": 1066}, {\"errors\": 0.24649085104465485, \"time-step\": 1067}, {\"errors\": 0.24647101759910583, \"time-step\": 1068}, {\"errors\": 0.24645109474658966, \"time-step\": 1069}, {\"errors\": 0.24643102288246155, \"time-step\": 1070}, {\"errors\": 0.24641084671020508, \"time-step\": 1071}, {\"errors\": 0.24639053642749786, \"time-step\": 1072}, {\"errors\": 0.2463701069355011, \"time-step\": 1073}, {\"errors\": 0.2463495433330536, \"time-step\": 1074}, {\"errors\": 0.24632886052131653, \"time-step\": 1075}, {\"errors\": 0.24630805850028992, \"time-step\": 1076}, {\"errors\": 0.24628716707229614, \"time-step\": 1077}, {\"errors\": 0.24626605212688446, \"time-step\": 1078}, {\"errors\": 0.2462449073791504, \"time-step\": 1079}, {\"errors\": 0.2462235391139984, \"time-step\": 1080}, {\"errors\": 0.24620214104652405, \"time-step\": 1081}, {\"errors\": 0.24618054926395416, \"time-step\": 1082}, {\"errors\": 0.24615886807441711, \"time-step\": 1083}, {\"errors\": 0.24613700807094574, \"time-step\": 1084}, {\"errors\": 0.24611502885818481, \"time-step\": 1085}, {\"errors\": 0.24609294533729553, \"time-step\": 1086}, {\"errors\": 0.24607068300247192, \"time-step\": 1087}, {\"errors\": 0.24604831635951996, \"time-step\": 1088}, {\"errors\": 0.24602580070495605, \"time-step\": 1089}, {\"errors\": 0.246003195643425, \"time-step\": 1090}, {\"errors\": 0.24598033726215363, \"time-step\": 1091}, {\"errors\": 0.24595743417739868, \"time-step\": 1092}, {\"errors\": 0.245934396982193, \"time-step\": 1093}, {\"errors\": 0.24591118097305298, \"time-step\": 1094}, {\"errors\": 0.2458878457546234, \"time-step\": 1095}, {\"errors\": 0.24586434662342072, \"time-step\": 1096}, {\"errors\": 0.24584075808525085, \"time-step\": 1097}, {\"errors\": 0.24581697583198547, \"time-step\": 1098}, {\"errors\": 0.24579307436943054, \"time-step\": 1099}, {\"errors\": 0.24576902389526367, \"time-step\": 1100}, {\"errors\": 0.24574483931064606, \"time-step\": 1101}, {\"errors\": 0.2457205057144165, \"time-step\": 1102}, {\"errors\": 0.245696023106575, \"time-step\": 1103}, {\"errors\": 0.2456713616847992, \"time-step\": 1104}, {\"errors\": 0.24564658105373383, \"time-step\": 1105}, {\"errors\": 0.2456216663122177, \"time-step\": 1106}, {\"errors\": 0.24559660255908966, \"time-step\": 1107}, {\"errors\": 0.24557137489318848, \"time-step\": 1108}, {\"errors\": 0.24554598331451416, \"time-step\": 1109}, {\"errors\": 0.2455204427242279, \"time-step\": 1110}, {\"errors\": 0.2454947531223297, \"time-step\": 1111}, {\"errors\": 0.24546891450881958, \"time-step\": 1112}, {\"errors\": 0.24544291198253632, \"time-step\": 1113}, {\"errors\": 0.2454167753458023, \"time-step\": 1114}, {\"errors\": 0.24539047479629517, \"time-step\": 1115}, {\"errors\": 0.2453640252351761, \"time-step\": 1116}, {\"errors\": 0.24533739686012268, \"time-step\": 1117}, {\"errors\": 0.24531066417694092, \"time-step\": 1118}, {\"errors\": 0.24528369307518005, \"time-step\": 1119}, {\"errors\": 0.24525657296180725, \"time-step\": 1120}, {\"errors\": 0.2452293187379837, \"time-step\": 1121}, {\"errors\": 0.24520190060138702, \"time-step\": 1122}, {\"errors\": 0.2451743483543396, \"time-step\": 1123}, {\"errors\": 0.24514660239219666, \"time-step\": 1124}, {\"errors\": 0.24511872231960297, \"time-step\": 1125}, {\"errors\": 0.24509061872959137, \"time-step\": 1126}, {\"errors\": 0.24506241083145142, \"time-step\": 1127}, {\"errors\": 0.24503394961357117, \"time-step\": 1128}, {\"errors\": 0.24500542879104614, \"time-step\": 1129}, {\"errors\": 0.2449766993522644, \"time-step\": 1130}, {\"errors\": 0.24494780600070953, \"time-step\": 1131}, {\"errors\": 0.24491870403289795, \"time-step\": 1132}, {\"errors\": 0.24488943815231323, \"time-step\": 1133}, {\"errors\": 0.24486005306243896, \"time-step\": 1134}, {\"errors\": 0.24483045935630798, \"time-step\": 1135}, {\"errors\": 0.24480068683624268, \"time-step\": 1136}, {\"errors\": 0.24477073550224304, \"time-step\": 1137}, {\"errors\": 0.24474062025547028, \"time-step\": 1138}, {\"errors\": 0.24471035599708557, \"time-step\": 1139}, {\"errors\": 0.24467989802360535, \"time-step\": 1140}, {\"errors\": 0.2446492612361908, \"time-step\": 1141}, {\"errors\": 0.24461844563484192, \"time-step\": 1142}, {\"errors\": 0.24458742141723633, \"time-step\": 1143}, {\"errors\": 0.2445562779903412, \"time-step\": 1144}, {\"errors\": 0.24452492594718933, \"time-step\": 1145}, {\"errors\": 0.24449339509010315, \"time-step\": 1146}, {\"errors\": 0.24446168541908264, \"time-step\": 1147}, {\"errors\": 0.2444297820329666, \"time-step\": 1148}, {\"errors\": 0.24439765512943268, \"time-step\": 1149}, {\"errors\": 0.24436543881893158, \"time-step\": 1150}, {\"errors\": 0.244332954287529, \"time-step\": 1151}, {\"errors\": 0.24430033564567566, \"time-step\": 1152}, {\"errors\": 0.2442675232887268, \"time-step\": 1153}, {\"errors\": 0.24423447251319885, \"time-step\": 1154}, {\"errors\": 0.24420127272605896, \"time-step\": 1155}, {\"errors\": 0.24416787922382355, \"time-step\": 1156}, {\"errors\": 0.24413429200649261, \"time-step\": 1157}, {\"errors\": 0.24410049617290497, \"time-step\": 1158}, {\"errors\": 0.24406656622886658, \"time-step\": 1159}, {\"errors\": 0.2440323531627655, \"time-step\": 1160}, {\"errors\": 0.24399805068969727, \"time-step\": 1161}, {\"errors\": 0.24396349489688873, \"time-step\": 1162}, {\"errors\": 0.24392876029014587, \"time-step\": 1163}, {\"errors\": 0.2438938021659851, \"time-step\": 1164}, {\"errors\": 0.24385866522789001, \"time-step\": 1165}, {\"errors\": 0.2438233196735382, \"time-step\": 1166}, {\"errors\": 0.24378779530525208, \"time-step\": 1167}, {\"errors\": 0.24375203251838684, \"time-step\": 1168}, {\"errors\": 0.24371612071990967, \"time-step\": 1169}, {\"errors\": 0.2436799705028534, \"time-step\": 1170}, {\"errors\": 0.2436436265707016, \"time-step\": 1171}, {\"errors\": 0.24360710382461548, \"time-step\": 1172}, {\"errors\": 0.24357035756111145, \"time-step\": 1173}, {\"errors\": 0.24353337287902832, \"time-step\": 1174}, {\"errors\": 0.24349623918533325, \"time-step\": 1175}, {\"errors\": 0.24345886707305908, \"time-step\": 1176}, {\"errors\": 0.24342131614685059, \"time-step\": 1177}, {\"errors\": 0.2433835119009018, \"time-step\": 1178}, {\"errors\": 0.24334554374217987, \"time-step\": 1179}, {\"errors\": 0.24330733716487885, \"time-step\": 1180}, {\"errors\": 0.2432689666748047, \"time-step\": 1181}, {\"errors\": 0.24323031306266785, \"time-step\": 1182}, {\"errors\": 0.24319151043891907, \"time-step\": 1183}, {\"errors\": 0.2431524097919464, \"time-step\": 1184}, {\"errors\": 0.2431131899356842, \"time-step\": 1185}, {\"errors\": 0.24307368695735931, \"time-step\": 1186}, {\"errors\": 0.2430340200662613, \"time-step\": 1187}, {\"errors\": 0.24299408495426178, \"time-step\": 1188}, {\"errors\": 0.24295394122600555, \"time-step\": 1189}, {\"errors\": 0.2429136484861374, \"time-step\": 1190}, {\"errors\": 0.24287305772304535, \"time-step\": 1191}, {\"errors\": 0.2428322583436966, \"time-step\": 1192}, {\"errors\": 0.24279125034809113, \"time-step\": 1193}, {\"errors\": 0.24275003373622894, \"time-step\": 1194}, {\"errors\": 0.24270853400230408, \"time-step\": 1195}, {\"errors\": 0.24266687035560608, \"time-step\": 1196}, {\"errors\": 0.24262496829032898, \"time-step\": 1197}, {\"errors\": 0.24258284270763397, \"time-step\": 1198}, {\"errors\": 0.24254050850868225, \"time-step\": 1199}, {\"errors\": 0.24249792098999023, \"time-step\": 1200}, {\"errors\": 0.24245509505271912, \"time-step\": 1201}, {\"errors\": 0.24241207540035248, \"time-step\": 1202}, {\"errors\": 0.24236880242824554, \"time-step\": 1203}, {\"errors\": 0.2423253357410431, \"time-step\": 1204}, {\"errors\": 0.24228157103061676, \"time-step\": 1205}, {\"errors\": 0.24223759770393372, \"time-step\": 1206}, {\"errors\": 0.24219343066215515, \"time-step\": 1207}, {\"errors\": 0.2421489655971527, \"time-step\": 1208}, {\"errors\": 0.24210433661937714, \"time-step\": 1209}, {\"errors\": 0.2420593947172165, \"time-step\": 1210}, {\"errors\": 0.24201427400112152, \"time-step\": 1211}, {\"errors\": 0.24196891486644745, \"time-step\": 1212}, {\"errors\": 0.24192330241203308, \"time-step\": 1213}, {\"errors\": 0.2418774664402008, \"time-step\": 1214}, {\"errors\": 0.24183133244514465, \"time-step\": 1215}, {\"errors\": 0.24178500473499298, \"time-step\": 1216}, {\"errors\": 0.2417384386062622, \"time-step\": 1217}, {\"errors\": 0.24169163405895233, \"time-step\": 1218}, {\"errors\": 0.24164456129074097, \"time-step\": 1219}, {\"errors\": 0.2415972501039505, \"time-step\": 1220}, {\"errors\": 0.24154970049858093, \"time-step\": 1221}, {\"errors\": 0.24150191247463226, \"time-step\": 1222}, {\"errors\": 0.2414538860321045, \"time-step\": 1223}, {\"errors\": 0.24140557646751404, \"time-step\": 1224}, {\"errors\": 0.24135702848434448, \"time-step\": 1225}, {\"errors\": 0.2413082718849182, \"time-step\": 1226}, {\"errors\": 0.24125917255878448, \"time-step\": 1227}, {\"errors\": 0.24120992422103882, \"time-step\": 1228}, {\"errors\": 0.24116036295890808, \"time-step\": 1229}, {\"errors\": 0.24111056327819824, \"time-step\": 1230}, {\"errors\": 0.2410605400800705, \"time-step\": 1231}, {\"errors\": 0.24101021885871887, \"time-step\": 1232}, {\"errors\": 0.24095967411994934, \"time-step\": 1233}, {\"errors\": 0.24090884625911713, \"time-step\": 1234}, {\"errors\": 0.2408577799797058, \"time-step\": 1235}, {\"errors\": 0.2408064752817154, \"time-step\": 1236}, {\"errors\": 0.2407548427581787, \"time-step\": 1237}, {\"errors\": 0.24070298671722412, \"time-step\": 1238}, {\"errors\": 0.24065087735652924, \"time-step\": 1239}, {\"errors\": 0.24059851467609406, \"time-step\": 1240}, {\"errors\": 0.24054589867591858, \"time-step\": 1241}, {\"errors\": 0.2404930293560028, \"time-step\": 1242}, {\"errors\": 0.24043983221054077, \"time-step\": 1243}, {\"errors\": 0.24038641154766083, \"time-step\": 1244}, {\"errors\": 0.2403327226638794, \"time-step\": 1245}, {\"errors\": 0.24027878046035767, \"time-step\": 1246}, {\"errors\": 0.24022454023361206, \"time-step\": 1247}, {\"errors\": 0.24017006158828735, \"time-step\": 1248}, {\"errors\": 0.24011527001857758, \"time-step\": 1249}, {\"errors\": 0.2400602549314499, \"time-step\": 1250}, {\"errors\": 0.24000497162342072, \"time-step\": 1251}, {\"errors\": 0.23994939029216766, \"time-step\": 1252}, {\"errors\": 0.23989354074001312, \"time-step\": 1253}, {\"errors\": 0.23983745276927948, \"time-step\": 1254}, {\"errors\": 0.23978106677532196, \"time-step\": 1255}, {\"errors\": 0.23972439765930176, \"time-step\": 1256}, {\"errors\": 0.23966746032238007, \"time-step\": 1257}, {\"errors\": 0.23961025476455688, \"time-step\": 1258}, {\"errors\": 0.23955275118350983, \"time-step\": 1259}, {\"errors\": 0.23949497938156128, \"time-step\": 1260}, {\"errors\": 0.23943692445755005, \"time-step\": 1261}, {\"errors\": 0.23937857151031494, \"time-step\": 1262}, {\"errors\": 0.23931995034217834, \"time-step\": 1263}, {\"errors\": 0.23926107585430145, \"time-step\": 1264}, {\"errors\": 0.23920190334320068, \"time-step\": 1265}, {\"errors\": 0.23914244771003723, \"time-step\": 1266}, {\"errors\": 0.2390826940536499, \"time-step\": 1267}, {\"errors\": 0.23902267217636108, \"time-step\": 1268}, {\"errors\": 0.2389623522758484, \"time-step\": 1269}, {\"errors\": 0.2389017641544342, \"time-step\": 1270}, {\"errors\": 0.23884087800979614, \"time-step\": 1271}, {\"errors\": 0.2387797236442566, \"time-step\": 1272}, {\"errors\": 0.23871824145317078, \"time-step\": 1273}, {\"errors\": 0.2386564463376999, \"time-step\": 1274}, {\"errors\": 0.2385944426059723, \"time-step\": 1275}, {\"errors\": 0.23853209614753723, \"time-step\": 1276}, {\"errors\": 0.2384694516658783, \"time-step\": 1277}, {\"errors\": 0.23840653896331787, \"time-step\": 1278}, {\"errors\": 0.23834331333637238, \"time-step\": 1279}, {\"errors\": 0.2382798194885254, \"time-step\": 1280}, {\"errors\": 0.23821599781513214, \"time-step\": 1281}, {\"errors\": 0.23815187811851501, \"time-step\": 1282}, {\"errors\": 0.2380875051021576, \"time-step\": 1283}, {\"errors\": 0.23802277445793152, \"time-step\": 1284}, {\"errors\": 0.23795779049396515, \"time-step\": 1285}, {\"errors\": 0.23789247870445251, \"time-step\": 1286}, {\"errors\": 0.23782683908939362, \"time-step\": 1287}, {\"errors\": 0.2377609759569168, \"time-step\": 1288}, {\"errors\": 0.23769474029541016, \"time-step\": 1289}, {\"errors\": 0.2376282662153244, \"time-step\": 1290}, {\"errors\": 0.23756143450737, \"time-step\": 1291}, {\"errors\": 0.23749437928199768, \"time-step\": 1292}, {\"errors\": 0.23742690682411194, \"time-step\": 1293}, {\"errors\": 0.2373591661453247, \"time-step\": 1294}, {\"errors\": 0.237291157245636, \"time-step\": 1295}, {\"errors\": 0.237222820520401, \"time-step\": 1296}, {\"errors\": 0.23715414106845856, \"time-step\": 1297}, {\"errors\": 0.23708517849445343, \"time-step\": 1298}, {\"errors\": 0.23701590299606323, \"time-step\": 1299}, {\"errors\": 0.23694632947444916, \"time-step\": 1300}, {\"errors\": 0.23687642812728882, \"time-step\": 1301}, {\"errors\": 0.2368062287569046, \"time-step\": 1302}, {\"errors\": 0.23673568665981293, \"time-step\": 1303}, {\"errors\": 0.23666487634181976, \"time-step\": 1304}, {\"errors\": 0.23659370839595795, \"time-step\": 1305}, {\"errors\": 0.23652225732803345, \"time-step\": 1306}, {\"errors\": 0.2364504486322403, \"time-step\": 1307}, {\"errors\": 0.23637835681438446, \"time-step\": 1308}, {\"errors\": 0.23630592226982117, \"time-step\": 1309}, {\"errors\": 0.2362332046031952, \"time-step\": 1310}, {\"errors\": 0.23616012930870056, \"time-step\": 1311}, {\"errors\": 0.23608674108982086, \"time-step\": 1312}, {\"errors\": 0.23601308465003967, \"time-step\": 1313}, {\"errors\": 0.23593904078006744, \"time-step\": 1314}, {\"errors\": 0.23586469888687134, \"time-step\": 1315}, {\"errors\": 0.23579002916812897, \"time-step\": 1316}, {\"errors\": 0.23571501672267914, \"time-step\": 1317}, {\"errors\": 0.23563969135284424, \"time-step\": 1318}, {\"errors\": 0.23556409776210785, \"time-step\": 1319}, {\"errors\": 0.23548808693885803, \"time-step\": 1320}, {\"errors\": 0.23541182279586792, \"time-step\": 1321}, {\"errors\": 0.23533520102500916, \"time-step\": 1322}, {\"errors\": 0.23525820672512054, \"time-step\": 1323}, {\"errors\": 0.23518095910549164, \"time-step\": 1324}, {\"errors\": 0.2351033091545105, \"time-step\": 1325}, {\"errors\": 0.23502540588378906, \"time-step\": 1326}, {\"errors\": 0.2349470853805542, \"time-step\": 1327}, {\"errors\": 0.23486849665641785, \"time-step\": 1328}, {\"errors\": 0.23478955030441284, \"time-step\": 1329}, {\"errors\": 0.23471027612686157, \"time-step\": 1330}, {\"errors\": 0.23463065922260284, \"time-step\": 1331}, {\"errors\": 0.23455068469047546, \"time-step\": 1332}, {\"errors\": 0.234470397233963, \"time-step\": 1333}, {\"errors\": 0.2343897819519043, \"time-step\": 1334}, {\"errors\": 0.23430879414081573, \"time-step\": 1335}, {\"errors\": 0.2342275232076645, \"time-step\": 1336}, {\"errors\": 0.234145849943161, \"time-step\": 1337}, {\"errors\": 0.23406389355659485, \"time-step\": 1338}, {\"errors\": 0.23398156464099884, \"time-step\": 1339}, {\"errors\": 0.23389889299869537, \"time-step\": 1340}, {\"errors\": 0.23381583392620087, \"time-step\": 1341}, {\"errors\": 0.2337324619293213, \"time-step\": 1342}, {\"errors\": 0.23364879190921783, \"time-step\": 1343}, {\"errors\": 0.23356474936008453, \"time-step\": 1344}, {\"errors\": 0.23348036408424377, \"time-step\": 1345}, {\"errors\": 0.23339563608169556, \"time-step\": 1346}, {\"errors\": 0.2333105355501175, \"time-step\": 1347}, {\"errors\": 0.23322510719299316, \"time-step\": 1348}, {\"errors\": 0.23313933610916138, \"time-step\": 1349}, {\"errors\": 0.23305322229862213, \"time-step\": 1350}, {\"errors\": 0.23296673595905304, \"time-step\": 1351}, {\"errors\": 0.2328799068927765, \"time-step\": 1352}, {\"errors\": 0.2327927052974701, \"time-step\": 1353}, {\"errors\": 0.23270517587661743, \"time-step\": 1354}, {\"errors\": 0.2326173037290573, \"time-step\": 1355}, {\"errors\": 0.23252907395362854, \"time-step\": 1356}, {\"errors\": 0.23244045674800873, \"time-step\": 1357}, {\"errors\": 0.23235154151916504, \"time-step\": 1358}, {\"errors\": 0.2322622537612915, \"time-step\": 1359}, {\"errors\": 0.23217256367206573, \"time-step\": 1360}, {\"errors\": 0.2320825457572937, \"time-step\": 1361}, {\"errors\": 0.23199217021465302, \"time-step\": 1362}, {\"errors\": 0.23190145194530487, \"time-step\": 1363}, {\"errors\": 0.23181036114692688, \"time-step\": 1364}, {\"errors\": 0.23171889781951904, \"time-step\": 1365}, {\"errors\": 0.23162710666656494, \"time-step\": 1366}, {\"errors\": 0.23153497278690338, \"time-step\": 1367}, {\"errors\": 0.2314424067735672, \"time-step\": 1368}, {\"errors\": 0.23134955763816833, \"time-step\": 1369}, {\"errors\": 0.23125627636909485, \"time-step\": 1370}, {\"errors\": 0.2311626672744751, \"time-step\": 1371}, {\"errors\": 0.2310686856508255, \"time-step\": 1372}, {\"errors\": 0.23097434639930725, \"time-step\": 1373}, {\"errors\": 0.23087963461875916, \"time-step\": 1374}, {\"errors\": 0.2307845801115036, \"time-step\": 1375}, {\"errors\": 0.230689138174057, \"time-step\": 1376}, {\"errors\": 0.23059332370758057, \"time-step\": 1377}, {\"errors\": 0.23049716651439667, \"time-step\": 1378}, {\"errors\": 0.23040062189102173, \"time-step\": 1379}, {\"errors\": 0.23030370473861694, \"time-step\": 1380}, {\"errors\": 0.2302064299583435, \"time-step\": 1381}, {\"errors\": 0.23010879755020142, \"time-step\": 1382}, {\"errors\": 0.2300107628107071, \"time-step\": 1383}, {\"errors\": 0.22991237044334412, \"time-step\": 1384}, {\"errors\": 0.2298136204481125, \"time-step\": 1385}, {\"errors\": 0.22971445322036743, \"time-step\": 1386}, {\"errors\": 0.2296149581670761, \"time-step\": 1387}, {\"errors\": 0.22951510548591614, \"time-step\": 1388}, {\"errors\": 0.22941485047340393, \"time-step\": 1389}, {\"errors\": 0.22931423783302307, \"time-step\": 1390}, {\"errors\": 0.22921325266361237, \"time-step\": 1391}, {\"errors\": 0.22911188006401062, \"time-step\": 1392}, {\"errors\": 0.22901012003421783, \"time-step\": 1393}, {\"errors\": 0.2289080172777176, \"time-step\": 1394}, {\"errors\": 0.22880548238754272, \"time-step\": 1395}, {\"errors\": 0.2287026196718216, \"time-step\": 1396}, {\"errors\": 0.22859936952590942, \"time-step\": 1397}, {\"errors\": 0.2284957319498062, \"time-step\": 1398}, {\"errors\": 0.22839170694351196, \"time-step\": 1399}, {\"errors\": 0.22828733921051025, \"time-step\": 1400}, {\"errors\": 0.2281825840473175, \"time-step\": 1401}, {\"errors\": 0.22807744145393372, \"time-step\": 1402}, {\"errors\": 0.2279718965291977, \"time-step\": 1403}, {\"errors\": 0.22786597907543182, \"time-step\": 1404}, {\"errors\": 0.2277596890926361, \"time-step\": 1405}, {\"errors\": 0.22765301167964935, \"time-step\": 1406}, {\"errors\": 0.22754600644111633, \"time-step\": 1407}, {\"errors\": 0.22743850946426392, \"time-step\": 1408}, {\"errors\": 0.22733069956302643, \"time-step\": 1409}, {\"errors\": 0.2272225022315979, \"time-step\": 1410}, {\"errors\": 0.22711388766765594, \"time-step\": 1411}, {\"errors\": 0.22700494527816772, \"time-step\": 1412}, {\"errors\": 0.22689560055732727, \"time-step\": 1413}, {\"errors\": 0.22678588330745697, \"time-step\": 1414}, {\"errors\": 0.22667574882507324, \"time-step\": 1415}, {\"errors\": 0.22656521201133728, \"time-step\": 1416}, {\"errors\": 0.22645431756973267, \"time-step\": 1417}, {\"errors\": 0.2263430655002594, \"time-step\": 1418}, {\"errors\": 0.22623135149478912, \"time-step\": 1419}, {\"errors\": 0.2261192947626114, \"time-step\": 1420}, {\"errors\": 0.2260068655014038, \"time-step\": 1421}, {\"errors\": 0.2258940190076828, \"time-step\": 1422}, {\"errors\": 0.22578079998493195, \"time-step\": 1423}, {\"errors\": 0.22566720843315125, \"time-step\": 1424}, {\"errors\": 0.2255532145500183, \"time-step\": 1425}, {\"errors\": 0.22543878853321075, \"time-step\": 1426}, {\"errors\": 0.22532403469085693, \"time-step\": 1427}, {\"errors\": 0.2252088487148285, \"time-step\": 1428}, {\"errors\": 0.2250932902097702, \"time-step\": 1429}, {\"errors\": 0.22497737407684326, \"time-step\": 1430}, {\"errors\": 0.2248609960079193, \"time-step\": 1431}, {\"errors\": 0.2247442752122879, \"time-step\": 1432}, {\"errors\": 0.22462713718414307, \"time-step\": 1433}, {\"errors\": 0.22450962662696838, \"time-step\": 1434}, {\"errors\": 0.22439169883728027, \"time-step\": 1435}, {\"errors\": 0.22427339851856232, \"time-step\": 1436}, {\"errors\": 0.2241547405719757, \"time-step\": 1437}, {\"errors\": 0.22403565049171448, \"time-step\": 1438}, {\"errors\": 0.223916158080101, \"time-step\": 1439}, {\"errors\": 0.2237963080406189, \"time-step\": 1440}, {\"errors\": 0.22367604076862335, \"time-step\": 1441}, {\"errors\": 0.22355537116527557, \"time-step\": 1442}, {\"errors\": 0.22343431413173676, \"time-step\": 1443}, {\"errors\": 0.2233128845691681, \"time-step\": 1444}, {\"errors\": 0.2231910079717636, \"time-step\": 1445}, {\"errors\": 0.22306880354881287, \"time-step\": 1446}, {\"errors\": 0.2229461818933487, \"time-step\": 1447}, {\"errors\": 0.2228231579065323, \"time-step\": 1448}, {\"errors\": 0.22269976139068604, \"time-step\": 1449}, {\"errors\": 0.22257593274116516, \"time-step\": 1450}, {\"errors\": 0.22245174646377563, \"time-step\": 1451}, {\"errors\": 0.2223271131515503, \"time-step\": 1452}, {\"errors\": 0.2222021073102951, \"time-step\": 1453}, {\"errors\": 0.22207671403884888, \"time-step\": 1454}, {\"errors\": 0.221950963139534, \"time-step\": 1455}, {\"errors\": 0.2218247354030609, \"time-step\": 1456}, {\"errors\": 0.22169819474220276, \"time-step\": 1457}, {\"errors\": 0.2215711772441864, \"time-step\": 1458}, {\"errors\": 0.22144381701946259, \"time-step\": 1459}, {\"errors\": 0.22131603956222534, \"time-step\": 1460}, {\"errors\": 0.22118785977363586, \"time-step\": 1461}, {\"errors\": 0.22105932235717773, \"time-step\": 1462}, {\"errors\": 0.22093036770820618, \"time-step\": 1463}, {\"errors\": 0.22080101072788239, \"time-step\": 1464}, {\"errors\": 0.22067126631736755, \"time-step\": 1465}, {\"errors\": 0.2205411195755005, \"time-step\": 1466}, {\"errors\": 0.2204105406999588, \"time-step\": 1467}, {\"errors\": 0.22027958929538727, \"time-step\": 1468}, {\"errors\": 0.2201482653617859, \"time-step\": 1469}, {\"errors\": 0.22001653909683228, \"time-step\": 1470}, {\"errors\": 0.21988441050052643, \"time-step\": 1471}, {\"errors\": 0.21975187957286835, \"time-step\": 1472}, {\"errors\": 0.21961891651153564, \"time-step\": 1473}, {\"errors\": 0.2194855958223343, \"time-step\": 1474}, {\"errors\": 0.2193518579006195, \"time-step\": 1475}, {\"errors\": 0.21921773254871368, \"time-step\": 1476}, {\"errors\": 0.21908320486545563, \"time-step\": 1477}, {\"errors\": 0.2189483344554901, \"time-step\": 1478}, {\"errors\": 0.2188130021095276, \"time-step\": 1479}, {\"errors\": 0.21867728233337402, \"time-step\": 1480}, {\"errors\": 0.21854114532470703, \"time-step\": 1481}, {\"errors\": 0.218404620885849, \"time-step\": 1482}, {\"errors\": 0.21826773881912231, \"time-step\": 1483}, {\"errors\": 0.2181304395198822, \"time-step\": 1484}, {\"errors\": 0.21799272298812866, \"time-step\": 1485}, {\"errors\": 0.21785463392734528, \"time-step\": 1486}, {\"errors\": 0.21771615743637085, \"time-step\": 1487}, {\"errors\": 0.217577263712883, \"time-step\": 1488}, {\"errors\": 0.2174379974603653, \"time-step\": 1489}, {\"errors\": 0.21729826927185059, \"time-step\": 1490}, {\"errors\": 0.21715818345546722, \"time-step\": 1491}, {\"errors\": 0.21701772511005402, \"time-step\": 1492}, {\"errors\": 0.21687687933444977, \"time-step\": 1493}, {\"errors\": 0.2167356312274933, \"time-step\": 1494}, {\"errors\": 0.216593936085701, \"time-step\": 1495}, {\"errors\": 0.21645186841487885, \"time-step\": 1496}, {\"errors\": 0.21630939841270447, \"time-step\": 1497}, {\"errors\": 0.21616652607917786, \"time-step\": 1498}, {\"errors\": 0.2160232812166214, \"time-step\": 1499}, {\"errors\": 0.2158796340227127, \"time-step\": 1500}, {\"errors\": 0.21573559939861298, \"time-step\": 1501}, {\"errors\": 0.2155911773443222, \"time-step\": 1502}, {\"errors\": 0.2154463231563568, \"time-step\": 1503}, {\"errors\": 0.21530112624168396, \"time-step\": 1504}, {\"errors\": 0.2151554524898529, \"time-step\": 1505}, {\"errors\": 0.21500945091247559, \"time-step\": 1506}, {\"errors\": 0.21486301720142365, \"time-step\": 1507}, {\"errors\": 0.21471622586250305, \"time-step\": 1508}, {\"errors\": 0.2145690619945526, \"time-step\": 1509}, {\"errors\": 0.21442140638828278, \"time-step\": 1510}, {\"errors\": 0.21427343785762787, \"time-step\": 1511}, {\"errors\": 0.21412503719329834, \"time-step\": 1512}, {\"errors\": 0.21397626399993896, \"time-step\": 1513}, {\"errors\": 0.21382704377174377, \"time-step\": 1514}, {\"errors\": 0.21367749571800232, \"time-step\": 1515}, {\"errors\": 0.21352753043174744, \"time-step\": 1516}, {\"errors\": 0.21337716281414032, \"time-step\": 1517}, {\"errors\": 0.21322640776634216, \"time-step\": 1518}, {\"errors\": 0.21307528018951416, \"time-step\": 1519}, {\"errors\": 0.21292373538017273, \"time-step\": 1520}, {\"errors\": 0.21277178823947906, \"time-step\": 1521}, {\"errors\": 0.21261951327323914, \"time-step\": 1522}, {\"errors\": 0.2124667912721634, \"time-step\": 1523}, {\"errors\": 0.2123137265443802, \"time-step\": 1524}, {\"errors\": 0.21216024458408356, \"time-step\": 1525}, {\"errors\": 0.21200639009475708, \"time-step\": 1526}, {\"errors\": 0.21185210347175598, \"time-step\": 1527}, {\"errors\": 0.21169744431972504, \"time-step\": 1528}, {\"errors\": 0.21154241263866425, \"time-step\": 1529}, {\"errors\": 0.21138697862625122, \"time-step\": 1530}, {\"errors\": 0.21123115718364716, \"time-step\": 1531}, {\"errors\": 0.21107493340969086, \"time-step\": 1532}, {\"errors\": 0.2109183520078659, \"time-step\": 1533}, {\"errors\": 0.21076135337352753, \"time-step\": 1534}, {\"errors\": 0.2106040120124817, \"time-step\": 1535}, {\"errors\": 0.21044623851776123, \"time-step\": 1536}, {\"errors\": 0.21028807759284973, \"time-step\": 1537}, {\"errors\": 0.21012955904006958, \"time-step\": 1538}, {\"errors\": 0.209970623254776, \"time-step\": 1539}, {\"errors\": 0.20981130003929138, \"time-step\": 1540}, {\"errors\": 0.2096516191959381, \"time-step\": 1541}, {\"errors\": 0.2094915509223938, \"time-step\": 1542}, {\"errors\": 0.20933108031749725, \"time-step\": 1543}, {\"errors\": 0.20917022228240967, \"time-step\": 1544}, {\"errors\": 0.20900900661945343, \"time-step\": 1545}, {\"errors\": 0.20884738862514496, \"time-step\": 1546}, {\"errors\": 0.20868536829948425, \"time-step\": 1547}, {\"errors\": 0.2085230052471161, \"time-step\": 1548}, {\"errors\": 0.2083602249622345, \"time-step\": 1549}, {\"errors\": 0.20819708704948425, \"time-step\": 1550}, {\"errors\": 0.20803356170654297, \"time-step\": 1551}, {\"errors\": 0.20786964893341064, \"time-step\": 1552}, {\"errors\": 0.2077053338289261, \"time-step\": 1553}, {\"errors\": 0.20754069089889526, \"time-step\": 1554}, {\"errors\": 0.20737560093402863, \"time-step\": 1555}, {\"errors\": 0.20721018314361572, \"time-step\": 1556}, {\"errors\": 0.20704437792301178, \"time-step\": 1557}, {\"errors\": 0.206878200173378, \"time-step\": 1558}, {\"errors\": 0.20671164989471436, \"time-step\": 1559}, {\"errors\": 0.2065446972846985, \"time-step\": 1560}, {\"errors\": 0.20637738704681396, \"time-step\": 1561}, {\"errors\": 0.2062096744775772, \"time-step\": 1562}, {\"errors\": 0.2060416042804718, \"time-step\": 1563}, {\"errors\": 0.20587316155433655, \"time-step\": 1564}, {\"errors\": 0.20570434629917145, \"time-step\": 1565}, {\"errors\": 0.2055351585149765, \"time-step\": 1566}, {\"errors\": 0.2053655982017517, \"time-step\": 1567}, {\"errors\": 0.20519565045833588, \"time-step\": 1568}, {\"errors\": 0.205025315284729, \"time-step\": 1569}, {\"errors\": 0.20485463738441467, \"time-step\": 1570}, {\"errors\": 0.2046835720539093, \"time-step\": 1571}, {\"errors\": 0.20451213419437408, \"time-step\": 1572}, {\"errors\": 0.20434033870697021, \"time-step\": 1573}, {\"errors\": 0.2041681855916977, \"time-step\": 1574}, {\"errors\": 0.20399567484855652, \"time-step\": 1575}, {\"errors\": 0.2038227915763855, \"time-step\": 1576}, {\"errors\": 0.20364950597286224, \"time-step\": 1577}, {\"errors\": 0.20347584784030914, \"time-step\": 1578}, {\"errors\": 0.2033018320798874, \"time-step\": 1579}, {\"errors\": 0.20312748849391937, \"time-step\": 1580}, {\"errors\": 0.20295274257659912, \"time-step\": 1581}, {\"errors\": 0.20277760922908783, \"time-step\": 1582}, {\"errors\": 0.20260211825370789, \"time-step\": 1583}, {\"errors\": 0.20242631435394287, \"time-step\": 1584}, {\"errors\": 0.20225012302398682, \"time-step\": 1585}, {\"errors\": 0.20207352936267853, \"time-step\": 1586}, {\"errors\": 0.20189659297466278, \"time-step\": 1587}, {\"errors\": 0.20171934366226196, \"time-step\": 1588}, {\"errors\": 0.20154163241386414, \"time-step\": 1589}, {\"errors\": 0.20136362314224243, \"time-step\": 1590}, {\"errors\": 0.20118525624275208, \"time-step\": 1591}, {\"errors\": 0.20100651681423187, \"time-step\": 1592}, {\"errors\": 0.2008274644613266, \"time-step\": 1593}, {\"errors\": 0.20064802467823029, \"time-step\": 1594}, {\"errors\": 0.20046818256378174, \"time-step\": 1595}, {\"errors\": 0.20028802752494812, \"time-step\": 1596}, {\"errors\": 0.20010755956172943, \"time-step\": 1597}, {\"errors\": 0.19992665946483612, \"time-step\": 1598}, {\"errors\": 0.19974543154239655, \"time-step\": 1599}, {\"errors\": 0.1995638608932495, \"time-step\": 1600}, {\"errors\": 0.19938188791275024, \"time-step\": 1601}, {\"errors\": 0.1991995871067047, \"time-step\": 1602}, {\"errors\": 0.19901695847511292, \"time-step\": 1603}, {\"errors\": 0.19883394241333008, \"time-step\": 1604}, {\"errors\": 0.19865064322948456, \"time-step\": 1605}, {\"errors\": 0.1984669417142868, \"time-step\": 1606}, {\"errors\": 0.19828294217586517, \"time-step\": 1607}, {\"errors\": 0.1980985552072525, \"time-step\": 1608}, {\"errors\": 0.19791379570960999, \"time-step\": 1609}, {\"errors\": 0.1977287083864212, \"time-step\": 1610}, {\"errors\": 0.19754329323768616, \"time-step\": 1611}, {\"errors\": 0.19735747575759888, \"time-step\": 1612}, {\"errors\": 0.1971713900566101, \"time-step\": 1613}, {\"errors\": 0.1969849318265915, \"time-step\": 1614}, {\"errors\": 0.19679811596870422, \"time-step\": 1615}, {\"errors\": 0.1966109424829483, \"time-step\": 1616}, {\"errors\": 0.1964234709739685, \"time-step\": 1617}, {\"errors\": 0.19623568654060364, \"time-step\": 1618}, {\"errors\": 0.19604751467704773, \"time-step\": 1619}, {\"errors\": 0.19585901498794556, \"time-step\": 1620}, {\"errors\": 0.19567012786865234, \"time-step\": 1621}, {\"errors\": 0.19548098742961884, \"time-step\": 1622}, {\"errors\": 0.1952914297580719, \"time-step\": 1623}, {\"errors\": 0.1951015293598175, \"time-step\": 1624}, {\"errors\": 0.19491137564182281, \"time-step\": 1625}, {\"errors\": 0.19472084939479828, \"time-step\": 1626}, {\"errors\": 0.19452998042106628, \"time-step\": 1627}, {\"errors\": 0.19433876872062683, \"time-step\": 1628}, {\"errors\": 0.1941472589969635, \"time-step\": 1629}, {\"errors\": 0.19395537674427032, \"time-step\": 1630}, {\"errors\": 0.19376322627067566, \"time-step\": 1631}, {\"errors\": 0.19357067346572876, \"time-step\": 1632}, {\"errors\": 0.19337785243988037, \"time-step\": 1633}, {\"errors\": 0.19318468868732452, \"time-step\": 1634}, {\"errors\": 0.19299116730690002, \"time-step\": 1635}, {\"errors\": 0.19279734790325165, \"time-step\": 1636}, {\"errors\": 0.192603200674057, \"time-step\": 1637}, {\"errors\": 0.1924087107181549, \"time-step\": 1638}, {\"errors\": 0.19221395254135132, \"time-step\": 1639}, {\"errors\": 0.19201883673667908, \"time-step\": 1640}, {\"errors\": 0.19182337820529938, \"time-step\": 1641}, {\"errors\": 0.1916275918483734, \"time-step\": 1642}, {\"errors\": 0.19143149256706238, \"time-step\": 1643}, {\"errors\": 0.19123512506484985, \"time-step\": 1644}, {\"errors\": 0.19103847444057465, \"time-step\": 1645}, {\"errors\": 0.1908414214849472, \"time-step\": 1646}, {\"errors\": 0.19064410030841827, \"time-step\": 1647}, {\"errors\": 0.1904463768005371, \"time-step\": 1648}, {\"errors\": 0.19024845957756042, \"time-step\": 1649}, {\"errors\": 0.1900501251220703, \"time-step\": 1650}, {\"errors\": 0.1898515820503235, \"time-step\": 1651}, {\"errors\": 0.18965265154838562, \"time-step\": 1652}, {\"errors\": 0.18945345282554626, \"time-step\": 1653}, {\"errors\": 0.18925392627716064, \"time-step\": 1654}, {\"errors\": 0.18905405700206757, \"time-step\": 1655}, {\"errors\": 0.18885394930839539, \"time-step\": 1656}, {\"errors\": 0.18865352869033813, \"time-step\": 1657}, {\"errors\": 0.18845273554325104, \"time-step\": 1658}, {\"errors\": 0.18825165927410126, \"time-step\": 1659}, {\"errors\": 0.1880502998828888, \"time-step\": 1660}, {\"errors\": 0.18784862756729126, \"time-step\": 1661}, {\"errors\": 0.18764673173427582, \"time-step\": 1662}, {\"errors\": 0.18744438886642456, \"time-step\": 1663}, {\"errors\": 0.18724185228347778, \"time-step\": 1664}, {\"errors\": 0.18703901767730713, \"time-step\": 1665}, {\"errors\": 0.18683584034442902, \"time-step\": 1666}, {\"errors\": 0.18663239479064941, \"time-step\": 1667}, {\"errors\": 0.18642869591712952, \"time-step\": 1668}, {\"errors\": 0.18622465431690216, \"time-step\": 1669}, {\"errors\": 0.18602029979228973, \"time-step\": 1670}, {\"errors\": 0.1858157068490982, \"time-step\": 1671}, {\"errors\": 0.18561075627803802, \"time-step\": 1672}, {\"errors\": 0.18540559709072113, \"time-step\": 1673}, {\"errors\": 0.1852000653743744, \"time-step\": 1674}, {\"errors\": 0.18499429523944855, \"time-step\": 1675}, {\"errors\": 0.1847882717847824, \"time-step\": 1676}, {\"errors\": 0.18458192050457, \"time-step\": 1677}, {\"errors\": 0.18437530100345612, \"time-step\": 1678}, {\"errors\": 0.18416836857795715, \"time-step\": 1679}, {\"errors\": 0.18396121263504028, \"time-step\": 1680}, {\"errors\": 0.18375372886657715, \"time-step\": 1681}, {\"errors\": 0.18354594707489014, \"time-step\": 1682}, {\"errors\": 0.1833379566669464, \"time-step\": 1683}, {\"errors\": 0.18312963843345642, \"time-step\": 1684}, {\"errors\": 0.18292108178138733, \"time-step\": 1685}, {\"errors\": 0.18271224200725555, \"time-step\": 1686}, {\"errors\": 0.18250307440757751, \"time-step\": 1687}, {\"errors\": 0.18229368329048157, \"time-step\": 1688}, {\"errors\": 0.18208402395248413, \"time-step\": 1689}, {\"errors\": 0.1818741112947464, \"time-step\": 1690}, {\"errors\": 0.1816639006137848, \"time-step\": 1691}, {\"errors\": 0.18145343661308289, \"time-step\": 1692}, {\"errors\": 0.1812427043914795, \"time-step\": 1693}, {\"errors\": 0.18103168904781342, \"time-step\": 1694}, {\"errors\": 0.18082045018672943, \"time-step\": 1695}, {\"errors\": 0.18060889840126038, \"time-step\": 1696}, {\"errors\": 0.18039709329605103, \"time-step\": 1697}, {\"errors\": 0.18018503487110138, \"time-step\": 1698}, {\"errors\": 0.17997275292873383, \"time-step\": 1699}, {\"errors\": 0.1797601729631424, \"time-step\": 1700}, {\"errors\": 0.17954735457897186, \"time-step\": 1701}, {\"errors\": 0.17933425307273865, \"time-step\": 1702}, {\"errors\": 0.1791209578514099, \"time-step\": 1703}, {\"errors\": 0.17890730500221252, \"time-step\": 1704}, {\"errors\": 0.17869353294372559, \"time-step\": 1705}, {\"errors\": 0.17847944796085358, \"time-step\": 1706}, {\"errors\": 0.17826512455940247, \"time-step\": 1707}, {\"errors\": 0.17805057764053345, \"time-step\": 1708}, {\"errors\": 0.17783574759960175, \"time-step\": 1709}, {\"errors\": 0.17762067914009094, \"time-step\": 1710}, {\"errors\": 0.17740538716316223, \"time-step\": 1711}, {\"errors\": 0.17718976736068726, \"time-step\": 1712}, {\"errors\": 0.17697399854660034, \"time-step\": 1713}, {\"errors\": 0.1767580211162567, \"time-step\": 1714}, {\"errors\": 0.17654170095920563, \"time-step\": 1715}, {\"errors\": 0.17632518708705902, \"time-step\": 1716}, {\"errors\": 0.1761084645986557, \"time-step\": 1717}, {\"errors\": 0.17589148879051208, \"time-step\": 1718}, {\"errors\": 0.17567427456378937, \"time-step\": 1719}, {\"errors\": 0.17545688152313232, \"time-step\": 1720}, {\"errors\": 0.1752392202615738, \"time-step\": 1721}, {\"errors\": 0.17502130568027496, \"time-step\": 1722}, {\"errors\": 0.17480319738388062, \"time-step\": 1723}, {\"errors\": 0.17458488047122955, \"time-step\": 1724}, {\"errors\": 0.1743662804365158, \"time-step\": 1725}, {\"errors\": 0.17414751648902893, \"time-step\": 1726}, {\"errors\": 0.17392849922180176, \"time-step\": 1727}, {\"errors\": 0.17370925843715668, \"time-step\": 1728}, {\"errors\": 0.17348980903625488, \"time-step\": 1729}, {\"errors\": 0.17327016592025757, \"time-step\": 1730}, {\"errors\": 0.17305025458335876, \"time-step\": 1731}, {\"errors\": 0.17283019423484802, \"time-step\": 1732}, {\"errors\": 0.17260988056659698, \"time-step\": 1733}, {\"errors\": 0.17238932847976685, \"time-step\": 1734}, {\"errors\": 0.1721685826778412, \"time-step\": 1735}, {\"errors\": 0.1719476729631424, \"time-step\": 1736}, {\"errors\": 0.1717265099287033, \"time-step\": 1737}, {\"errors\": 0.1715051680803299, \"time-step\": 1738}, {\"errors\": 0.17128360271453857, \"time-step\": 1739}, {\"errors\": 0.17106185853481293, \"time-step\": 1740}, {\"errors\": 0.17083990573883057, \"time-step\": 1741}, {\"errors\": 0.1706177443265915, \"time-step\": 1742}, {\"errors\": 0.1703953891992569, \"time-step\": 1743}, {\"errors\": 0.17017285525798798, \"time-step\": 1744}, {\"errors\": 0.16995009779930115, \"time-step\": 1745}, {\"errors\": 0.16972719132900238, \"time-step\": 1746}, {\"errors\": 0.1695040762424469, \"time-step\": 1747}, {\"errors\": 0.1692807674407959, \"time-step\": 1748}, {\"errors\": 0.16905727982521057, \"time-step\": 1749}, {\"errors\": 0.1688336282968521, \"time-step\": 1750}, {\"errors\": 0.16860973834991455, \"time-step\": 1751}, {\"errors\": 0.16838568449020386, \"time-step\": 1752}, {\"errors\": 0.16816148161888123, \"time-step\": 1753}, {\"errors\": 0.16793707013130188, \"time-step\": 1754}, {\"errors\": 0.1677124798297882, \"time-step\": 1755}, {\"errors\": 0.16748768091201782, \"time-step\": 1756}, {\"errors\": 0.16726276278495789, \"time-step\": 1757}, {\"errors\": 0.16703766584396362, \"time-step\": 1758}, {\"errors\": 0.16681237518787384, \"time-step\": 1759}, {\"errors\": 0.16658689081668854, \"time-step\": 1760}, {\"errors\": 0.1663612425327301, \"time-step\": 1761}, {\"errors\": 0.16613543033599854, \"time-step\": 1762}, {\"errors\": 0.16590946912765503, \"time-step\": 1763}, {\"errors\": 0.165683314204216, \"time-step\": 1764}, {\"errors\": 0.16545704007148743, \"time-step\": 1765}, {\"errors\": 0.16523057222366333, \"time-step\": 1766}, {\"errors\": 0.1650039404630661, \"time-step\": 1767}, {\"errors\": 0.16477718949317932, \"time-step\": 1768}, {\"errors\": 0.16455024480819702, \"time-step\": 1769}, {\"errors\": 0.16432318091392517, \"time-step\": 1770}, {\"errors\": 0.1640959233045578, \"time-step\": 1771}, {\"errors\": 0.1638685166835785, \"time-step\": 1772}, {\"errors\": 0.16364097595214844, \"time-step\": 1773}, {\"errors\": 0.16341327130794525, \"time-step\": 1774}, {\"errors\": 0.16318543255329132, \"time-step\": 1775}, {\"errors\": 0.16295747458934784, \"time-step\": 1776}, {\"errors\": 0.16272933781147003, \"time-step\": 1777}, {\"errors\": 0.16250106692314148, \"time-step\": 1778}, {\"errors\": 0.16227266192436218, \"time-step\": 1779}, {\"errors\": 0.16204413771629333, \"time-step\": 1780}, {\"errors\": 0.16181543469429016, \"time-step\": 1781}, {\"errors\": 0.16158662736415863, \"time-step\": 1782}, {\"errors\": 0.16135767102241516, \"time-step\": 1783}, {\"errors\": 0.16112864017486572, \"time-step\": 1784}, {\"errors\": 0.16089940071105957, \"time-step\": 1785}, {\"errors\": 0.16067004203796387, \"time-step\": 1786}, {\"errors\": 0.1604405641555786, \"time-step\": 1787}, {\"errors\": 0.1602109968662262, \"time-step\": 1788}, {\"errors\": 0.15998128056526184, \"time-step\": 1789}, {\"errors\": 0.15975145995616913, \"time-step\": 1790}, {\"errors\": 0.15952152013778687, \"time-step\": 1791}, {\"errors\": 0.15929146111011505, \"time-step\": 1792}, {\"errors\": 0.1590612530708313, \"time-step\": 1793}, {\"errors\": 0.15883095562458038, \"time-step\": 1794}, {\"errors\": 0.1586005687713623, \"time-step\": 1795}, {\"errors\": 0.1583700329065323, \"time-step\": 1796}, {\"errors\": 0.1581394374370575, \"time-step\": 1797}, {\"errors\": 0.15790870785713196, \"time-step\": 1798}, {\"errors\": 0.15767784416675568, \"time-step\": 1799}, {\"errors\": 0.15744692087173462, \"time-step\": 1800}, {\"errors\": 0.15721583366394043, \"time-step\": 1801}, {\"errors\": 0.15698470175266266, \"time-step\": 1802}, {\"errors\": 0.15675346553325653, \"time-step\": 1803}, {\"errors\": 0.15652215480804443, \"time-step\": 1804}, {\"errors\": 0.15629075467586517, \"time-step\": 1805}, {\"errors\": 0.15605920553207397, \"time-step\": 1806}, {\"errors\": 0.1558275818824768, \"time-step\": 1807}, {\"errors\": 0.15559586882591248, \"time-step\": 1808}, {\"errors\": 0.15536408126354218, \"time-step\": 1809}, {\"errors\": 0.1551322191953659, \"time-step\": 1810}, {\"errors\": 0.15490026772022247, \"time-step\": 1811}, {\"errors\": 0.15466824173927307, \"time-step\": 1812}, {\"errors\": 0.1544361114501953, \"time-step\": 1813}, {\"errors\": 0.15420390665531158, \"time-step\": 1814}, {\"errors\": 0.15397165715694427, \"time-step\": 1815}, {\"errors\": 0.15373928844928741, \"time-step\": 1816}, {\"errors\": 0.15350686013698578, \"time-step\": 1817}, {\"errors\": 0.15327435731887817, \"time-step\": 1818}, {\"errors\": 0.153041809797287, \"time-step\": 1819}, {\"errors\": 0.15280915796756744, \"time-step\": 1820}, {\"errors\": 0.15257646143436432, \"time-step\": 1821}, {\"errors\": 0.1523437201976776, \"time-step\": 1822}, {\"errors\": 0.15211084485054016, \"time-step\": 1823}, {\"errors\": 0.1518779844045639, \"time-step\": 1824}, {\"errors\": 0.15164503455162048, \"time-step\": 1825}, {\"errors\": 0.15141203999519348, \"time-step\": 1826}, {\"errors\": 0.15117895603179932, \"time-step\": 1827}, {\"errors\": 0.15094585716724396, \"time-step\": 1828}, {\"errors\": 0.15071268379688263, \"time-step\": 1829}, {\"errors\": 0.15047946572303772, \"time-step\": 1830}, {\"errors\": 0.15024621784687042, \"time-step\": 1831}, {\"errors\": 0.15001292526721954, \"time-step\": 1832}, {\"errors\": 0.14977958798408508, \"time-step\": 1833}, {\"errors\": 0.14954620599746704, \"time-step\": 1834}, {\"errors\": 0.14931276440620422, \"time-step\": 1835}, {\"errors\": 0.14907927811145782, \"time-step\": 1836}, {\"errors\": 0.14884577691555023, \"time-step\": 1837}, {\"errors\": 0.14861223101615906, \"time-step\": 1838}, {\"errors\": 0.1483786404132843, \"time-step\": 1839}, {\"errors\": 0.14814503490924835, \"time-step\": 1840}, {\"errors\": 0.14791138470172882, \"time-step\": 1841}, {\"errors\": 0.1476777195930481, \"time-step\": 1842}, {\"errors\": 0.1474440097808838, \"time-step\": 1843}, {\"errors\": 0.1472102701663971, \"time-step\": 1844}, {\"errors\": 0.1469765305519104, \"time-step\": 1845}, {\"errors\": 0.14674276113510132, \"time-step\": 1846}, {\"errors\": 0.14650899171829224, \"time-step\": 1847}, {\"errors\": 0.14627520740032196, \"time-step\": 1848}, {\"errors\": 0.1460413783788681, \"time-step\": 1849}, {\"errors\": 0.14580750465393066, \"time-step\": 1850}, {\"errors\": 0.1455736607313156, \"time-step\": 1851}, {\"errors\": 0.14533980190753937, \"time-step\": 1852}, {\"errors\": 0.14510595798492432, \"time-step\": 1853}, {\"errors\": 0.14487206935882568, \"time-step\": 1854}, {\"errors\": 0.14463821053504944, \"time-step\": 1855}, {\"errors\": 0.1444043219089508, \"time-step\": 1856}, {\"errors\": 0.14417043328285217, \"time-step\": 1857}, {\"errors\": 0.14393654465675354, \"time-step\": 1858}, {\"errors\": 0.1437026858329773, \"time-step\": 1859}, {\"errors\": 0.14346876740455627, \"time-step\": 1860}, {\"errors\": 0.14323493838310242, \"time-step\": 1861}, {\"errors\": 0.14300107955932617, \"time-step\": 1862}, {\"errors\": 0.14276722073554993, \"time-step\": 1863}, {\"errors\": 0.14253339171409607, \"time-step\": 1864}, {\"errors\": 0.14229954779148102, \"time-step\": 1865}, {\"errors\": 0.14206573367118835, \"time-step\": 1866}, {\"errors\": 0.14183194935321808, \"time-step\": 1867}, {\"errors\": 0.1415981650352478, \"time-step\": 1868}, {\"errors\": 0.14136441051959991, \"time-step\": 1869}, {\"errors\": 0.14113068580627441, \"time-step\": 1870}, {\"errors\": 0.14089693129062653, \"time-step\": 1871}, {\"errors\": 0.1406632512807846, \"time-step\": 1872}, {\"errors\": 0.14042963087558746, \"time-step\": 1873}, {\"errors\": 0.14019598066806793, \"time-step\": 1874}, {\"errors\": 0.13996241986751556, \"time-step\": 1875}, {\"errors\": 0.13972881436347961, \"time-step\": 1876}, {\"errors\": 0.13949528336524963, \"time-step\": 1877}, {\"errors\": 0.13926178216934204, \"time-step\": 1878}, {\"errors\": 0.13902835547924042, \"time-step\": 1879}, {\"errors\": 0.13879495859146118, \"time-step\": 1880}, {\"errors\": 0.13856159150600433, \"time-step\": 1881}, {\"errors\": 0.13832823932170868, \"time-step\": 1882}, {\"errors\": 0.138094961643219, \"time-step\": 1883}, {\"errors\": 0.1378617137670517, \"time-step\": 1884}, {\"errors\": 0.13762851059436798, \"time-step\": 1885}, {\"errors\": 0.13739535212516785, \"time-step\": 1886}, {\"errors\": 0.13716226816177368, \"time-step\": 1887}, {\"errors\": 0.1369291990995407, \"time-step\": 1888}, {\"errors\": 0.13669618964195251, \"time-step\": 1889}, {\"errors\": 0.13646328449249268, \"time-step\": 1890}, {\"errors\": 0.13623040914535522, \"time-step\": 1891}, {\"errors\": 0.13599756360054016, \"time-step\": 1892}, {\"errors\": 0.13576483726501465, \"time-step\": 1893}, {\"errors\": 0.13553214073181152, \"time-step\": 1894}, {\"errors\": 0.13529951870441437, \"time-step\": 1895}, {\"errors\": 0.1350669413805008, \"time-step\": 1896}, {\"errors\": 0.13483446836471558, \"time-step\": 1897}, {\"errors\": 0.13460204005241394, \"time-step\": 1898}, {\"errors\": 0.13436968624591827, \"time-step\": 1899}, {\"errors\": 0.13413740694522858, \"time-step\": 1900}, {\"errors\": 0.13390520215034485, \"time-step\": 1901}, {\"errors\": 0.1336730718612671, \"time-step\": 1902}, {\"errors\": 0.13344106078147888, \"time-step\": 1903}, {\"errors\": 0.13320907950401306, \"time-step\": 1904}, {\"errors\": 0.1329771876335144, \"time-step\": 1905}, {\"errors\": 0.13274537026882172, \"time-step\": 1906}, {\"errors\": 0.13251370191574097, \"time-step\": 1907}, {\"errors\": 0.13228203356266022, \"time-step\": 1908}, {\"errors\": 0.1320504993200302, \"time-step\": 1909}, {\"errors\": 0.13181906938552856, \"time-step\": 1910}, {\"errors\": 0.1315876841545105, \"time-step\": 1911}, {\"errors\": 0.13135641813278198, \"time-step\": 1912}, {\"errors\": 0.13112522661685944, \"time-step\": 1913}, {\"errors\": 0.13089418411254883, \"time-step\": 1914}, {\"errors\": 0.1306632161140442, \"time-step\": 1915}, {\"errors\": 0.1304323375225067, \"time-step\": 1916}, {\"errors\": 0.130201518535614, \"time-step\": 1917}, {\"errors\": 0.12997087836265564, \"time-step\": 1918}, {\"errors\": 0.12974032759666443, \"time-step\": 1919}, {\"errors\": 0.12950986623764038, \"time-step\": 1920}, {\"errors\": 0.1292794644832611, \"time-step\": 1921}, {\"errors\": 0.12904924154281616, \"time-step\": 1922}, {\"errors\": 0.12881912291049957, \"time-step\": 1923}, {\"errors\": 0.12858906388282776, \"time-step\": 1924}, {\"errors\": 0.12835918366909027, \"time-step\": 1925}, {\"errors\": 0.12812936305999756, \"time-step\": 1926}, {\"errors\": 0.1278996765613556, \"time-step\": 1927}, {\"errors\": 0.12767012417316437, \"time-step\": 1928}, {\"errors\": 0.1274406611919403, \"time-step\": 1929}, {\"errors\": 0.127211332321167, \"time-step\": 1930}, {\"errors\": 0.12698210775852203, \"time-step\": 1931}, {\"errors\": 0.1267530471086502, \"time-step\": 1932}, {\"errors\": 0.12652412056922913, \"time-step\": 1933}, {\"errors\": 0.1262952983379364, \"time-step\": 1934}, {\"errors\": 0.12606659531593323, \"time-step\": 1935}, {\"errors\": 0.125838041305542, \"time-step\": 1936}, {\"errors\": 0.1256096214056015, \"time-step\": 1937}, {\"errors\": 0.12538130581378937, \"time-step\": 1938}, {\"errors\": 0.12515313923358917, \"time-step\": 1939}, {\"errors\": 0.12492512166500092, \"time-step\": 1940}, {\"errors\": 0.1246972382068634, \"time-step\": 1941}, {\"errors\": 0.12446947395801544, \"time-step\": 1942}, {\"errors\": 0.12424184381961823, \"time-step\": 1943}, {\"errors\": 0.12401436269283295, \"time-step\": 1944}, {\"errors\": 0.123787060379982, \"time-step\": 1945}, {\"errors\": 0.1235598623752594, \"time-step\": 1946}, {\"errors\": 0.12333285808563232, \"time-step\": 1947}, {\"errors\": 0.1231059804558754, \"time-step\": 1948}, {\"errors\": 0.12287923693656921, \"time-step\": 1949}, {\"errors\": 0.12265266478061676, \"time-step\": 1950}, {\"errors\": 0.12242622673511505, \"time-step\": 1951}, {\"errors\": 0.12219995260238647, \"time-step\": 1952}, {\"errors\": 0.12197379022836685, \"time-step\": 1953}, {\"errors\": 0.12174785882234573, \"time-step\": 1954}, {\"errors\": 0.12152201682329178, \"time-step\": 1955}, {\"errors\": 0.12129634618759155, \"time-step\": 1956}, {\"errors\": 0.12107086181640625, \"time-step\": 1957}, {\"errors\": 0.12084551155567169, \"time-step\": 1958}, {\"errors\": 0.12062034755945206, \"time-step\": 1959}, {\"errors\": 0.12039535492658615, \"time-step\": 1960}, {\"errors\": 0.12017051875591278, \"time-step\": 1961}, {\"errors\": 0.11994585394859314, \"time-step\": 1962}, {\"errors\": 0.11972135305404663, \"time-step\": 1963}, {\"errors\": 0.11949700862169266, \"time-step\": 1964}, {\"errors\": 0.1192728728055954, \"time-step\": 1965}, {\"errors\": 0.11904887855052948, \"time-step\": 1966}, {\"errors\": 0.1188250407576561, \"time-step\": 1967}, {\"errors\": 0.11860143393278122, \"time-step\": 1968}, {\"errors\": 0.11837795376777649, \"time-step\": 1969}, {\"errors\": 0.11815465241670609, \"time-step\": 1970}, {\"errors\": 0.11793157458305359, \"time-step\": 1971}, {\"errors\": 0.11770864576101303, \"time-step\": 1972}, {\"errors\": 0.11748585104942322, \"time-step\": 1973}, {\"errors\": 0.1172633245587349, \"time-step\": 1974}, {\"errors\": 0.1170409768819809, \"time-step\": 1975}, {\"errors\": 0.11681877076625824, \"time-step\": 1976}, {\"errors\": 0.11659672856330872, \"time-step\": 1977}, {\"errors\": 0.1163749098777771, \"time-step\": 1978}, {\"errors\": 0.1161532998085022, \"time-step\": 1979}, {\"errors\": 0.11593182384967804, \"time-step\": 1980}, {\"errors\": 0.11571060866117477, \"time-step\": 1981}, {\"errors\": 0.11548952758312225, \"time-step\": 1982}, {\"errors\": 0.11526863276958466, \"time-step\": 1983}, {\"errors\": 0.11504796147346497, \"time-step\": 1984}, {\"errors\": 0.11482749134302139, \"time-step\": 1985}, {\"errors\": 0.11460721492767334, \"time-step\": 1986}, {\"errors\": 0.1143871396780014, \"time-step\": 1987}, {\"errors\": 0.11416725814342499, \"time-step\": 1988}, {\"errors\": 0.11394760012626648, \"time-step\": 1989}, {\"errors\": 0.11372808367013931, \"time-step\": 1990}, {\"errors\": 0.11350880563259125, \"time-step\": 1991}, {\"errors\": 0.1132897138595581, \"time-step\": 1992}, {\"errors\": 0.11307086050510406, \"time-step\": 1993}, {\"errors\": 0.11285218596458435, \"time-step\": 1994}, {\"errors\": 0.11263374984264374, \"time-step\": 1995}, {\"errors\": 0.11241552233695984, \"time-step\": 1996}, {\"errors\": 0.11219753324985504, \"time-step\": 1997}, {\"errors\": 0.11197969317436218, \"time-step\": 1998}, {\"errors\": 0.11176207661628723, \"time-step\": 1999}, {\"errors\": 0.11154468357563019, \"time-step\": 2000}, {\"errors\": 0.11132749915122986, \"time-step\": 2001}, {\"errors\": 0.11111052334308624, \"time-step\": 2002}, {\"errors\": 0.11089377105236053, \"time-step\": 2003}, {\"errors\": 0.11067724227905273, \"time-step\": 2004}, {\"errors\": 0.11046090722084045, \"time-step\": 2005}, {\"errors\": 0.11024482548236847, \"time-step\": 2006}, {\"errors\": 0.1100289523601532, \"time-step\": 2007}, {\"errors\": 0.10981328040361404, \"time-step\": 2008}, {\"errors\": 0.1095978319644928, \"time-step\": 2009}, {\"errors\": 0.10938264429569244, \"time-step\": 2010}, {\"errors\": 0.10916764289140701, \"time-step\": 2011}, {\"errors\": 0.10895290225744247, \"time-step\": 2012}, {\"errors\": 0.10873837769031525, \"time-step\": 2013}, {\"errors\": 0.10852407664060593, \"time-step\": 2014}, {\"errors\": 0.10830996930599213, \"time-step\": 2015}, {\"errors\": 0.1080961525440216, \"time-step\": 2016}, {\"errors\": 0.10788252204656601, \"time-step\": 2017}, {\"errors\": 0.1076691523194313, \"time-step\": 2018}, {\"errors\": 0.10745599865913391, \"time-step\": 2019}, {\"errors\": 0.10724307596683502, \"time-step\": 2020}, {\"errors\": 0.10703037679195404, \"time-step\": 2021}, {\"errors\": 0.10681794583797455, \"time-step\": 2022}, {\"errors\": 0.10660572350025177, \"time-step\": 2023}, {\"errors\": 0.10639376193284988, \"time-step\": 2024}, {\"errors\": 0.1061820238828659, \"time-step\": 2025}, {\"errors\": 0.10597053170204163, \"time-step\": 2026}, {\"errors\": 0.10575921833515167, \"time-step\": 2027}, {\"errors\": 0.10554824769496918, \"time-step\": 2028}, {\"errors\": 0.10533744096755981, \"time-step\": 2029}, {\"errors\": 0.10512691736221313, \"time-step\": 2030}, {\"errors\": 0.10491663217544556, \"time-step\": 2031}, {\"errors\": 0.10470660030841827, \"time-step\": 2032}, {\"errors\": 0.1044967994093895, \"time-step\": 2033}, {\"errors\": 0.10428723692893982, \"time-step\": 2034}, {\"errors\": 0.10407793521881104, \"time-step\": 2035}, {\"errors\": 0.10386888682842255, \"time-step\": 2036}, {\"errors\": 0.10366006940603256, \"time-step\": 2037}, {\"errors\": 0.10345149785280228, \"time-step\": 2038}, {\"errors\": 0.10324321687221527, \"time-step\": 2039}, {\"errors\": 0.10303515195846558, \"time-step\": 2040}, {\"errors\": 0.10282734036445618, \"time-step\": 2041}, {\"errors\": 0.10261976718902588, \"time-step\": 2042}, {\"errors\": 0.10241246223449707, \"time-step\": 2043}, {\"errors\": 0.10220541805028915, \"time-step\": 2044}, {\"errors\": 0.10199864208698273, \"time-step\": 2045}, {\"errors\": 0.101792111992836, \"time-step\": 2046}, {\"errors\": 0.10158583521842957, \"time-step\": 2047}, {\"errors\": 0.10137981921434402, \"time-step\": 2048}, {\"errors\": 0.10117405652999878, \"time-step\": 2049}, {\"errors\": 0.10096854716539383, \"time-step\": 2050}, {\"errors\": 0.10076332092285156, \"time-step\": 2051}, {\"errors\": 0.100558340549469, \"time-step\": 2052}, {\"errors\": 0.10035362094640732, \"time-step\": 2053}, {\"errors\": 0.10014918446540833, \"time-step\": 2054}, {\"errors\": 0.09994501620531082, \"time-step\": 2055}, {\"errors\": 0.09974107146263123, \"time-step\": 2056}, {\"errors\": 0.09953740984201431, \"time-step\": 2057}, {\"errors\": 0.09933401644229889, \"time-step\": 2058}, {\"errors\": 0.09913086891174316, \"time-step\": 2059}, {\"errors\": 0.09892798960208893, \"time-step\": 2060}, {\"errors\": 0.09872537851333618, \"time-step\": 2061}, {\"errors\": 0.09852306544780731, \"time-step\": 2062}, {\"errors\": 0.09832099080085754, \"time-step\": 2063}, {\"errors\": 0.09811919927597046, \"time-step\": 2064}, {\"errors\": 0.09791766107082367, \"time-step\": 2065}, {\"errors\": 0.09771640598773956, \"time-step\": 2066}, {\"errors\": 0.09751543402671814, \"time-step\": 2067}, {\"errors\": 0.09731469303369522, \"time-step\": 2068}, {\"errors\": 0.09711426496505737, \"time-step\": 2069}, {\"errors\": 0.09691409021615982, \"time-step\": 2070}, {\"errors\": 0.09671419858932495, \"time-step\": 2071}, {\"errors\": 0.09651461243629456, \"time-step\": 2072}, {\"errors\": 0.09631524235010147, \"time-step\": 2073}, {\"errors\": 0.09611617028713226, \"time-step\": 2074}, {\"errors\": 0.09591740369796753, \"time-step\": 2075}, {\"errors\": 0.09571889787912369, \"time-step\": 2076}, {\"errors\": 0.09552065283060074, \"time-step\": 2077}, {\"errors\": 0.09532269835472107, \"time-step\": 2078}, {\"errors\": 0.09512501955032349, \"time-step\": 2079}, {\"errors\": 0.09492760896682739, \"time-step\": 2080}, {\"errors\": 0.09473048150539398, \"time-step\": 2081}, {\"errors\": 0.09453365206718445, \"time-step\": 2082}, {\"errors\": 0.094337098300457, \"time-step\": 2083}, {\"errors\": 0.09414081275463104, \"time-step\": 2084}, {\"errors\": 0.09394480288028717, \"time-step\": 2085}, {\"errors\": 0.09374910593032837, \"time-step\": 2086}, {\"errors\": 0.09355366230010986, \"time-step\": 2087}, {\"errors\": 0.09335850179195404, \"time-step\": 2088}, {\"errors\": 0.0931636393070221, \"time-step\": 2089}, {\"errors\": 0.09296905249357224, \"time-step\": 2090}, {\"errors\": 0.09277477860450745, \"time-step\": 2091}, {\"errors\": 0.09258078038692474, \"time-step\": 2092}, {\"errors\": 0.09238703548908234, \"time-step\": 2093}, {\"errors\": 0.0921935886144638, \"time-step\": 2094}, {\"errors\": 0.09200046956539154, \"time-step\": 2095}, {\"errors\": 0.09180758893489838, \"time-step\": 2096}, {\"errors\": 0.09161503612995148, \"time-step\": 2097}, {\"errors\": 0.09142274409532547, \"time-step\": 2098}, {\"errors\": 0.09123074263334274, \"time-step\": 2099}, {\"errors\": 0.09103904664516449, \"time-step\": 2100}, {\"errors\": 0.09084758907556534, \"time-step\": 2101}, {\"errors\": 0.09065649658441544, \"time-step\": 2102}, {\"errors\": 0.09046566486358643, \"time-step\": 2103}, {\"errors\": 0.0902751013636589, \"time-step\": 2104}, {\"errors\": 0.09008488804101944, \"time-step\": 2105}, {\"errors\": 0.08989487588405609, \"time-step\": 2106}, {\"errors\": 0.08970527350902557, \"time-step\": 2107}, {\"errors\": 0.08951584249734879, \"time-step\": 2108}, {\"errors\": 0.08932677656412125, \"time-step\": 2109}, {\"errors\": 0.08913800865411758, \"time-step\": 2110}, {\"errors\": 0.08894946426153183, \"time-step\": 2111}, {\"errors\": 0.08876128494739532, \"time-step\": 2112}, {\"errors\": 0.0885733813047409, \"time-step\": 2113}, {\"errors\": 0.08838576823472977, \"time-step\": 2114}, {\"errors\": 0.08819843828678131, \"time-step\": 2115}, {\"errors\": 0.08801141381263733, \"time-step\": 2116}, {\"errors\": 0.08782470971345901, \"time-step\": 2117}, {\"errors\": 0.08763827383518219, \"time-step\": 2118}, {\"errors\": 0.08745216578245163, \"time-step\": 2119}, {\"errors\": 0.08726633340120316, \"time-step\": 2120}, {\"errors\": 0.08708079159259796, \"time-step\": 2121}, {\"errors\": 0.08689554035663605, \"time-step\": 2122}, {\"errors\": 0.0867106169462204, \"time-step\": 2123}, {\"errors\": 0.08652596920728683, \"time-step\": 2124}, {\"errors\": 0.08634161949157715, \"time-step\": 2125}, {\"errors\": 0.08615758270025253, \"time-step\": 2126}, {\"errors\": 0.08597385883331299, \"time-step\": 2127}, {\"errors\": 0.08579041063785553, \"time-step\": 2128}, {\"errors\": 0.08560729026794434, \"time-step\": 2129}, {\"errors\": 0.08542443811893463, \"time-step\": 2130}, {\"errors\": 0.08524191379547119, \"time-step\": 2131}, {\"errors\": 0.08505968749523163, \"time-step\": 2132}, {\"errors\": 0.08487774431705475, \"time-step\": 2133}, {\"errors\": 0.08469610661268234, \"time-step\": 2134}, {\"errors\": 0.08451478183269501, \"time-step\": 2135}, {\"errors\": 0.08433377742767334, \"time-step\": 2136}, {\"errors\": 0.08415303379297256, \"time-step\": 2137}, {\"errors\": 0.08397257328033447, \"time-step\": 2138}, {\"errors\": 0.08379249274730682, \"time-step\": 2139}, {\"errors\": 0.08361266553401947, \"time-step\": 2140}, {\"errors\": 0.08343316614627838, \"time-step\": 2141}, {\"errors\": 0.08325394988059998, \"time-step\": 2142}, {\"errors\": 0.08307504653930664, \"time-step\": 2143}, {\"errors\": 0.08289643377065659, \"time-step\": 2144}, {\"errors\": 0.0827181488275528, \"time-step\": 2145}, {\"errors\": 0.0825401321053505, \"time-step\": 2146}, {\"errors\": 0.08236243575811386, \"time-step\": 2147}, {\"errors\": 0.0821850597858429, \"time-step\": 2148}, {\"errors\": 0.08200795948505402, \"time-step\": 2149}, {\"errors\": 0.08183120936155319, \"time-step\": 2150}, {\"errors\": 0.08165473490953445, \"time-step\": 2151}, {\"errors\": 0.0814785584807396, \"time-step\": 2152}, {\"errors\": 0.0813027024269104, \"time-step\": 2153}, {\"errors\": 0.08112715184688568, \"time-step\": 2154}, {\"errors\": 0.08095192909240723, \"time-step\": 2155}, {\"errors\": 0.08077698945999146, \"time-step\": 2156}, {\"errors\": 0.08060237765312195, \"time-step\": 2157}, {\"errors\": 0.08042801916599274, \"time-step\": 2158}, {\"errors\": 0.08025399595499039, \"time-step\": 2159}, {\"errors\": 0.0800803005695343, \"time-step\": 2160}, {\"errors\": 0.0799068734049797, \"time-step\": 2161}, {\"errors\": 0.07973380386829376, \"time-step\": 2162}, {\"errors\": 0.07956098765134811, \"time-step\": 2163}, {\"errors\": 0.07938851416110992, \"time-step\": 2164}, {\"errors\": 0.07921633869409561, \"time-step\": 2165}, {\"errors\": 0.07904446870088577, \"time-step\": 2166}, {\"errors\": 0.07887288182973862, \"time-step\": 2167}, {\"errors\": 0.07870163768529892, \"time-step\": 2168}, {\"errors\": 0.07853071391582489, \"time-step\": 2169}, {\"errors\": 0.07836007326841354, \"time-step\": 2170}, {\"errors\": 0.07818976044654846, \"time-step\": 2171}, {\"errors\": 0.07801972329616547, \"time-step\": 2172}, {\"errors\": 0.07785001397132874, \"time-step\": 2173}, {\"errors\": 0.07768058776855469, \"time-step\": 2174}, {\"errors\": 0.0775115117430687, \"time-step\": 2175}, {\"errors\": 0.07734271138906479, \"time-step\": 2176}, {\"errors\": 0.07717423141002655, \"time-step\": 2177}, {\"errors\": 0.07700607180595398, \"time-step\": 2178}, {\"errors\": 0.0768381804227829, \"time-step\": 2179}, {\"errors\": 0.07667063176631927, \"time-step\": 2180}, {\"errors\": 0.07650341838598251, \"time-step\": 2181}, {\"errors\": 0.07633647322654724, \"time-step\": 2182}, {\"errors\": 0.07616982609033585, \"time-step\": 2183}, {\"errors\": 0.07600350677967072, \"time-step\": 2184}, {\"errors\": 0.07583751529455185, \"time-step\": 2185}, {\"errors\": 0.07567179203033447, \"time-step\": 2186}, {\"errors\": 0.07550638914108276, \"time-step\": 2187}, {\"errors\": 0.07534132152795792, \"time-step\": 2188}, {\"errors\": 0.07517655938863754, \"time-step\": 2189}, {\"errors\": 0.07501208782196045, \"time-step\": 2190}, {\"errors\": 0.07484793663024902, \"time-step\": 2191}, {\"errors\": 0.07468407601118088, \"time-step\": 2192}, {\"errors\": 0.074520543217659, \"time-step\": 2193}, {\"errors\": 0.07435733079910278, \"time-step\": 2194}, {\"errors\": 0.07419440150260925, \"time-step\": 2195}, {\"errors\": 0.0740317776799202, \"time-step\": 2196}, {\"errors\": 0.07386946678161621, \"time-step\": 2197}, {\"errors\": 0.07370748370885849, \"time-step\": 2198}, {\"errors\": 0.07354581356048584, \"time-step\": 2199}, {\"errors\": 0.07338444143533707, \"time-step\": 2200}, {\"errors\": 0.07322333753108978, \"time-step\": 2201}, {\"errors\": 0.07306257635354996, \"time-step\": 2202}, {\"errors\": 0.0729021430015564, \"time-step\": 2203}, {\"errors\": 0.07274201512336731, \"time-step\": 2204}, {\"errors\": 0.07258216291666031, \"time-step\": 2205}, {\"errors\": 0.07242264598608017, \"time-step\": 2206}, {\"errors\": 0.07226341217756271, \"time-step\": 2207}, {\"errors\": 0.07210448384284973, \"time-step\": 2208}, {\"errors\": 0.07194589078426361, \"time-step\": 2209}, {\"errors\": 0.07178762555122375, \"time-step\": 2210}, {\"errors\": 0.07162964344024658, \"time-step\": 2211}, {\"errors\": 0.0714719370007515, \"time-step\": 2212}, {\"errors\": 0.07131458818912506, \"time-step\": 2213}, {\"errors\": 0.07115752249956131, \"time-step\": 2214}, {\"errors\": 0.07100076973438263, \"time-step\": 2215}, {\"errors\": 0.07084433734416962, \"time-step\": 2216}, {\"errors\": 0.07068818807601929, \"time-step\": 2217}, {\"errors\": 0.07053236663341522, \"time-step\": 2218}, {\"errors\": 0.07037685811519623, \"time-step\": 2219}, {\"errors\": 0.07022161781787872, \"time-step\": 2220}, {\"errors\": 0.07006672769784927, \"time-step\": 2221}, {\"errors\": 0.06991211324930191, \"time-step\": 2222}, {\"errors\": 0.06975782662630081, \"time-step\": 2223}, {\"errors\": 0.0696038156747818, \"time-step\": 2224}, {\"errors\": 0.06945015490055084, \"time-step\": 2225}, {\"errors\": 0.06929679214954376, \"time-step\": 2226}, {\"errors\": 0.06914372742176056, \"time-step\": 2227}, {\"errors\": 0.06899094581604004, \"time-step\": 2228}, {\"errors\": 0.06883850693702698, \"time-step\": 2229}, {\"errors\": 0.0686863362789154, \"time-step\": 2230}, {\"errors\": 0.06853450834751129, \"time-step\": 2231}, {\"errors\": 0.06838294863700867, \"time-step\": 2232}, {\"errors\": 0.0682317465543747, \"time-step\": 2233}, {\"errors\": 0.06808081269264221, \"time-step\": 2234}, {\"errors\": 0.0679301843047142, \"time-step\": 2235}, {\"errors\": 0.06777986139059067, \"time-step\": 2236}, {\"errors\": 0.06762988865375519, \"time-step\": 2237}, {\"errors\": 0.0674801617860794, \"time-step\": 2238}, {\"errors\": 0.06733076274394989, \"time-step\": 2239}, {\"errors\": 0.06718166172504425, \"time-step\": 2240}, {\"errors\": 0.06703287363052368, \"time-step\": 2241}, {\"errors\": 0.06688437610864639, \"time-step\": 2242}, {\"errors\": 0.06673621386289597, \"time-step\": 2243}, {\"errors\": 0.06658831238746643, \"time-step\": 2244}, {\"errors\": 0.06644076108932495, \"time-step\": 2245}, {\"errors\": 0.06629346311092377, \"time-step\": 2246}, {\"errors\": 0.06614647805690765, \"time-step\": 2247}, {\"errors\": 0.06599981337785721, \"time-step\": 2248}, {\"errors\": 0.06585347652435303, \"time-step\": 2249}, {\"errors\": 0.06570740789175034, \"time-step\": 2250}, {\"errors\": 0.06556162238121033, \"time-step\": 2251}, {\"errors\": 0.06541616469621658, \"time-step\": 2252}, {\"errors\": 0.06527098268270493, \"time-step\": 2253}, {\"errors\": 0.06512614339590073, \"time-step\": 2254}, {\"errors\": 0.06498158723115921, \"time-step\": 2255}, {\"errors\": 0.06483732163906097, \"time-step\": 2256}, {\"errors\": 0.06469336152076721, \"time-step\": 2257}, {\"errors\": 0.06454972922801971, \"time-step\": 2258}, {\"errors\": 0.06440633535385132, \"time-step\": 2259}, {\"errors\": 0.06426329910755157, \"time-step\": 2260}, {\"errors\": 0.06412056088447571, \"time-step\": 2261}, {\"errors\": 0.06397809833288193, \"time-step\": 2262}, {\"errors\": 0.06383596360683441, \"time-step\": 2263}, {\"errors\": 0.06369409710168839, \"time-step\": 2264}, {\"errors\": 0.06355252116918564, \"time-step\": 2265}, {\"errors\": 0.06341125816106796, \"time-step\": 2266}, {\"errors\": 0.06327030807733536, \"time-step\": 2267}, {\"errors\": 0.06312964856624603, \"time-step\": 2268}, {\"errors\": 0.06298927962779999, \"time-step\": 2269}, {\"errors\": 0.06284922361373901, \"time-step\": 2270}, {\"errors\": 0.06270945817232132, \"time-step\": 2271}, {\"errors\": 0.06256997585296631, \"time-step\": 2272}, {\"errors\": 0.062430836260318756, \"time-step\": 2273}, {\"errors\": 0.0622919499874115, \"time-step\": 2274}, {\"errors\": 0.062153369188308716, \"time-step\": 2275}, {\"errors\": 0.06201506778597832, \"time-step\": 2276}, {\"errors\": 0.061877086758613586, \"time-step\": 2277}, {\"errors\": 0.06173940375447273, \"time-step\": 2278}, {\"errors\": 0.061601992696523666, \"time-step\": 2279}, {\"errors\": 0.061464883387088776, \"time-step\": 2280}, {\"errors\": 0.06132808327674866, \"time-step\": 2281}, {\"errors\": 0.061191581189632416, \"time-step\": 2282}, {\"errors\": 0.06105533987283707, \"time-step\": 2283}, {\"errors\": 0.06091943010687828, \"time-step\": 2284}, {\"errors\": 0.06078379973769188, \"time-step\": 2285}, {\"errors\": 0.06064845621585846, \"time-step\": 2286}, {\"errors\": 0.060513414442539215, \"time-step\": 2287}, {\"errors\": 0.06037866696715355, \"time-step\": 2288}, {\"errors\": 0.06024421378970146, \"time-step\": 2289}, {\"errors\": 0.06011001393198967, \"time-step\": 2290}, {\"errors\": 0.05997615307569504, \"time-step\": 2291}, {\"errors\": 0.059842564165592194, \"time-step\": 2292}, {\"errors\": 0.059709277004003525, \"time-step\": 2293}, {\"errors\": 0.05957626923918724, \"time-step\": 2294}, {\"errors\": 0.05944357439875603, \"time-step\": 2295}, {\"errors\": 0.059311117976903915, \"time-step\": 2296}, {\"errors\": 0.05917900428175926, \"time-step\": 2297}, {\"errors\": 0.059047143906354904, \"time-step\": 2298}, {\"errors\": 0.058915574103593826, \"time-step\": 2299}, {\"errors\": 0.058784306049346924, \"time-step\": 2300}, {\"errors\": 0.058653343468904495, \"time-step\": 2301}, {\"errors\": 0.058522626757621765, \"time-step\": 2302}, {\"errors\": 0.0583922415971756, \"time-step\": 2303}, {\"errors\": 0.05826213210821152, \"time-step\": 2304}, {\"errors\": 0.05813229829072952, \"time-step\": 2305}, {\"errors\": 0.05800275877118111, \"time-step\": 2306}, {\"errors\": 0.05787351354956627, \"time-step\": 2307}, {\"errors\": 0.05774454027414322, \"time-step\": 2308}, {\"errors\": 0.05761585012078285, \"time-step\": 2309}, {\"errors\": 0.057487450540065765, \"time-step\": 2310}, {\"errors\": 0.057359322905540466, \"time-step\": 2311}, {\"errors\": 0.057231489568948746, \"time-step\": 2312}, {\"errors\": 0.0571039617061615, \"time-step\": 2313}, {\"errors\": 0.056976690888404846, \"time-step\": 2314}, {\"errors\": 0.05684971809387207, \"time-step\": 2315}, {\"errors\": 0.056723058223724365, \"time-step\": 2316}, {\"errors\": 0.056596606969833374, \"time-step\": 2317}, {\"errors\": 0.05647047609090805, \"time-step\": 2318}, {\"errors\": 0.0563446469604969, \"time-step\": 2319}, {\"errors\": 0.05621907114982605, \"time-step\": 2320}, {\"errors\": 0.05609378218650818, \"time-step\": 2321}, {\"errors\": 0.05596878379583359, \"time-step\": 2322}, {\"errors\": 0.05584406480193138, \"time-step\": 2323}, {\"errors\": 0.055719632655382156, \"time-step\": 2324}, {\"errors\": 0.05559546500444412, \"time-step\": 2325}, {\"errors\": 0.05547155812382698, \"time-step\": 2326}, {\"errors\": 0.055347975343465805, \"time-step\": 2327}, {\"errors\": 0.05522466078400612, \"time-step\": 2328}, {\"errors\": 0.05510162189602852, \"time-step\": 2329}, {\"errors\": 0.05497884750366211, \"time-step\": 2330}, {\"errors\": 0.054856352508068085, \"time-step\": 2331}, {\"errors\": 0.054734162986278534, \"time-step\": 2332}, {\"errors\": 0.05461221933364868, \"time-step\": 2333}, {\"errors\": 0.054490529000759125, \"time-step\": 2334}, {\"errors\": 0.05436914786696434, \"time-step\": 2335}, {\"errors\": 0.054248057305812836, \"time-step\": 2336}, {\"errors\": 0.05412723869085312, \"time-step\": 2337}, {\"errors\": 0.0540066733956337, \"time-step\": 2338}, {\"errors\": 0.05388639122247696, \"time-step\": 2339}, {\"errors\": 0.053766388446092606, \"time-step\": 2340}, {\"errors\": 0.05364665389060974, \"time-step\": 2341}, {\"errors\": 0.05352717638015747, \"time-step\": 2342}, {\"errors\": 0.05340798199176788, \"time-step\": 2343}, {\"errors\": 0.053289078176021576, \"time-step\": 2344}, {\"errors\": 0.05317043513059616, \"time-step\": 2345}, {\"errors\": 0.05305204167962074, \"time-step\": 2346}, {\"errors\": 0.052933961153030396, \"time-step\": 2347}, {\"errors\": 0.05281613767147064, \"time-step\": 2348}, {\"errors\": 0.05269857496023178, \"time-step\": 2349}, {\"errors\": 0.05258128046989441, \"time-step\": 2350}, {\"errors\": 0.052464235574007034, \"time-step\": 2351}, {\"errors\": 0.05234749615192413, \"time-step\": 2352}, {\"errors\": 0.05223102867603302, \"time-step\": 2353}, {\"errors\": 0.05211479961872101, \"time-step\": 2354}, {\"errors\": 0.051998838782310486, \"time-step\": 2355}, {\"errors\": 0.05188315361738205, \"time-step\": 2356}, {\"errors\": 0.051767751574516296, \"time-step\": 2357}, {\"errors\": 0.05165261775255203, \"time-step\": 2358}, {\"errors\": 0.05153772234916687, \"time-step\": 2359}, {\"errors\": 0.051423121243715286, \"time-step\": 2360}, {\"errors\": 0.051308773458004, \"time-step\": 2361}, {\"errors\": 0.051194705069065094, \"time-step\": 2362}, {\"errors\": 0.05108088254928589, \"time-step\": 2363}, {\"errors\": 0.050967343151569366, \"time-step\": 2364}, {\"errors\": 0.05085404962301254, \"time-step\": 2365}, {\"errors\": 0.050741005688905716, \"time-step\": 2366}, {\"errors\": 0.05062825605273247, \"time-step\": 2367}, {\"errors\": 0.050515756011009216, \"time-step\": 2368}, {\"errors\": 0.05040349066257477, \"time-step\": 2369}, {\"errors\": 0.050291527062654495, \"time-step\": 2370}, {\"errors\": 0.050179801881313324, \"time-step\": 2371}, {\"errors\": 0.05006837472319603, \"time-step\": 2372}, {\"errors\": 0.04995718225836754, \"time-step\": 2373}, {\"errors\": 0.04984626546502113, \"time-step\": 2374}, {\"errors\": 0.049735598266124725, \"time-step\": 2375}, {\"errors\": 0.04962515830993652, \"time-step\": 2376}, {\"errors\": 0.049514997750520706, \"time-step\": 2377}, {\"errors\": 0.04940512031316757, \"time-step\": 2378}, {\"errors\": 0.049295470118522644, \"time-step\": 2379}, {\"errors\": 0.0491861030459404, \"time-step\": 2380}, {\"errors\": 0.04907696321606636, \"time-step\": 2381}, {\"errors\": 0.048968080431222916, \"time-step\": 2382}, {\"errors\": 0.04885947331786156, \"time-step\": 2383}, {\"errors\": 0.048751115798950195, \"time-step\": 2384}, {\"errors\": 0.04864300787448883, \"time-step\": 2385}, {\"errors\": 0.04853515326976776, \"time-step\": 2386}, {\"errors\": 0.04842754080891609, \"time-step\": 2387}, {\"errors\": 0.048320233821868896, \"time-step\": 2388}, {\"errors\": 0.04821313917636871, \"time-step\": 2389}, {\"errors\": 0.04810628294944763, \"time-step\": 2390}, {\"errors\": 0.047999732196331024, \"time-step\": 2391}, {\"errors\": 0.04789339005947113, \"time-step\": 2392}, {\"errors\": 0.047787316143512726, \"time-step\": 2393}, {\"errors\": 0.04768146574497223, \"time-step\": 2394}, {\"errors\": 0.04757588356733322, \"time-step\": 2395}, {\"errors\": 0.04747055843472481, \"time-step\": 2396}, {\"errors\": 0.04736548662185669, \"time-step\": 2397}, {\"errors\": 0.04726066440343857, \"time-step\": 2398}, {\"errors\": 0.04715607687830925, \"time-step\": 2399}, {\"errors\": 0.04705177992582321, \"time-step\": 2400}, {\"errors\": 0.04694768041372299, \"time-step\": 2401}, {\"errors\": 0.046843841671943665, \"time-step\": 2402}, {\"errors\": 0.04674025997519493, \"time-step\": 2403}, {\"errors\": 0.046636912971735, \"time-step\": 2404}, {\"errors\": 0.046533823013305664, \"time-step\": 2405}, {\"errors\": 0.04643096402287483, \"time-step\": 2406}, {\"errors\": 0.04632836952805519, \"time-step\": 2407}, {\"errors\": 0.04622599482536316, \"time-step\": 2408}, {\"errors\": 0.046123892068862915, \"time-step\": 2409}, {\"errors\": 0.04602201655507088, \"time-step\": 2410}, {\"errors\": 0.04592040181159973, \"time-step\": 2411}, {\"errors\": 0.0458189994096756, \"time-step\": 2412}, {\"errors\": 0.045717865228652954, \"time-step\": 2413}, {\"errors\": 0.04561696574091911, \"time-step\": 2414}, {\"errors\": 0.04551631212234497, \"time-step\": 2415}, {\"errors\": 0.04541587084531784, \"time-step\": 2416}, {\"errors\": 0.04531572386622429, \"time-step\": 2417}, {\"errors\": 0.04521578922867775, \"time-step\": 2418}, {\"errors\": 0.045116085559129715, \"time-step\": 2419}, {\"errors\": 0.04501663148403168, \"time-step\": 2420}, {\"errors\": 0.04491740092635155, \"time-step\": 2421}, {\"errors\": 0.04481843486428261, \"time-step\": 2422}, {\"errors\": 0.04471970349550247, \"time-step\": 2423}, {\"errors\": 0.044621191918849945, \"time-step\": 2424}, {\"errors\": 0.04452291131019592, \"time-step\": 2425}, {\"errors\": 0.04442489519715309, \"time-step\": 2426}, {\"errors\": 0.04432709142565727, \"time-step\": 2427}, {\"errors\": 0.044229548424482346, \"time-step\": 2428}, {\"errors\": 0.04413222521543503, \"time-step\": 2429}, {\"errors\": 0.044035136699676514, \"time-step\": 2430}, {\"errors\": 0.04393826797604561, \"time-step\": 2431}, {\"errors\": 0.0438416488468647, \"time-step\": 2432}, {\"errors\": 0.043745286762714386, \"time-step\": 2433}, {\"errors\": 0.04364911466836929, \"time-step\": 2434}, {\"errors\": 0.043553177267313004, \"time-step\": 2435}, {\"errors\": 0.043457500636577606, \"time-step\": 2436}, {\"errors\": 0.04336203634738922, \"time-step\": 2437}, {\"errors\": 0.04326682165265083, \"time-step\": 2438}, {\"errors\": 0.043171823024749756, \"time-step\": 2439}, {\"errors\": 0.04307705909013748, \"time-step\": 2440}, {\"errors\": 0.04298251122236252, \"time-step\": 2441}, {\"errors\": 0.042888205498456955, \"time-step\": 2442}, {\"errors\": 0.042794119566679, \"time-step\": 2443}, {\"errors\": 0.04270026460289955, \"time-step\": 2444}, {\"errors\": 0.04260664060711861, \"time-step\": 2445}, {\"errors\": 0.042513251304626465, \"time-step\": 2446}, {\"errors\": 0.04242008179426193, \"time-step\": 2447}, {\"errors\": 0.042327143251895905, \"time-step\": 2448}, {\"errors\": 0.042234428226947784, \"time-step\": 2449}, {\"errors\": 0.04214194416999817, \"time-step\": 2450}, {\"errors\": 0.04204965755343437, \"time-step\": 2451}, {\"errors\": 0.04195761680603027, \"time-step\": 2452}, {\"errors\": 0.04186580330133438, \"time-step\": 2453}, {\"errors\": 0.0417742058634758, \"time-step\": 2454}, {\"errors\": 0.04168284311890602, \"time-step\": 2455}, {\"errors\": 0.04159167781472206, \"time-step\": 2456}, {\"errors\": 0.0415007621049881, \"time-step\": 2457}, {\"errors\": 0.04141006991267204, \"time-step\": 2458}, {\"errors\": 0.041319556534290314, \"time-step\": 2459}, {\"errors\": 0.04122930392622948, \"time-step\": 2460}, {\"errors\": 0.041139256209135056, \"time-step\": 2461}, {\"errors\": 0.04104944318532944, \"time-step\": 2462}, {\"errors\": 0.04095984995365143, \"time-step\": 2463}, {\"errors\": 0.04087048023939133, \"time-step\": 2464}, {\"errors\": 0.040781307965517044, \"time-step\": 2465}, {\"errors\": 0.04069236293435097, \"time-step\": 2466}, {\"errors\": 0.0406036339700222, \"time-step\": 2467}, {\"errors\": 0.040515102446079254, \"time-step\": 2468}, {\"errors\": 0.04042680561542511, \"time-step\": 2469}, {\"errors\": 0.04033873230218887, \"time-step\": 2470}, {\"errors\": 0.04025088995695114, \"time-step\": 2471}, {\"errors\": 0.040163230150938034, \"time-step\": 2472}, {\"errors\": 0.04007580131292343, \"time-step\": 2473}, {\"errors\": 0.039988577365875244, \"time-step\": 2474}, {\"errors\": 0.03990159183740616, \"time-step\": 2475}, {\"errors\": 0.0398147813975811, \"time-step\": 2476}, {\"errors\": 0.03972818702459335, \"time-step\": 2477}, {\"errors\": 0.039641838520765305, \"time-step\": 2478}, {\"errors\": 0.03955567628145218, \"time-step\": 2479}, {\"errors\": 0.03946972265839577, \"time-step\": 2480}, {\"errors\": 0.03938400000333786, \"time-step\": 2481}, {\"errors\": 0.03929848223924637, \"time-step\": 2482}, {\"errors\": 0.0392131432890892, \"time-step\": 2483}, {\"errors\": 0.03912806510925293, \"time-step\": 2484}, {\"errors\": 0.03904317691922188, \"time-step\": 2485}, {\"errors\": 0.03895847871899605, \"time-step\": 2486}, {\"errors\": 0.038874007761478424, \"time-step\": 2487}, {\"errors\": 0.03878974914550781, \"time-step\": 2488}, {\"errors\": 0.038705673068761826, \"time-step\": 2489}, {\"errors\": 0.03862183913588524, \"time-step\": 2490}, {\"errors\": 0.038538187742233276, \"time-step\": 2491}, {\"errors\": 0.03845473751425743, \"time-step\": 2492}, {\"errors\": 0.038371492177248, \"time-step\": 2493}, {\"errors\": 0.038288481533527374, \"time-step\": 2494}, {\"errors\": 0.03820565715432167, \"time-step\": 2495}, {\"errors\": 0.03812302276492119, \"time-step\": 2496}, {\"errors\": 0.03804061934351921, \"time-step\": 2497}, {\"errors\": 0.037958402186632156, \"time-step\": 2498}, {\"errors\": 0.03787638619542122, \"time-step\": 2499}, {\"errors\": 0.0377945639193058, \"time-step\": 2500}, {\"errors\": 0.03771296888589859, \"time-step\": 2501}, {\"errors\": 0.0376315638422966, \"time-step\": 2502}, {\"errors\": 0.03755035623908043, \"time-step\": 2503}, {\"errors\": 0.03746935725212097, \"time-step\": 2504}, {\"errors\": 0.03738854080438614, \"time-step\": 2505}, {\"errors\": 0.037307947874069214, \"time-step\": 2506}, {\"errors\": 0.03722754120826721, \"time-step\": 2507}, {\"errors\": 0.03714732825756073, \"time-step\": 2508}, {\"errors\": 0.03706732392311096, \"time-step\": 2509}, {\"errors\": 0.03698749840259552, \"time-step\": 2510}, {\"errors\": 0.03690789267420769, \"time-step\": 2511}, {\"errors\": 0.03682848811149597, \"time-step\": 2512}, {\"errors\": 0.03674926236271858, \"time-step\": 2513}, {\"errors\": 0.036670245230197906, \"time-step\": 2514}, {\"errors\": 0.03659142926335335, \"time-step\": 2515}, {\"errors\": 0.03651278465986252, \"time-step\": 2516}, {\"errors\": 0.0364343486726284, \"time-step\": 2517}, {\"errors\": 0.03635609522461891, \"time-step\": 2518}, {\"errors\": 0.036278050392866135, \"time-step\": 2519}, {\"errors\": 0.036200203001499176, \"time-step\": 2520}, {\"errors\": 0.03612253814935684, \"time-step\": 2521}, {\"errors\": 0.03604504093527794, \"time-step\": 2522}, {\"errors\": 0.03596779704093933, \"time-step\": 2523}, {\"errors\": 0.03589067980647087, \"time-step\": 2524}, {\"errors\": 0.03581378981471062, \"time-step\": 2525}, {\"errors\": 0.03573707863688469, \"time-step\": 2526}, {\"errors\": 0.03566057235002518, \"time-step\": 2527}, {\"errors\": 0.035584237426519394, \"time-step\": 2528}, {\"errors\": 0.035508107393980026, \"time-step\": 2529}, {\"errors\": 0.035432152450084686, \"time-step\": 2530}, {\"errors\": 0.03535640984773636, \"time-step\": 2531}, {\"errors\": 0.035280827432870865, \"time-step\": 2532}, {\"errors\": 0.03520543873310089, \"time-step\": 2533}, {\"errors\": 0.03513025864958763, \"time-step\": 2534}, {\"errors\": 0.03505523130297661, \"time-step\": 2535}, {\"errors\": 0.0349804162979126, \"time-step\": 2536}, {\"errors\": 0.034905776381492615, \"time-step\": 2537}, {\"errors\": 0.03483132645487785, \"time-step\": 2538}, {\"errors\": 0.03475705906748772, \"time-step\": 2539}, {\"errors\": 0.0346829816699028, \"time-step\": 2540}, {\"errors\": 0.03460908308625221, \"time-step\": 2541}, {\"errors\": 0.03453536331653595, \"time-step\": 2542}, {\"errors\": 0.03446181118488312, \"time-step\": 2543}, {\"errors\": 0.034388475120067596, \"time-step\": 2544}, {\"errors\": 0.034315310418605804, \"time-step\": 2545}, {\"errors\": 0.03424232453107834, \"time-step\": 2546}, {\"errors\": 0.034169528633356094, \"time-step\": 2547}, {\"errors\": 0.03409690409898758, \"time-step\": 2548}, {\"errors\": 0.03402446210384369, \"time-step\": 2549}, {\"errors\": 0.03395219147205353, \"time-step\": 2550}, {\"errors\": 0.03388009965419769, \"time-step\": 2551}, {\"errors\": 0.03380821272730827, \"time-step\": 2552}, {\"errors\": 0.033736493438482285, \"time-step\": 2553}, {\"errors\": 0.03366493061184883, \"time-step\": 2554}, {\"errors\": 0.033593568950891495, \"time-step\": 2555}, {\"errors\": 0.03352237492799759, \"time-step\": 2556}, {\"errors\": 0.03345136716961861, \"time-step\": 2557}, {\"errors\": 0.03338051587343216, \"time-step\": 2558}, {\"errors\": 0.03330986201763153, \"time-step\": 2559}, {\"errors\": 0.03323938325047493, \"time-step\": 2560}, {\"errors\": 0.03316906839609146, \"time-step\": 2561}, {\"errors\": 0.033098939806222916, \"time-step\": 2562}, {\"errors\": 0.0330289863049984, \"time-step\": 2563}, {\"errors\": 0.03295918554067612, \"time-step\": 2564}, {\"errors\": 0.03288959339261055, \"time-step\": 2565}, {\"errors\": 0.032820139080286026, \"time-step\": 2566}, {\"errors\": 0.03275088965892792, \"time-step\": 2567}, {\"errors\": 0.03268178179860115, \"time-step\": 2568}, {\"errors\": 0.03261285275220871, \"time-step\": 2569}, {\"errors\": 0.03254411742091179, \"time-step\": 2570}, {\"errors\": 0.03247553110122681, \"time-step\": 2571}, {\"errors\": 0.032407134771347046, \"time-step\": 2572}, {\"errors\": 0.032338887453079224, \"time-step\": 2573}, {\"errors\": 0.03227081522345543, \"time-step\": 2574}, {\"errors\": 0.03220292553305626, \"time-step\": 2575}, {\"errors\": 0.03213519603013992, \"time-step\": 2576}, {\"errors\": 0.032067641615867615, \"time-step\": 2577}, {\"errors\": 0.03200023993849754, \"time-step\": 2578}, {\"errors\": 0.0319330208003521, \"time-step\": 2579}, {\"errors\": 0.03186595439910889, \"time-step\": 2580}, {\"errors\": 0.03179909288883209, \"time-step\": 2581}, {\"errors\": 0.03173236548900604, \"time-step\": 2582}, {\"errors\": 0.03166579455137253, \"time-step\": 2583}, {\"errors\": 0.031599417328834534, \"time-step\": 2584}, {\"errors\": 0.03153317794203758, \"time-step\": 2585}, {\"errors\": 0.03146713599562645, \"time-step\": 2586}, {\"errors\": 0.03140122443437576, \"time-step\": 2587}, {\"errors\": 0.031335506588220596, \"time-step\": 2588}, {\"errors\": 0.03126991540193558, \"time-step\": 2589}, {\"errors\": 0.031204506754875183, \"time-step\": 2590}, {\"errors\": 0.03113928996026516, \"time-step\": 2591}, {\"errors\": 0.031074197962880135, \"time-step\": 2592}, {\"errors\": 0.031009290367364883, \"time-step\": 2593}, {\"errors\": 0.03094453364610672, \"time-step\": 2594}, {\"errors\": 0.030879946425557137, \"time-step\": 2595}, {\"errors\": 0.030815493315458298, \"time-step\": 2596}, {\"errors\": 0.030751220881938934, \"time-step\": 2597}, {\"errors\": 0.030687112361192703, \"time-step\": 2598}, {\"errors\": 0.03062315471470356, \"time-step\": 2599}, {\"errors\": 0.0305593591183424, \"time-step\": 2600}, {\"errors\": 0.030495723709464073, \"time-step\": 2601}, {\"errors\": 0.03043225407600403, \"time-step\": 2602}, {\"errors\": 0.030368927866220474, \"time-step\": 2603}, {\"errors\": 0.030305776745080948, \"time-step\": 2604}, {\"errors\": 0.03024277277290821, \"time-step\": 2605}, {\"errors\": 0.03017992526292801, \"time-step\": 2606}, {\"errors\": 0.030117234215140343, \"time-step\": 2607}, {\"errors\": 0.030054697766900063, \"time-step\": 2608}, {\"errors\": 0.029992319643497467, \"time-step\": 2609}, {\"errors\": 0.029930107295513153, \"time-step\": 2610}, {\"errors\": 0.029868029057979584, \"time-step\": 2611}, {\"errors\": 0.029806114733219147, \"time-step\": 2612}, {\"errors\": 0.0297443438321352, \"time-step\": 2613}, {\"errors\": 0.029682759195566177, \"time-step\": 2614}, {\"errors\": 0.02962130680680275, \"time-step\": 2615}, {\"errors\": 0.029559995979070663, \"time-step\": 2616}, {\"errors\": 0.029498843476176262, \"time-step\": 2617}, {\"errors\": 0.029437849298119545, \"time-step\": 2618}, {\"errors\": 0.02937699668109417, \"time-step\": 2619}, {\"errors\": 0.029316319152712822, \"time-step\": 2620}, {\"errors\": 0.029255779460072517, \"time-step\": 2621}, {\"errors\": 0.02919538877904415, \"time-step\": 2622}, {\"errors\": 0.02913513407111168, \"time-step\": 2623}, {\"errors\": 0.029075052589178085, \"time-step\": 2624}, {\"errors\": 0.029015108942985535, \"time-step\": 2625}, {\"errors\": 0.02895531803369522, \"time-step\": 2626}, {\"errors\": 0.028895676136016846, \"time-step\": 2627}, {\"errors\": 0.02883618324995041, \"time-step\": 2628}, {\"errors\": 0.028776833787560463, \"time-step\": 2629}, {\"errors\": 0.02871764823794365, \"time-step\": 2630}, {\"errors\": 0.02865857630968094, \"time-step\": 2631}, {\"errors\": 0.028599677607417107, \"time-step\": 2632}, {\"errors\": 0.02854091115295887, \"time-step\": 2633}, {\"errors\": 0.028482303023338318, \"time-step\": 2634}, {\"errors\": 0.028423842042684555, \"time-step\": 2635}, {\"errors\": 0.028365518897771835, \"time-step\": 2636}, {\"errors\": 0.02830733358860016, \"time-step\": 2637}, {\"errors\": 0.028249308466911316, \"time-step\": 2638}, {\"errors\": 0.02819141373038292, \"time-step\": 2639}, {\"errors\": 0.028133675456047058, \"time-step\": 2640}, {\"errors\": 0.028076067566871643, \"time-step\": 2641}, {\"errors\": 0.02801862545311451, \"time-step\": 2642}, {\"errors\": 0.02796131744980812, \"time-step\": 2643}, {\"errors\": 0.027904128655791283, \"time-step\": 2644}, {\"errors\": 0.027847103774547577, \"time-step\": 2645}, {\"errors\": 0.027790207415819168, \"time-step\": 2646}, {\"errors\": 0.027733471244573593, \"time-step\": 2647}, {\"errors\": 0.027676863595843315, \"time-step\": 2648}, {\"errors\": 0.02762039192020893, \"time-step\": 2649}, {\"errors\": 0.027564071118831635, \"time-step\": 2650}, {\"errors\": 0.02750789001584053, \"time-step\": 2651}, {\"errors\": 0.027451835572719574, \"time-step\": 2652}, {\"errors\": 0.027395915240049362, \"time-step\": 2653}, {\"errors\": 0.027340158820152283, \"time-step\": 2654}, {\"errors\": 0.02728452906012535, \"time-step\": 2655}, {\"errors\": 0.027229033410549164, \"time-step\": 2656}, {\"errors\": 0.027173679322004318, \"time-step\": 2657}, {\"errors\": 0.027118464931845665, \"time-step\": 2658}, {\"errors\": 0.02706337720155716, \"time-step\": 2659}, {\"errors\": 0.02700844593346119, \"time-step\": 2660}, {\"errors\": 0.02695363014936447, \"time-step\": 2661}, {\"errors\": 0.026898961514234543, \"time-step\": 2662}, {\"errors\": 0.026844412088394165, \"time-step\": 2663}, {\"errors\": 0.02679002285003662, \"time-step\": 2664}, {\"errors\": 0.02673574537038803, \"time-step\": 2665}, {\"errors\": 0.026681607589125633, \"time-step\": 2666}, {\"errors\": 0.026627616956830025, \"time-step\": 2667}, {\"errors\": 0.026573745533823967, \"time-step\": 2668}, {\"errors\": 0.026520023122429848, \"time-step\": 2669}, {\"errors\": 0.02646641805768013, \"time-step\": 2670}, {\"errors\": 0.026412950828671455, \"time-step\": 2671}, {\"errors\": 0.026359621435403824, \"time-step\": 2672}, {\"errors\": 0.026306405663490295, \"time-step\": 2673}, {\"errors\": 0.026253344491124153, \"time-step\": 2674}, {\"errors\": 0.026200396940112114, \"time-step\": 2675}, {\"errors\": 0.026147592812776566, \"time-step\": 2676}, {\"errors\": 0.026094915345311165, \"time-step\": 2677}, {\"errors\": 0.02604236826300621, \"time-step\": 2678}, {\"errors\": 0.0259899590164423, \"time-step\": 2679}, {\"errors\": 0.025937668979167938, \"time-step\": 2680}, {\"errors\": 0.025885503739118576, \"time-step\": 2681}, {\"errors\": 0.025833474472165108, \"time-step\": 2682}, {\"errors\": 0.025781575590372086, \"time-step\": 2683}, {\"errors\": 0.025729797780513763, \"time-step\": 2684}, {\"errors\": 0.025678161531686783, \"time-step\": 2685}, {\"errors\": 0.025626644492149353, \"time-step\": 2686}, {\"errors\": 0.025575248524546623, \"time-step\": 2687}, {\"errors\": 0.02552397921681404, \"time-step\": 2688}, {\"errors\": 0.02547285333275795, \"time-step\": 2689}, {\"errors\": 0.025421828031539917, \"time-step\": 2690}, {\"errors\": 0.025370951741933823, \"time-step\": 2691}, {\"errors\": 0.02532019093632698, \"time-step\": 2692}, {\"errors\": 0.02526956982910633, \"time-step\": 2693}, {\"errors\": 0.025219056755304337, \"time-step\": 2694}, {\"errors\": 0.02516867220401764, \"time-step\": 2695}, {\"errors\": 0.025118403136730194, \"time-step\": 2696}, {\"errors\": 0.0250682570040226, \"time-step\": 2697}, {\"errors\": 0.025018244981765747, \"time-step\": 2698}, {\"errors\": 0.02496836893260479, \"time-step\": 2699}, {\"errors\": 0.02491859532892704, \"time-step\": 2700}, {\"errors\": 0.024868957698345184, \"time-step\": 2701}, {\"errors\": 0.024819418787956238, \"time-step\": 2702}, {\"errors\": 0.024770021438598633, \"time-step\": 2703}, {\"errors\": 0.024720754474401474, \"time-step\": 2704}, {\"errors\": 0.02467159368097782, \"time-step\": 2705}, {\"errors\": 0.024622557684779167, \"time-step\": 2706}, {\"errors\": 0.024573640897870064, \"time-step\": 2707}, {\"errors\": 0.024524863809347153, \"time-step\": 2708}, {\"errors\": 0.024476170539855957, \"time-step\": 2709}, {\"errors\": 0.02442760393023491, \"time-step\": 2710}, {\"errors\": 0.024379180744290352, \"time-step\": 2711}, {\"errors\": 0.024330874904990196, \"time-step\": 2712}, {\"errors\": 0.024282652884721756, \"time-step\": 2713}, {\"errors\": 0.024234578013420105, \"time-step\": 2714}, {\"errors\": 0.024186627939343452, \"time-step\": 2715}, {\"errors\": 0.024138767272233963, \"time-step\": 2716}, {\"errors\": 0.02409103512763977, \"time-step\": 2717}, {\"errors\": 0.024043433368206024, \"time-step\": 2718}, {\"errors\": 0.023995932191610336, \"time-step\": 2719}, {\"errors\": 0.023948561400175095, \"time-step\": 2720}, {\"errors\": 0.02390129491686821, \"time-step\": 2721}, {\"errors\": 0.023854153230786324, \"time-step\": 2722}, {\"errors\": 0.02380712516605854, \"time-step\": 2723}, {\"errors\": 0.02376021072268486, \"time-step\": 2724}, {\"errors\": 0.02371342107653618, \"time-step\": 2725}, {\"errors\": 0.023666733875870705, \"time-step\": 2726}, {\"errors\": 0.023620164021849632, \"time-step\": 2727}, {\"errors\": 0.023573705926537514, \"time-step\": 2728}, {\"errors\": 0.023527372628450394, \"time-step\": 2729}, {\"errors\": 0.023481125012040138, \"time-step\": 2730}, {\"errors\": 0.023435018956661224, \"time-step\": 2731}, {\"errors\": 0.02338901162147522, \"time-step\": 2732}, {\"errors\": 0.02334311604499817, \"time-step\": 2733}, {\"errors\": 0.02329733781516552, \"time-step\": 2734}, {\"errors\": 0.023251675069332123, \"time-step\": 2735}, {\"errors\": 0.02320612035691738, \"time-step\": 2736}, {\"errors\": 0.023160668089985847, \"time-step\": 2737}, {\"errors\": 0.02311534620821476, \"time-step\": 2738}, {\"errors\": 0.023070115596055984, \"time-step\": 2739}, {\"errors\": 0.02302500605583191, \"time-step\": 2740}, {\"errors\": 0.022980008274316788, \"time-step\": 2741}, {\"errors\": 0.022935116663575172, \"time-step\": 2742}, {\"errors\": 0.022890333086252213, \"time-step\": 2743}, {\"errors\": 0.022845666855573654, \"time-step\": 2744}, {\"errors\": 0.022801093757152557, \"time-step\": 2745}, {\"errors\": 0.02275664359331131, \"time-step\": 2746}, {\"errors\": 0.02271229214966297, \"time-step\": 2747}, {\"errors\": 0.022668056190013885, \"time-step\": 2748}, {\"errors\": 0.022623933851718903, \"time-step\": 2749}, {\"errors\": 0.022579902783036232, \"time-step\": 2750}, {\"errors\": 0.022535983473062515, \"time-step\": 2751}, {\"errors\": 0.0224921777844429, \"time-step\": 2752}, {\"errors\": 0.022448472678661346, \"time-step\": 2753}, {\"errors\": 0.022404883056879044, \"time-step\": 2754}, {\"errors\": 0.022361397743225098, \"time-step\": 2755}, {\"errors\": 0.022318001836538315, \"time-step\": 2756}, {\"errors\": 0.02227472886443138, \"time-step\": 2757}, {\"errors\": 0.022231562063097954, \"time-step\": 2758}, {\"errors\": 0.022188479080796242, \"time-step\": 2759}, {\"errors\": 0.022145522758364677, \"time-step\": 2760}, {\"errors\": 0.022102661430835724, \"time-step\": 2761}, {\"errors\": 0.022059909999370575, \"time-step\": 2762}, {\"errors\": 0.022017251700162888, \"time-step\": 2763}, {\"errors\": 0.021974710747599602, \"time-step\": 2764}, {\"errors\": 0.02193225361406803, \"time-step\": 2765}, {\"errors\": 0.021889925003051758, \"time-step\": 2766}, {\"errors\": 0.021847663447260857, \"time-step\": 2767}, {\"errors\": 0.021805547177791595, \"time-step\": 2768}, {\"errors\": 0.021763509139418602, \"time-step\": 2769}, {\"errors\": 0.021721582859754562, \"time-step\": 2770}, {\"errors\": 0.021679753437638283, \"time-step\": 2771}, {\"errors\": 0.021638011559844017, \"time-step\": 2772}, {\"errors\": 0.0215963963419199, \"time-step\": 2773}, {\"errors\": 0.0215548574924469, \"time-step\": 2774}, {\"errors\": 0.021513428539037704, \"time-step\": 2775}, {\"errors\": 0.02147209271788597, \"time-step\": 2776}, {\"errors\": 0.021430866792798042, \"time-step\": 2777}, {\"errors\": 0.02138974517583847, \"time-step\": 2778}, {\"errors\": 0.021348707377910614, \"time-step\": 2779}, {\"errors\": 0.02130778878927231, \"time-step\": 2780}, {\"errors\": 0.02126695215702057, \"time-step\": 2781}, {\"errors\": 0.021226221695542336, \"time-step\": 2782}, {\"errors\": 0.02118558995425701, \"time-step\": 2783}, {\"errors\": 0.021145060658454895, \"time-step\": 2784}, {\"errors\": 0.02110462635755539, \"time-step\": 2785}, {\"errors\": 0.021064281463623047, \"time-step\": 2786}, {\"errors\": 0.02102404460310936, \"time-step\": 2787}, {\"errors\": 0.020983899012207985, \"time-step\": 2788}, {\"errors\": 0.02094384841620922, \"time-step\": 2789}, {\"errors\": 0.02090389095246792, \"time-step\": 2790}, {\"errors\": 0.020864030346274376, \"time-step\": 2791}, {\"errors\": 0.020824268460273743, \"time-step\": 2792}, {\"errors\": 0.020784609019756317, \"time-step\": 2793}, {\"errors\": 0.020745042711496353, \"time-step\": 2794}, {\"errors\": 0.020705565810203552, \"time-step\": 2795}, {\"errors\": 0.02066618949174881, \"time-step\": 2796}, {\"errors\": 0.02062690258026123, \"time-step\": 2797}, {\"errors\": 0.020587708801031113, \"time-step\": 2798}, {\"errors\": 0.020548611879348755, \"time-step\": 2799}, {\"errors\": 0.02050962671637535, \"time-step\": 2800}, {\"errors\": 0.020470714196562767, \"time-step\": 2801}, {\"errors\": 0.020431896671652794, \"time-step\": 2802}, {\"errors\": 0.02039317600429058, \"time-step\": 2803}, {\"errors\": 0.02035455033183098, \"time-step\": 2804}, {\"errors\": 0.020316006615757942, \"time-step\": 2805}, {\"errors\": 0.02027757652103901, \"time-step\": 2806}, {\"errors\": 0.02023921348154545, \"time-step\": 2807}, {\"errors\": 0.020200954750180244, \"time-step\": 2808}, {\"errors\": 0.020162787288427353, \"time-step\": 2809}, {\"errors\": 0.02012472227215767, \"time-step\": 2810}, {\"errors\": 0.020086735486984253, \"time-step\": 2811}, {\"errors\": 0.0200488418340683, \"time-step\": 2812}, {\"errors\": 0.020011035725474358, \"time-step\": 2813}, {\"errors\": 0.019973324611783028, \"time-step\": 2814}, {\"errors\": 0.019935699179768562, \"time-step\": 2815}, {\"errors\": 0.019898170605301857, \"time-step\": 2816}, {\"errors\": 0.01986072212457657, \"time-step\": 2817}, {\"errors\": 0.01982337422668934, \"time-step\": 2818}, {\"errors\": 0.019786100834608078, \"time-step\": 2819}, {\"errors\": 0.019748935475945473, \"time-step\": 2820}, {\"errors\": 0.019711846485733986, \"time-step\": 2821}, {\"errors\": 0.019674845039844513, \"time-step\": 2822}, {\"errors\": 0.01963793858885765, \"time-step\": 2823}, {\"errors\": 0.019601108506321907, \"time-step\": 2824}, {\"errors\": 0.019564379006624222, \"time-step\": 2825}, {\"errors\": 0.019527727738022804, \"time-step\": 2826}, {\"errors\": 0.019491171464323997, \"time-step\": 2827}, {\"errors\": 0.019454702734947205, \"time-step\": 2828}, {\"errors\": 0.019418321549892426, \"time-step\": 2829}, {\"errors\": 0.019382033497095108, \"time-step\": 2830}, {\"errors\": 0.019345812499523163, \"time-step\": 2831}, {\"errors\": 0.019309688359498978, \"time-step\": 2832}, {\"errors\": 0.01927363872528076, \"time-step\": 2833}, {\"errors\": 0.019237689673900604, \"time-step\": 2834}, {\"errors\": 0.019201816990971565, \"time-step\": 2835}, {\"errors\": 0.01916602998971939, \"time-step\": 2836}, {\"errors\": 0.01913033425807953, \"time-step\": 2837}, {\"errors\": 0.019094718620181084, \"time-step\": 2838}, {\"errors\": 0.0190591923892498, \"time-step\": 2839}, {\"errors\": 0.019023746252059937, \"time-step\": 2840}, {\"errors\": 0.018988385796546936, \"time-step\": 2841}, {\"errors\": 0.018953103572130203, \"time-step\": 2842}, {\"errors\": 0.018917908892035484, \"time-step\": 2843}, {\"errors\": 0.01888280361890793, \"time-step\": 2844}, {\"errors\": 0.018847767263650894, \"time-step\": 2845}, {\"errors\": 0.01881282776594162, \"time-step\": 2846}, {\"errors\": 0.018777959048748016, \"time-step\": 2847}, {\"errors\": 0.018743179738521576, \"time-step\": 2848}, {\"errors\": 0.0187084898352623, \"time-step\": 2849}, {\"errors\": 0.018673870712518692, \"time-step\": 2850}, {\"errors\": 0.018639344722032547, \"time-step\": 2851}, {\"errors\": 0.018604889512062073, \"time-step\": 2852}, {\"errors\": 0.018570512533187866, \"time-step\": 2853}, {\"errors\": 0.018536221235990524, \"time-step\": 2854}, {\"errors\": 0.018502023071050644, \"time-step\": 2855}, {\"errors\": 0.018467886373400688, \"time-step\": 2856}, {\"errors\": 0.018433846533298492, \"time-step\": 2857}, {\"errors\": 0.018399881199002266, \"time-step\": 2858}, {\"errors\": 0.01836598664522171, \"time-step\": 2859}, {\"errors\": 0.018332183361053467, \"time-step\": 2860}, {\"errors\": 0.018298450857400894, \"time-step\": 2861}, {\"errors\": 0.018264804035425186, \"time-step\": 2862}, {\"errors\": 0.018231242895126343, \"time-step\": 2863}, {\"errors\": 0.01819775253534317, \"time-step\": 2864}, {\"errors\": 0.018164340406656265, \"time-step\": 2865}, {\"errors\": 0.01813100278377533, \"time-step\": 2866}, {\"errors\": 0.01809775084257126, \"time-step\": 2867}, {\"errors\": 0.018064577132463455, \"time-step\": 2868}, {\"errors\": 0.018031472340226173, \"time-step\": 2869}, {\"errors\": 0.017998460680246353, \"time-step\": 2870}, {\"errors\": 0.017965517938137054, \"time-step\": 2871}, {\"errors\": 0.017932647839188576, \"time-step\": 2872}, {\"errors\": 0.017899852246046066, \"time-step\": 2873}, {\"errors\": 0.01786714978516102, \"time-step\": 2874}, {\"errors\": 0.017834505066275597, \"time-step\": 2875}, {\"errors\": 0.01780194789171219, \"time-step\": 2876}, {\"errors\": 0.017769480124115944, \"time-step\": 2877}, {\"errors\": 0.017737064510583878, \"time-step\": 2878}, {\"errors\": 0.017704736441373825, \"time-step\": 2879}, {\"errors\": 0.017672477290034294, \"time-step\": 2880}, {\"errors\": 0.01764030195772648, \"time-step\": 2881}, {\"errors\": 0.01760820485651493, \"time-step\": 2882}, {\"errors\": 0.017576176673173904, \"time-step\": 2883}, {\"errors\": 0.017544208094477654, \"time-step\": 2884}, {\"errors\": 0.017512336373329163, \"time-step\": 2885}, {\"errors\": 0.01748053915798664, \"time-step\": 2886}, {\"errors\": 0.017448794096708298, \"time-step\": 2887}, {\"errors\": 0.017417149618268013, \"time-step\": 2888}, {\"errors\": 0.017385564744472504, \"time-step\": 2889}, {\"errors\": 0.017354050651192665, \"time-step\": 2890}, {\"errors\": 0.017322618514299393, \"time-step\": 2891}, {\"errors\": 0.017291255295276642, \"time-step\": 2892}, {\"errors\": 0.017259959131479263, \"time-step\": 2893}, {\"errors\": 0.01722874864935875, \"time-step\": 2894}, {\"errors\": 0.017197594046592712, \"time-step\": 2895}, {\"errors\": 0.01716652885079384, \"time-step\": 2896}, {\"errors\": 0.017135534435510635, \"time-step\": 2897}, {\"errors\": 0.017104603350162506, \"time-step\": 2898}, {\"errors\": 0.017073744907975197, \"time-step\": 2899}, {\"errors\": 0.01704295538365841, \"time-step\": 2900}, {\"errors\": 0.017012255266308784, \"time-step\": 2901}, {\"errors\": 0.01698160730302334, \"time-step\": 2902}, {\"errors\": 0.01695103757083416, \"time-step\": 2903}, {\"errors\": 0.016920533031225204, \"time-step\": 2904}, {\"errors\": 0.016890108585357666, \"time-step\": 2905}, {\"errors\": 0.016859738156199455, \"time-step\": 2906}, {\"errors\": 0.01682945340871811, \"time-step\": 2907}, {\"errors\": 0.016799241304397583, \"time-step\": 2908}, {\"errors\": 0.01676909253001213, \"time-step\": 2909}, {\"errors\": 0.016739007085561752, \"time-step\": 2910}, {\"errors\": 0.01670900359749794, \"time-step\": 2911}, {\"errors\": 0.016679072752594948, \"time-step\": 2912}, {\"errors\": 0.01664920337498188, \"time-step\": 2913}, {\"errors\": 0.016619395464658737, \"time-step\": 2914}, {\"errors\": 0.016589660197496414, \"time-step\": 2915}, {\"errors\": 0.016559995710849762, \"time-step\": 2916}, {\"errors\": 0.01653040014207363, \"time-step\": 2917}, {\"errors\": 0.01650087535381317, \"time-step\": 2918}, {\"errors\": 0.016471417620778084, \"time-step\": 2919}, {\"errors\": 0.01644202321767807, \"time-step\": 2920}, {\"errors\": 0.016412699595093727, \"time-step\": 2921}, {\"errors\": 0.016383450478315353, \"time-step\": 2922}, {\"errors\": 0.016354257240891457, \"time-step\": 2923}, {\"errors\": 0.01632513850927353, \"time-step\": 2924}, {\"errors\": 0.016296083107590675, \"time-step\": 2925}, {\"errors\": 0.016267089173197746, \"time-step\": 2926}, {\"errors\": 0.016238179057836533, \"time-step\": 2927}, {\"errors\": 0.016209319233894348, \"time-step\": 2928}, {\"errors\": 0.016180532053112984, \"time-step\": 2929}, {\"errors\": 0.016151808202266693, \"time-step\": 2930}, {\"errors\": 0.016123153269290924, \"time-step\": 2931}, {\"errors\": 0.016094567254185677, \"time-step\": 2932}, {\"errors\": 0.01606603153049946, \"time-step\": 2933}, {\"errors\": 0.016037583351135254, \"time-step\": 2934}, {\"errors\": 0.016009189188480377, \"time-step\": 2935}, {\"errors\": 0.015980849042534828, \"time-step\": 2936}, {\"errors\": 0.015952588990330696, \"time-step\": 2937}, {\"errors\": 0.015924392268061638, \"time-step\": 2938}, {\"errors\": 0.015896258875727654, \"time-step\": 2939}, {\"errors\": 0.015868179500102997, \"time-step\": 2940}, {\"errors\": 0.01584017649292946, \"time-step\": 2941}, {\"errors\": 0.015812236815690994, \"time-step\": 2942}, {\"errors\": 0.015784354880452156, \"time-step\": 2943}, {\"errors\": 0.015756547451019287, \"time-step\": 2944}, {\"errors\": 0.01572878658771515, \"time-step\": 2945}, {\"errors\": 0.01570110209286213, \"time-step\": 2946}, {\"errors\": 0.015673479065299034, \"time-step\": 2947}, {\"errors\": 0.015645913779735565, \"time-step\": 2948}, {\"errors\": 0.015618405304849148, \"time-step\": 2949}, {\"errors\": 0.015590978786349297, \"time-step\": 2950}, {\"errors\": 0.0155636016279459, \"time-step\": 2951}, {\"errors\": 0.015536293387413025, \"time-step\": 2952}, {\"errors\": 0.015509044751524925, \"time-step\": 2953}, {\"errors\": 0.015481849201023579, \"time-step\": 2954}, {\"errors\": 0.015454726293683052, \"time-step\": 2955}, {\"errors\": 0.015427663922309875, \"time-step\": 2956}, {\"errors\": 0.015400657430291176, \"time-step\": 2957}, {\"errors\": 0.01537371426820755, \"time-step\": 2958}, {\"errors\": 0.015346834436058998, \"time-step\": 2959}, {\"errors\": 0.015320008620619774, \"time-step\": 2960}, {\"errors\": 0.015293250791728497, \"time-step\": 2961}, {\"errors\": 0.015266559086740017, \"time-step\": 2962}, {\"errors\": 0.015239915810525417, \"time-step\": 2963}, {\"errors\": 0.015213346108794212, \"time-step\": 2964}, {\"errors\": 0.015186816453933716, \"time-step\": 2965}, {\"errors\": 0.015160365030169487, \"time-step\": 2966}, {\"errors\": 0.01513397041708231, \"time-step\": 2967}, {\"errors\": 0.015107627958059311, \"time-step\": 2968}, {\"errors\": 0.015081359073519707, \"time-step\": 2969}, {\"errors\": 0.015055134892463684, \"time-step\": 2970}, {\"errors\": 0.015028983354568481, \"time-step\": 2971}, {\"errors\": 0.015002870932221413, \"time-step\": 2972}, {\"errors\": 0.01497683860361576, \"time-step\": 2973}, {\"errors\": 0.01495085097849369, \"time-step\": 2974}, {\"errors\": 0.01492492388933897, \"time-step\": 2975}, {\"errors\": 0.014899065718054771, \"time-step\": 2976}, {\"errors\": 0.014873253181576729, \"time-step\": 2977}, {\"errors\": 0.014847498387098312, \"time-step\": 2978}, {\"errors\": 0.014821816235780716, \"time-step\": 2979}, {\"errors\": 0.014796182513237, \"time-step\": 2980}, {\"errors\": 0.01477060280740261, \"time-step\": 2981}, {\"errors\": 0.014745088294148445, \"time-step\": 2982}, {\"errors\": 0.014719623140990734, \"time-step\": 2983}, {\"errors\": 0.01469422783702612, \"time-step\": 2984}, {\"errors\": 0.014668864198029041, \"time-step\": 2985}, {\"errors\": 0.014643581584095955, \"time-step\": 2986}, {\"errors\": 0.01461835578083992, \"time-step\": 2987}, {\"errors\": 0.014593180269002914, \"time-step\": 2988}, {\"errors\": 0.014568055048584938, \"time-step\": 2989}, {\"errors\": 0.014542992226779461, \"time-step\": 2990}, {\"errors\": 0.01451798528432846, \"time-step\": 2991}, {\"errors\": 0.014493027701973915, \"time-step\": 2992}, {\"errors\": 0.014468137174844742, \"time-step\": 2993}, {\"errors\": 0.014443294145166874, \"time-step\": 2994}, {\"errors\": 0.014418494887650013, \"time-step\": 2995}, {\"errors\": 0.014393781311810017, \"time-step\": 2996}, {\"errors\": 0.014369109645485878, \"time-step\": 2997}, {\"errors\": 0.014344487339258194, \"time-step\": 2998}, {\"errors\": 0.014319928362965584, \"time-step\": 2999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = history.history['loss']\n",
    "\n",
    "df2 = pd.DataFrame({\"errors\":errors, \"time-step\": np.arange(0, len(errors))})\n",
    "\n",
    "alt.Chart(df2).mark_line().encode(x=\"time-step\", y=\"errors\").properties(title='Chart 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the error curve for our own implementation (**Chart 2**) and the Keras version is the speed at which the error declines. This is mostly accounted for the selection of the Adam optimizer instead of \"plain\" backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X).round()\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we reached 100% of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer perceptrons (and multilayer neural networks more) generally have many limitations worth mentioning. I will focus on a few that are more evident at this point and I'll introduce more complex issues in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and more obvious limitation of the multilayer perceptron is **training time**. It takes an awful lot of iterations for the algorithm to learn to solve a very simple logic problem like the XOR. **This is not an exception but the norm**. Most neural networks you'd encounter in the wild nowadays need from hundreds up to thousands of iterations to reach their top-level accuracy. This has been a common point of criticism, particularly because human learning seems to be way more sample efficient. \n",
    "\n",
    "There are multiple answers to the training time problem. A first argument has to do with raw **processing capacity**. It is seemingly obvious that a neural network with 1 hidden layer and 3 units does not get even close to the massive computational capacity of the human brain. Even if you consider a small subsection of the brain, and design a very large neural network with dozens of layers and units, the brain still has the advantage in most cases. Of course, this alone probably does not account for the entire gap between humans and neural networks but is a point to consider. A second argument refers to the massive **past training experience** accumulated by humans. Neural networks start from scratch every single time. Humans do not reset their storage memories and skills before attempting to learn something new. On the contrary, humans learn and reuse past learning experience across domains continuously. A third argument is related to the **richness of the training data** experienced by humans. Humans not only rely on past learning experiences but also on more *complex and multidimensional training data*. Humans integrate signals from all senses (visual, auditory, tactile, etc.) when learning which most likely speeds up the process. In any case, this is still a major issue and a hot topic of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptrons are \"fragile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second notorious limitation is how **brittle** multilayer perceptrons are to **architectural decisions**. An extra layer, a +0.001 in the learning rate, random uniform weight instead for random normal weights, and or even a different random seed can turn perfectly a functional neural network into a useless one. This is partially related to the fact we are trying to solve a nonconvex optimization problem. Gradient descent has no way to find the actual global minima in the error surface. You just can hope it will find a good enough local minima for your problem. All of this force neural network researchers to **search over enormous combinatorial spaces of \"hyperparameters\"** (i.e., like the learning rate, number layers, etc. Anything but the network weights and biases). In a way, you have to embrace the fact that perfect solutions are rarely found unless you are dealing with simple problems with known solutions like the XOR. Surprisingly, it is often the case that well designed neural networks are able to learn \"good enough\" solutions for a wide variety of problems. Creating more robust neural networks architectures is another present challenge and hot research topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The biological plasubility of backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last issue I'll mention is the elephant in the room: **it is not clear that the brain learns via backpropagation**. Rumelhart, Hinton, and Williams presented no evidence in favor of this assumption. You may think that it does not matter because neural networks do not pretend to be exact replicas of the brain anyways. Yet, it is a highly critical issue coming from the perspective of creating \"biologically plausible\" models of cognition, which is the PDP group perspective. Remember that one of the main problems for Rumelhart was to find a learning mechanism for networks with non-linear units. If the learning mechanism is not plausible, Does the model have any credibility at all? Fortunately, in the last 35 years we have learned quite a lot about the brain, and [several researchers have proposed how the brain could implement \"something like\" backpropagation](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30012-9). Still, keep in mind that this is a highly debated topic and it may pass some time before we reach a resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of multilayer perceptrons trained with backpropagation was a major breakthrough in cognitive science and artificial intelligence in the '80s. It brought back to life a line of research that many thought dead for a while. The key for its success was its ability to overcome one of the major criticism from the previous decade: **its inability to solve problems that required non-linear solutions**. \n",
    "\n",
    "From a cognitive science perspective, the real question is whether such advance says something meaningful about the **plausibility of neural networks as models of cognition**. That is a tough question. If you are in the \"neural network team\" of course you'd think it does. If you are more skeptic you'd rapidly point out to the many weaknesses and unrealistic assumptions on which neural networks depend on.\n",
    "\n",
    "Maybe the best way of thinking about this type of advances in neural networks models of cognition is as another piece of a very complicated puzzle. The \"puzzle\" here is a **working hypothesis**: you are committed to the idea that the puzzle of cognition looks like a neural network when assembled, and your mission is to figure out all the pieces and putting them together. You may be wrong, maybe the puzzle at the end looks like something different, and you'll be proven wrong. Yet, at least in this sense, multilayer perceptrons were a crucial step forward in the neural network research agenda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Feedforward Networks. In Deep Learning. MIT Press. https://www.deeplearningbook.org/contents/mlp.html\n",
    "\n",
    "Kelley, H. J. (1960). Gradient theory of optimal flight paths. Ars Journal, 30(10), 947954.\n",
    "\n",
    "Bryson, A. E. (1961). A gradient method for optimizing multi-stage allocation processes. Proc. Harvard Univ. Symposium on Digital Computers and Their Applications, 72.\n",
    "\n",
    "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning Internal Representations by Error Propagation. In Parallel Distributed Processing: Explorations in the Microestructure of Cognition (Vol. 1). MIT Press.\n",
    "\n",
    "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533536.\n",
    "\n",
    "Werbos, P. J. (1994). The roots of backpropagation: From ordered derivatives to neural networks and political forecasting (Vol. 1). John Wiley & Sons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful on-line resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internet is flooded with learning resourced about neural networks. Here a selection of my personal favorites for this topic:\n",
    "\n",
    "- [3Blue1Brown: Neural Networks Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "- [Welch Labs: Neural Networks Demystified](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU)\n",
    "- [Michael Nielsen's Neural Networks and Deep Learning Book: How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
